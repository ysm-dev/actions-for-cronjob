<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://jeongukjae.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jeongukjae.github.io/" rel="alternate" type="text/html" /><updated>2019-05-08T12:23:17+00:00</updated><id>https://jeongukjae.github.io/feed.xml</id><title type="html">Blog</title><subtitle>ê°œë°œ ê´€ë ¨ ê¸°ë¡/ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤.</subtitle><entry><title type="html">ğŸƒ Mongo DB Sharding</title><link href="https://jeongukjae.github.io/posts/mongodb-sharding/" rel="alternate" type="text/html" title="ğŸƒ Mongo DB Sharding" /><published>2019-04-22T00:00:00+00:00</published><updated>2019-04-22T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/mongodb%20sharding</id><content type="html" xml:base="https://jeongukjae.github.io/posts/mongodb-sharding/">&lt;p&gt;ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ì–¸ì œê¹Œì§€ë‚˜ ì¸ìŠ¤í„´ìŠ¤ í•˜ë‚˜ë§Œì„ ì‚¬ìš©í•  ìˆ˜ëŠ” ì—†ë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì— ë§ì€ ë¶€í•˜ê°€ ëª°ë¦°ë‹¤ë©´, ë‹¤ë¥¸ ëŒ€ì±…ì´ í•„ìš”í•˜ë‹¤. ë‘ ê°€ì§€ ë°©ë²•ì´ ì¡´ì¬í•˜ëŠ”ë°, Vertical Scalingê³¼ Horizontal Scalingì´ë‹¤. Vertical Scalingì€ í•˜ë‚˜ì˜ ë¨¸ì‹ ì— ë” ë§ì€ RAMê³¼ ë” ë§ì€ ì½”ì–´ ë“±ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì´ë‹¤. Horizontal Scalingì€ ì—¬ëŸ¬ ëŒ€ì˜ ë¨¸ì‹ ì„ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì„±í•˜ë©´ì„œ horizontal scalingì„ í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ì€ replicaë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì´ë‹¤. mysqlì˜ ê²½ìš°ëŠ” read replicaë¥¼ ì—¬ëŸ¬ëŒ€ ìƒì„±í•˜ì—¬ writeëŠ” masterì—ì„œ ì‹¤í–‰í•˜ê³  read ì‘ì—…ì€ replicatedëœ ë…¸ë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ë¶€í•˜ë¥¼ ë¶„ì‚°ì‹œí‚¨ë‹¤.&lt;/p&gt;

&lt;p&gt;mongodbë„ ê·¸ëŸ¬í•œ ê°œë…ì˜ ê¸°ëŠ¥ì„ ì§€ì›í•˜ëŠ”ë°, shardingì´ë‹¤. &lt;a href=&quot;https://docs.mongodb.com/manual/sharding/&quot;&gt;mongodbì˜ ë¬¸ì„œ&lt;/a&gt;ì—ì„œëŠ” ì•„ë˜ì²˜ëŸ¼ ì„¤ëª…í•œë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sharding is a method for distributing data across multiple machines. MongoDB uses sharding to support deployments with very large data sets and high throughput operations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ì‹œìŠ¤í…œì´ ë” ì´ìƒ ë¶€í•˜ë¥¼ ê²¬ë””ì§€ ëª»í•  ë•Œ, shardingì„ í†µí•´ ê°€ìš©ì„±ì„ ëŠ˜ë ¤ì£¼ê³ , ë²„í‹¸ ìˆ˜ ìˆëŠ” throughputë„ ëŠ˜ë ¤ì£¼ëŠ” ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;sharded-cluster&quot;&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/reference/glossary/#term-sharded-cluster&quot;&gt;Sharded Cluster&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;mongodbì˜ sharded clusterëŠ” 3ê°€ì§€ componentë¡œ êµ¬ì„±ëœë‹¤. shard, mongosì™€ config serverì´ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;shard&quot;&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/core/sharded-cluster-shards/&quot;&gt;Shard&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;shardëŠ” sharded clusterì•ˆì—ì„œ sharded dataì˜ subsetì„ ê°€ì§„ë‹¤. clusterì˜ shardë“¤ì— ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë¥¼ í•©í•˜ë©´ ì›ë³¸ì˜ ë°ì´í„°ê°€ ëœë‹¤. ê·¸ë˜ì„œ í•˜ë‚˜ì˜ shardì— ëŒ€í•´ì„œ queryë¥¼ ì‹¤í–‰í•˜ë©´, í•´ë‹¹ shardì•ˆì˜ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¨ë‹¤. cluster levelì—ì„œ queryë¥¼ ì‹¤í–‰í•˜ê³  ì‹¶ë‹¤ë©´, mongosë¥¼ ì‚¬ìš©í•˜ì.&lt;/p&gt;

&lt;p&gt;shardëŠ” ê³ ê°€ìš©ì„±ì„ ìœ„í•´ ë°˜ë“œì‹œ &lt;a href=&quot;https://docs.mongodb.com/manual/reference/glossary/#term-replica-set&quot;&gt;replica set&lt;/a&gt;ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•œë‹¤.&lt;/p&gt;

&lt;p&gt;í•˜ë‚˜ì˜ ë°ì´í„°ë² ì´ìŠ¤ ì•ˆì—ì„œ primary shardëŠ” ë°˜ë“œì‹œ ì¡´ì¬í•œë‹¤. primary shardëŠ” shardë˜ì§€ ì•Šì€ ëª¨ë“  collectionë“¤ì„ ì €ì¥í•œë‹¤. ë‹¤ë§Œ, ì´ë¦„ì—ì„œ í˜¼ë™ì´ ì˜¬ ìˆ˜ ìˆëŠ”ë°, primary shardëŠ” replica setì˜ primaryì™€ ê´€ê³„ê°€ ì—†ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;mongos&quot;&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/core/sharded-cluster-query-router/&quot;&gt;mongos&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;mongodbëŠ” ê°ê°ì˜ shardì— ëŒ€í•´ queryë¥¼ ë¶„ì‚°ì‹œí‚¤ê¸° ìœ„í•´ mongosë¼ëŠ” instanceë¥¼ ì œê³µí•œë‹¤. mongosì— ëŒ€í•œ ì—­í• ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ì²˜ëŸ¼ mongodb ë¬¸ì„œê°€ ì„¤ëª…í•œë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mongos&lt;/code&gt; provide the only interface to a sharded cluster from the perspective of applications. Applications never connect or communicate directly with the shards.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ì ì ˆí•œ shardë¡œ routeí•˜ê¸° ìœ„í•´ì„œ config serverë¡œë¶€í„° metadataë¥¼ ìºì‹±í•´ë‘ê³  ìˆë‹¤. í•˜ì§€ë§Œ, persistent stateëŠ” ì—†ë‹¤.&lt;/p&gt;

&lt;p&gt;queryë¥¼ routingí•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œëŠ” ë¬¸ì„œë¥¼ ì°¸ê³ í•´ë³´ì.&lt;/p&gt;

&lt;h3 id=&quot;config-server&quot;&gt;&lt;a href=&quot;https://docs.mongodb.com/manual/core/sharded-cluster-config-servers/&quot;&gt;config server&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;config serverëŠ” sharded clusterì— ëŒ€í•œ metadataë¥¼ ì €ì¥í•˜ëŠ” ì„œë²„ì´ë‹¤. ëª¨ë“  shardì— ëŒ€í•´ ì–´ë–¤ chunkë¥¼ ë“¤ê³ ìˆëŠ”ì§€ì˜ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë°, í•´ë‹¹ metadataë¥¼ mongosì—ì„œ í™œìš©í•˜ì—¬ queryë¥¼ routeí•œë‹¤.&lt;/p&gt;

&lt;p&gt;ë˜í•œ ì¶”ê°€ì ìœ¼ë¡œ mongodbê°€ distributed lockì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ config serverë¥¼ ì‚¬ìš©í•œë‹¤ê³  í•˜ëŠ”ë°, ì´ëŠ” ì˜ ëª¨ë¥´ê² ë‹¤..&lt;/p&gt;

&lt;p&gt;config serverì— ëŒ€í•´ì„œë„ replica setì„ êµ¬ì„±í•´ì•¼ í• í…ë°, ì´ëŠ” ë‚˜ì¤‘ì— ì•Œì•„ë³´ì.&lt;/p&gt;

&lt;h3 id=&quot;ë³´ì•ˆ&quot;&gt;ë³´ì•ˆ&lt;/h3&gt;

&lt;p&gt;sharded clusterëŠ” ë³´ì•ˆì„ ìœ„í•´ì„œ &lt;a href=&quot;https://docs.mongodb.com/manual/core/security-internal-authentication/&quot;&gt;internal authentication&lt;/a&gt;ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. mongodì— ê°ê° ë³´ì•ˆ ì„¤ì •ì„ ë„£ì–´ì£¼ì–´ì•¼ í•˜ëŠ” ì ì„ ìŠì§€ ë§ì. ì‹¤ì œë¡œ êµ¬ì„±í•˜ê¸° ìœ„í•´ì„œëŠ” &lt;a href=&quot;https://docs.mongodb.com/manual/tutorial/deploy-sharded-cluster-with-keyfile-access-control/&quot;&gt;Deploy Sharded Clsuter wit Keyfile Access Control&lt;/a&gt;ì„ ì°¸ê³ í•˜ì.&lt;/p&gt;

&lt;h2 id=&quot;ì´ë¥¼-í†µí•´-ì–»ëŠ”-ì¥ì ë“¤&quot;&gt;ì´ë¥¼ í†µí•´ ì–»ëŠ” ì¥ì ë“¤&lt;/h2&gt;

&lt;p&gt;Read Writeê°€ ë¶„ì‚°ë˜ì–´ ì˜ ì‹¤í–‰ë˜ëŠ” ê²ƒê³¼ ì €ì¥ì†Œë¥¼ í™•ì¥í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ë‹¹ì—°í•˜ê³ , ì œì¼ ê¶ê¸ˆí•œ ê²ƒì€ â€œê³ ê°€ìš©ì„±ì´ ë³´ì¥ë˜ëŠ”ê°€?â€ì´ë‹¤. ê·¸ì— ëŒ€í•´ ë¬¸ì„œì— ì„¤ëª…ë˜ì–´ ìˆëŠ”ë°, ì•„ë˜ì²˜ëŸ¼ ì í˜€ìˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A sharded cluster can continue to perform partial read / write operations even if one or more shards are unavailable. While the subset of data on the unavailable shards cannot be accessed during the downtime, reads or writes directed at the available shards can still succeed.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;í•˜ë‚˜ì˜ shardë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ ë•Œ, ë‹¤ë¥¸ shardì— ëŒ€í•´ì„œ ì—¬ì „íˆ queryë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ì‹¤ì œë¡œ-êµ¬ì„±í•´ë³´ê¸°&quot;&gt;ì‹¤ì œë¡œ êµ¬ì„±í•´ë³´ê¸°&lt;/h2&gt;

&lt;p&gt;ê¹”ë”í•˜ê²Œ êµ¬ì„±ì„ í•´ë³´ê¸° ìœ„í•´ dockerë¥¼ í†µí•´ì„œ êµ¬ì„±í•´ë³´ê² ë‹¤. ì¼ë‹¨ container ì‚¬ì´ë¥¼ ì´ì–´ì£¼ê¸° ìœ„í•´ networkë¶€í„° ë§Œë“¤ì–´ì£¼ê³ , docker imageë¶€í„° ë°›ì•„ì£¼ì.&lt;/p&gt;

&lt;div class=&quot;language-zsh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;â¯ docker pull mongo
Using default tag: latest
latest: Pulling from library/mongo
...

~
â¯ docker network create mongo
0836403418d33db29b701e6911f641048d0a880720c88a6de4d3a9f3c4376bc5

~
â¯ docker network &lt;span class=&quot;nb&quot;&gt;ls
&lt;/span&gt;NETWORK ID          NAME                                DRIVER              SCOPE
...
...
0836403418d3        mongo                               bridge              &lt;span class=&quot;nb&quot;&gt;local&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ê·¸ë¦¬ê³ , containerë¥¼ &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo1&lt;/code&gt; ~ &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo7&lt;/code&gt;ê¹Œì§€ ì¼œì£¼ì.&lt;/p&gt;

&lt;div class=&quot;language-zsh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;â¯ docker run &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;mongo &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;mongo1 mongo bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;config-server-êµ¬ì„±í•˜ê¸°&quot;&gt;config server êµ¬ì„±í•˜ê¸°&lt;/h3&gt;

&lt;p&gt;ìš°ì„ , &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo1&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo2&lt;/code&gt;ì—ì„œ config serverë¶€í„° í‚¨ë‹¤. replica setìœ¼ë¡œ êµ¬ì„±í•  ì˜ˆì •ì´ë‹ˆ &lt;code class=&quot;highlighter-rouge&quot;&gt;replSet&lt;/code&gt; ì˜µì…˜ì„ ì§€ì •í•´ì¤€ë‹¤. ë‹¤ë¥¸ containerì—ì„œ ì ‘ì†í•  ì˜ˆì •ì´ë‹ˆ &lt;code class=&quot;highlighter-rouge&quot;&gt;--bind_ip 0.0.0.0&lt;/code&gt;ì„ ì„¤ì •í•´ì¤€ë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@bd14e1c615b0:/# mongod &lt;span class=&quot;nt&quot;&gt;--configsvr&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--replSet&lt;/span&gt; config-replica-set &lt;span class=&quot;nt&quot;&gt;--bind_ip&lt;/span&gt; 0.0.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ìœ„ì—ì„œ ì„¤ì •í•œ &lt;code class=&quot;highlighter-rouge&quot;&gt;replSet&lt;/code&gt;ì˜ ì´ë¦„ëŒ€ë¡œ replicasetì„ ì„¤ì •í•´ì¤€ë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@8b69f35de3b5:/# mongo mongo1:27019
...
...
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; rs.initiate&lt;span class=&quot;o&quot;&gt;({&lt;/span&gt;
... _id: &lt;span class=&quot;s2&quot;&gt;&quot;config-replica-set&quot;&lt;/span&gt;,
... configsvr: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
... members: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
...   &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;_id: 0, host: &lt;span class=&quot;s2&quot;&gt;&quot;mongo1:27019&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
...   &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;_id: 1, host: &lt;span class=&quot;s2&quot;&gt;&quot;mongo2:27019&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
... &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
... &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ì œëŒ€ë¡œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ëŠ” &lt;code class=&quot;highlighter-rouge&quot;&gt;rs.status()&lt;/code&gt;ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;shard-êµ¬ì„±í•˜ê¸°&quot;&gt;shard êµ¬ì„±í•˜ê¸°&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mongo3&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo4&lt;/code&gt;ì—ì„œ shard serverë¥¼ ì„¤ì •í•´ì¤€ë‹¤. replica setìœ¼ë¡œ &lt;code class=&quot;highlighter-rouge&quot;&gt;shard-replica-set&lt;/code&gt;ì„ ì„¤ì •í•´ì¤€ë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@8b69f35de3b5:/# mongod &lt;span class=&quot;nt&quot;&gt;--shardsvr&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--replSet&lt;/span&gt; shard-replica-set &lt;span class=&quot;nt&quot;&gt;--bind_ip&lt;/span&gt; 0.0.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;replicat setë„ ì„¤ì •í•´ì£¼ì&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@7d536b10b886:/# mongo mongo3:27018
...
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; rs.initiate&lt;span class=&quot;o&quot;&gt;({&lt;/span&gt;
... _id: &lt;span class=&quot;s2&quot;&gt;&quot;shard-replica-set&quot;&lt;/span&gt;,
... members: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
...   &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;_id: 0, host: &lt;span class=&quot;s2&quot;&gt;&quot;mongo3:27018&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
...   &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;_id: 1, host: &lt;span class=&quot;s2&quot;&gt;&quot;mongo4:27018&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
... &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
... &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;mongos-êµ¬ì„±í•˜ê¸°&quot;&gt;mongos êµ¬ì„±í•˜ê¸°&lt;/h3&gt;

&lt;p&gt;mongosì—ì„œëŠ” ì‹œì‘í•˜ë©´ì„œ config serverë¥¼ ë°”ë¡œ ì—°ê²°í•´ì¤€ë‹¤. &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo5&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo6&lt;/code&gt;ì—ì„œ &lt;code class=&quot;highlighter-rouge&quot;&gt;mongos&lt;/code&gt;ë¥¼ ì¼œì£¼ì.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@7d536b10b886:/# mongos &lt;span class=&quot;nt&quot;&gt;--configdb&lt;/span&gt; config-replica-set/mongo1:27019,mongo2:27019 &lt;span class=&quot;nt&quot;&gt;--bind_ip&lt;/span&gt; 0.0.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;config serverë¥¼ ì—°ê²°í–ˆìœ¼ë‹ˆ &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo7&lt;/code&gt;ì—ì„œ &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo5&lt;/code&gt;ì— ì ‘ì†í•´ì„œ ì•„ë˜ì²˜ëŸ¼ ì ì–´ì¤€ë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@a5cadafbc76f:/# mongo mongo5:27017
mongos&amp;gt; sh.addShard&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;shard-replica-set/mongo3:27018,mongo4:27018&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s2&quot;&gt;&quot;shardAdded&quot;&lt;/span&gt; : &lt;span class=&quot;s2&quot;&gt;&quot;shard-replica-set&quot;&lt;/span&gt;,
  &lt;span class=&quot;s2&quot;&gt;&quot;ok&quot;&lt;/span&gt; : 1,
  &lt;span class=&quot;s2&quot;&gt;&quot;operationTime&quot;&lt;/span&gt; : Timestamp&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1555859895, 5&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,
  &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$clusterTime&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; : &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;clusterTime&quot;&lt;/span&gt; : Timestamp&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1555859895, 5&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,
    &lt;span class=&quot;s2&quot;&gt;&quot;signature&quot;&lt;/span&gt; : &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;hash&quot;&lt;/span&gt; : BinData&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0,&lt;span class=&quot;s2&quot;&gt;&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;keyId&quot;&lt;/span&gt; : NumberLong&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;shardê°€ ì œëŒ€ë¡œ ë˜ì—ˆë‚˜ í™•ì¸í•´ë³´ì&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mongos&amp;gt; db.stats&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s2&quot;&gt;&quot;raw&quot;&lt;/span&gt; : &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;shard-replica-set/mongo3:27018,mongo4:27018&quot;&lt;/span&gt; : &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;db&quot;&lt;/span&gt; : &lt;span class=&quot;s2&quot;&gt;&quot;test&quot;&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;collections&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;views&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;objects&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;avgObjSize&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;dataSize&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;storageSize&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;numExtents&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;indexes&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;indexSize&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;fileSize&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;fsUsedSize&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;fsTotalSize&quot;&lt;/span&gt; : 0,
      &lt;span class=&quot;s2&quot;&gt;&quot;ok&quot;&lt;/span&gt; : 1
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
  &lt;span class=&quot;s2&quot;&gt;&quot;objects&quot;&lt;/span&gt; : 0,
  ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;replica setì— ì œëŒ€ë¡œ ë“¤ì–´ìˆë‹¤!! &lt;code class=&quot;highlighter-rouge&quot;&gt;mongo6&lt;/code&gt;ì—ì„œë„ ì ‘ì†í•´ì„œ ë³´ë‹ˆ ì˜ ëœë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ë&quot;&gt;ë&lt;/h2&gt;

&lt;p&gt;ì •ë§ ê°„ë‹¨í•˜ê²Œ êµ¬ì„±í•´ë³´ê³  ì•Œì•„ë³¸ ê²ƒì´ë‹¤. ì‹¤ì œë¡œ ì‚¬ìš©í•´ë³´ê³ ì í•œë‹¤ë©´ ë” êµ¬ì„±í•´ì•¼í•  ë¶€ë¶„ì´ ë§ë‹¤. ë³´ì•ˆê°™ì€ ë¶€ë¶„ì—ì„œ ì¢€ ë” ì—„ê²©í•˜ê²Œ ì„¤ì •í•´ì•¼ í•  ë“¯ ì‹¶ë‹¤.&lt;/p&gt;</content><author><name></name></author><category term="db" /><summary type="html">ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ì–¸ì œê¹Œì§€ë‚˜ ì¸ìŠ¤í„´ìŠ¤ í•˜ë‚˜ë§Œì„ ì‚¬ìš©í•  ìˆ˜ëŠ” ì—†ë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì— ë§ì€ ë¶€í•˜ê°€ ëª°ë¦°ë‹¤ë©´, ë‹¤ë¥¸ ëŒ€ì±…ì´ í•„ìš”í•˜ë‹¤. ë‘ ê°€ì§€ ë°©ë²•ì´ ì¡´ì¬í•˜ëŠ”ë°, Vertical Scalingê³¼ Horizontal Scalingì´ë‹¤. Vertical Scalingì€ í•˜ë‚˜ì˜ ë¨¸ì‹ ì— ë” ë§ì€ RAMê³¼ ë” ë§ì€ ì½”ì–´ ë“±ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì´ë‹¤. Horizontal Scalingì€ ì—¬ëŸ¬ ëŒ€ì˜ ë¨¸ì‹ ì„ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì´ë‹¤.</summary></entry><entry><title type="html">ğŸ“• CS224n Lecture 6 Language Models and RNNs</title><link href="https://jeongukjae.github.io/posts/cs224n-lecture-6-language-model-and-rnn/" rel="alternate" type="text/html" title="ğŸ“• CS224n Lecture 6 Language Models and RNNs" /><published>2019-04-21T00:00:00+00:00</published><updated>2019-04-21T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/cs224n%20lecture%206%20language%20model%20and%20rnn</id><content type="html" xml:base="https://jeongukjae.github.io/posts/cs224n-lecture-6-language-model-and-rnn/">&lt;p&gt;CS224n ì—¬ì„¯ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!&lt;/p&gt;

&lt;h2 id=&quot;language-modeling&quot;&gt;Language Modeling&lt;/h2&gt;

&lt;p&gt;Language Modelingì´ë€ ì´í›„ì— ì–´ë–¤ ë‹¨ì–´ê°€ ë‚˜ì˜¬ì§€ ì˜ˆì¸¡í•˜ëŠ” íƒœìŠ¤í¬ì´ë‹¤. ì¡°ê¸ˆ ë” ì •í™•í•˜ê²Œ ë§í•˜ìë©´, &lt;script type=&quot;math/tex&quot;&gt;x^{(1)}, ..., x^{(t)}&lt;/script&gt;ì˜ ë‹¨ì–´ê°€ ì£¼ì–´ì§€ë©´, ë‹¤ìŒ ë‹¨ì–´ &lt;script type=&quot;math/tex&quot;&gt;x^{(t+1)}&lt;/script&gt;ì˜ í™•ë¥  ë¶„í¬ë¥¼ ì˜ˆì¸¡í•˜ëŠ” íƒœìŠ¤í¬ì´ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;n-gram-language-model&quot;&gt;n-gram language model&lt;/h3&gt;

&lt;p&gt;n-gramì´ë€? a chunk of n consecutive words&lt;/p&gt;

&lt;p&gt;ngram language modelì´ë€? collect statistics about how frequent different ngrams are, and use these to predict next word.&lt;/p&gt;

&lt;p&gt;ì´ê²Œ ë¬´ìŠ¨ ë§ì´ëƒë©´, ì•„ë˜ê°™ì€ ì‹ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤ëŠ” ë§ì´ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}P(x^{t+1}|x^t, ... , x ^{t-n+2}) &amp;= \frac {P(x^{t+1}, .., x^{t-n+2})} {P(x^t,...,x^{t-n+2})}\\
&amp; \approx \frac {count(x^{t+1}, .., x^{t-n+2})} {count(x^{t}, .., x^{t-n+2})}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;ê·¼ë° ì—¬ê¸°ì„œ ë¬¸ì œì ì´ ëª‡ê°€ì§€ ìˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nê°œì˜ ë‹¨ì–´ ë°–ì— ìˆëŠ” ë‹¨ì–´ë“¤ì„ ê³ ë ¤í•˜ì§€ ëª»í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;sparsity problem
    &lt;ul&gt;
      &lt;li&gt;ê°¯ìˆ˜ê°€ 0ê°œë©´..?&lt;/li&gt;
      &lt;li&gt;denominatorë„ 0ì´ë©´? -&amp;gt; Nì„ 1 ì¤„ì—¬ì„œ ë‹¤ì‹œ ì ìš©í•œë‹¤.&lt;/li&gt;
      &lt;li&gt;ë‚˜íƒ€ë‚˜ê¸´ ë‚˜íƒ€ë‚˜ì§€ë§Œ, ë„ˆë¬´ ì¡°ê¸ˆ ë‚˜íƒ€ë‚˜ì„œ, ì ì ˆí•˜ë‹¤ê³  íŒë‹¨ì´ ë¶ˆê°€ëŠ¥í• ë•Œ&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;storage problem
    &lt;ul&gt;
      &lt;li&gt;corpus ì•ˆì˜ ëª¨ë“  ê°¯ìˆ˜ë¥¼ ë³´ì¡´í•´ì•¼í•œë‹¤.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ê·¸ë˜ë„ ì´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ textë¥¼ ë§Œë“¤ì–´ë³´ë©´ ìƒê°ë³´ë‹¤ grammaticalí•˜ë‹¤. ê·¼ë°, incoherentí•˜ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;neural-network-language-model&quot;&gt;Neural Network Language Model&lt;/h3&gt;

&lt;p&gt;fixed window neural networkë¥¼ ì‚¬ìš©í•´ì•¼í•˜ë‚˜?? -&amp;gt; ì˜ˆì¸¡í•  ë‹¨ì–´ì˜ Nê°œì˜ ë‹¨ì–´ë¥¼ ë“¤ê³ ì™€ì„œ ì„ë² ë”© í•œ í›„ ëª¨ë¸ì— ë„£ì–´ì„œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤??&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sparsity problemì´ ì—†ë‹¤.&lt;/li&gt;
  &lt;li&gt;ëª¨ë“  ê°¯ìˆ˜ë¥¼ ë³´ì¡´í•  í•„ìš”ê°€ ì—†ë‹¤.&lt;/li&gt;
  &lt;li&gt;fixed windowê°€ ì‘ë‹¤ë©´?
    &lt;ul&gt;
      &lt;li&gt;large windowë¥¼ ì“´ë‹¤ë©´ ì–´ë–¤ê°€? -&amp;gt; weight matrixê°€ ë„ˆë¬´ ì»¤ì§„ë‹¤.&lt;/li&gt;
      &lt;li&gt;ê·¸ë˜ì„œ ì‘ê²Œ ìœ ì§€í•œë‹¤ë©´? -&amp;gt; ì˜ë¯¸ìˆëŠ” contextë¥¼ ìƒê²Œ ëœë‹¤.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;symmetryí•˜ì§€ ì•Šë‹¤.
    &lt;ul&gt;
      &lt;li&gt;ê°™ì€ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ìœ„ì¹˜ì— ë‚˜íƒ€ë‚œë‹¤ë©´, ë‹¤ë¥´ê²Œ ì²˜ë¦¬ëœë‹¤.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rnn&quot;&gt;RNN&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/6-1.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;ì´ í•œì¥ìœ¼ë¡œ ì„¤ëª…ì´ ëë‚˜ëŠ” ë“¯í•˜ë‹¤&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;core ideaê°€ ì¤‘ìš”í•˜ë‹¤!!&lt;/p&gt;

&lt;p&gt;ê·¸ëŸ¼ RNNì„ ì‚¬ìš©í–ˆì„ ë•Œ ì¤‘ìš”í•œ ì ë“¤ì€?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ì–´ë–¤ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ì´ë˜ ê³„ì‚° ê°€ëŠ¥í•˜ë‹¤&lt;/li&gt;
  &lt;li&gt;ê·¸ ì´ì „ì˜ ì •ë³´ë“¤ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ëª¨ë¸ ì‚¬ì´ì¦ˆê°€ ê³ ì •ë˜ì–´ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;symmetryí•˜ê²Œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ê·¼ë°,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ëŠë¦¬ë‹¤.&lt;/li&gt;
  &lt;li&gt;ê·¸ ì´ì „ì˜ ì •ë³´ë¥¼ í™œìš©í•˜ê¸°ëŠ” ì‚¬ì‹¤ìƒ í˜ë“¤ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;training-rnn&quot;&gt;Training RNN&lt;/h3&gt;

&lt;p&gt;í° corpusì•ˆì—ì„œ &lt;script type=&quot;math/tex&quot;&gt;\hat y&lt;/script&gt;ë¥¼ ê³„ì† ì—°ì‚°í•´ì„œ í›ˆë ¨í•œë‹¤. cross entropyë¥¼ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤. ê·¼ë° ì´ê²Œ ë„ˆë¬´ ì—°ì‚°ëŸ‰ì´ ë§ì•„ì„œ, SGDì²˜ëŸ¼ ë¯¸ë‹ˆ ë°°ì¹˜ê°™ì€ ê°œë…ì„ ì°¨ìš©í•˜ëŠ” ê²ƒ ê°™ë‹¤.&lt;/p&gt;

&lt;p&gt;ì–´ì°Œë˜ì—ˆë“  RNNì„ í†µí•´ ë§Œë“¤ì–´ë‚¸ í…ìŠ¤íŠ¸ëŠ” ìƒê°ë³´ë‹¤ ì˜ ë™ì‘í•˜ì§€ë§Œ, ê¸°ì–µí•˜ëŠ” ë¶€ë¶„ê³¼ ê´€ë ¨í•´ì„œëŠ” ì¢€ ëª¨ìë¼ë‹¤. ìì„¸í•œ ê²ƒì€ &lt;a href=&quot;https://medium.com/deep-writing/harry-potter-written-by-artificial-intelligence-8a9431803da6&quot;&gt;medium ê¸€&lt;/a&gt;ì„ ì°¸ê³ í•´ë³´ì.&lt;/p&gt;

&lt;h3 id=&quot;evaluating&quot;&gt;Evaluating&lt;/h3&gt;

&lt;p&gt;perplexityë¥¼ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•œë‹¤. ê°’ì€ ë‚®ì€ ê²ƒì´ ì¢‹ë‹¤.&lt;/p&gt;</content><author><name></name></author><category term="nlp" /><category term="cs224n" /><category term="machine learning" /><summary type="html">CS224n ì—¬ì„¯ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!</summary></entry><entry><title type="html">ğŸ“• CS224n Lecture 5 Dependency Parsing</title><link href="https://jeongukjae.github.io/posts/cs224n-lecture-5-dependency-parsing/" rel="alternate" type="text/html" title="ğŸ“• CS224n Lecture 5 Dependency Parsing" /><published>2019-04-20T00:00:00+00:00</published><updated>2019-04-20T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/cs224n%20lecture%205%20dependency%20parsing</id><content type="html" xml:base="https://jeongukjae.github.io/posts/cs224n-lecture-5-dependency-parsing/">&lt;p&gt;CS224n ë‹¤ì„¯ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸! Assignment 2ê°€ ëë‚¬ê³ , Assignment 3ê°€ ì‹œì‘ë˜ì—ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;syntactic-structure-consistuency-and-dependency&quot;&gt;Syntactic Structure: Consistuency and Dependency&lt;/h2&gt;

&lt;p&gt;linguistic structureì—ëŠ” ë‘ê°€ì§€ ê´€ì ì´ ìˆë‹¤.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Consistuency ( = phrase structure grammar = context-free grammars (CFGs))&lt;/li&gt;
  &lt;li&gt;Dependency&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;consistuency&quot;&gt;Consistuency&lt;/h3&gt;

&lt;p&gt;ì´ ë°©ë²•ì€ wordë¥¼ ëª¨ì•„ì„œ í•˜ë‚˜ì˜ phraseê°€ ë˜ê³ , phraseê°€ ëª¨ì—¬ bigger phraseê°€ ë˜ëŠ” ê²ƒì²˜ëŸ¼ ë‹¨ì–´ë“¤ì˜ êµ¬ì¡°ë¥¼ ë³¸ë‹¤. í’ˆì‚¬ë“±ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•œë‹¤.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/5-1.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;phrase structure&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;dependency&quot;&gt;Dependency&lt;/h3&gt;

&lt;p&gt;Dependency structureëŠ” ë‹¨ì–´ë“¤ì´ ì–´ë””ì— ì˜ì¡´ì ì¸ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì¡°ë¥¼ ë³¸ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ &lt;code class=&quot;highlighter-rouge&quot;&gt;Look in the large crate in the kitchen by the door&lt;/code&gt;ì—ì„œ crateëŠ” Lookì— ì˜ì¡´ì ì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ë‹¨ì–´ ìì²´ê°€ ì–´ëŠ ë¬¸ë§¥ì— ìˆëŠëƒì— ë”°ë¼ì„œ ë§¤ìš° ëª¨í˜¸í•´ì§ˆ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì •í™•í•˜ê²Œ í•´ì„í•˜ê¸° ìœ„í•´ì„œ ì´ëŸ¬í•œ êµ¬ì¡°ë¥¼ í•„ìš”ë¡œ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ &lt;code class=&quot;highlighter-rouge&quot;&gt;San Jose cops kill man with knife&lt;/code&gt;ëŠ” ê²½ì°°ì´ ì¹¼ë¡œ ë‚¨ìë¥¼ ì‚´í•´í•˜ì˜€ë‹¤ëŠ” ë§ì´ ë  ìˆ˜ë„, ì¹¼ì„ ë“  ë‚¨ìë¥¼ ì‚´í•´í•˜ì˜€ë‹¤ëŠ” ë§ì´ ë  ìˆ˜ë„ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì¶”ê°€ì ìœ¼ë¡œ ë” ì‚´í´ë³´ê³  ì‹¶ìœ¼ë©´ â€œErkan et al. EMNLP 07, Fundel et al. 2007, etc.â€ë¥¼ ì‚´í´ë³´ì&lt;/p&gt;

&lt;h2 id=&quot;dependency-grammar-and-treebanks&quot;&gt;Dependency Grammar and Treebanks&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/5-2.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;dependencies&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;dependencyëŠ” tree representationì„ ì´ìš©í•œë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;dependencyëŠ” binary asymmetric arrowë¡œ ë‚˜íƒ€ë‚¸ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ arrowë“¤ì€ ë³´í†µ typedì´ë©°, ë¬¸ë²•ì ì¸ ê´€ê³„ì´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ë³´í†µ fake ROOTë¥¼ ì¶”ê°€í•œë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì´ëŸ° dependency structureëŠ” ê¸°ì›ì „ 5ì„¸ê¸°ë¶€í„° ë‚´ë ¤ì˜¤ëŠ” ì•„ì´ë””ì–´ì´ê³ , Constituency/context-free grammarëŠ” ìƒë‹¹íˆ ìµœê·¼ì˜ 20ì„¸ê¸°ì¦ˆìŒë¶€í„° ì“°ì´ê¸° ì‹œì‘í•œ ë°©ë²•ì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ìµœê·¼ ì¤‘ìš”í•œ íˆ´ë¡œ ì‚¬ìš©ë˜ê³  ìˆëŠ” Treebankì— ëŒ€í•´ì„œëŠ” â€œUniversal Dependencies: http://universaldependencies.org/ ; cf. Marcus et al. 1993, The Penn Treebank, Computational Linguisticsâ€ë¥¼ ì°¸ê³ í•˜ì. Universal Dependenciesì— ë“¤ì–´ê°€ë³´ë©´, í•œêµ­ì–´ì— ëŒ€í•œ ë°ì´í„°ë„ ì¡´ì¬í•œë‹¤. &lt;a href=&quot;https://github.com/UniversalDependencies/UD_Korean-Kaist&quot;&gt;KAIST Korean Universal Dependency Treebank&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dependency Parsingì€ ëª‡ê°€ì§€ ì œí•œ/preferenceê°€ ì¡´ì¬í•œë‹¤. ì§€ê¸ˆì€ â€œfake ROOTë¥¼ ë¬´ì¡°ê±´ ì¶”ê°€í•´ì•¼í•œë‹¤!â€ â€œìˆœí™˜í•˜ê²Œ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤.â€ ë“±ì´ ìˆê³ , ë” ê³ ë ¤í•  ê²ƒìœ¼ë¡œ â€œnon-projectiveí•˜ê²Œ ë§Œë“ ë‹¤.â€ ì •ë„ê°€ ìˆë‹¤. ì—¬ê¸°ì„œ projectiveí•œ ê²ƒì€ ë¬¸ì¥ì˜ ë‹¨ì–´ë“¤ì´ ìˆœì°¨ì ìœ¼ë¡œ ë†“ì—¬ìˆì„ ë•Œ dependency arrowê°€ ë‹¤ë¥¸ arrowë¥¼ êµì°¨í•˜ì§€ ì•ŠëŠ” ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬íŠ¼ ë„˜ì–´ê°€ì„œ Dependency Parsingì˜ ë°©ë²•ë“¤ì€ ì•„ë˜ê°™ì€ ë°©ë²•ë“¤ì´ ìˆë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dynamic programming&lt;/li&gt;
  &lt;li&gt;Graph algorithms&lt;/li&gt;
  &lt;li&gt;Constraint Satisfaction&lt;/li&gt;
  &lt;li&gt;â€œTransition-based parsingâ€ or â€œdeterministic dependency parsingâ€
    &lt;ul&gt;
      &lt;li&gt;Greedyí•œ ë°©ë²•ê³¼ ml classifierì˜ ì¡°í•©(MaltParser, Nivre et al. 2008)ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;transition-based-dependency-parsing&quot;&gt;Transition-based dependency parsing&lt;/h2&gt;

&lt;p&gt;stack, buffer, dependency arcsë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/5-3.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;transition-based dependency parsing&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;neural-dependency-parsing&quot;&gt;Neural dependency parsing&lt;/h2&gt;

&lt;p&gt;ì™œ NN Parserë¥¼ ì“°ë‚˜ë©´, ì†ë„ê°€ ë„ˆë¬´ ì°¨ì´ê°€ ë‚œë‹¤. (Chen and Manning 2014ë¥¼ ì°¸ê³ í•´ë³´ì) MaltParserê°€ ì´ˆë‹¹ 469ê°œì˜ ë¬¸ì¥ì„ íŒŒì‹±í•˜ëŠ”ë°, NN ê¸°ë°˜ì˜ íŒŒì„œ(C &amp;amp; M 2014)ê°€ ì´ˆë‹¹ 654ê°œì˜ ë¬¸ì¥ì„ íŒŒì‹±í–ˆë‹¤.&lt;/p&gt;</content><author><name></name></author><category term="nlp" /><category term="cs224n" /><category term="machine learning" /><summary type="html">CS224n ë‹¤ì„¯ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸! Assignment 2ê°€ ëë‚¬ê³ , Assignment 3ê°€ ì‹œì‘ë˜ì—ˆë‹¤.</summary></entry><entry><title type="html">ğŸ“— Deep Learning Chapter 2 Linear Algebra</title><link href="https://jeongukjae.github.io/posts/Deep-Learning-Chapter-2-Linear-Algebra/" rel="alternate" type="text/html" title="ğŸ“— Deep Learning Chapter 2 Linear Algebra" /><published>2019-04-18T00:00:00+00:00</published><updated>2019-04-18T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/Deep%20Learning%20Chapter%202%20Linear%20Algebra</id><content type="html" xml:base="https://jeongukjae.github.io/posts/Deep-Learning-Chapter-2-Linear-Algebra/">&lt;p&gt;Ian Goodfellowì˜ &lt;a href=&quot;http://www.deeplearningbook.org&quot;&gt;Deep Learning&lt;/a&gt; ì±…ì„ ë³´ê¸° ì‹œì‘í–ˆë‹¤. í•´ë‹¹ ì±…ì— ëŒ€í•´ ì¶”ì²œì„ ë§ì´ ë°›ì•˜ê³ , ë§ˆì¹¨ ì¶œíŒì‚¬ ì´ë²¤íŠ¸ë¡œ ì°¸ê°€í•´ì„œ ë²ˆì—­ë³¸ë„ ìš´ ì¢‹ê²Œ ì§‘ì— ìˆì—ˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•œ ë¶€ë¶„ë§Œ ê³¨ë¼ì„œ ì •ë¦¬í•´ë³¸ë‹¤!&lt;/p&gt;

&lt;p&gt;ì±…ì€ í¬ê²Œ 3ê°œì˜ Partë¡œ ë‚˜ëˆ„ì–´ì§„ë‹¤. Part 1ì€ 4ê°œì˜ ì¥ìœ¼ë¡œ ë˜ì–´ ìˆê³ , Linear Algebra, Probability and Information Theory, Numerical Computation, Machine Learning Basics ìˆœì„œë¡œ ë˜ì–´ ìˆë‹¤. ê¸°ë³¸ ìˆ˜í•™ ì§€ì‹ê³¼ ML ê°œë…ë“¤ì„ ì„¤ëª…í•œë‹¤. ê·¸ë˜ì„œ í•´ë‹¹ ì¥ë¶€í„° ì •ë¦¬í•´ë³´ê¸°ë¡œ í–ˆë‹¤. ë¬¼ë¡  ì•„ëŠ” ë¶€ë¶„ì€ í‚¤ì›Œë“œë§Œ ì ì–´ë‘ê³  ë„˜ì–´ê°„ë‹¤.&lt;/p&gt;

&lt;p&gt;ì¼ë‹¨ ì„ í˜• ëŒ€ìˆ˜ì— ìµìˆ™í•˜ë©´ ì•ˆë´ë„ ë˜ëŠ” ì±•í„°ë¡œ ë³´ì´ì§€ë§Œ ìˆ˜ì—…ì—ì„œ ë“¤ì—ˆë˜ ë‚´ìš©ë“¤ì„ ê°„ë‹¨í•˜ê²Œ ë– ì˜¬ë¦´ ê²¸ ì½ì–´ë³´ê¸°ë¡œ í–ˆë‹¤. ì±…ì„ ì½ëŠ”ë° ì§€ì¥ ì—†ëŠ” ìˆ˜ì¤€ë§Œ ì„¤ëª…í•˜ê¸° ë•Œë¬¸ì— ë” ê³µë¶€í•˜ê³  ì‹¶ë‹¤ë©´, &lt;em&gt;The Matrix Cookbook&lt;/em&gt; (Petersen &amp;amp; Pedersen, 2006)ì´ë‚˜, Shilov 1997ì„ ì½ì–´ë³´ë¼ê³  í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;scalars-vectors-matrices-and-tensors&quot;&gt;Scalars, Vectors, Matrices, and Tensors&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Scalars&lt;/li&gt;
  &lt;li&gt;Vectors&lt;/li&gt;
  &lt;li&gt;Matrices&lt;/li&gt;
  &lt;li&gt;Tensors : an array of numbers arranged on a regular grid with a variable number of axes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;broadcasting&quot;&gt;broadcasting&lt;/h3&gt;

&lt;p&gt;ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ëœ ì—„ë°€í•œ ê°œë…ì„ ëª‡ëª‡ ì‚¬ìš©í•˜ëŠ”ë° ê·¸ ì¤‘ í•˜ë‚˜ê°€ broad castingì´ë‹¤. matrixì™€ vectorë¥¼ ë”í•´ì„œ ë‹¤ë¥¸ matrixê°€ ë‚˜ì˜¤ëŠ” ì—°ì‚°ì´ broadcastingì´ê³ , ì˜ˆë¥¼ ë“¤ì–´ &lt;script type=&quot;math/tex&quot;&gt;\textbf C = \textbf A  + \textbf b&lt;/script&gt;ë¥¼ &lt;script type=&quot;math/tex&quot;&gt;C_{i,j} = A_{i,j} + b_j&lt;/script&gt;ì²˜ëŸ¼ ì—°ì‚°í•˜ëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤. ì´ ì—°ì‚°ì€ &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;ë¥¼ êµ³ì´ ë³µì‚¬í•´ì„œ ìƒˆ matrixë¥¼ ë§Œë“¤ì§€ ì•Šì•„ë„ ë˜ê²Œ í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;multiplying-matrices-and-vectors&quot;&gt;Multiplying Matrices and Vectors&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;standard product : &lt;script type=&quot;math/tex&quot;&gt;\textbf C = \textbf A \textbf B&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Hadamard product (element-wise product) : &lt;script type=&quot;math/tex&quot;&gt;\textbf C = \textbf A \odot \textbf B&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-system-of-linear-equation&quot;&gt;a system of linear equation&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf A \textbf x = \textbf b&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\textbf A \in \mathbb R^{m \times n}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\textbf b \in \mathbb R^m&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\textbf x \in \mathbb R^n&lt;/script&gt; (&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is unknown vector)&lt;/p&gt;

&lt;h2 id=&quot;identity-and-inverse-matrices&quot;&gt;Identity and Inverse Matrices&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Identity matrices : &lt;script type=&quot;math/tex&quot;&gt;I_n \in \mathbb R^{n\times n}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Invese Matrix of &lt;script type=&quot;math/tex&quot;&gt;\textbf A&lt;/script&gt; : &lt;script type=&quot;math/tex&quot;&gt;\textbf A ^{-1}&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;linear-dependence-and-span&quot;&gt;Linear Dependence and Span&lt;/h2&gt;

&lt;p&gt;ìœ„ì—ì„œ ë‚˜ì˜¨ a system of linear equationì‹ì´ ì•„ë˜ì™€ ê°™ë‹¤.&lt;script type=&quot;math/tex&quot;&gt;\textbf A_{:,i}&lt;/script&gt;ëŠ” &lt;script type=&quot;math/tex&quot;&gt;\textbf A&lt;/script&gt;ì˜ &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;ë²ˆì§¸ column.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf A \textbf x = \sum_i x_i \textbf A_{:,i} = \textbf b&lt;/script&gt;

&lt;p&gt;ì¦‰, &lt;script type=&quot;math/tex&quot;&gt;\textbf A&lt;/script&gt;ì˜ columnë“¤ì˜ linear combinationìœ¼ë¡œ ë³´ëŠ” ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;p&gt;spanì€ ì£¼ì–´ì§„ ë²¡í„° ì§‘í•©ì—ì„œ linear combinationìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì ì˜ ì§‘í•©ì´ë‹¤. ë”°ë¼ì„œ &lt;script type=&quot;math/tex&quot;&gt;\textbf A \textbf x = \textbf b&lt;/script&gt;ì‹ì„ í–‰ë ¬ &lt;script type=&quot;math/tex&quot;&gt;\textbf A&lt;/script&gt;ì˜ columnë“¤ì˜ spanì— &lt;script type=&quot;math/tex&quot;&gt;\textbf b&lt;/script&gt;ê°€ ìˆëŠ”ì§€ì˜ ë¬¸ì œë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”ë°, ì´ ê²½ìš° í•´ë‹¹ spanì„ column spaceë¼ í•œë‹¤.&lt;/p&gt;

&lt;p&gt;linear independentëŠ” ì£¼ì–´ì§„ ë²¡í„° ì§‘í•©ì—ì„œ ì–´ëŠ í•œ ë²¡í„°ê°€ ë‹¤ë¥¸ ë²¡í„°ì˜ linear combinationìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤. linear dependentëŠ” ê·¸ ë°˜ëŒ€.&lt;/p&gt;

&lt;p&gt;square matrixì´ë©´ì„œ &lt;script type=&quot;math/tex&quot;&gt;\textbf A&lt;/script&gt;ì˜ columnë“¤ì´ linearly independentí•˜ë©´ singular matrixë¼ í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;norm&quot;&gt;Norm&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;L^p&lt;/script&gt; Norm
&lt;script type=&quot;math/tex&quot;&gt;||x||_p = (\sum_i |x_i|^p)^{\frac 1 p}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;L^2&lt;/script&gt; Norm = Euclidean norm&lt;/li&gt;
  &lt;li&gt;ê°€ë” nonzero elementì˜ ê°¯ìˆ˜ë¥¼ ì„¼ ê²ƒì„ &lt;script type=&quot;math/tex&quot;&gt;L^0&lt;/script&gt; normì´ë¼ í•˜ëŠ”ë°, ì´ê±´ ì˜ëª»ëœ ìš©ì–´. ê·¸ëƒ¥ &lt;script type=&quot;math/tex&quot;&gt;L^1&lt;/script&gt; normìœ¼ë¡œ ëŒ€ì²´í•˜ì.&lt;/li&gt;
  &lt;li&gt;max norm
&lt;script type=&quot;math/tex&quot;&gt;||x||_\infty = \max_i |x_i|&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;special-kinds-of-matrices-and-vectors&quot;&gt;Special Kinds of Matrices and Vectors&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;diagonal matrix: main diagonal ë¹¼ê³  ë‹¤ 0ì¸ í–‰ë ¬
    &lt;ul&gt;
      &lt;li&gt;multiplicationì´ ë§¤ìš° íš¨ìœ¨ì &lt;/li&gt;
      &lt;li&gt;invertingë„ ë§¤ìš° íš¨ìœ¨ì &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;symmetric matrix: &lt;script type=&quot;math/tex&quot;&gt;\textbf A = \textbf A ^\intercal&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;unit vector
&lt;script type=&quot;math/tex&quot;&gt;||x||_2 = 1&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;orthogonal vector: &lt;script type=&quot;math/tex&quot;&gt;\textbf x^\intercal \textbf y = 0&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;orthogonal matrix: &lt;script type=&quot;math/tex&quot;&gt;\textbf A^\intercal \textbf A = \textbf A \textbf A^\intercal = \textbf I&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;eigen-decomposition&quot;&gt;eigen decomposition&lt;/h2&gt;

&lt;p&gt;ì•„ë˜ëŠ” right eigen vectorë¥¼ êµ¬í•˜ëŠ” ì‹ì¸ë°, leftëŠ” êµ³ì´ ë³„ë¡œ ì•ˆì“´ë‹¤ê³  í•œë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf A \textbf v = \lambda \textbf v&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;eigen value: &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;eigen vector: &lt;script type=&quot;math/tex&quot;&gt;\textbf v&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;eigendecompositoin: &lt;script type=&quot;math/tex&quot;&gt;\textbf A = \textbf V diag (\lambda) \textbf V ^{-1}&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;ë³´í†µ eigen valueì˜ ë²¡í„°ëŠ” ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ ì‘ì„±í•œë‹¤ê³  í•¨.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ì„ì˜ì˜ real symmetric matrixëŠ” ìµœì†Œí•œ í•˜ë‚˜ì˜ eigen decompositionì´ ì¡´ì¬í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;eigen valueì˜ ë¶€í˜¸ì— ë”°ë¼ positive definite, positive semidefinite, negative definite, negative semidefiniteë¡œ ë¶€ë¥¸ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;singular-value-decomposition&quot;&gt;Singular Value Decomposition&lt;/h2&gt;

&lt;p&gt;singular valueì™€ singular vectorë¡œ decomposeí•˜ëŠ” ê²ƒì´ë‹¤. square matrixê°€ ì•„ë‹ ë•Œ eigen decompositionì„ í•˜ì§€ ëª»í•˜ë‹ˆ ì“´ë‹¤ê³  í•œë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf A = \textbf U \textbf D \textbf V^\intercal&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\textbf U&lt;/script&gt;ëŠ” &lt;script type=&quot;math/tex&quot;&gt;m\times m&lt;/script&gt;ì´ë©´ì„œ orthogonalí•˜ê³  ê·¸ columnë“¤ì´ left singular vectorsì´ë‹¤. &lt;script type=&quot;math/tex&quot;&gt;\textbf D&lt;/script&gt;ëŠ” diagonal matrixì´ë©´ì„œ &lt;script type=&quot;math/tex&quot;&gt;m \times n&lt;/script&gt;ì´ë©° main diagonalì— ìˆëŠ” elementë“¤ì´ singular valuesì´ë‹¤. &lt;script type=&quot;math/tex&quot;&gt;\textbf V&lt;/script&gt;ëŠ” &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt;ì´ë©´ì„œ orthogonalí•˜ê³  ê·¸ columnë“¤ì„ right singular vectorsë¡œ ë¶€ë¥¸ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;the-moore-penrose-pseudoinverse&quot;&gt;The Moore-Penrose Pseudoinverse&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf A^{+} = \lim_{a \rightarrow 0} (\textbf  A^\intercal \textbf  A + \alpha \textbf I) ^ {-1} \textbf  A ^\intercal&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf A^{+} = \textbf V \textbf D^+ \textbf U^\intercal&lt;/script&gt;

&lt;p&gt;ì²«ë²ˆì§¸ê°€ ì •ì˜ì´ê³  ì‹¤ì œë¡œ êµ¬í˜„í•  ë•ŒëŠ” ë‘ë²ˆì§¸ì‹ì„ ë”°ë¥¸ë‹¤ê³  í•œë‹¤. &lt;script type=&quot;math/tex&quot;&gt;\textbf D^+&lt;/script&gt;ëŠ” 0ì´ ì•„ë‹Œ elementë“¤ì— ì—­ìˆ˜ë¥¼ ì·¨í•˜ê³  transposeí•´ì„œ ì–»ì€ í–‰ë ¬ì´ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;trace-operator&quot;&gt;Trace Operator&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ì •ì˜: &lt;script type=&quot;math/tex&quot;&gt;Tr(\textbf A) = \sum_i \textbf A_{i, j}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;ì„±ì§ˆ: &lt;script type=&quot;math/tex&quot;&gt;Tr(\textbf A \textbf B \textbf C) = Tr(\textbf B \textbf C \textbf A) = ...&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-determinant&quot;&gt;The Determinant&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ê·¸ëƒ¥ &lt;script type=&quot;math/tex&quot;&gt;det (\textbf A)&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="machine learning" /><category term="ì±…" /><category term="linear algebra" /><summary type="html">Ian Goodfellowì˜ Deep Learning ì±…ì„ ë³´ê¸° ì‹œì‘í–ˆë‹¤. í•´ë‹¹ ì±…ì— ëŒ€í•´ ì¶”ì²œì„ ë§ì´ ë°›ì•˜ê³ , ë§ˆì¹¨ ì¶œíŒì‚¬ ì´ë²¤íŠ¸ë¡œ ì°¸ê°€í•´ì„œ ë²ˆì—­ë³¸ë„ ìš´ ì¢‹ê²Œ ì§‘ì— ìˆì—ˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•œ ë¶€ë¶„ë§Œ ê³¨ë¼ì„œ ì •ë¦¬í•´ë³¸ë‹¤!</summary></entry><entry><title type="html">ğŸ‘¨â€ğŸ’» CS224n assignments 1 &amp;amp; 2</title><link href="https://jeongukjae.github.io/posts/cs224n-assignments/" rel="alternate" type="text/html" title="ğŸ‘¨â€ğŸ’» CS224n assignments 1 &amp; 2" /><published>2019-04-18T00:00:00+00:00</published><updated>2019-04-18T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/cs224n%20assignments</id><content type="html" xml:base="https://jeongukjae.github.io/posts/cs224n-assignments/">&lt;p&gt;cs224n ìŠ¤í„°ë””ë¥¼ í•˜ë©´ì„œ ë‚˜ì˜¤ëŠ” ê³¼ì œë“¤ë„ ê°™ì´ í•˜ê¸°ë¡œ í—€ë‹¤. ê·¸ë˜ì„œ 1, 2ì£¼ì°¨ ê³¼ì œë¥¼ ëª°ì•„ì„œ í•´ë´¤ë‹¤. ê³¼ì œë¥¼ í•˜ë©´ì„œ ë‚´ê°€ ë‹¤ì‹œ ë´ì•¼í•  ë‚´ìš©ê°™ì€ ê²ƒì„ ì ì–´ë†“ì•˜ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;1ì£¼ì°¨-ê³¼ì œ&quot;&gt;&lt;a href=&quot;https://github.com/jeongukjae/cs224n-assignments/blob/master/assignment%201/exploring_word_vectors.ipynb&quot;&gt;1ì£¼ì°¨ ê³¼ì œ&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Question 1ì—ì„œ Word Vectorë¥¼ ê°„ë‹¨í•˜ê²Œ ì¨ë³´ê³ , Question 2ì—ì„œ gensimìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ analogyë“±ì„ í•´ë³´ëŠ” ê³¼ì œì˜€ë‹¤. ì „ì²´ì˜ ì†ŒìŠ¤ì½”ë“œëŠ” jupyter notebookìœ¼ë¡œ ì œê³µë˜ì—ˆê³ , ë¹„ì–´ìˆëŠ” ì¼ë¶€ ì†ŒìŠ¤ì½”ë“œë¥¼ ì±„ìš°ê±°ë‚˜, ê²°ê³¼ë¥¼ ë³´ê³  ì„¤ëª…ì„ ì¨ë‚´ëŠ” ê³¼ì œì˜€ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;question-1&quot;&gt;Question 1&lt;/h3&gt;

&lt;p&gt;ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ìë©´, co occuranceë¥¼ ì° ë’¤ truncated svd(PCAë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤)ì™€ matplotlibì„ ì´ìš©í•˜ì—¬ ëª‡ëª‡ ë‹¨ì–´ë“¤ì„ í•˜ëŠ” ê²ƒì´ë‹¤.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/a1-1.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;cooccurance matrix&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/a1-2.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;Truncated SVD (Singular Value Decomposition)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;ìœ„ì˜ ë‚´ìš©ê³¼ ì•„ë˜ì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ë©´ ì¢‹ë‹¤ê³  í•œë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html&quot;&gt;Computation Broadcasting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ê²°êµ­ ê·¸ ì •ë³´ë¥¼ ì´ìš©í•´ì„œ plotting í•˜ë©´ ì•„ë˜ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤. ë‚˜ë¼ ì´ë¦„ë“¤ì€ ìƒë‹¹íˆ ë§ì´ ëª¨ì—¬ìˆëŠ” ëª¨ìŠµì´ë‹¤.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/a1-3.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;Result of question1 in a1&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;question-2&quot;&gt;Question 2&lt;/h3&gt;

&lt;p&gt;prediction-based word vectorsì— ê´€í•œ ë‚´ìš©ì´ë‹¤. ì§ì ‘ êµ¬í˜„í•´ë³´ëŠ” ë‚´ìš©ì€ ì•„ë‹ˆê³  ì‚¬ìš©í•´ë³´ëŠ” ë‚´ìš©ì´ê¸° ë•Œë¬¸ì— í¬ê²Œ ë³¼ ë‚´ìš©ì€ ì—†ê³ , ì•„ë˜ ë…¼ë¬¸ë§Œ ì‚´í´ë³´ë©´ ë  ê²ƒ ê°™ë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf&quot;&gt;origin paper&lt;/a&gt; (ë¬´ì—‡ì¸ê°€ í–ˆëŠ”ë° negative sampling ë…¼ë¬¸)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2ì£¼ì°¨-ê³¼ì œ&quot;&gt;&lt;a href=&quot;https://github.com/jeongukjae/cs224n-assignments/tree/master/assignment%202/a2&quot;&gt;2ì£¼ì°¨ ê³¼ì œ&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;ì´ê²ƒë„ Questionì´ ë‘ê°€ì§€ê°€ ìˆëŠ”ë°, ì²«ë²ˆì§¸ëŠ” word2vecì— í•„ìš”í•œ ìˆ˜ì‹ì„ êµ¬í•´ë³´ëŠ” ë‹¨ê³„ì´ê³ , ë‘ë²ˆì§¸ëŠ” ê·¸ ìˆ˜ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë‹¨ê³„ì´ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;a2-question-1&quot;&gt;a2 Question 1&lt;/h3&gt;

&lt;p&gt;Question 1ì€ ì´ &lt;a href=&quot;https://github.com/jeongukjae/cs224n-assignments/blob/master/assignment%202/a2.pdf&quot;&gt;pdf íŒŒì¼&lt;/a&gt;ì„ ë³´ì. ì•Œì•„ë‘ì–´ì•¼ í•  ì‹ì€ ì•„ë˜ ì •ë„ì´ë‹¤. ì´ê±´ written ê³¼ì œë¼ ì—¬ê¸°ì— ì •ë¦¬í•´ë†“ëŠ”ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(O=o|C=c)= \frac {\exp (u_o^\intercal v_c)} {\sum_{w\in Vocab} \exp (u_w^\intercal v_c)}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J_{naive-softmax}(v_c, o, U) = - \log P(O=o|C=c)&lt;/script&gt;

&lt;h4 id=&quot;a&quot;&gt;a&lt;/h4&gt;

&lt;p&gt;aëŠ” naive-softmax lossê°€ cross entropy lossì™€ ê°™ì•„ì§€ëŠ” ì´ìœ ë¥¼ ì ì–´ë¼ê³  í•œë‹¤. ì¦‰, ì•„ë˜ ì‹ì´ ì°¸ì¸ ì´ìœ ë¥¼ ë§í•˜ë¼ê³  í•œë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;- \sum_{w \in Vocab} y_w \log \hat y_w = - \log \hat y_o&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;ëŠ” ì‹¤ì œ í™•ë¥  ë¶„í¬ì´ê³ , &lt;script type=&quot;math/tex&quot;&gt;\hat y&lt;/script&gt;ëŠ” ëª¨ë¸ì—ì„œ êµ¬í•œ í™•ë¥  ë¶„í¬ì´ë‹¤. ê·¸ë ‡ë‹¤ë©´, &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;ëŠ” context word &lt;script type=&quot;math/tex&quot;&gt;o&lt;/script&gt;ì— í•´ë‹¹í•˜ëŠ” elementë§Œ 1ì¸ one-hot vectorì´ê³ , ìœ„ì˜ ì‹ì´ ì°¸ì´ ëœë‹¤.&lt;/p&gt;

&lt;h4 id=&quot;b-c&quot;&gt;b, c&lt;/h4&gt;

&lt;p&gt;bëŠ” naive softmax lossì‹ì„ &lt;script type=&quot;math/tex&quot;&gt;v_c&lt;/script&gt;ì— ëŒ€í•´ í¸ë¯¸ë¶„ í•  ë•Œ!&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J} {\partial v_c} = - u_o + \sum_{x \in Vocab} P(x|c) u_x&lt;/script&gt;

&lt;p&gt;ê·¼ë° ìœ„ì˜ ì‹ì´ ì‹¤ì œ ë¶„í¬ì™€ ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” í™•ë¥  ë¶„í¬ì˜ ì°¨ì´ê°’ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì¸ë°, &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;ê°€ outside word &lt;script type=&quot;math/tex&quot;&gt;o&lt;/script&gt;ì— ëŒ€í•´ì„œë§Œ 1ì´ë‹ˆ ê²°êµ­ ê·¸ëƒ¥ ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” ì‹¤ì œ ë¶„í¬ì™€ ê³„ì‚°í•œ í™•ë¥  ë¶„í¬ì˜ ì°¨ì´ì™€ ê°™ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J} {\partial v_c} = U (\hat y - y)&lt;/script&gt;

&lt;p&gt;cëŠ” naive softmax lossì‹ì„ &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt;ì— ëŒ€í•´ í¸ë¯¸ë¶„ í•  ë•Œ! ê³„ì‚°í•˜ë©´ &lt;script type=&quot;math/tex&quot;&gt;w = o&lt;/script&gt;ì¸ ê²½ìš°ëŠ” ì•„ë˜ì²˜ëŸ¼ ë‚˜ì˜¨ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J } {\partial u_o} = (\hat y_o - y_o) v_c&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;(\hat y_o - y_o)&lt;/script&gt; ëŠ” í™•ë¥  ë¶„í¬ì˜ elementë¼ë¦¬ ë”í•˜ê³  ëº€ê±°ë‹ˆê¹Œ ìŠ¤ì¹¼ë¼ê°’!&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;w \neq o&lt;/script&gt;ì¸ê²½ìš°ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J } {\partial u_w} = \hat y_w v_c&lt;/script&gt;

&lt;p&gt;ê·¼ë°, ì´ê²Œ &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;ê°€ &lt;script type=&quot;math/tex&quot;&gt;o&lt;/script&gt;ë²ˆì§¸ elementë§Œ 1ì¸ one-hot vectorì´ë‹ˆ ê²°êµ­ ì „ì²´ &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt;ì— ëŒ€í•´ í¸ë¯¸ë¶„ í•˜ë©´ ì•„ë˜ì™€ ê°™ì•„ì§„ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J} {\partial U} = (\hat y - y) v_c^\intercal&lt;/script&gt;

&lt;h4 id=&quot;d&quot;&gt;d&lt;/h4&gt;

&lt;p&gt;sigmoid í¸ë¯¸ë¶„. ì´ê±´ ë‹¤ë¥¸ ê³³ì—ë„ ì„¤ëª…ì´ ì›Œë‚™ ë§ìœ¼ë‹ˆâ€¦&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial \sigma} {\partial x} = \sigma (1 - \sigma)&lt;/script&gt;

&lt;h4 id=&quot;e&quot;&gt;e&lt;/h4&gt;

&lt;p&gt;ì´ê±´ negative sampleì— ëŒ€í•œ lossì˜ í¸ë¯¸ë¶„ ì‹ì„ êµ¬í•˜ëŠ” ê²ƒì¸ë°, ì¼ë‹¨ neg sampleì˜ lossëŠ” ì•„ë˜ì™€ ê°™ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J_{neg-sample}(v_c, o, U) = - \log (\sigma (u_o^\intercal v_c)) - \sum_{k=1}^K \log (\sigma (-u_k^\intercal v_c))&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt;ê°€ negative samplesì´ê³ , &lt;script type=&quot;math/tex&quot;&gt;o&lt;/script&gt;ëŠ” neg sampleì— ì•ˆë“¤ì–´ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë•Œ ê°ê°ì˜ ë¯¸ë¶„í•œ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J} {\partial v_c} = - (1 - \sigma (u_o^\intercal v_c))u_o + \sum_{k = 1}^K (1 - \sigma(-u_k^\intercal v_c))u_k&lt;/script&gt;

&lt;p&gt;ì´ ê²½ìš° ì‹¤ì œ ì½”ë“œë¡œ êµ¬í˜„í•  ë•ŒëŠ” &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt;ì—ì„œ &lt;script type=&quot;math/tex&quot;&gt;o&lt;/script&gt;ë²ˆì§¸ë¥¼ ì œì™¸í•˜ê³  ì „ë¶€ -1ì„ ê³±í•´ì¤€ í›„ í•´ë‹¹ matrix ì „ì²´ì— ëŒ€í•´ sigmoidë¥¼ ì—°ì‚°í•´ì„œ ì‚¬ìš©í–ˆë‹¤. ë˜ &lt;script type=&quot;math/tex&quot;&gt;o&lt;/script&gt;ë²ˆì§¸ë§Œ &lt;script type=&quot;math/tex&quot;&gt;- (1 - \sigma)&lt;/script&gt;ì´ê³  ë‚˜ë¨¸ì§€ëŠ” &lt;script type=&quot;math/tex&quot;&gt;1- \sigma&lt;/script&gt;ì¸ì ë„ ë¯¸ë¦¬ ì „ì²´ì— ëŒ€í•´ ì—°ì‚°í•´ì„œ ì‚¬ìš©í–ˆë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J} {\partial u_o} = - (1 - \sigma (u_o^\intercal v_c))v_c&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac {\partial J} {\partial u_k} = \sum_{x=1}^K (1 - \sigma(-u_x^\intercal v_c))\frac {\partial u_x^\intercal v_c} {\partial u_k}&lt;/script&gt;

&lt;p&gt;ì´ê²Œ ìœ„ì˜ ì‹ì²˜ëŸ¼ ì‘ì„±í•œ ì´ìœ ëŠ” neg sampleì— ì—¬ëŸ¬ë²ˆ ë“¤ì–´ê°ˆ ê²½ìš° ê·¸ ìˆ˜ë§Œí¼ ë”í•´ì£¼ì–´ì•¼ í•œë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ì´ê²Œ ê·¼ë° ë‹¤ ë§ëŠ”ì§€ëŠ” ëª¨ë¥´ê² ê³  ì¼ë‹¨ í’€ì–´ë³¸ê±°ë‹¤. ì•„ë˜ ì½”ë“œë¡œ êµ¬í˜„í–ˆì„ ë•Œ ì˜ ë‚˜ì™”ìœ¼ë‹ˆ ë§ëŠ” ê±°ê² ì§€..?&lt;/p&gt;

&lt;h3 id=&quot;a2-question-2&quot;&gt;a2 Question 2&lt;/h3&gt;

&lt;p&gt;êµ¬í˜„!!!ì€ ê·¸ë ‡ê²Œê¹Œì§€ ì–´ë µì§„ ì•Šê³ , ìˆ˜í•™ìˆ˜ì‹ì„ ê·¸ëŒ€ë¡œ ì˜®ê²¨ì•¼ í•˜ëŠ”ë°, ê±°ê¸°ì„œ í—·ê°ˆë ¸ë‹¤. ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ ê²°ê³¼ë¥¼ ë½‘ì•„ë‚´ê¸°ê¹Œì§€ì˜ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦°ë‹¤. (numpyë¡œ ì‹¤ì œ í•™ìŠµì„ ì‹œì¼œë³¸ë‹¤)&lt;/p&gt;

&lt;p&gt;ê·¸ë ‡ê²Œ ì–»ì€ ê²°ê³¼ëŠ” ì•„ë˜ì •ë„ì´ë‹¤.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;https://github.com/jeongukjae/cs224n-assignments/raw/master/assignment%202/a2/word_vectors.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;word vectors&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;ê·¸ë ‡ê²Œ ê²°ê³¼ê°€ ì˜ ë‚˜ì˜¨ê²ƒê°™ì§„ ì•Šë‹¤. ê·¸ëƒ¥ì €ëƒ¥ ë½‘ì•„ë³¸ ê²ƒì— ë§Œì¡±í•œë‹¤.&lt;/p&gt;</content><author><name></name></author><category term="nlp" /><category term="cs224n" /><category term="machine learning" /><category term="python" /><summary type="html">cs224n ìŠ¤í„°ë””ë¥¼ í•˜ë©´ì„œ ë‚˜ì˜¤ëŠ” ê³¼ì œë“¤ë„ ê°™ì´ í•˜ê¸°ë¡œ í—€ë‹¤. ê·¸ë˜ì„œ 1, 2ì£¼ì°¨ ê³¼ì œë¥¼ ëª°ì•„ì„œ í•´ë´¤ë‹¤. ê³¼ì œë¥¼ í•˜ë©´ì„œ ë‚´ê°€ ë‹¤ì‹œ ë´ì•¼í•  ë‚´ìš©ê°™ì€ ê²ƒì„ ì ì–´ë†“ì•˜ë‹¤.</summary></entry><entry><title type="html">ğŸ“• CS224n Lecture 4 Backpropagation</title><link href="https://jeongukjae.github.io/posts/cs224n-lecture-4-back-propagation/" rel="alternate" type="text/html" title="ğŸ“• CS224n Lecture 4 Backpropagation" /><published>2019-04-13T00:00:00+00:00</published><updated>2019-04-13T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/cs224n%20lecture%204%20back%20propagation</id><content type="html" xml:base="https://jeongukjae.github.io/posts/cs224n-lecture-4-back-propagation/">&lt;p&gt;CS224n ë„¤ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!! ì´ë²ˆ ê°•ì˜ëŠ” ë‹¤ë¥¸ ê°•ì˜ë¥¼ ë“¤ìœ¼ë©´ì„œ ë§ì´ ë³´ì•˜ë˜ ë‚´ìš©ì´ê³  ë§ì´ ë‹¤ë¥¼ ê²ƒì´ ì—†ë‹¤ ìƒê°í•˜ê³  ë³„ ê¸°ëŒ€ì—†ì´ ë“¤ì—ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;matrix-gradients-for-our-simple-neural-net-and-some-tips&quot;&gt;Matrix gradients for our simple neural net and some tips&lt;/h2&gt;

&lt;p&gt;í¸ë¯¸ë¶„ í•˜ëŠ” ì‹ì€ ê±´ë„ˆë›´ë‹¤! ë„ˆë¬´ ì—¬ê¸°ì €ê¸° ë§ì´ ë‚˜ì˜¤ê¸°ë„ í–ˆê³  ê°œì¸ì ìœ¼ë¡œë„ ì •ë¦¬í•  í•„ìš”ì„±ì„ ëª» ëŠë‚€ë‹¤.&lt;/p&gt;

&lt;p&gt;ë‹¤ë§Œ, ì´ëŸ°ì €ëŸ° íŒì´ ë‚˜ì™”ëŠ”ë° ì•„ë˜ì™€ ê°™ë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tip 1: Carefully define your variables and keep track of their dimensionality!&lt;/li&gt;
  &lt;li&gt;Tip 2: Chain rule!&lt;/li&gt;
  &lt;li&gt;Tip 3: For the top softmax part of a model: First consider the derivative wrt &lt;script type=&quot;math/tex&quot;&gt;f_c&lt;/script&gt; when &lt;script type=&quot;math/tex&quot;&gt;c = y&lt;/script&gt; (the correct class), then consider derivative wrt &lt;script type=&quot;math/tex&quot;&gt;f_c&lt;/script&gt; when &lt;script type=&quot;math/tex&quot;&gt;c \neq y&lt;/script&gt; (all the incorrect classes)&lt;/li&gt;
  &lt;li&gt;Tip 4: Work out element-wise partial derivatives if youâ€™re getting confused by matrix calculus!&lt;/li&gt;
  &lt;li&gt;Tip 5: Use Shape Convention. Note: The error message &lt;script type=&quot;math/tex&quot;&gt;\delta&lt;/script&gt; that arrives at a hidden layer has the same dimensionality as that hidden layer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì—¬íŠ¼ ì­‰ ê±´ë„ˆë›°ì–´ì„œ word gradientsë¥¼ window modelì—ì„œ ê³„ì‚°í•˜ëŠ” ë¶€ë¶„ê¹Œì§€ ì™”ë‹¤. windowë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì˜ ê²½ìš° &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;ì˜ gradientë¥¼ ê³„ì‚°í•œ ê²°ê³¼ê°€ window ì „ì²´ì¸ë°, ì´ëŠ” word vectorë“¤ì„ ë‹¨ìˆœíˆ ì—°ê²°í•œ ê²ƒì´ë¯€ë¡œ ë‹¤ì‹œ ë‚˜ëˆ ì„œ ìƒê°í•´ì¤€ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
x_{window} = \pmatrix { x_{museums} &amp;&amp; x_{in} &amp;&amp; x_{Paris} &amp;&amp; x_{is} &amp;&amp; x_{amazing} } %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;updating-word-gradients-in-window-model&quot;&gt;Updating word gradients in window model&lt;/h3&gt;

&lt;p&gt;gradientë¥¼ ê°€ì ¸ì™¸ì„œ word vectorë¥¼ ì—…ë°ì´íŠ¸í•  ë•Œ ì£¼ì˜í•´ì•¼í•˜ëŠ” ì ì´ ìˆë‹¤. ì˜ ìƒê°í•´ë³´ë©´ ì›ë˜ì˜ ML ì ‘ê·¼ë²•ì€ nì°¨ì›ì— ë°ì´í„°ë“¤ì´ ê³µê°„ì— ì¡´ì¬í•  ë•Œ decision boundaryë¥¼ ì •í•˜ëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ, word vectorë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì€ word vector ìì²´ê°€ ì›€ì§ì¸ë‹¤. íŠ¹ì • batchì— ëŒ€í•´ í•™ìŠµí•œë‹¤ê³  í•  ë•Œ, batchì— ì¡´ì¬í•˜ì§€ ì•Šì€ ë‹¨ì–´ë“¤ì€ ì›€ì§ì´ì§€ ì•Šì§€ë§Œ, batchì— ë“¤ì–´ìˆëŠ” ë‹¨ì–´ë“¤ì€ ì›€ì§ì´ê²Œ ëœë‹¤.&lt;/p&gt;

&lt;p&gt;ê·¸ì— ëŒ€í•œ ë¹„êµì  ì¢‹ì€ í•´ê²°ì±…ì€ pre-trained word vectorë“¤ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ëŒ€ë¶€ë¶„, ê±°ì˜ ëª¨ë“  ê²½ìš°ì— ì¢‹ì€ ë‹µì´ ë  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. ë§Œì•½ ì¢‹ì€ ë°©ëŒ€í•œ ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  ìˆëŠ” ê²½ìš° pre trained ëª¨ë¸ì— ëŒ€í•´ì„œ fine tuningì„ í•´ì¤˜ë„ ì¢‹ë‹¤ê³  í•œë‹¤. (ë‹¤ë§Œ, ì‘ì€ ë°ì´í„°ì…‹ì¸ ê²½ìš° í•™ìŠµí•˜ëŠ” ê²ƒì´ ì˜¤íˆë ¤ í•´ê°€ ë ìˆ˜ë„ ìˆë‹¤ê³ )&lt;/p&gt;

&lt;h2 id=&quot;computation-graphs-and-backpropagation&quot;&gt;Computation graphs and backpropagation&lt;/h2&gt;

&lt;p&gt;ì´ì œ graphë¡œ ì„¤ëª…í•˜ëŠ” backprop ë¶€ë¶„ì¸ë°, ê±´ë„ˆë›´ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;stuff-you-should-know&quot;&gt;Stuff you should know&lt;/h2&gt;

&lt;p&gt;ë‹¤ì–‘í•œ, ì¢€ ì•Œì•„ë‘ë©´ ì¢‹ì„ ê²ƒë“¤ì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ëŠ”ë° ì•„ë˜ì™€ ê°™ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì•Œë ¤ì¤€ë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Regularization: overfittingì„ ë°©ì§€í•˜ëŠ” ê¸°ë²•&lt;/li&gt;
  &lt;li&gt;Vecotrization: pythonicí•œ ë°©ë²•ì€ MLì—ì„œëŠ” ì¢€ ë§ì´.. ëŠë¦´ ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;non-linearity: activation functionì— ëŒ€í•´ ì„¤ëª…ì„ í–ˆëŠ”ë°, sigmoid, tanhëŠ” ì´ì œ íŠ¹ë³„í•œ ìƒí™©ì—ì„œë§Œ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤. ReLUë¥¼ ê·¸ëƒ¥ ì²˜ìŒ ì‹œë„í•´ë³´ëŠ” ê²ƒì´ ì¢‹ì„ ê±°ë¼ê³ ..&lt;/li&gt;
  &lt;li&gt;parameter initialization: weightë¥¼ ì²˜ìŒ ì–´ë–»ê²Œ ì´ˆê¸°í™”í• ì§€ê°€ ë¬¸ì œì¸ë°, 0ì€ ì“°ì§€ë§ê³ (backprop í•´ì•¼í•˜ë‹ˆê¹Œ) Xavierê°™ì€ ê²ƒì„ ì¨ì£¼ë©´ ì˜ ëœë‹¤ê³  í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;optimization: SGD, adargrad, RMSProp, Adam, SparseAdamê°™ì€ ê²ƒë“¤ì´ ë§ì´ ë‚˜ì™”ëŠ”ë°, SGDê°€ ë³´í†µì˜ ìƒí™©ì— ì˜ ë™ì‘í•œëŒ€ìš”.&lt;/li&gt;
  &lt;li&gt;Learning Rate: ì ì ˆí•œ lrë¥¼ ì •í•´ì£¼ëŠ” ê²ƒì´ ì¢‹ì€ë°, cyclic learning ratesê°™ì€ ì‹ ê¸°í•œ ë°©ë²•ë„ ìˆìœ¼ë‹ˆ ì˜ ì •í•©ì‹œë‹¤.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="nlp" /><category term="cs224n" /><category term="machine learning" /><summary type="html">CS224n ë„¤ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!! ì´ë²ˆ ê°•ì˜ëŠ” ë‹¤ë¥¸ ê°•ì˜ë¥¼ ë“¤ìœ¼ë©´ì„œ ë§ì´ ë³´ì•˜ë˜ ë‚´ìš©ì´ê³  ë§ì´ ë‹¤ë¥¼ ê²ƒì´ ì—†ë‹¤ ìƒê°í•˜ê³  ë³„ ê¸°ëŒ€ì—†ì´ ë“¤ì—ˆë‹¤.</summary></entry><entry><title type="html">ğŸ“• CS224n Lecture 3 Neural Network</title><link href="https://jeongukjae.github.io/posts/cs224n-lecture-3-neural-network/" rel="alternate" type="text/html" title="ğŸ“• CS224n Lecture 3 Neural Network" /><published>2019-04-09T00:00:00+00:00</published><updated>2019-04-09T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/cs224n%20lecture%203%20neural%20network</id><content type="html" xml:base="https://jeongukjae.github.io/posts/cs224n-lecture-3-neural-network/">&lt;p&gt;CS224n ì„¸ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!!&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;ì•ìœ¼ë¡œ ì§„í–‰í•  ê°•ì˜:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2ì£¼ì°¨: neural network (3, 4ê°•)&lt;/li&gt;
  &lt;li&gt;3ì£¼ì°¨: nlp (ex&amp;gt; dependency parsing) (5, 6ê°•)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;HW2(gradient derivation of word2vec, implement word2vec with numpy)ë„ ìˆë‹¤!&lt;/p&gt;

&lt;h2 id=&quot;classification-review&quot;&gt;Classification Review&lt;/h2&gt;

&lt;p&gt;classificationì— ëŒ€í•œ ë¦¬ë·°. ì¼ë‹¨, &lt;script type=&quot;math/tex&quot;&gt;\{x_i, y_i\}_{i=1}^N&lt;/script&gt; ì´ ìˆë‹¤ê³  ê°€ì •. (training set consisting of samples) &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;ëŠ” input, &lt;script type=&quot;math/tex&quot;&gt;y_i&lt;/script&gt;ëŠ” labelì´ë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ ì „í†µì ì¸ ML, í†µê³„í•™ì˜ ì ‘ê·¼ë²•ì€ softmax, logistic regressionì„ í†µí•´ decision boundaryë¥¼ ì •í•˜ëŠ” ë¬¸ì œë¡œ ë³¸ë‹¤. ê·¸ë˜ì„œ ì•„ë˜ì™€ ê°™ì€ xì— ëŒ€í•œ ì‹ì´ ë§Œë“¤ì–´ì§„ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y|x) = \frac {\exp {w_y x}} {\sum_{c=1}^C \exp w_c x}&lt;/script&gt;

&lt;p&gt;ì´ê±°ë¥¼ &lt;script type=&quot;math/tex&quot;&gt;w_y x = f_y&lt;/script&gt;ë¡œ ë³´ê³  í‘œê¸°ë„ ê°€ëŠ¥í•˜ë‹¤. ê·¸ë˜ì„œ softmax ì‹ì„ &lt;script type=&quot;math/tex&quot;&gt;softmax(f_y)&lt;/script&gt;ë¼ í‘œê¸°í•˜ê¸°ë„ í•œë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;cross-entropy-loss&quot;&gt;Cross Entropy Loss&lt;/h3&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;ì˜ probì„ maximizeí•œë‹¤. (ì•„ë˜ ì‹, negative log probì„ minimizeí•œë‹¤)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;- \log p(y|x)&lt;/script&gt;

&lt;p&gt;cross entropy errorëŠ” &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;ê°€ ì‹¤ì œ í™•ë¥  ë¶„í¬ì´ê³ , &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;ê°€ ëª¨ë¸ì—ì„œ ê³„ì‚°í•œ í™•ë¥  ë¶„í¬ì¼ ë•Œ, ì•„ë˜ ì‹ê³¼ ê°™ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(p, q) = - \sum_{c=1}^C p(c) \log q(c)&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;ê°€ one-hot vectorì´ë©´ (ì‹¤ì œë¡œ ì˜³ì€ labelì€ ë³´í†µ í•˜ë‚˜ë¥¼ ì„ ì •í•´ë†“ìœ¼ë‹ˆ?), q í•˜ë‚˜ë§Œì„ ê³„ì‚°í•œë‹¤. ê·¸ë¦¬ê³  ì•„ë˜ëŠ” cross entropyë¥¼ ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ê³„ì‚°í•œ ê²°ê³¼ì´ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta) = \frac 1 N \sum_{i=1}^N - \log \frac {\exp f_{y_i}} {\sum_{c=1}^C \exp f_c }&lt;/script&gt;

&lt;h2 id=&quot;neural-net-classifier&quot;&gt;Neural Net Classifier&lt;/h2&gt;

&lt;p&gt;softmaxëŠ” decision boundaryë§Œ ì œê³µí•˜ëŠ”ë°, softmaxë§Œ ì‚¬ìš©í•˜ê¸°ì—ëŠ” íš¨ê³¼ì ì´ì§€ ì•Šë‹¤. ê·¸ë˜ì„œ neural netì„ ê°™ì´ ì“´ë‹¤. NLPì—ì„œì˜ classificationì€ word vectorë¥¼ í•™ìŠµí•˜ë©´ì„œ classificationì— í•„ìš”í•œ weightê¹Œì§€ í•™ìŠµí•œë‹¤. (ë³´í†µì€ weightë§Œ í•™ìŠµ)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla_\theta J (\theta) = \pmatrix {\nabla W_1 \\ ... \\ \nabla W_d \\ \nabla x_{first word} \\ ... \\ \nabla x_{last word}} \in \mathbb R ^{Cd + Vd}&lt;/script&gt;

&lt;p&gt;ì¤‘ê°„ì—ëŠ” ì•„ëŠ” ë‚´ìš©ì´ë¼ ê±´ë„ˆëœ€. (ì¼ë°˜ì ì¸ neural net ì„¤ëª…)&lt;/p&gt;

&lt;p&gt;non linearityëŠ” ì›Œë‚™ ë‹¤ë“¤ ê°•ì¡°í•˜ëŠ” ë‚´ìš©. ê·¸ ì´ìœ ? ê²°êµ­ ì‹ì„ ë‹¤ ì „ê°œí•˜ë©´ í•˜ë‚˜ì˜ ì¸µì„ ìŒ“ì€ ê²ƒì´ ë˜ë¯€ë¡œ, non linearityë¥¼ ë§Œë“¤ì–´ì£¼ì–´ì•¼ í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ner-named-entity-recognition&quot;&gt;NER (Named Entity Recognition)&lt;/h2&gt;

&lt;p&gt;NERì€ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì •í•œ ë‹¨ì–´ë“¤ì„ ì°¾ê³  ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì´ë‹¤. ê·¸ë˜ì„œ í¬ê²Œ ë‘ ë‹¨ê³„ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ”ë°, ë‹¨ì–´ë¥¼ ì°¾ëŠ” ê²ƒì´ 1, ê·¸ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê²ƒì´ 2ì´ë‹¤. ê·¼ë° NERì„ ìˆ˜í–‰í•˜ë‹¤ë³´ë©´ ë¬¸ì œì ì´ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ future schoolì´ë¼ëŠ” ë‹¨ì–´ê°€ ìˆì„ ë–„, í•™êµì˜ ì´ë¦„ì´ Future Schoolì¸ì§€, ì•„ë‹ˆë©´ ì •ë§ ë¯¸ë˜ì˜ í•™êµì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ”ì§€ ë¬¸ë§¥ì„ ëª¨ë¥´ë©´ ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ë„ˆë¬´ ëª¨í˜¸í•˜ë‹¤ëŠ” ë¬¸ì œì ì´ ìˆë‹¤. ì¦‰, contextì— ì˜ì¡´ì ì´ë‹¤.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/3-1.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;NER&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;binary-word-window-classification&quot;&gt;Binary Word Window Classification&lt;/h2&gt;

&lt;p&gt;contextì—ì„œ ëª¨í˜¸í•¨ì´ ìƒê¸°ë‹ˆ, context windowì™€ í•¨ê»˜ ë‹¨ì–´ë¥¼ ë¶„ë¥˜í•˜ìëŠ” ê²ƒì´ ë©”ì¸ì´ ë˜ëŠ” ì•„ì´ë””ì–´ì´ë‹¤.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/cs224n/3-2.png&quot; alt=&quot;&quot; class=&quot;&quot; /&gt;
  &lt;figcaption&gt;word classification&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;ì´ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ Collobert &amp;amp; Weston (2008, 2011)ë¥¼ ì°¾ì•„ë³´ì.&lt;/p&gt;</content><author><name></name></author><category term="nlp" /><category term="cs224n" /><category term="machine learning" /><summary type="html">CS224n ì„¸ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!!</summary></entry><entry><title type="html">ğŸ“ƒ GloVe ë…¼ë¬¸ ì •ë¦¬í•´ë³´ê¸°</title><link href="https://jeongukjae.github.io/posts/GloVe/" rel="alternate" type="text/html" title="ğŸ“ƒ GloVe ë…¼ë¬¸ ì •ë¦¬í•´ë³´ê¸°" /><published>2019-04-08T00:00:00+00:00</published><updated>2019-04-08T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/GloVe</id><content type="html" xml:base="https://jeongukjae.github.io/posts/GloVe/">&lt;p&gt;ì´ ë…¼ë¬¸ì€ cs224n ê°•ì˜ 2ê°•ì—ì„œ suggested readingsë¡œ ì¶”ì²œëœ ë…¼ë¬¸ì´ë‹¤. ìŠ¤íƒ í¬ë“œì—ì„œ ì‘ì„±í•œ ë…¼ë¬¸ì´ê³ , ì˜ë¯¸ê¶Œì—ì„œ ë² ì´ìŠ¤ë¡œ í™œìš©ì´ ë§ì´ ëœë‹¤ê³  í•´ì„œ ë”°ë¡œ ì •ë¦¬ë¥¼ í•´ë³´ê¸°ë¡œ í—€ë‹¤! ì‚¬ì‹¤ ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” ë‚´ê°€ ë‹¤ì‹œ ë³´ê¸° ìœ„í•´ ê°„ë‹¨í•˜ê²Œ ì •ë¦¬í•˜ëŠ” ê²ƒì´ë¼ ì„¤ëª…ì´ ë¶€ì¡±í•˜ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;word vectorë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•ì—ëŠ” ë‘ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤. í•˜ë‚˜ëŠ” global matrix factorization methodsì´ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” local context window methodsì´ë‹¤. ì „ìì—ëŠ” LSA ê°™ì€ ê²ƒì´ í•´ë‹¹ë˜ê³ , í›„ìì—ëŠ” skipgramê°™ì€ ê²ƒì´ í•´ë‹¹ëœë‹¤. LSAì™€ ê°™ì€ ëª¨ë¸ë“¤ì€ í†µê³„í•™ì  ì •ë³´ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê·¹ëŒ€í™”ì‹œí‚¤ëŠ” ëŒ€ì‹  analogy taskì—ëŠ” í˜•í¸ì—†ë‹¤. skipgramê³¼ ê°™ì€ ëª¨ë¸ë“¤ì€ ê·¸ì— ë¹„í•´ analogyì—ëŠ” íŠ¹í™”ë˜ì–´ ìˆìœ¼ë‚˜, í†µê³„ì ì¸ ì •ë³´ë“¤ì„ ì œëŒ€ë¡œ ìˆ˜ì§‘í•˜ê¸°ê°€ í˜ë“¤ë‹¤.&lt;/p&gt;

&lt;p&gt;ê·¸ë˜ì„œ ì´ ë…¼ë¬¸ì—ì„œ weighted least squares modelì„ ì†Œê°œí•˜ëŠ”ë° global word-word co-occurance countsë¥¼ í›ˆë ¨í•œ ëª¨ë¸ì´ê³ , í†µê²Œì ì¸ ì •ë³´ë„ ì˜ í™œìš©í•˜ê²Œ ë§Œë“¤ì—ˆë‹¤ê³  í•œë‹¤. &lt;sup id=&quot;fnref:glove&quot;&gt;&lt;a href=&quot;#fn:glove&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-glove-model&quot;&gt;The GloVe Model&lt;/h2&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt;ê°€ ê¸°ë³¸ ë‹¨ìœ„ì¸ word-word co-occurance countë¥¼ &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;ë¼ê³  í•œë‹¤. ê·¸ë¦¬ê³  &lt;script type=&quot;math/tex&quot;&gt;X_i = \sum_k X_{ik}&lt;/script&gt;ë¼ í•œë‹¤. context word &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;ì—ì„œ word &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;ê°€ ë‚˜íƒ€ë‚  í™•ë¥ ì€&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{ij} = P(j|i) = \frac {X_{ij}} {X_i}&lt;/script&gt;

&lt;p&gt;ì´ë‹¤. ì—¬ê¸°ì„œ ê°ê°ì˜ ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚  í™•ë¥ ì˜ ë¹„ìœ¨ì„ GloVeì—ì„œ í™œìš©í•˜ê²Œ ë˜ëŠ”ë° ì„¸ ë‹¨ì–´ &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;ì— ëŒ€í•´ ì•„ë˜ì²˜ëŸ¼ ì ì„ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(w_i, w_j, \tilde {w}_k ) = \frac {P_{ik}} {P_{jk}}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\tilde{w}&lt;/script&gt;ëŠ” context word vectorì¸ë°, word2vecì´ &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; ë²¡í„°ë¥¼ ë‚˜ëˆ„ì–´ì“°ëŠ” ê²ƒê³¼ ë¹„ìŠ·í•˜ê²Œ ìƒê°í•˜ë©´ ë ë“¯ ì‹¶ë‹¤. ì ìœ„ì˜ ì‹ì—ì„œ &lt;script type=&quot;math/tex&quot;&gt;F&lt;/script&gt;ê°€ ë‘ ë‹¨ì–´ì˜ ì°¨ì´ì— ì˜ì¡´ì ì´ë‹ˆ ì´ë ‡ê²Œ ë°”ê¾¸ê³ ,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(w_i - w_j, \tilde {w}_k ) = \frac {P_{ik}} {P_{jk}}&lt;/script&gt;

&lt;p&gt;ë˜ ì¸ìëŠ” ë²¡í„°ì¸ë° ë°˜í™˜í•˜ëŠ” ê²ƒì€ ìŠ¤ì¹¼ë¼ê°’ì´ë‹ˆ ì´ë ‡ê²Œ ë°”ê¾¸ì&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F((w_i - w_j)^\intercal \tilde {w}_k ) = \frac {P_{ik}} {P_{jk}}&lt;/script&gt;

&lt;p&gt;ê·¼ë° ì—¬ê¸°ì„œ ì•Œì•„ì•¼ í•  ì ì´, word-word co-occurance matrix &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;ë‘, word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;, context word &lt;script type=&quot;math/tex&quot;&gt;\tilde{w}&lt;/script&gt;ë‘ êµ¬ë¶„ì´ ëª¨í˜¸í•˜ë‹¤. ê·¸ë˜ì„œ &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;ë¥¼ symmetricí•˜ê²Œ, &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;ëŠ” &lt;script type=&quot;math/tex&quot;&gt;\tilde{w}&lt;/script&gt;ì™€ ë°”ê¿”ì“¸ ìˆ˜ ìˆê²Œ í•´ì•¼í•œë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ì„œ &lt;script type=&quot;math/tex&quot;&gt;F&lt;/script&gt;ê°€ group &lt;script type=&quot;math/tex&quot;&gt;(\mathbb{R}, +)&lt;/script&gt;ì™€ &lt;script type=&quot;math/tex&quot;&gt;(\mathbb{R}, \times)&lt;/script&gt;ì— ëŒ€í•´ homomorphismí•¨ì„ í•„ìš”ë¡œ í•œë‹¤. &lt;sup id=&quot;fnref:homomorphism&quot;&gt;&lt;a href=&quot;#fn:homomorphism&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; ê·¸ëŸ¬í•œ homomorphismì„ ë³´ì¥ë°›ìœ¼ë©´ ì´ë ‡ê²Œ ìˆ˜ì •ì´ ê°€ëŠ¥í•˜ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F((w_i - w_j)^\intercal \tilde {w}_k ) = F(w_i^\intercal \tilde {w}_k - w_j^\intercal \tilde {w}_k) = \frac {F(w_i^\intercal \tilde {w}_k)} {F(w_j^\intercal \tilde {w}_k)}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;F&lt;/script&gt;ëŠ” ë§ˆì¹˜ expì™€ ë¹„ìŠ·í•˜ê²Œ í’€ì–´ì§€ë¯€ë¡œ, ì´ëŸ°ì‹ìœ¼ë¡œ ìœ ë„í•´ë³´ì. (ë§¨ ìœ„ì˜ ì‹ ì°¸ê³ )&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_i^\intercal \tilde {w}_k = \log P_{ik} = \log {X_{ik}} - \log {X_i}&lt;/script&gt;

&lt;p&gt;ê·¼ë° ì´ê²Œ &lt;script type=&quot;math/tex&quot;&gt;\log {X_i}&lt;/script&gt; í•­ì´ &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;$ì— ë…ë¦½ì ì´ë¼ ì´ëŸ°ì‹ìœ¼ë¡œ biasë¡œ ì •ë¦¬ê°€ëŠ¥í•˜ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_i^\intercal \tilde {w}_k + b_i + \tilde{b}_k = \log {X_{ik}}&lt;/script&gt;

&lt;p&gt;ê·¼ë° ì—¬ê¸°ì„œ ë˜ ë¬¸ì œì ì´ &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;ê°€ 0ì´ ë‚˜ì˜¬ìˆ˜ ìˆë‹¤ëŠ” ì ..ì¸ë°, ì´ê±¸ &lt;script type=&quot;math/tex&quot;&gt;\log (X_{ik}) \rightarrow \log (1 + X_{ik})&lt;/script&gt;ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;ì˜ sparsityë¥¼ ìœ ì§€í•˜ë©´ì„œ divergenceë¥¼ í”¼í•œë‹¤ê³  í•œë‹¤. ì ì—¬íŠ¼ ì—¬ê¸°ì„œ cost functionì„ ë½‘ì•„ë‚´ëŠ”ë°, ê·¸ ì‹ì´ ì•„ë˜ì™€ ê°™ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J = \sum_{i,j = 1}^V f(X_{ij}) ( w_i^\intercal \tilde{w}_j +b_i + \tilde{b}_j - \log {X_{ij}} )^2&lt;/script&gt;

&lt;p&gt;ì´ ì‹ì„ ë³´ë©´ì„œ ì–´ëŠì •ë„ ë– ì˜¤ë¥¸ ì•„ì´ë””ì–´ëŠ” â€œ&lt;script type=&quot;math/tex&quot;&gt;\log {X_{ij}}&lt;/script&gt;ê°€ ì‹¤ì œ co-occuranceì´ê³ , &lt;script type=&quot;math/tex&quot;&gt;w_i^\intercal \tilde{w}_j +b_i + \tilde{b}_j&lt;/script&gt;ëŠ” word vectorë¡œë¶€í„° ë½‘ì•„ë‚´ëŠ” ì˜ˆìƒ co-occuranceë‹ˆê¹Œ ê·¸ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ì œê³±í•œë‹¤ìŒ ê°ê° ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì–´ í•©í•˜ë©´ cost functionì¸ê°€?â€ ì •ë„ì´ë‹¤. ë¬¼ë¡  í˜¼ì ìƒê°í•œê±°ë¼ ì •í™•í•œì§€ëŠ”.. ëª¨ë¥´ê² ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;relationship-to-other-models&quot;&gt;Relationship to Other Models&lt;/h3&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;Q_{ij}&lt;/script&gt; ì„ word &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;ê°€ context of word &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;ì— ë‚˜íƒ€ë‚  í™•ë¥ ì´ë¼ê³  í•  ë•Œ, ë‹¤ìŒ ì‹ê³¼ ê°™ì•„ì§„ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q_{ij} = \frac {\exp (w_i^\intercal \tilde w _j)} {\sum_{k=1}^V \exp(w_i^\intercal \tilde w _k)}&lt;/script&gt;

&lt;p&gt;softmaxì¸ë°, ê·¸ë¥¼ ì´ìš©í•œ objective functionì€ ë‹¤ìŒê³¼ ê°™ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J = - \sum_{i \in corpus \\ j \in context(i)} \log Q_{ij}&lt;/script&gt;

&lt;p&gt;ì´ë¥¼ co-occurance matrix &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•´ì„œ ì´ë ‡ê²Œ ë³€í˜•í•˜ë©´ í›¨ì”¬ ë¹¨ë¼ì§„ë‹¤. (&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;ì˜ 75% ~ 90%ê°€ 0ì´ë‹ˆ..)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J = - \sum_{i = 1}^V \sum_{j=1}^V X_{ij} \log Q_{ij}&lt;/script&gt;

&lt;p&gt;ì—¬ê¸°ì„œ ì•ì˜ ì‹ë“¤ì„ ì´ìš©í•´ ì´ë ‡ê²Œ ë³€í˜•ì´ ê°€ëŠ¥í•˜ë‹¤.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J = - \sum_{i = 1}^V X_i \sum_{j=1}^V P_{ij} \log Q_{ij} = \sum_{i=1}^V  X_{i} H(P_i, Q_i)&lt;/script&gt;

&lt;p&gt;ì—¬ê¸°ì„œ &lt;script type=&quot;math/tex&quot;&gt;H(P_i, Q_i)&lt;/script&gt;ëŠ” Cross entropyì´ë‹¤. ê·¼ë°, cross entropyëŠ” distanceë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì¤‘ í•˜ë‚˜ì¸ë°, ì–´ë–¤ ë•Œì— weightë¥¼ ë„ˆë¬´ ë§ì´ ì¤€ë‹¤ê³  í•œë‹¤. ê·¸ë˜ì„œ ì´ë ‡ê²Œ ë‹¤ë¥¸ ê±°ë¦¬ë¥¼ ì“°ë„ë¡ ë°”ê¿”ì£¼ì.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat J = \sum_{i, j}^V  X_{i} (\hat P_{ij} - \hat Q_{ij}) ^2&lt;/script&gt;

&lt;p&gt;ì—¬ê¸°ì„œ &lt;script type=&quot;math/tex&quot;&gt;\hat P_{ij} = X_{ij}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\hat Q_{ij} = \exp(w_i^\intercal \tilde {w}_j)&lt;/script&gt;ì²˜ëŸ¼ unnormalizeëœ ë¶„í¬ê°€ ëœë‹¤. ê·¼ë° ì´ê²ƒë„ ë¬¸ì œê°€ ìˆë‹¤. &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt;ëŠ” ë³´í†µ ë„ˆë¬´ í° ê°’ì„ ì·¨í•˜ê²Œ ë˜ë¯€ë¡œ, squared errorë¥¼ minimizeí•´ì£¼ì.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat J = \sum_{i, j}^V  X_{i} (\log \hat P_{ij} - \log \hat Q_{ij}) ^2 \\
= \sum_{i, j}^V  X_{i} (w_i^\intercal \tilde {w}_j - \log X_{ij}) ^2\\
= \sum_{i, j}^V  f(X_{ij}) (w_i^\intercal \tilde {w}_j - \log X_{ij}) ^2&lt;/script&gt;

&lt;p&gt;ì ê·¼ë° ì´ê±´ ê²°êµ­ GloVeì˜ cost functionê³¼ ê°™ì€ í˜•íƒœê°€ ë˜ì—ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ê·¸ ë’¤ëŠ” ë„ˆë¬´ ì–´ë ¤ì›Œë³´ì—¬ì„œ ì•„ì§ ëª»ë´¤ë‹¤ ã… ã… &lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:glove&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://nlp.stanford.edu/projects/glove/&quot;&gt;http://nlp.stanford.edu/projects/glove/&lt;/a&gt; ì—¬ê¸°ì— ì†ŒìŠ¤ì½”ë“œê°€ ì˜¬ë¼ê°€ ìˆë‹¤.Â &lt;a href=&quot;#fnref:glove&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:homomorphism&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Group_homomorphism&quot;&gt;https://en.wikipedia.org/wiki/Group_homomorphism&lt;/a&gt; ì—¬ê¸°ì— ê°„ëµí•˜ê²Œ ì˜ ì„¤ëª…ë˜ì–´ ìˆë‹¤.Â &lt;a href=&quot;#fnref:homomorphism&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="paper" /><category term="cs224n" /><category term="nlp" /><category term="machine learning" /><summary type="html">ì´ ë…¼ë¬¸ì€ cs224n ê°•ì˜ 2ê°•ì—ì„œ suggested readingsë¡œ ì¶”ì²œëœ ë…¼ë¬¸ì´ë‹¤. ìŠ¤íƒ í¬ë“œì—ì„œ ì‘ì„±í•œ ë…¼ë¬¸ì´ê³ , ì˜ë¯¸ê¶Œì—ì„œ ë² ì´ìŠ¤ë¡œ í™œìš©ì´ ë§ì´ ëœë‹¤ê³  í•´ì„œ ë”°ë¡œ ì •ë¦¬ë¥¼ í•´ë³´ê¸°ë¡œ í—€ë‹¤! ì‚¬ì‹¤ ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” ë‚´ê°€ ë‹¤ì‹œ ë³´ê¸° ìœ„í•´ ê°„ë‹¨í•˜ê²Œ ì •ë¦¬í•˜ëŠ” ê²ƒì´ë¼ ì„¤ëª…ì´ ë¶€ì¡±í•˜ë‹¤.</summary></entry><entry><title type="html">ğŸš€ jekyll ì†ë„ ì˜¬ë¦¬ê¸°</title><link href="https://jeongukjae.github.io/posts/1jekyll-%EC%86%8D%EB%8F%84-%EC%98%AC%EB%A6%AC%EA%B8%B0/" rel="alternate" type="text/html" title="ğŸš€ jekyll ì†ë„ ì˜¬ë¦¬ê¸°" /><published>2019-04-07T00:00:00+00:00</published><updated>2019-04-07T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/1jekyll-%EC%86%8D%EB%8F%84-%EC%98%AC%EB%A6%AC%EA%B8%B0</id><content type="html" xml:base="https://jeongukjae.github.io/posts/1jekyll-%EC%86%8D%EB%8F%84-%EC%98%AC%EB%A6%AC%EA%B8%B0/">&lt;p&gt;ê°œì¸ ë¸”ë¡œê·¸ë¡œ github pagesì™€ jekyllì„ ì‚¬ìš©í•˜ê³  ë‚˜ì„œë¶€í„° ë¡œì»¬ì—ì„œ jekyllì„ ëŒë¦¬ë©´ì„œ í¬ìŠ¤íŠ¸ê°€ ì œëŒ€ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ì§€ í‘¸ì‰¬í•˜ê¸° ì „ ë§¤ë²ˆ í™•ì¸í•˜ê³  ìˆë‹¤. ë³´í†µ ë‚˜ëŠ” í¬ìŠ¤íŠ¸ë¥¼ &lt;code class=&quot;highlighter-rouge&quot;&gt;_drafts&lt;/code&gt; í´ë”ì— ìš°ì„  ë„£ì–´ë†“ê³  ì‘ì„±í•˜ëŠ” í¸ì´ë¼, ë“œë˜í”„íŠ¸ê¹Œì§€ ë¹Œë“œí•˜ë©´ì„œ í™•ì¸í•˜ê³  ìˆì—ˆëŠ”ë°, í•œë²ˆ ì €ì¥í•˜ë©´ ë‹¤ì‹œ ë¹Œë“œë ë•Œê¹Œì§€ ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦°ë‹¤. (12ì¸ì¹˜ ë§¥ë¶ì—ì„œ 2ì´ˆì •ë„ ê±¸ë¦°ë‹¤) ê·¸ë˜ì„œ ì´ê±¸ ì–´ë–»ê²Œ ë” ë¹ ë¥´ê²Œ ë§Œë“¤ ë°©ë²•ì´ ì—†ì„ê¹Œ í•˜ë©´ì„œ ì°¾ì•„ë³´ë‹¤ê°€ ì•„ë˜ì²˜ëŸ¼ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì˜ ì†ë„ë¥¼ ì˜¬ë ¸ë‹¤. (í‘¸ì‰¬ë˜ê³  ë‚œ í›„ì•¼.. ë­ ë‚´ ì„œë²„ ì•„ë‹ˆë‹ˆê¹Œ..)&lt;/p&gt;

&lt;h2 id=&quot;configyml-ìˆ˜ì •&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;config.yml&lt;/code&gt; ìˆ˜ì •&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.git/&lt;/code&gt; í´ë”ì˜ ê²½ìš° ìƒë‹¹íˆ ë§ì€ íŒŒì¼ë“¤ì„ í¬í•¨í•˜ëŠ”ë° &lt;code class=&quot;highlighter-rouge&quot;&gt;tree .git&lt;/code&gt;ì„ í•´ë³´ë‹ˆ ì•„ë˜ì²˜ëŸ¼ ë‚˜ì˜¨ë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;tree .git
...
...
    â”œâ”€â”€ remotes
    â”‚   â””â”€â”€ origin
    â”‚       â””â”€â”€ master
    â””â”€â”€ tags

267 directories, 799 files
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ì•½ 800ê°œì˜ íŒŒì¼ê³¼ 270ê°œì˜ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ë°, ì´ë¥¼ ì¼ì¼íˆ ë‹¤ íƒìƒ‰í•˜ëŠ” ê²ƒì€, ì½”ì–´ Mì—ì„œ ëŒì•„ê°€ëŠ” í•« ë¦¬ë¡œë”ì—ê²ŒëŠ” ë„ˆë¬´ ë²„ê±°ìš´ ì‘ì—…ì¼í…Œë‹ˆ excludeì— ë‹¤ìŒì²˜ëŸ¼ ì¶”ê°€ì‹œì¼œì£¼ì—ˆë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Gemfile&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Gemfile.lock&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;LICENSE&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;README.md&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.vscode&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.git&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.gitignore&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.DS_Store&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ì¢€ ë‹¤ë¥¸ í•„ìš”ì—†ëŠ” íŒŒì¼ê¹Œì§€ ë‹¤ í•©ì³¤ë‹¤. ì´ë ‡ê²Œ í•˜ë‹ˆê¹Œ &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;ë¥¼ ì‹¤í–‰í•  ë•Œ ë¦¬ë¡œë“œ ì†ë„ê°€ í‰ê· ì ìœ¼ë¡œ 0.2ì´ˆ ì •ë„..? ë¹¨ë¦¬ì§„ ëŠë‚Œì´ë‹¤. (ëŒ€ëµ 2.0ì´ˆì—ì„œ 1.8ì´ˆì •ë„ê¹Œì§€ ì¤„ì—ˆë‹¤)&lt;/p&gt;

&lt;h2 id=&quot;ë Œë”ë§-í•˜ëŠ”ë°-ì˜¤ë˜ê±¸ë¦¬ëŠ”-íŒŒì¼-ìˆ˜ì •&quot;&gt;ë Œë”ë§ í•˜ëŠ”ë° ì˜¤ë˜ê±¸ë¦¬ëŠ” íŒŒì¼ ìˆ˜ì •&lt;/h2&gt;

&lt;p&gt;jekyll ì†ë„ ì´ìŠˆë¡œ ì°¾ë‹¤ë³´ë‹ˆ jekyllì—ì„œ í”„ë¡œíŒŒì¼ë§ ì˜µì…˜ì„ ì œê³µí•˜ëŠ” ê²ƒì„ ì•Œê²Œë˜ì—ˆë‹¤. ë‹¤ìŒì²˜ëŸ¼ ì‹¤í–‰í•˜ë©´ ëœë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Configuration file: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;github repo ê²½ë¡œ!!&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/jeongukjae.github.io/_config.yml
            Source: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;github repo ê²½ë¡œ!!&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/jeongukjae.github.io
       Destination: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;github repo ê²½ë¡œ!!&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/jeongukjae.github.io/_site
 Incremental build: disabled. Enable with &lt;span class=&quot;nt&quot;&gt;--incremental&lt;/span&gt;
      Generating...
       Jekyll Feed: Generating feed &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;posts

Filename                                       | Count |   Bytes |  Time
&lt;span class=&quot;nt&quot;&gt;-----------------------------------------------&lt;/span&gt;+-------+---------+------
_layouts/default.html                          |    57 | 775.53K | 0.214
_includes/meta.html                            |    57 |  54.90K | 0.093
feed.xml                                       |     1 | 123.26K | 0.083
sitemap.xml                                    |     1 |   8.51K | 0.062
_includes/svg-icons.html                       |    57 |  20.87K | 0.052
tags.html                                      |     1 |  33.85K | 0.049
_layouts/post.html                             |    49 | 541.59K | 0.029
_includes/analytics.html                       |    57 |   0.06K | 0.018
_posts/2018/2018-11-13-CNN ê³µë¶€.md              |     1 |   8.04K | 0.006
index.html                                     |     1 |  10.08K | 0.006
page2/index.html                               |     1 |  11.61K | 0.004
about.md                                       |     1 |   0.83K | 0.004
_includes/image.html                           |    12 |   4.28K | 0.004
...
...
                    &lt;span class=&quot;k&quot;&gt;done in &lt;/span&gt;2.226 seconds.
 Auto-regeneration: disabled. Use &lt;span class=&quot;nt&quot;&gt;--watch&lt;/span&gt; to enable.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ì´ë ‡ê²Œ ì­‰ ë‚˜ì˜¤ëŠ”ë°, tags.htmlì˜ ê²½ìš°ëŠ” ë§ì´ ì¤„ì¸ê±°ë‹¤. ì›ë˜ 0.150ì •ë„ë¥¼ ì¡ì•„ë¨¹ê³  ìˆì—ˆë‹¤.. ã… ã…  ëª¨ë“  í¬ìŠ¤íŠ¸ë¥¼ íƒœê·¸ ìˆ˜ + 1ë§Œí¼ ìˆœíšŒí•˜ëŠ”ë°, liquidì˜ ê¸°ëŠ¥ì´ ë¶€ì¡±í•œê±´ì§€ ë‚´ê°€ ëª»ì°¾ëŠ”ê±´ì§€ ë§ì´ëŠ” ëª»ì¤„ì´ê³  ì–´ë–¤ íƒœê·¸ê°€ ìˆëŠ”ì§€ ì°¾ì•„ì˜¤ëŠ” ë¶€ë¶„ë§Œ ì¤„ì˜€ë‹¤. ë¬¸ì„œë¥¼ ì°¾ì•„ë³´ë‹ˆ ì•„ë˜ì²˜ëŸ¼ ëª¨ë“  íƒœê·¸ë¥¼ ì¤‘ë³µì œê±°í•˜ë©´ì„œ ì •ë ¬í•´ì„œ ì´ë ‡ê²Œ ë“¤ê³  ì˜¬ ìˆ˜ ìˆë”ë¼.&lt;/p&gt;

&lt;div class=&quot;language-liquid highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;assign&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;all_tags&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;posts&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'tags'&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;compact&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;uniq&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;%}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ì´ë ‡ê²Œ ì‚¬ìš©í•˜ë‹ˆê¹Œ ì•½ê°„.. ë” ì¤„ì—ˆë‹¤. ë§¤ ë¦¬ë¡œë“œë§ˆë‹¤ 1.7 ~ 1.8ì´ˆì •ë„ ê±¸ë¦°ë‹¤. ê·¼ë° ì´ê²Œ ê·¸ë˜ë„ ë§ì´ ëŠë¦¬ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;incremental-serve&quot;&gt;incremental serve&lt;/h2&gt;

&lt;p&gt;jekyll ë¬¸ì„œì— &lt;a href=&quot;https://jekyllrb.com/docs/configuration/incremental-regeneration/&quot;&gt;incremental regeneration&lt;/a&gt;ì— ê´€í•œ ë¬¸ì„œê°€ ìˆë‹¤. ì•„ì§ experimental featureì´ê¸´ í•˜ì§€ë§Œ, ë­ ë³„ ë¬¸ì œ ì—†ìœ¼ë©´ ê°œì¸ìš©ìœ¼ë¡œ ì‚¬ìš©í• ë§Œ í•˜ë‹¤ê³  ìƒê°í•´ì„œ ì ìš©í•´ë³´ì•˜ë‹¤. ì ìš©í•´ë³´ë‹ˆ live reload, drafts ë¹Œë“œê¹Œì§€ í•©ì³¤ì„ ë•Œ 0.7ì´ˆê¹Œì§€ ì¤„ì–´ë“ ë‹¤.. ã… ã… ã… ã… ã…  ë­ 1ì´ˆ ê°€ê¹Œì´ ì¤„ì–´ë“  ì…ˆì´ë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;limit-posts&quot;&gt;limit posts&lt;/h2&gt;

&lt;p&gt;ê·¸ë¦¬ê³  í•œê°œì˜ í¬ìŠ¤íŠ¸ë§Œ ë¹Œë“œí•˜ë„ë¡ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤. ì–´ì°¨í”¼ ì‘ì„±ì‹œì—ëŠ” í•˜ë‚˜ì˜ í¬ìŠ¤íŠ¸ë§Œ ë³´ë‹ˆê¹Œ ì„¤ì •í•˜ë©´ ì¢‹ì„ ë“¯í•˜ë‹¤.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jekyll serve &lt;span class=&quot;nt&quot;&gt;--help&lt;/span&gt;
...
...
        &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--source&lt;/span&gt; SOURCE  Custom &lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;directory
            &lt;span class=&quot;nt&quot;&gt;--future&lt;/span&gt;       Publishes posts with a future date
            &lt;span class=&quot;nt&quot;&gt;--limit_posts&lt;/span&gt; MAX_POSTS  Limits the number of posts to parse and publish
        &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;no-]watch   Watch &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;changes and rebuild
...
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ì´ë ‡ê²Œ ì¤‘ê°„ì— &lt;code class=&quot;highlighter-rouge&quot;&gt;limit-posts&lt;/code&gt; ì˜µì…˜ì´ ìˆë‹¤. 1ë¡œ ì„¤ì •í•´ì„œ ì‚¬ìš©í•˜ì! ì´ë ‡ê²Œ ì“°ë‹ˆê¹Œ ì´ˆê¸° ë¡œë”©ì€ ì¡°ê¸ˆ ëŠë ¸ëŠ”ë° (2ì´ˆ) ì´ˆê¸°ë¡œë”©ê¹Œì§€ 0.6ì´ˆì •ë„ë¡œ ì—„ì²­ ë¹¨ë¼ì¡Œë‹¤!! ê²Œë‹¤ê°€ ë¼ì´ë¸Œ ë¼ë¡œë“œëŠ” 0.3ì´ˆì •ë„ë¡œ ê±°ì˜ ìˆ˜ì •ì‚¬í•­ì„ ë°”ë¡œ í™•ì¸í•  ìˆ˜ ìˆê²Œ ë¹¨ë¼ì¡Œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ê·¸ë˜ì„œ-ì´ë ‡ê²Œ-ì“°ëŠ”-ì¤‘ì´ë‹¤&quot;&gt;ê·¸ë˜ì„œ ì´ë ‡ê²Œ ì“°ëŠ” ì¤‘ì´ë‹¤&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jekyll serve &lt;span class=&quot;nt&quot;&gt;-lDI&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--limit-posts&lt;/span&gt; 1
Configuration file: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;githug repo ë§í¬ì…ë‹ˆë‹¤!!&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/jeongukjae.github.io/_config.yml
            Source: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;githug repo ë§í¬ì…ë‹ˆë‹¤!!&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/jeongukjae.github.io
       Destination: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;githug repo ë§í¬ì…ë‹ˆë‹¤!!&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;/jeongukjae.github.io/_site
 Incremental build: enabled
      Generating...
       Jekyll Feed: Generating feed &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;posts
                    &lt;span class=&quot;k&quot;&gt;done in &lt;/span&gt;0.657 seconds.
 Auto-regeneration: enabled &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{githug repo ë§í¬ì…ë‹ˆë‹¤!!}/jeongukjae.github.io'&lt;/span&gt;
LiveReload address: http://127.0.0.1:35729
    Server address: http://127.0.0.1:4000/
  Server running... press ctrl-c to stop.
      Regenerating: 1 file&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; changed at 2019-04-07 14:25:31
                    _posts/2019/2019-04-07-jekyll-ì†ë„-ì˜¬ë¦¬ê¸°.md
       Jekyll Feed: Generating feed &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;posts
                    ...done &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;0.363427 seconds.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ì €ì¥í•˜ê³  ë¸Œë¼ìš°ì € ì˜¬ë¦¬ë©´ ë¦¬ë¡œë“œê°€ ëë‚˜ ìˆì„ ì •ë„ì´ë‹¤. ëŒ€ëµ ì´ˆê¸°ë¡œë”©ë„ 2.5ì´ˆì •ë„ì—ì„œ 0.6 ~ 0.7ì´ˆê¹Œì§€ ì¤„ì—ˆê³ , ë¼ì´ë¸Œ ë¦¬ë¡œë“œë„ 2ì´ˆì—ì„œ 0.3 ~ 0.4ì´ˆê¹Œì§€ ì¤„ì—ˆë‹¤. ì´ì œ ì•ìœ¼ë¡œ í¸í•˜ê²Œ ë¸”ë¡œê·¸ ê¸€ ì‘ì„±í•©ì‹œë‹¤ ğŸ¤—&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><summary type="html">ê°œì¸ ë¸”ë¡œê·¸ë¡œ github pagesì™€ jekyllì„ ì‚¬ìš©í•˜ê³  ë‚˜ì„œë¶€í„° ë¡œì»¬ì—ì„œ jekyllì„ ëŒë¦¬ë©´ì„œ í¬ìŠ¤íŠ¸ê°€ ì œëŒ€ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ì§€ í‘¸ì‰¬í•˜ê¸° ì „ ë§¤ë²ˆ í™•ì¸í•˜ê³  ìˆë‹¤. ë³´í†µ ë‚˜ëŠ” í¬ìŠ¤íŠ¸ë¥¼ _drafts í´ë”ì— ìš°ì„  ë„£ì–´ë†“ê³  ì‘ì„±í•˜ëŠ” í¸ì´ë¼, ë“œë˜í”„íŠ¸ê¹Œì§€ ë¹Œë“œí•˜ë©´ì„œ í™•ì¸í•˜ê³  ìˆì—ˆëŠ”ë°, í•œë²ˆ ì €ì¥í•˜ë©´ ë‹¤ì‹œ ë¹Œë“œë ë•Œê¹Œì§€ ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦°ë‹¤. (12ì¸ì¹˜ ë§¥ë¶ì—ì„œ 2ì´ˆì •ë„ ê±¸ë¦°ë‹¤) ê·¸ë˜ì„œ ì´ê±¸ ì–´ë–»ê²Œ ë” ë¹ ë¥´ê²Œ ë§Œë“¤ ë°©ë²•ì´ ì—†ì„ê¹Œ í•˜ë©´ì„œ ì°¾ì•„ë³´ë‹¤ê°€ ì•„ë˜ì²˜ëŸ¼ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì˜ ì†ë„ë¥¼ ì˜¬ë ¸ë‹¤. (í‘¸ì‰¬ë˜ê³  ë‚œ í›„ì•¼.. ë­ ë‚´ ì„œë²„ ì•„ë‹ˆë‹ˆê¹Œ..)</summary></entry><entry><title type="html">ğŸ“• CS224n Lecture 2 Word Vectors and Word Senses</title><link href="https://jeongukjae.github.io/posts/2cs224n-lecture-2-word-vectors-and-word-senses/" rel="alternate" type="text/html" title="ğŸ“• CS224n Lecture 2 Word Vectors and Word Senses" /><published>2019-04-07T00:00:00+00:00</published><updated>2019-04-07T00:00:00+00:00</updated><id>https://jeongukjae.github.io/posts/2cs224n%20lecture%202%20word%20vectors%20and%20word%20senses</id><content type="html" xml:base="https://jeongukjae.github.io/posts/2cs224n-lecture-2-word-vectors-and-word-senses/">&lt;p&gt;CS224n ë‘ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!!&lt;/p&gt;

&lt;h2 id=&quot;finish-looking-at-word-vectors-and-word2vec&quot;&gt;Finish Looking at Word Vectors and Word2Vec&lt;/h2&gt;

&lt;p&gt;ì¼ë‹¨ ê°•ì˜ë¥¼ ì‹œì‘í•˜ë©´ì„œ ì§€ë‚œë²ˆ ê°•ì˜ë•Œë¶€í„° ì´ì–´ì„œ word2vecì™€ word vectorì— ê´€í•œ ë‚´ìš©ì„ ë§ˆë¬´ë¦¬í•œë‹¤. reviewë¥¼ í•´ë³´ë©´ word2vecì˜ main ideaëŠ” ì£¼ë³€ì˜ ë‹¨ì–´(context)ë¥¼ word vectorë¥¼ í†µí•´ ì˜ˆì¸¡í•˜ê±°ë‚˜ ê·¸ ë°˜ëŒ€ì˜ ê²ƒì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ì—ˆë‹¤. (CBOW, Skip-gram) í•œ ë‹¨ì–´ë‹¹ ë‘ê°œì˜ ë²¡í„°ë¥¼ ì‚¬ìš©í–ˆê³ , &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; (context), &lt;script type=&quot;math/tex&quot;&gt;\vec sv&lt;/script&gt; (center) ë‘ê°œì˜ ë²¡í„°ë¥¼ dot productë¥¼ í•œ ë‹¤ìŒì— softmaxë¥¼ ì·¨í•´ ê°’ë“¤ì„ ê³„ì‚°í–ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ í•™ìŠµ ê³¼ì •ì„ í†µí•´ ê²°ê³¼ë¡œ ë¹„ìŠ·í•œ ë‹¨ì–´ë¥¼ ë¹„ìŠ·í•œ ê³µê°„ì— ë†“ì•„ë†“ì•˜ë‹¤. ì´ ê³¼ì •ì´ cost functionì„ maximizeí•˜ëŠ” ê³¼ì •ì´ì—ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;optimization&quot;&gt;Optimization&lt;/h2&gt;

&lt;p&gt;ì´ì œ Optimizationì— ëŒ€í•´ ê³µë¶€ë¥¼ í•˜ëŠ”ë°, ìì„¸í•œ ë¶€ë¶„ì„ ê°€ë¥´ì¹˜ì§„ ì•Šìœ¼ë‹ˆ ì•Œì•„ë‘ë¼ê³  ë§í•œë‹¤. ìì„¸í•œ optimization ê³¼ì •ì€ CS229 (ì•„ë§ˆ ë¨¸ì‹  ëŸ¬ë‹ ìì²´ì— ëŒ€í•œ ê°•ì¢Œì˜€ë˜ ê±¸ë¡œ ê¸°ì–µí•œë‹¤)ë¥¼ ë“¤ì–´ë³´ë©´ ë°°ìš¸ ìˆ˜ ìˆë‹¤ê³ .&lt;/p&gt;

&lt;p&gt;ì–´ì¨Œë“  gradient descentë¥¼ ì‚¬ìš©í•´ì„œ &lt;script type=&quot;math/tex&quot;&gt;J(\theta)&lt;/script&gt;ë¥¼ minimize í•˜ëŠ”ë°, ê·¸ ê³¼ì •ì—ì„œ backpropì„ ì‚¬ìš©í•œë‹¤. ì—…ë°ì´íŠ¸ í•˜ëŠ” ë°©ë²•ì€&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_{new} = \theta_{old} - \alpha \nabla_{\theta} J(\theta)&lt;/script&gt;

&lt;p&gt;ì˜ ì‹ì„ í™œìš©í•œë‹¤. ì—¬ê¸°ì„œ alphaëŠ” step sizeë¡œ ê·¸ learning rateë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²ƒ ê°™ë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë¬¸ì œì ì€ ëª¨ë“  corpusì— ëŒ€í•´ ì´ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ì—°ì‚°ëŸ‰ì´ ë§ë‹¤. ê·¸ë˜ì„œ SGDë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, Stochastic Gradient Descentì´ë‹¤. samplingì„ í•´ì„œ Grdient Descentë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì´ëŸ¬í•œ ì´ì ì´ ìˆë‹¤ê³  í•œë‹¤.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;noiseê°€ ì ë‹¤&lt;/li&gt;
  &lt;li&gt;ë³‘ë ¬í™”ê°€ ê°€ëŠ¥í•˜ë‹¤ -&amp;gt; ë¹ ë¥¸ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;í•˜ì§€ë§Œ SGDë¥¼ ì ìš©í•˜ë©´ word vectorë“¤ì´ ë§¤ìš° sparseí•´ì§„ë‹¤. (samplingì„ í–ˆìœ¼ë‹ˆ..?) ê·¸ëŸ¼ ì—¬ê¸°ì„œ êµ³ì´ ë‹¤ ì—…ë°ì´íŠ¸ë¥¼ í•  í•„ìš”ê°€ ìˆë‚˜?ë¼ëŠ” ìƒê°ì´ ë“ ë‹¤. ê·¸ë˜ì„œ UV decompositionì„ ì‚¬ìš©í•˜ë¼ê³  í•œë‹¤. ì´ê±´ ì œëŒ€ë¡œ ì´í•´ë¥¼ ëª»í•œ ë¶€ë¶„ì¸ ê²ƒ ê°™ë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬íŠ¼ ì´ì œ word2vecë¥¼ êµ¬í˜„í•  ë•Œ ì™œ ë²¡í„°ë¥¼ ë‘ê°œë‚˜ ì“°ëŠ”ì§€ì— ëŒ€í•´ ì„¤ëª…ì„ í•´ì£¼ëŠ”ë°, ê·¸ ì´ìœ ëŠ” ê·¸ì € optimizationì´ ì‰¬ì›Œì§€ê¸° ë•Œë¬¸ì´ë¼ê³  í•œë‹¤. ì•„ë§ˆ ì´ê±´ ì´ë¡ ì ì¸ ì´ìœ ë³´ë‹¤ ì‹¤í—˜ì ì¸ ì´ìœ ê°€ ì•„ë‹ê¹Œ ì‹¶ë‹¤. í•™ìŠµì´ ëë‚˜ê³  ë‚˜ì„œ í‰ê· ì„ ì·¨í•´ì¤€ë‹¤ê³  í•œë‹¤.&lt;/p&gt;

&lt;p&gt;ê·¸ë¦¬ê³  ë‹¤ë¥¸ optim ë°©ë²•ì€ training method ë¶€ë¶„ì—ì„œ negative samplingì„ í•˜ëŠ” ë°©ë²•ë„ ìˆê³  (ë…¼ë¬¸ì„ ì½ì–´ë³´ì•˜ëŠ”ë° ë” ìì„¸íˆ ë´ì•¼í•  ê²ƒ ê°™ë‹¤) naive softmaxë¥¼ ì·¨í•˜ëŠ” ë°©ë²•ë„ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ negative samplingì— ëŒ€í•œ main ideaëŠ” true pairì™€ noise pairì— ëŒ€í•´ binary logistic regressionì„ í›ˆë ¨í•œë‹¤ëŠ” ê²ƒì´ë‹¤. NCEë„ ë‚˜ì˜¤ê³  ë­ ë§ì´ ë‚˜ì˜¤ë˜ë°, ë”°ë¡œ ì •ë¦¬í•˜ì ã… ã… &lt;/p&gt;

&lt;h2 id=&quot;capture-co-occurance-counts-directly&quot;&gt;Capture co-occurance counts directly?&lt;/h2&gt;

&lt;h3 id=&quot;count-base&quot;&gt;count base&lt;/h3&gt;

&lt;p&gt;ë‹¨ì–´ì˜ ìˆ«ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ co-occuranceë¥¼ íŒë‹¨í•˜ëŠ”ë°, ë‘ê°€ì§€ ë°©ì‹ì´ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;window sizeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°: syntactixí•œ ì •ë³´ì™€ semanticí•œ ì •ë³´ë¥¼ ë°›ì„ ìˆ˜ ìˆê³ , high dimensionalityí•œ ì´ìŠˆì™€ sparsityí•œ ì´ìŠˆê°€ ìˆë‹¤. ê·¸ë¦¬ê³  robustí•˜ì§€ ì•Šë‹¤. ê·¸ë˜ì„œ UV decompositionê°™ì€ ê²ƒì„ í†µí•´ low dimensionality vectorë¡œ ë°”ê¾¸ì–´ì¤€ë‹¤.&lt;/p&gt;

&lt;p&gt;full document -&amp;gt; general topicì— ê´€í•´ ì¡ì•„ë‚´ê¸° ì¢‹ë‹¤. (Latent Semantic Analysisë¥¼ ë³´ì) ëŒ€ì¶© ì´ëŸ° ìª½ìœ¼ë¡œëŠ” LSA, HAL, COALS, Hellinger-PCA ë“±ë“±ì´ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì–´ì¨Œë“  count baseëŠ” ë¹ ë¥´ê³ , íš¨ìœ¨ì ì¸ í†µê³„í•™ ê¸°ë°˜ì˜ ì ‘ê·¼ë²•ì´ê³ , ë‹¤ë§Œ ê¸°ëŠ¥ì´ ì œí•œì ì´ë©° ë§ì€ ê°¯ìˆ˜ì˜ ë‹¨ì–´(theê°™ì€?)ì— ëŒ€í•´ ì·¨ì•½í•˜ë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;direct-prediction&quot;&gt;direct prediction&lt;/h3&gt;

&lt;p&gt;ì–´ì©„ë“  ê·¸ë˜ì„œ ì§ì ‘ predictioní•˜ëŠ” ê²ƒìœ¼ë¡œ ë„˜ì–´ê°€ì. ì´ê±´ skip-gram, cbowë¥¼ ìƒê°í•˜ë©´ ëœë‹¤. ì„±ëŠ¥ì´ ë§¤ìš° ì¢‹ê³  ë³µì¡í•œ íŒ¨í„´ì— ëŒ€í•´ ë§¤ìš° ì˜ ì•Œì•„ì°¨ë¦°ë‹¤. ë‹¤ë§Œ corpus ì‚¬ì´ì¦ˆê°€ ë§¤ìš° ì¤‘ìš”í•˜ê³  íš¨ìœ¨ì ì´ì§€ ì•Šì€ í†µê³„ë¥¼ ì‚¬ìš©í•œë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;encodig-meaning-in-vector-differences&quot;&gt;Encodig Meaning in vector differences&lt;/h2&gt;

&lt;p&gt;co-occuranceë¥¼ ë¶„ì„í•´ì„œ meaning componentë¥¼ ì•Œì•„ë‚¸ë‹¤. ê·¼ë° ì´ê±´ ê·¸ëƒ¥ EMNLP 2014, Penningtokn et al. ì„ ì‚´í´ë³´ì.&lt;/p&gt;

&lt;h2 id=&quot;evaluating&quot;&gt;Evaluating&lt;/h2&gt;

&lt;p&gt;Intrinsicí•œ ë°©ë²•ê³¼ Extrinsicí•œ ë°©ë²•ì´ ìˆëŠ”ë°, Intrinsicí•œ ë°©ë²•ì€ ë¹ ë¥´ê³  clearí•˜ì§€ ì•Šë‹¤. ìì„¸í•œ ë°©ë²•ìœ¼ë¡œëŠ” cos-distanceë¥¼ í™œìš©í•´ analofy í…ŒìŠ¤íŠ¸ë¥¼ í•˜ê±°ë‚˜ wordsimë“±ì„ í™œìš©í•œë‹¤. Extrinsicí•œ ë°©ë²•ì€ ê¸´ ì‹œê°„ì´ ê±¸ë¦¬ì§€ë§Œ ì •í™•í•˜ë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ì¶”ê°€ë¡œ í•œ ë‹¨ì–´ê°€ ì—¬ëŸ¬ê°€ì§€ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ” ê²½ìš°ì— ëŒ€í•´ ë¶„ì„í•œ ë…¼ë¬¸ì´ ìˆëŠ”ë° ì´ê±´ Huang et al. 2012ì„ ì‚´í´ë³´ì.&lt;/p&gt;</content><author><name></name></author><category term="nlp" /><category term="cs224n" /><category term="machine learning" /><summary type="html">CS224n ë‘ë²ˆì§¸ ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸!!</summary></entry></feed>