<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Writer, IT Blog</title>
  
  <subtitle>Eric Han&#39;s IT Blog Powered by Hexo</subtitle>
  <link href="/feed.xml" rel="self"/>
  
  <link href="https://futurecreator.github.io/"/>
  <updated>2019-03-13T15:39:19.742Z</updated>
  <id>https://futurecreator.github.io/</id>
  
  <author>
    <name>Eric Han</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>서버리스 Serverless 아키텍처 파헤치기</title>
    <link href="https://futurecreator.github.io/2019/03/14/serverless-architecture/"/>
    <id>https://futurecreator.github.io/2019/03/14/serverless-architecture/</id>
    <published>2019-03-13T15:38:26.000Z</published>
    <updated>2019-03-13T15:39:19.742Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>서버리스(Serverless)하면 대부분 AWS Lambda 를 떠올리곤 합니다. 하지만 서버리스는 단순히 FaaS(Function-as-a-Service)만을 의미하지는 않습니다. 이번 포스트에서는 서버리스 아키텍처에 대한 개념과 키워드를 정리하고, FaaS 의 내부 구조를 살펴봅니다.</p><h2 id="serverless">Serverless</h2><p>서버리스는 말 그대로 ‘서버(Server)가 없다(-less)’는 뜻입니다. 그래서 처음 접했을 때 물리적인 서버가 아예 없고 클라이언트에서 모든 것을 처리하는 구조로 보이기도 합니다. 하지만 실제로 서버가 없는 구조는 아니고, 서버에서 처리하는 작업을 클라우드 기반의 서비스로 처리해서 서버 구축 및 관리 비용을 줄이는 구조입니다. 따라서 개발 기간과 비용을 단축할 수 있을 뿐 아니라, 서버 운영과 유지 보수의 어려움을 크게 줄일 수 있습니다.</p><p>서버리스는 두 가지 개념으로 나눌 수 있습니다.</p><ul><li>서비스형 서버리스(Serviceful Serverless)</li><li>FaaS(Functions as a Service)</li></ul><p>두 가지 모두 서비스 형태로 무언가를 제공한다는 의미인데요. 여기서 ‘서비스’라는 의미는 소유하지 않고 사용한 만큼만 비용을 지불한다는 의미입니다. 렌트카가 좋은 예입니다. 차를 구매하지 않아도 사용할 수 있고, 사용한만큼만 비용을 지불하니까요.</p><p>그럼 이 두 영역을 좀 더 자세하게 알아봅시다.</p><h3 id="serviceful-serverless">Serviceful Serverless</h3><p><img src="firebase.png" alt="모바일 백엔드에 기능을 서비스 형태로 제공하는 Google Firebase"></p><p>클라이언트의 사양이 좋아지고 각종 프레임워크가 발전하면서 많은 로직을 클라이언트에서 자체적으로 처리하게 되었습니다. 자연스럽게 서버의 역할은 줄어들었고, 서버에서 처리하는 작업은 단순해졌습니다.</p><p>서비스형 서버리스는 직접 서버를 구축하고 프로비저닝하고 관리할 필요 없이, 서버의 역할을 서비스 형태로 사용하는 것을 의미합니다. 예를 들어 인증의 경우, 매번 새로 구축해야 하지만 <a href="https://auth0.com/" rel="external nofollow noopener noreferrer" target="_blank">Auth0</a> 이나 <a href="https://aws.amazon.com/ko/cognito/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Cognito</a> 와 같은 인증 서비스를 사용하면 대부분의 구현을 대체할 수 있습니다.</p><p>특히 <a href="https://aws.amazon.com/ko/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Web Service</a> 나 <a href="https://cloud.google.com/" rel="external nofollow noopener noreferrer" target="_blank">Google Cloud Platform</a> 같은 Public Cloud 는 많은 종류의 서비스를 제공하고 있습니다. 단순히 컴퓨팅 리소스, 스토리지, 네트워크 뿐 아니라 머신 러닝과 모바일 백엔드, 머신 러닝, 블록체인, IoT, 그리고 인공위성 제어까지. 데이터베이스와 파일 스토리지, 메시징 서비스도 빼놓을 수 없죠. 이러한 기능을 복잡한 인프라 구성 없이  간편하게 사용할 수 있습니다.</p><h3 id="faas">FaaS</h3><p>FaaS(Function-as-a-Service)는 함수를 서비스로 제공하는 형태입니다. 개발자는 로직이 담긴 함수 구현만 신경쓰면 됩니다.</p><p>함수(코드)를 실행하기 위해 서버를 올리고 런타임을 구성하고 코드를 배포해서 실행해야 하는 일련의 과정을 없애고, 사용자가 원하는 로직을 함수로 작성만 해놓으면 (특정 조건 하에) 함수가 실행됩니다. 좀 더 구체적으로는 함수가 호출되면 VM(또는 컨테이너)가 실행되고 해당 런타임 내에서 정의해놓은 함수가 실행됩니다. 실행 후 VM(또는 컨테이너)는 종료됩니다.</p><p>이러한 함수는 서버가 계속 대기하면서 사용자의 요청을 처리하는 것이 아니라, 이벤트가 있을 때마다 실행되는 작은 코드입니다. 따라서 주요 서비스 사이에서 간단한 작업을 처리하는 용도로 쓰이고, FaaS 는 앞서 알아본 서비스형 애플리케이션과 결합해 시너지 효과를 낼 수 있습니다.</p><p><img src="https://d1.awsstatic.com/product-marketing/Lambda/Diagrams/product-page-diagram_Lambda-RealTimeFileProcessing.a59577de4b6471674a540b878b0b684e0249a18c.png" alt="AWS Lambda 이미지 처리 예제"></p><p>대표적인 FaaS 는 <a href="https://aws.amazon.com/ko/lambda/?nc2=h_m1" rel="external nofollow noopener noreferrer" target="_blank">AWS Lambda</a> 로 AWS 의 각종 서비스와 쉽게 연동됩니다. 예를 들어 사용자가 이미지를 업로드하면 해당 이미지를 해상도별로 처리해서 S3 에 저장하는 로직을 함수로 구현할 수 있습니다. 이외에도 Lambda 홈페이지에서 다양한 사례를 찾아볼 수 있습니다.</p><p>요청이 많으면 알아서 확장도 해주니 서버에 대해 신경쓸 필요가 없습니다. 비용은 함수가 실행되는 시간과 호출된 회수만큼만 지불합니다. 서버를 띄워놓았다면 요청이 없어도 비용을 지불하겠지만 람다는 요청이 없으면 비용도 지불하지 않습니다.</p><h2 id="aws-lambda">AWS Lambda</h2><p>FaaS 의 대표주자는 Lambda 입니다. 처음 Lambda 의 기본 개념은 간단했습니다. 그런데 서버리스의 활용도가 늘어나고 사람들의 관심이 많아지면서 AWS 는 서버리스 영역을 대폭 지원하고 있습니다.</p><table><thead><tr><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>IDE</td><td>Lambda 개발 플러그인 제공 (Eclipse, Intellij, Visual Studio Code, etc.)</td></tr><tr><td>Custom Runtime 지원</td><td>미지원 언어의 경우 직접 런타임을 구성할 수 있도록 지원 (e.g., Ruby, Erlang, Cobol)</td></tr><tr><td>실행 시간</td><td>최대 15분의 실행 시간</td></tr><tr><td><a href="https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/configuration-layers.html" rel="external nofollow noopener noreferrer" target="_blank">Lambda Layers</a></td><td>공통 패키지 모듈 지원으로 코드가 가벼워지고 개발 생산성 향상</td></tr><tr><td><a href="https://aws.amazon.com/ko/step-functions/" rel="external nofollow noopener noreferrer" target="_blank">AWS Step Functions</a></td><td>Lambda 함수를 단계적으로나 병렬적으로 실행할 수 있도록 워크플로우 구성</td></tr><tr><td><a href="https://firecracker-microvm.github.io/" rel="external nofollow noopener noreferrer" target="_blank">Firecraker</a></td><td>서버리스 컴퓨팅에 최적화된 microVM 오픈소스</td></tr><tr><td><a href="https://aws.amazon.com/ko/serverless/serverlessrepo/" rel="external nofollow noopener noreferrer" target="_blank">Serverless Application Repository</a></td><td>서버리스 애플리케이션을 공유하고 판매하는 마켓플레이스</td></tr></tbody></table><p>AWS Lambda 외에 주목할 만한 서비스도 있습니다.</p><ul><li><a href="https://cloud.google.com/knative/" rel="external nofollow noopener noreferrer" target="_blank">Knative</a>: 쿠버네티스(Kubernetes) 기반의 서버리스 플랫폼</li><li><a href="https://nuclio.io/" rel="external nofollow noopener noreferrer" target="_blank">Nuclio</a>: 직접 FaaS 를 제공할 수 있는 오픈 소스 서버리스 프레임워크</li></ul><h2 id="serverless-application">Serverless Application</h2><p>그렇다면 서버리스 애플리케이션이란 어떤 유형의 애플리케이션을 말할까요?</p><ul><li>클라이언트에서 사용자 인터랙션 로직을 대부분 처리</li><li>자주 사용하는 서버 기능은 서버리스형 서비스로 처리</li><li>각종 연계를 위해 사용하는 작은 함수(FaaS)</li></ul><p>먼저 클라이언트에서 사용자와 상호작용하는 로직을 대부분을 처리해서 서버의 역할을 줄입니다. 그리고 서버에서 제공하는 기능은 서버리스형 서비스를 적극 활용하고, 각 서비스 간 로직은 FaaS 를 이용해 구현합니다.</p><p>몇 가지 애플리케이션 형태에 따른 서버리스 아키텍처를 살펴보겠습니다. 여기서 사용한 모든 서비스는 AWS 의 서비스입니다.</p><h3 id="web-application">Web Application</h3><p><img src="web_application_architecture.png" alt="https://github.com/aws-samples/lambda-refarch-webapp"></p><p>먼저 일반적인 웹 애플리케이션을 서버리스 형태로 구성한 아키텍처입니다.</p><ul><li>사용자에게 보여줄 웹 페이지 및 정적 콘텐츠는 S3 에 저장 후 호스팅</li><li>사용자 요청은 API Gateway 로 받기</li><li>처리할 내용은 Lambda 에 작성</li><li>데이터 저장은 DB 서비스(DynamoDB) 사용</li><li>사용자 인증은 Amazon Cognito 사용</li><li>Route 53으로 도메인 구입 및 제공</li></ul><h3 id="mobile-backend">Mobile Backend</h3><p><img src="mobile-backend-architecture.png" alt="https://github.com/aws-samples/lambda-refarch-mobilebackend"></p><p>모바일 백엔드 아키텍처는 웹 애플리케이션과 비슷하지만 몇 가지 추가된 서비스가 있습니다.</p><ul><li>DynamoDB 에 저장하는 데이터는 람다를 이용해 검색엔진 서비스인 CloudSearch 에 저장합니다.</li><li>SNS(Simple Notification Service)를 이용해 사용자에게 푸시를 보냅니다.</li></ul><h3 id="real-time-stream-processing">Real-time Stream Processing</h3><p><img src="realtime-stream-processing-architecture.png" alt="https://github.com/aws-samples/lambda-refarch-streamprocessing"></p><p>이번엔 실시간 스트림 데이터를 처리하는 아키텍처입니다.</p><ul><li>Kinesis 로 실시간 스트리밍 데이터를 수집합니다.</li><li>람다에서 들어오는 데이터를 처리하고 저장합니다.</li><li>이벤트 자체를 장기간 보존하기 위해 S3 에 저장합니다.</li><li>수집한 데이터는 CloudWatch 를 이용해 모니터링할 수 있습니다.</li></ul><p>이러한 아키텍처 외에도 서버리스 애플리케이션을 효과적으로 설계하기 위한 디자인 패턴이 있습니다. OOP 설계를 잘하기 위해 디자인 패턴이 있는 것처럼 말이죠. 이에 대해서는 다음 포스트에서 자세히 다뤄보도록 하겠습니다.</p><h2 id="vs-xaas">vs. XaaS</h2><p>지금까지 서버리스에 대한 개념과 아키텍처에 대해 살펴봤습니다. 더 나아가기에 앞서, FaaS 라는 개념이 와닿지 않거나 기존 IaaS, PaaS 와는 어떻게 다른지 궁금하실 수 있습니다. 이런 서비스 형태를 통틀어 XaaS 라고 부르는데요, 피자에 비유해서 이해하기 쉽게 살펴보겠습니다. 바로 Pizza-as-a-Service 입니다.<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="http://www.paulkerrision.co.uk/">[1]</span></a></sup></p><p><img src="pizza-as-a-service.png" alt="Pizza as a Service"></p><ul><li><strong>홈메이드</strong>: 집에서 전기와 가스, 오븐부터 피자, 맥주, 친구까지 필요한 모든 것을 준비해야 합니다.</li><li><strong>공동 부엌</strong>: 돈을 내고 요리에 필요한 기구를 사용할 수 있는 공동 부엌입니다. 피자는 직접 만들어야 합니다.</li><li><strong>BYOP</strong>: 자기가 먹을 피자와 맥주를 직접 가져가는 Bring Your Own Plate 파티입니다.</li><li><strong>배달 주문</strong>: 피자를 시켜먹는 형태입니다. 맥주는 직접 시켜야 하고 친구들도 불러야 합니다.</li><li><strong>피자 매장</strong>: 친구들과 직접 매장에 가서 피자와 맥주를 사먹습니다.</li><li><strong>피자 파티</strong>: 모든 것이 준비되어 있습니다. 이미 친구들도 와있습니다. 그냥 즐기기만 하면 됩니다.</li></ul><p>이해하기 쉽게 먼저 비유를 살펴봤는데요, 이번엔 실제로 XaaS 를 비교해봅시다.</p><p><img src="xaas.png" alt="XaaS 비교"></p><ul><li><strong>Legacy</strong>: 기존 시스템은 인프라부터 소프트웨어까지 전부 구축하고 개발해야 합니다.</li><li><strong>Infrastructure-as-a-Service</strong>:필요한 하드웨어와 가상화, OS 등 인프라 요소를 서비스 형태로 제공합니다. 원하는 사양의 서버를 VM 으로 생성할 수 있습니다.</li><li><strong>Container-as-a-Service</strong>: 서비스 형태로 제공되는 컨테이너를 활용해 애플리케이션을 배포합니다.</li><li><strong>Platform-as-a-Service</strong>: 애플리케이션 개발에 집중할 수 있도록 인프라와 런타임 환경을 제공합니다.</li><li><strong>Function-as-a-Service</strong>: 실행할 함수 코드에만 집중할 수 있습니다.</li><li><strong>Software-as-a-Service</strong>: 제공되는 소프트웨어를 사용하는 형태입니다.</li></ul><p>여기서 유사하게 보이는 PaaS 와 FaaS 의  차이점은 다음과 같습니다.</p><ul><li>서버 유무: PaaS 는 그 플랫폼 위에 내 서버를 띄워야 하는 반면, FaaS 는 사용자가 관리할 서버가 없습니다.</li><li>확장: PaaS 는 확장이 서버 단위로, FaaS 는 함수 단위로 이루어집니다.</li><li>비용: PaaS 는 실행되는 서버 리소스의 스펙과 사용 시간에 따라 과금이 되고, FaaS 는 해당 함수의 호출 횟수와 수행 시간에 따라 과금됩니다.</li></ul><h2 id="function-구성-요소">Function 구성 요소</h2><p>이번엔 함수의 기본적인 구성 요소를 살펴봅시다.</p><p>다음은 Python 으로 &quot;Hello from Lambda!&quot;를 출력하는 함수입니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lambda_handler</span><span class="params">(event, context)</span>:</span></span><br><span class="line">    <span class="comment"># TODO implement</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">'statusCode'</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">'body'</span>: json.dumps(<span class="string">'Hello from Lambda!'</span>)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>다음은 Ruby 로 만든 예제입니다.</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">require</span> <span class="string">'json'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lambda_handler</span><span class="params">(<span class="symbol">event:</span>, <span class="symbol">context:</span>)</span></span></span><br><span class="line">    <span class="comment"># TODO implement</span></span><br><span class="line">    &#123; <span class="symbol">statusCode:</span> <span class="number">200</span>, <span class="symbol">body:</span> JSON.generate(<span class="string">'Hello from Lambda!'</span>) &#125;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>마지막으로 Node.js 런타임에서 동작하는 JavaScript 함수입니다.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">exports.handler = <span class="keyword">async</span> (event) =&gt; &#123;</span><br><span class="line">    <span class="comment">// TODO implement</span></span><br><span class="line">    <span class="keyword">const</span> response = &#123;</span><br><span class="line">        statusCode: <span class="number">200</span>,</span><br><span class="line">        body: <span class="built_in">JSON</span>.stringify(<span class="string">'Hello from Lambda!'</span>),</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>언어는 다르지만 모두 세 가지의 구성 요소로 이루어져 있다는 걸 알 수 있습니다.</p><ol><li>Handler 함수: 호출 시 실행되는 함수</li><li>Event 객체: 함수가 호출된 이벤트 정보를 담고 있는 객체</li><li>Context 객체: 해당 함수의 컨텍스트 정보(실행 관련 정보)를 담고 있는 객체</li></ol><h2 id="function-내부-구조">Function 내부 구조</h2><p>FaaS 는 개념적으로 보면 다음과 같이 구성되어 있습니다.</p><p><img src="faas-architecture.jpg" alt="https://www.slideshare.net/AmazonWebServices/optimizing-your-serverless-applications-srv401r2-aws-reinvent-2018"></p><ul><li>Event Source: 함수가 실행될 조건이자 이벤트 소스 (HTTP 요청, 메시징, Cron 등)</li><li>Function: 작업할 내용</li><li>Service: 작업 결과를 처리(DB 저장, 다른 서비스로 전달, 메시징, 출력 등)</li></ul><p>특정 조건 하에 이벤트가 발생하면 VM(또는 컨테이너)을 띄워서 해당 함수를 실행하고, 해당 결과를 지정한 대로 처리하게 됩니다. 여기서 함수를 실행하려면 해당 함수를 실행할 수 있는 환경이 필요한데요, 이를 런타임이라고 합니다. 당연한 얘기지만, 런타임은 해당 함수를 어떤 언어로 작성하느냐에 따라 다를 것입니다. Node.js, Python, Java 등 실행에 필요한 환경이 미리 설치되어 있어야 합니다.<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="AWS 에서는 런타임을 직접 만들어서 다양한 언어를 사용할 수 있도록 지원합니다.">[2]</span></a></sup></p><p><img src="lambda-function.jpg" alt="https://www.slideshare.net/AmazonWebServices/optimizing-your-serverless-applications-srv401r2-aws-reinvent-2018"></p><p>위 그림은 함수를 좀 더 자세히 들여다본 그림입니다.</p><ul><li>Compute substrate: 함수가 실행될 VM(또는 컨테이너)입니다.</li><li>Execution Environment: 그 위에 환경 변수 등 실행 환경이 포함됩니다.</li><li>Language runtime: 그 위에 언어별 런타임이 올라갑니다. 언어에 따라 성능 차이가 생깁니다 (e.g. Python vs. Node.js)</li><li>Your function: 마지막으로 우리가 작성한 코드 조각이 있습니다.</li></ul><h2 id="faas-성능-최적화">FaaS 성능 최적화</h2><p>FaaS 는 항상 띄워놓은 서버에 비해서 확실히 자원을 적게 소모하고 비용을 줄일 수 있습니다. 그런데 문제가 하나 있습니다. 서버에서 요청이 있을 때마다 VM 이나 컨테이너를 띄운다? 바로 성능 이슈가 생깁니다.</p><p>이번 섹션에서는 FaaS 의 성능을 향상시킬 수 있는 방법에 대해 알아봅니다.</p><h3 id="cold-start-delay">Cold Start Delay</h3><p><img src="function-lifecycle.jpg" alt="https://www.slideshare.net/AmazonWebServices/optimizing-your-serverless-applications-srv401r2-aws-reinvent-2018"></p><p>위 그림은 AWS Lambda 함수의 라이프사이클입니다. 처음에 해당 함수 코드를 찾아 다운로드하고 새로운 실행 환경을 구성합니다. 이 과정을 차갑게 식은 서버를 실행하는 것에 비유해 콜드 스타트(Cold Start)라고 합니다. 함수를 처음 호출할 때나 업데이트 된 후 실행할 경우 어쩔 수 없이 발생하는 지연(delay)입니다.</p><p>그렇다면 이런 콜드 스타트 지연을 어떻게 줄일 수 있을까요? 함수가 실행되고 나면 이후에 또 다른 호출을 대비해서 실행 컨텍스트를 잠깐 동안 유지합니다. 따라서 해당 서버가 아직 내려가지 않은 따뜻한(warm) 상태라면 준비 과정을 거치지 않고 빠르게 함수가 수행됩니다. 이를 이용해 주기적으로 함수를 호출하도록 스케줄링하면, 서버가 내려가지 않도록 warm 상태를 유지하게 됩니다.</p><p><img src="cold-start-performance.png" alt="https://medium.com/thundra/dealing-with-cold-starts-in-aws-lambda-a5e3aa8f532"></p><p>5분 마다 지속적으로 함수를 실행시켰더니 지연이 확실히 줄어든 걸 보실 수 있습니다. 하지만 계속해서 호출하다보니 비용이 추가적으로 발생합니다.</p><p>주의할 점은 컨텍스트가 동일하게 계속해서 유지될거란 보장은 없다는 겁니다. 콜드 스타트를 줄이기 위해서 해당 컨텍스트를 재사용하지만, 어떠한 이유로라도 서버는 새로운 컨텍스트를 생성할 수 있습니다. 따라서 컨텍스트가 재사용될 것을 염두에 두고 해당 컨텍스트에 저장된 값을 다른 함수에서 재사용해서는 안됩니다.</p><h3 id="execution-environment">Execution Environment</h3><p><img src="lambda-function.jpg" alt="https://www.slideshare.net/AmazonWebServices/optimizing-your-serverless-applications-srv401r2-aws-reinvent-2018"></p><p>위 그림은 람다 함수를 자세히 들여다 본 그림입니다. 위에서 한 번 본 그림이죠? 이번에 함수의 성능 향상을 위해서 살펴볼 부분은 서버 위에 구성될 실행 환경입니다.</p><p>이 실행 환경의 성능을 개선하려면 메모리를 더 하는 수밖에 없습니다. 람다의 경우 메모리만 지정할 수 있고 다른 리소스는 메모리를 기준으로 자동 할당됩니다. 물론 그만큼 비용은 더 지불해야 합니다. 빠른 성능을 원하면 돈을 더 내야하는 거죠. 여기서 재미있는 점은 돈을 많이 낸다고 성능이 그에 비례하게 올라가진 않는다는 점입니다. 즉, 가성비를 따져봐야 합니다.</p><p><img src="smart-resource-allocation.jpg" alt="https://www.slideshare.net/AmazonWebServices/optimizing-your-serverless-applications-srv401r2-aws-reinvent-2018"></p><p>위 그림을 보면 메모리를 더 많이 할당할수록 소요되는 시간이 줄어들어 성능이 향상된 걸 볼 수 있습니다. 하지만 비용은 256MB, 512MB 보다 1024MB 일 때가 더 저렴합니다. $0.00001 추가 비용으로 성능을 10배 정도 높인 셈입니다.</p><p>재미있는 점은 람다의 경우 호출 횟수와 메모리 사용량을 보고 과금을 한다는 점인데, 메모리만 적게 쓴다면 CPU 또는 네트워크를 많이 사용하더라도 비용을 적게 낼 수 있습니다.</p><h3 id="function">Function</h3><p>마지막으로 함수 영역을 최적화할 수 있는 방법입니다.</p><ul><li>함수는 처음 콜드 스타트할 때만 처음부터 끝까지 실행하고, 재사용할 때는 진입점인 핸들러 함수만 실행합니다. 따라서 필요치 않은 초기화 로직은 핸들러 밖으로 빼서 중복 실행되는 것을 막습니다.</li><li>라이브러리와 프레임워크는 꼭 필요한 것만 사용하고, 무거운 것보다는 가벼운 것을 사용합니다(e.g. Spring -&gt; Dagger, Guice).</li><li>코드를 간결하게 유지해야 합니다. 처음에 함수의 코드를 다운로드하고 압축을 풀기 때문에 코드의 양이 적을수록 좋습니다.</li><li>모든 로직을 하나의 함수에 담는 것보다 여러 작은 함수로 쪼개는 것이 좋습니다. 시간이 오래 걸리는 작업이 있을 경우 전체 리소스가 전부 대기해야 하기 때문입니다. 이런 경우 <a href="https://aws.amazon.com/ko/getting-started/tutorials/create-a-serverless-workflow-step-functions-lambda/" rel="external nofollow noopener noreferrer" target="_blank">AWS Step Functions</a> 를 이용해 서버리스 워크플로우를 구성하는 것도 하나의 방법입니다.</li></ul><p>이외에도 함수 코드를 작성할 때 참고할만한 팁입니다.</p><ul><li>핵심 로직에서 핸들러(진입점) 함수를 분리하면 단위 테스트를 더 많이 생성할 수 있습니다.</li><li>람다 환경 변수를 활용해 하드 코딩을 없앱니다.</li><li>재귀 함수 호출은 사용하지 않는 것이 좋습니다.</li></ul><h2 id="참고">참고</h2><ul><li><a href="https://blog.symphonia.io/revisiting-serverless-architectures-29f0b831303c" rel="external nofollow noopener noreferrer" target="_blank">Revisiting “Serverless Architectures”</a></li><li><a href="https://medium.com/@dabit3/full-stack-development-in-the-era-of-serverless-computing-c1e49bba8580" rel="external nofollow noopener noreferrer" target="_blank">Full-Stack Development in the Era of Serverless Computing</a></li><li><a href="https://www.slideshare.net/AmazonWebServices/optimizing-your-serverless-applications-srv401r2-aws-reinvent-2018" rel="external nofollow noopener noreferrer" target="_blank">Optimizing Your Serverless Applications</a></li></ul><h2 id="related-posts">Related Posts</h2><ul><li><a href="/2019/02/25/kubernetes-cluster-on-google-compute-engine-for-developers/" title="개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)">개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)</a></li><li><a href="/2019/01/19/spring-boot-containerization-and-ci-cd-to-kubernetes-cluster/" title="스프링 부트 컨테이너와 CI/CD 환경 구성하기">스프링 부트 컨테이너와 CI/CD 환경 구성하기</a></li><li><a href="/2018/11/09/it-infrastructure-basics/" title="개발자를 위한 인프라 기초 총정리">개발자를 위한 인프라 기초 총정리</a></li><li><a href="/2018/11/16/docker-container-basics/" title="도커 Docker 기초 확실히 다지기">도커 Docker 기초 확실히 다지기</a></li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">http://www.paulkerrision.co.uk/<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">AWS 에서는 런타임을 직접 만들어서 다양한 언어를 사용할 수 있도록 지원합니다.<a href="#fnref:2" rev="footnote"> ↩</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;서버리스(Serverless)하면 대부분 AWS Lambda 를 떠올
      
    
    </summary>
    
      <category term="Cloud" scheme="https://futurecreator.github.io/categories/Cloud/"/>
    
    
      <category term="aws" scheme="https://futurecreator.github.io/tags/aws/"/>
    
      <category term="lambda" scheme="https://futurecreator.github.io/tags/lambda/"/>
    
      <category term="cloud" scheme="https://futurecreator.github.io/tags/cloud/"/>
    
      <category term="gcp" scheme="https://futurecreator.github.io/tags/gcp/"/>
    
      <category term="serverless" scheme="https://futurecreator.github.io/tags/serverless/"/>
    
      <category term="faas" scheme="https://futurecreator.github.io/tags/faas/"/>
    
      <category term="serviceful_serverless" scheme="https://futurecreator.github.io/tags/serviceful-serverless/"/>
    
  </entry>
  
  <entry>
    <title>오픈 소스 컨트리뷰션을 위한 GitHub Fork &amp; Pull Request</title>
    <link href="https://futurecreator.github.io/2019/03/05/github-fork-and-pull-request-process-for-open-source-contribution/"/>
    <id>https://futurecreator.github.io/2019/03/05/github-fork-and-pull-request-process-for-open-source-contribution/</id>
    <published>2019-03-04T16:46:15.000Z</published>
    <updated>2019-03-04T16:49:35.239Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>GitHub 에서 오픈 소스를 사용하다보면 발견한 버그를 직접 수정하거나, 새로운 기능을 추가하고 싶을 때가 있습니다. 하지만 어디서부터 어떻게 시작해야할 지 막막하기도 합니다. 이번 포스트에서는 오픈 소스에 컨트리뷰션(기여)하는 절차를 간단히 알아보겠습니다.</p><h2 id="1-new-issue">1. New Issue</h2><p>먼저, 사용하다가 발견한 버그나 기능에 대한 의견을 이슈(Issue)로 만들어 제기합니다. 내가 바로 처리할 수 있는 것이라도 먼저 이슈를 제기해서 다른 사람들의 의견과 동의를 구하는 것이 좋습니다. 누군가는 해당 이슈에 대해 다르게 생각할 수도 있고, 내 아이디어를 발전시켜 줄 수도 있기 때문입니다.</p><p><img src="new-issue.png" alt="이슈 제기"></p><p><img src="same-issue.png" alt="비슷한 이슈를 발견했다는 코멘트"></p><p><img src="fix-issue.png" alt="이슈를 고치겠다는 컨트리뷰터"></p><p><img src="reopen-issue.png" alt="PR 반영 후에도 비슷한 이슈를 발견했다는 코멘트"></p><p>이렇게 올라간 이슈는 해당 주제에 대해 토론과 대화가 이뤄집니다. 이슈에는 새롭게 번호가 붙는데 <code>#</code> 을 이용해서 특정 이슈를 검색하거나 언급할 수 있습니다(e.g. 111번 이슈라면 <code>#111</code>). 그리고 이슈를 올리기 전에, 기존에 올라간 이슈 중에 비슷한 이슈가 있는지 미리 검색해보는 것이 좋습니다.</p><p>수정 또는 새로운 기능에 대한 동의가 이뤄지면 누군가가 개발을 해야하는데요, 이번엔 직접 개발해볼까요?</p><h2 id="2-fork-clone-하기">2. Fork &amp; Clone 하기</h2><p>먼저 기여하고 싶은 저장소에서 <strong>Fork</strong> 버튼을 눌러 포크를 진행합니다.</p><p><img src="fork-button.png" alt="기여하고 싶은 저장소"></p><p>그러면 내 계정으로 저장소가 복사됩니다.</p><p><img src="forked-repository.png" alt="포크된 저장소"></p><p>이렇게 포크된 저장소를 클론(Clone)해서 내려받습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/futureCreator/kube-backup.git</span><br></pre></td></tr></table></figure><h2 id="3-remote-repository-추가하기">3. Remote Repository 추가하기</h2><p>현재 원격 저장소(<code>origin</code>)은 포크된 우리의 저장소입니다. 이와 별개로 원래 저장소에서는 따로 개발이 진행될 것이기 때문에 최신 버전과 싱크를 맞추는 작업이 필요합니다. 그래서 원래 저장소도 원격 저장소(<code>upstream</code>)로 추가합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add upstream https://github.com/kuberhost/kube-backup.git</span><br></pre></td></tr></table></figure><p>추가된 저장소는 다음과 같이 확인할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git remote -v</span><br><span class="line">originhttps://github.com/futureCreator/kube-backup.git (fetch)</span><br><span class="line">originhttps://github.com/futureCreator/kube-backup.git (push)</span><br><span class="line">upstreamhttps://github.com/kuberhost/kube-backup.git (fetch)</span><br><span class="line">upstreamhttps://github.com/kuberhost/kube-backup.git (push)</span><br></pre></td></tr></table></figure><h2 id="4-branch-생성하고-작업하기">4. Branch 생성하고 작업하기</h2><p>이제 로컬에서 마음껏 작업하면 됩니다. 간단한 작업이라면 그냥 <code>master</code> 브랜치에서 작업해도 됩니다. 하지만 복잡한 작업은 새로운 브랜치(e.g. <code>newfeature</code>)를 생성해서 작업하는 것이 좋겠죠.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git checkout master</span><br><span class="line">git branch newfeature   </span><br><span class="line">git checkout newfeature</span><br></pre></td></tr></table></figure><p>작업할 때 커밋 메시지를 고민하는 경우가 많은데, 로컬에서 개발할 때는 커밋 메시지를 크게 고민하지 않아도 됩니다. 푸시(Push)하지 않는 한 해당 메시지는 올라가지 않으니까요. 푸시 하기 전에 커밋 내역을 정리할 수 있으므로 로컬에서는 마음껏 커밋해도 괜찮습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git commit add .</span><br><span class="line">git commit -m ‘Update ...’</span><br></pre></td></tr></table></figure><h2 id="5-작업-정리하기">5. 작업 정리하기</h2><p>작업이 완료된 후 푸시하기 전에 원래 저장소에 수정된 작업이 있으면 포크된 저장소와 싱크를 맞춰야 합니다. <code>upstream</code> 브랜치와 <code>master</code> 를 머지(Merge)합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git fetch upstream</span><br><span class="line">git checkout master</span><br><span class="line">git merge upstream/master</span><br></pre></td></tr></table></figure><p>이제 <code>rebase -i</code> 명령어를 이용해 커밋 내역을 정리하고 <code>newfeature</code> 와 <code>master</code> 브랜치를 합칩니다. <code>-i</code> 옵션은 인터랙티브 옵션으로 커밋 이력을 보여주고, 사용자가 특정 커밋을 선택하거나 합칠 수 있는 명령어입니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout newfeature</span><br><span class="line">git rebase -i master</span><br></pre></td></tr></table></figure><h2 id="6-push-하기">6. Push 하기</h2><p>이제 모든 수정 사항이 반영된 <code>master</code> 브랜치를 포크된 원격 저장소(<code>origin</code>)으로 푸시합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin master</span><br></pre></td></tr></table></figure><h2 id="7-pull-request-만들기">7. Pull Request 만들기</h2><p>GitHub 웹 페이지에서 포크한 저장소를 찾아가면 내가 푸시한 브랜치 기반으로 <strong>Create Pull Request</strong> 버튼이 생긴 걸 볼 수 있습니다. 또는 <strong>Compare</strong> 버튼을 눌러 브랜치를 비교하고, 원하는 브랜치로 Pull Request 를 생성할 수 있습니다. 인터페이스가 직관적이어서 쉽게 비교할 수 있습니다.</p><p><img src="comparing-changes.png" alt="Pull Request 만들기"></p><p>Pull Request 생성 시 본문에 수정한 내용을 간단히 적을 수 있는데요, 특정 문법으로 해당 이슈를 바로 닫을(Close) 수 있습니다.</p><ul><li>close</li><li>closes</li><li>closed</li><li>fix</li><li>fixes</li><li>fixed</li><li>resolve</li><li>resolves</li><li>resolved</li></ul><p>e.g. 111번 이슈에 대한 PR: <code>close #111</code>, <code>fixes #111</code>, etc.</p><p>그럼 Pull Request 가 승인될 때 해당 이슈가 자동으로 닫힙니다.</p><h2 id="8-merged">8. Merged!</h2><p><img src="merged.png" alt="Pull Request 승인"></p><p>생성된 Pull Request 가 검토 과정을 거쳐 승인이 나면 수정한 소스는 원본 소스로 머지됩니다.</p><p><img src="closed-issue.png" alt="해결된 이슈"></p><p>해당 이슈는 자동으로 닫혔습니다.</p><p>물론 승인이 나지 않을 수도 있습니다. 방향이 다르거나 혹은 더 수정이 필요한 것일 수도 있습니다.</p><h2 id="정리">정리</h2><p>이번 포스트에서는 오픈 소스 기여 절차에 대해 알아봤습니다. 컨트리뷰션이라고 하면 거창해보이지만 꼭 대단한 기여만 있는 것은 아닙니다. 작은 버그를 발견하고 이슈를 제기하는 것도 일종의 기여이고, 해당 오픈 소스가 발전할 수 있도록 의견을 제시하는 것도 일종의 기여니까요. 직접 소스를 커밋해서 이슈를 해결하려면 그 전에 커뮤니티의 의견을 듣고 동의를 구하는 과정이 중요한 것 같습니다. 그렇게 여러 사람이 힘을 모아서 소프트웨어를 발전시켜 나가는 것이 진정한 오픈 소스의 힘이 아닐까 합니다.</p><h2 id="참고">참고</h2><ul><li><a href="https://gist.github.com/Chaser324/ce0505fbed06b947d962" rel="external nofollow noopener noreferrer" target="_blank">GitHub Forking</a></li><li><a href="https://help.github.com/articles/closing-issues-using-keywords/" rel="external nofollow noopener noreferrer" target="_blank">Closing issues using keywords</a></li></ul><h2 id="related-posts">Related Posts</h2><ul><li><a href="/2018/06/07/computer-system-time/" title="컴퓨터 시간의 1970년은 무슨 의미일까?">컴퓨터 시간의 1970년은 무슨 의미일까?</a></li><li><a href="/2018/06/05/metasyntactic-variables-foo-bar/" title="foo, bar 의 어원을 찾아서">foo, bar 의 어원을 찾아서</a></li><li><a href="/2018/06/11/about-clean-code/" title="클린코드가 시작되는 곳">클린코드가 시작되는 곳</a></li><li><a href="/2018/09/09/software-versioning/" title="SW 라이브러리 버전 제대로 읽기">SW 라이브러리 버전 제대로 읽기</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;GitHub 에서 오픈 소스를 사용하다보면 발견한 버그를 직접 수정하
      
    
    </summary>
    
      <category term="Programming" scheme="https://futurecreator.github.io/categories/Programming/"/>
    
    
      <category term="github" scheme="https://futurecreator.github.io/tags/github/"/>
    
      <category term="open_source" scheme="https://futurecreator.github.io/tags/open-source/"/>
    
      <category term="issue" scheme="https://futurecreator.github.io/tags/issue/"/>
    
      <category term="pull_request" scheme="https://futurecreator.github.io/tags/pull-request/"/>
    
      <category term="fork" scheme="https://futurecreator.github.io/tags/fork/"/>
    
      <category term="clone" scheme="https://futurecreator.github.io/tags/clone/"/>
    
      <category term="community" scheme="https://futurecreator.github.io/tags/community/"/>
    
  </entry>
  
  <entry>
    <title>Git과 CronJob을 활용한 쿠버네티스 오브젝트 YAML 자동 백업</title>
    <link href="https://futurecreator.github.io/2019/02/27/kubernetes-object-yaml-auto-backup-using-git-and-cronjob/"/>
    <id>https://futurecreator.github.io/2019/02/27/kubernetes-object-yaml-auto-backup-using-git-and-cronjob/</id>
    <published>2019-02-26T15:10:14.000Z</published>
    <updated>2019-02-26T15:18:20.314Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>쿠버네티스(Kubernetes)에서 시시각각으로 변하는 오브젝트의 상태를 저장하고 관리하려면 어떻게 해야 할까요? 가장 먼저 생각할 수 있는 방법은 YAML 파일로 export 해서 저장하는 것입니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># e.g. kube-system Namespace 의 모든 Pod 을 YAML 형태로 출력하기</span></span><br><span class="line">kubectl get po -n kube-system -o yaml</span><br></pre></td></tr></table></figure><p>Pod 뿐만 아니라 Deployment, Service, ConfigMap 등 모든 Namespace 의 다양한 오브젝트를 YAML 형태로 출력할 수 있습니다. YAML 은 복잡하지 않고 데이터를 체계적으로 보여주기 때문에 읽기 쉬운 장점이 있습니다. 이를 주기적으로 수행하도록 쉘 스크립트를 짜서 관리할 수도 있을텐데요. YAML 파일을 만들기는 쉽지만 관리가 어렵고, 문제가 생겼을 시에 활용하기 어려운 단점이 있습니다.</p><p>이번 포스트에서는 이런 문제를 해결할 수 있는 오픈 소스를 소개하려고 합니다.</p><h2 id="kube-backup">Kube-backup</h2><p><a href="https://github.com/kuberhost/kube-backup" rel="external nofollow noopener noreferrer" target="_blank">Kube-backup</a> 은 Git과 CronJob 을 이용해 쿠버네티스 오브젝트를 YAML 파일로 백업하는 오픈소스입니다.</p><p>이 오픈소스의 핵심은 다음과 같습니다.</p><ul><li>설정한 쿠버네티스 오브젝트를 YAML 파일로 백업</li><li>지정한 Git의 브랜치로 Push</li><li>CronJob 형태로 주기적 수행</li></ul><p><img src="https://user-images.githubusercontent.com/26019/48974539-12be7600-f097-11e8-91d7-b19c4c8d3e23.png" alt="https://github.com/kuberhost/kube-backup"></p><p>설정을 이용해 백업할 오브젝트의 선별이 쉽고, Namespace 와 오브젝트 별로 체계적인 분류가 가능합니다.</p><p><img src="https://user-images.githubusercontent.com/26019/48974571-b9a31200-f097-11e8-8f0a-52afc67e4112.png" alt="https://github.com/kuberhost/kube-backup"></p><p>또한 Git 을 이용해서 변경 이력을 관리하기가 쉽고 문제가 생기는 부분을 쉽게 파악할 수 있습니다. 또한 변경이 있는 부분만 Push 하기 때문에 관리가 용이하고, 시스템 버전에 따라서 저장소 또는 브랜치를 분리해서 관리할 수 있습니다.</p><p>물론 위 그림은 간단한 클러스터의 경우이고, 대규모 운영 클러스터의 경우에는 백업할 내용이 많아 적절한 설정이 필요합니다.</p><h2 id="클러스터-준비하기">클러스터 준비하기</h2><p>먼저 설치할 클러스터가 필요합니다. 이번 포스트에서는 쿠버네티스 클러스터가 있다는 전제 하에 진행됩니다. 쿠버네티스 클러스터가 필요하다면 다음 포스트를 참고하세요.</p><a href="/2019/02/25/kubernetes-cluster-on-google-compute-engine-for-developers/" title="개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)">개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)</a><h2 id="사전-준비하기">사전 준비하기</h2><p>그럼 실제 클러스터에 배포해보겠습니다. <a href="https://github.com/kuberhost/kube-backup" rel="external nofollow noopener noreferrer" target="_blank">GitHub 리파지토리</a>에 있는 배포용 YAML 을 이용하면 쉽게 배포가 가능합니다. 그 전에 앞서 몇 가지 설정이 필요합니다.</p><p><img src="create-github-repository.png" alt="GitHub 리파지토리 생성하기"></p><p>먼저 백업 YAML 파일을 저장할 라피지토리가 필요하겠죠? GitHub이나 GitLab 등 원하는 리파지토리를 생성합니다. 백업용이니까 Private 리파지토리가 좋겠습니다. 이번 포스트에는 GitHub 기준으로 진행합니다.</p><p>그리고 기본 설정인 <code>master</code> 브랜치가 필요하므로 <code>README.md</code> 파일로 초기화해서 <code>master</code> 브랜치를 만들어줍니다.</p><p>이렇게 프로그램 상에서 자동으로 Git 에 접속하는 경우에는 <code>https</code> 대신 <code>ssh</code> 방식을 사용합니다. <code>https</code> 방식은 보안을 위해 계정 정보를 직접 입력해야 하기 때문에 Key 를 이용해 인증을 할 수 있는 <code>ssh</code>방식을 사용합니다.</p><p>이를 위해서 먼저 포트가 열려 있어야 합니다. 운영 환경의 경우에는 방화벽이 있을 수 있으므로 사전에 <code>22</code> 포트를 오픈합니다.</p><p>그리고 GitHub 에 접속할 SSH Key 를 생성합니다. GitHub 에서는 다른 리파지토리 또는 유저가 사용하는 Key 를 사용할 수 없기 때문에 새로 Key 를 생성합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -f ./new-key</span><br></pre></td></tr></table></figure><p>그러면 Private Key 와 Public Key 한 쌍이 생성됩니다.</p><p><img src="deploy-keys.png" alt="Public Key 등록하기"></p><p>이제 GitHub 의 <strong>Settings &gt; Deploy Keys</strong> 에 생성한 Public Key 를 등록합니다.</p><p><img src="deploy-yaml-files.png" alt="배포용 YAML 파일"></p><p>배포용 YAML 파일을 내려받습니다. 또는 포스트에 내용을 복사해서 사용합니다.</p><h2 id="설치하기">설치하기</h2><p>배포용 YAML 파일명 앞에 붙어있는 숫자 순서대로 설치를 진행하면 됩니다.</p><h3 id="namespace">Namespace</h3><p><code>0_namespace.yaml</code> 파일로 Namespace <code>kube-backup</code> 을 생성합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-backup</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f 0_namespace.yaml</span><br></pre></td></tr></table></figure><h3 id="rbac">RBAC</h3><p>그리고 <code>1_service_account.yaml</code> 파일로 ServiceAccount 를 생성하고 Role 을 설정합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-backup-user</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-backup</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-backup-view-all</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="attr">  resources:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="attr">  verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">]</span></span><br><span class="line"><span class="attr">- nonResourceURLs:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="attr">  verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">]</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-backup-user</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">kube-backup-user</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">kube-backup</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-backup-view-all</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="attr">psp:unprivileged</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-backup</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="attr">podsecuritypolicy:unprivileged</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">Group</span></span><br><span class="line"><span class="attr">    name:</span> <span class="attr">system:serviceaccounts:kube-backup</span></span><br><span class="line"><span class="attr">    apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f 1_service_account.yaml</span><br></pre></td></tr></table></figure><h3 id="configmap">ConfigMap</h3><p>다음으로 <code>2_config_map.yaml</code>에 위에서 만든 SSH key 를 추가합니다. 해당 ConfigMap 은 Volume 으로 마운트되어 컨테이너에서 Git Clone 및 Push 할 때 사용됩니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-backup-ssh-config</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-backup</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">  id_rsa:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    -----BEGIN RSA PRIVATE KEY-----</span></span><br><span class="line"><span class="string">    # private key 내용 추가</span></span><br><span class="line"><span class="string">    -----END RSA PRIVATE KEY-----</span></span><br><span class="line"><span class="string">  id_rsa.pub: |</span></span><br><span class="line"><span class="string">    # public key 내용 추가</span></span><br></pre></td></tr></table></figure><p><code>2_config_map.yaml</code> 파일을 이용해 ConfigMap 을 생성합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f 2_config_map.yaml</span><br></pre></td></tr></table></figure><h3 id="cronjob">CronJob</h3><p>이제 <code>3_cronjob.yaml</code>를 수정해 백업을 수행할 CronJob 을 만들어봅시다.</p><p>먼저 해당 CronJob 의 스케쥴을 원하는 만큼 cron 형태로 수정합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  schedule:</span> <span class="string">"0 */1 * * *"</span> <span class="comment"># e.g. 매 정시 수행</span></span><br></pre></td></tr></table></figure><p>여기서 주의할 점은 특정 시각을 cron으로 설정하는 경우는 UTC 기준으로 설정해야 합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># e.g. 매일 오전 1시에 백업 수행</span></span><br><span class="line"><span class="comment"># 01:00 KST -&gt; 16:00 UTC</span></span><br><span class="line"><span class="attr">schedule:</span> <span class="string">"0 16 * * *"</span></span><br></pre></td></tr></table></figure><p>다음으로 <code>GIT_REPO</code>에 백업할 저장소 위치를 SSH 형식으로 추가합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">env:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">GIT_REPO_URL</span></span><br><span class="line"><span class="attr">    value:</span> <span class="string">git@github.com:futureCreator/kube-backup-test.git</span></span><br></pre></td></tr></table></figure><p>Custom Resource 는 따로 이름을 추가해줘야 합니다. 다음 명령어로 Custom Resources 를 조회합니다.<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="jq 설치 안내 https://zetawiki.com/wiki/리눅스_jq_다운로드_설치">[1]</span></a></sup></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl get crd -o json | jq -r <span class="string">'.items | (.[] | [.spec.names.singular, .spec.group, .spec.scope]) | @tsv'</span></span><br><span class="line"><span class="comment"># 출력 예시</span></span><br><span class="line">adapter            config.istio.io         Namespaced</span><br><span class="line">alertmanager       monitoring.coreos.com   Namespaced</span><br><span class="line">apikey             config.istio.io         Namespaced</span><br><span class="line">attributemanifest  config.istio.io         Namespaced</span><br><span class="line">clusterbus         channels.knative.dev    Cluster</span><br></pre></td></tr></table></figure><p>출력 결과를 보면 세 번째 열의 항목이 <code>Namespaced</code> 와 <code>Cluster</code> 로 나뉘는데 이에 맞춰서 <code>EXTRA_RESOURCES</code> 와 <code>EXTRA_GLOBAL_RESOURCES</code> 로 나눠서 추가합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">env:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">EXTRA_GLOBAL_RESOURCES</span> <span class="comment"># spec.scope 이 Cluster인 항목</span></span><br><span class="line"><span class="attr">    value:</span> <span class="string">clusterbus</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">EXTRA_RESOURCES</span> <span class="comment"># spec.scope이 Namespaced인 항목</span></span><br><span class="line"><span class="attr">    value:</span> <span class="string">adapter,</span> <span class="string">alertmanager,</span> <span class="string">apikey,</span> <span class="string">attributemanifest</span></span><br></pre></td></tr></table></figure><p>Commit 에 사용할 타임존을 설정합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">env:</span> </span><br><span class="line"><span class="attr">  - name:</span> <span class="string">TZ</span></span><br><span class="line"><span class="attr">    value:</span> <span class="string">:Asia/Seoul</span></span><br></pre></td></tr></table></figure><p>여기까지 작성한 CronJob의 예시입니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-system-backup</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-backup</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  schedule:</span> <span class="string">"0 */1 * * *"</span></span><br><span class="line"><span class="attr">  concurrencyPolicy:</span> <span class="string">Forbid</span></span><br><span class="line"><span class="attr">  successfulJobsHistoryLimit:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  failedJobsHistoryLimit:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  jobTemplate:</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      template:</span></span><br><span class="line"><span class="attr">        spec:</span></span><br><span class="line"><span class="attr">          restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line"><span class="attr">          serviceAccount:</span> <span class="string">kube-backup-user</span></span><br><span class="line"><span class="attr">          containers:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">backup</span></span><br><span class="line"><span class="attr">              image:</span> <span class="string">kuberhost/kube-backup</span></span><br><span class="line"><span class="attr">              imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">              env:</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">BACKUP_VERBOSE</span></span><br><span class="line"><span class="attr">                  value:</span> <span class="string">"1"</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">GIT_REPO_URL</span></span><br><span class="line"><span class="attr">                  value:</span> <span class="string">git@github.com:futureCreator/kube-backup-test.git</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">EXTRA_GLOBAL_RESOURCES</span></span><br><span class="line"><span class="attr">                  value:</span> <span class="string">clusterbus</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">EXTRA_RESOURCES</span></span><br><span class="line"><span class="attr">                  value:</span> <span class="string">adapter,</span> <span class="string">alertmanager,</span> <span class="string">apikey,</span> <span class="string">attributemanifest</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">TZ</span></span><br><span class="line"><span class="attr">                  value:</span> <span class="string">:Asia/Seoul</span></span><br><span class="line"><span class="attr">              volumeMounts:</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">ssh-config</span></span><br><span class="line"><span class="attr">                  mountPath:</span> <span class="string">/root/.ssh/id_rsa</span></span><br><span class="line"><span class="attr">                  subPath:</span> <span class="string">id_rsa</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">ssh-config</span></span><br><span class="line"><span class="attr">                  mountPath:</span> <span class="string">/root/.ssh/id_rsa.pub</span></span><br><span class="line"><span class="attr">                  subPath:</span> <span class="string">id_rsa.pub</span></span><br><span class="line"><span class="attr">          volumes:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">ssh-config</span></span><br><span class="line"><span class="attr">              configMap:</span></span><br><span class="line"><span class="attr">                name:</span> <span class="string">kube-backup-ssh-config</span></span><br><span class="line"><span class="attr">                defaultMode:</span> <span class="number">256</span></span><br></pre></td></tr></table></figure><p>테스트 시에는 Pod 으로 생성하면 편리합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-system-backup</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-backup</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line"><span class="attr">  serviceAccount:</span> <span class="string">kube-backup-user</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">backup</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">kuberhost/kube-backup</span></span><br><span class="line"><span class="attr">    imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">    env:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">BACKUP_VERBOSE</span></span><br><span class="line"><span class="attr">      value:</span> <span class="string">"1"</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">GIT_REPO_URL</span></span><br><span class="line"><span class="attr">      value:</span> <span class="string">git@github.com:futureCreator/kube-backup-test.git</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">EXTRA_GLOBAL_RESOURCES</span></span><br><span class="line"><span class="attr">      value:</span> <span class="string">clusterbus</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">EXTRA_RESOURCES</span></span><br><span class="line"><span class="attr">      value:</span> <span class="string">adapter,</span> <span class="string">alertmanager,</span> <span class="string">apikey,</span> <span class="string">attributemanifest</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">TZ</span></span><br><span class="line"><span class="attr">      value:</span> <span class="string">:Asia/Seoul</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">ssh-config</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/root/.ssh/id_rsa</span></span><br><span class="line"><span class="attr">      subPath:</span> <span class="string">id_rsa</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">ssh-config</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/root/.ssh/id_rsa.pub</span></span><br><span class="line"><span class="attr">      subPath:</span> <span class="string">id_rsa.pub</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">ssh-config</span></span><br><span class="line"><span class="attr">    configMap:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">kube-backup-ssh-config</span></span><br><span class="line"><span class="attr">      defaultMode:</span> <span class="number">256</span></span><br></pre></td></tr></table></figure><p><code>3_cronjob.yaml</code> 파일로 CronJob 을 생성합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f 3_cronjob.yaml</span><br></pre></td></tr></table></figure><h2 id="확인하기">확인하기</h2><p>설정한 시간마다 Job 과 Pod 이 생성되고 작업이 수행되는 것을 확인할 수 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n kube-backup</span><br><span class="line">NAME                                      READY     STATUS      RESTARTS   AGE</span><br><span class="line">pod/kube-system-backup-1547712000-zcdr9   0/1       Completed   0          1h</span><br><span class="line">pod/kube-system-backup-1547715600-x6988   0/1       Completed   0          1m</span><br><span class="line"></span><br><span class="line">NAME                                      DESIRED   SUCCESSFUL   AGE</span><br><span class="line">job.batch/kube-system-backup-1547712000   1         1            1h</span><br><span class="line">job.batch/kube-system-backup-1547715600   1         1            1m</span><br><span class="line"></span><br><span class="line">NAME                               SCHEDULE      SUSPEND   ACTIVE    LAST SCHEDULE   AGE</span><br><span class="line">cronjob.batch/kube-system-backup   0 */1 * * *   False     0         1m              7d</span><br></pre></td></tr></table></figure><p>GitHub에서 Commit 내역을 확인할 수 있습니다.</p><p><img src="github-repository.png" alt="GitHub Repository"></p><p><img src="commit-history.png" alt="Commit 내역"></p><p>Commit 상세 내역에서 변경 사항을 확인할 수 있습니다.</p><p><img src="commit-diff.png" alt="Commit 상세 내역"></p><h2 id="추가-설정하기">추가 설정하기</h2><p>필요한 경우 환경변수(<code>env</code>)에 설정을 추가할 수 있습니다.</p><table><thead><tr><th>항목</th><th>내용</th></tr></thead><tbody><tr><td>SKIP_NAMESPACES</td><td>특정 네임스페이스 제외</td></tr><tr><td>SKIP_GLOBAL_RESOURCES</td><td>특정 글로벌 리소스 제외</td></tr><tr><td>SKIP_RESOURCES</td><td>특정 리소스 제외</td></tr><tr><td>SKIP_OBJECTS</td><td>특정 오브젝트 제외</td></tr><tr><td>ONLY_NAMESPACES</td><td>특정 네임스페이스의 항목만 관리(whitelist)</td></tr><tr><td>GIT_USER</td><td>기본은 <code>kube-backup</code></td></tr><tr><td>GIT_EMAIL</td><td>기본은 <code>kube-backup@$(HOSTNAME)</code></td></tr><tr><td>GIT_BRANCH</td><td>기본은 <code>master</code> 브랜치</td></tr></tbody></table><p>이 외에도 Grafana 의 Dashboard 및 설정을 백업하기 위한 옵션도 있습니다. 백업 내용은 <code>_grafana_</code> 폴더에 저장됩니다.</p><table><thead><tr><th>항목</th><th>내용</th></tr></thead><tbody><tr><td>GRAFANA_URL</td><td>Grafana 의 URL</td></tr><tr><td>GRAFANA_TOKEN</td><td>Grafana API Key</td></tr></tbody></table><p>API Key 는 Grafana 의 <strong>Configuration &gt; API Keys</strong> 에서 Admin 권한으로 생성하면 됩니다.</p><h2 id="참고">참고</h2><p>세부 내용은 다음 링크를 참고하세요.</p><ul><li><a href="https://github.com/kuberhost/kube-backup" rel="external nofollow noopener noreferrer" target="_blank">kuberhost/kube-backup | GitHub</a></li><li><a href="https://hub.docker.com/r/kuberhost/kube-backup" rel="external nofollow noopener noreferrer" target="_blank">kuberhost/kube-backup | Docker Hub</a></li></ul><h2 id="related-posts">Related Posts</h2><ul><li><a href="/2019/02/25/kubernetes-cluster-on-google-compute-engine-for-developers/" title="개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)">개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)</a></li><li><a href="/2019/01/19/spring-boot-containerization-and-ci-cd-to-kubernetes-cluster/" title="스프링 부트 컨테이너와 CI/CD 환경 구성하기">스프링 부트 컨테이너와 CI/CD 환경 구성하기</a></li><li><a href="/2018/11/16/docker-container-basics/" title="도커 Docker 기초 확실히 다지기">도커 Docker 기초 확실히 다지기</a></li><li><a href="/2018/11/09/it-infrastructure-basics/" title="개발자를 위한 인프라 기초 총정리">개발자를 위한 인프라 기초 총정리</a></li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">jq 설치 안내 https://zetawiki.com/wiki/리눅스_jq_다운로드_설치<a href="#fnref:1" rev="footnote"> ↩</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;쿠버네티스(Kubernetes)에서 시시각각으로 변하는 오브젝트의 상
      
    
    </summary>
    
      <category term="Cloud" scheme="https://futurecreator.github.io/categories/Cloud/"/>
    
    
      <category term="open_source" scheme="https://futurecreator.github.io/tags/open-source/"/>
    
      <category term="backup" scheme="https://futurecreator.github.io/tags/backup/"/>
    
      <category term="kubernetes" scheme="https://futurecreator.github.io/tags/kubernetes/"/>
    
      <category term="cluster" scheme="https://futurecreator.github.io/tags/cluster/"/>
    
      <category term="kube_backup" scheme="https://futurecreator.github.io/tags/kube-backup/"/>
    
      <category term="object" scheme="https://futurecreator.github.io/tags/object/"/>
    
      <category term="yaml" scheme="https://futurecreator.github.io/tags/yaml/"/>
    
      <category term="git" scheme="https://futurecreator.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)</title>
    <link href="https://futurecreator.github.io/2019/02/25/kubernetes-cluster-on-google-compute-engine-for-developers/"/>
    <id>https://futurecreator.github.io/2019/02/25/kubernetes-cluster-on-google-compute-engine-for-developers/</id>
    <published>2019-02-24T16:43:07.000Z</published>
    <updated>2019-02-27T15:48:52.409Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>이제 개발자가 컨테이너 기반으로 애플리케이션을 개발하면서 도커(Docker)를 많이 사용합니다. 그리고 이러한 컨테이너를 쉽게 관리하고 테스트할 쿠버네티스(Kubernetes) 환경이 필요한 경우가 생기게 됩니다.</p><p>쿠버네티스 클러스터 중 가장 쉽게 접할 수 있는 건 <a href="https://kubernetes.io/docs/setup/minikube/" rel="external nofollow noopener noreferrer" target="_blank">Minikube</a> 입니다. 하지만 Minikube 는 Master 하나로 이루어져 있어 부족한 점이 많습니다. 쿠버네티스의 다양한 기능을 살펴보려면 Master 노드와 Worker 노드 여러 개로 이루어진 실제 클러스터 환경을 구성할 필요가 있습니다.</p><p>물론 쿠버네티스 클러스터를 구성하는 것이 간단한 일은 아닙니다. 그래서 개발자들이 처음 쿠버네티스 클러스터를 구성할 때 많은 어려움을 겪습니다. 하지만 쿠버네티스에서 제공하는 <code>kubeadm</code>이라는 툴을 이용하면 비교적 쉽게 설치할 수 있습니다.</p><p>이번 포스트에서는 GCE 위에 Master 노드 하나, Worker 노드 둘로 이루어진 클러스터를 구성해보겠습니다.</p><h2 id="쿠버네티스의-구조">쿠버네티스의 구조</h2><p>설치를 진행하기에 앞서 우리가 구축할 시스템이 어떻게 구성되어 있는지 간단하게 알아보는게 좋겠습니다.</p><p><img src="kubernetes-architecture.png" alt="쿠버네티스 아키텍처"></p><p>Worker 노드는 실제 Pod 이 실행되는 서버이고, Master 노드는 각 Worker 노드를 제어하는 서버입니다. 각 노드에는 쿠버네티스의 구성 요소가 돌아가고 있습니다.</p><p>API 서버는 작업 상태를 정의하고 조회할 수 있는 RESTful 웹 서비스를 제공하고, 쿠버네티스의 각 구성 요소는 API 서버를 거쳐 서로 통신합니다. 특히 쿠버네티스 오브젝트의 상태를 저장하는 etcd 는 API 서버를 통해서만 접근할 수 있습니다.</p><p>쿠버네티스는 현재 시스템을 사용자가 정의한 상태, 즉 사용자가 원하는 상태(어떤 Pod 이 몇 개가 떠있고, 어떤 Service 가 어떤 포트로 열려있고 등)로 맞춰줍니다. 그러려면 오브젝트의 현재 상태를 지속적으로 체크하고 상태를 제어해야 합니다. 컨트롤러 매니저(Controller Manager)에는 Replication, DaemonSet, Job, Service 등 다양한 오브젝트를 제어하는 컨트롤러가 존재합니다.</p><p>스케쥴러(Scheduler)는 노드의 정보와 알고리즘을 통해 특정 Pod 을 어떤 노드에 배포할 지 결정합니다. 대상 노드들을 조건에 따라 걸러내고 남은 노드는 우선 순위(점수)를 매겨서 가장 최적의 노드를 선택합니다.</p><p>위의 모듈은 Control Plane 인 Master 노드에 존재하지만, Kubelet 과 Kube-proxy 는 Worker 노드에 존재합니다. Kubelet 은 API 서버와 통신하며 Worker 노드의 작업을 제어하는 에이전트입니다. Kube-proxy 는 Pod 에 접근하기 위한 <code>iptables</code> 를 설정합니다. <code>iptables</code> 는 리눅스 커널의 패킷 필터링 기능을 관리하는 도구입니다. 이전에는 해당 패킷이 Kube-proxy 를 거쳐 지나갔기 때문에 proxy 라는 이름이 붙었지만, 지금은 패킷이 직접 통과하진 않습니다.</p><p>각 구성 요소에 대한 상세한 설명은 이후 포스트에서 알아보기로 하고, 다시 설치 과정으로 돌아갑시다.</p><h2 id="준비하기">준비하기</h2><p>쿠버네티스는 3개월 마다 새로운 버전이 릴리즈 되고 해당 버전은 9개월 동안 버그와 보안 이슈를 수정하는 패치가 이루어집니다. 2019년 2월 현재 최신 버전인 1.13 버전으로 설치하겠습니다.</p><p>우리가 구성할 노드는 Master 노드 하나와 Worker 노드 두 개로, 총 세 개의 서버가 필요합니다.</p><p>쿠버네티스 노드로 사용할 서버의 사양을 확인합니다.</p><table><thead><tr><th>항목</th><th>사양</th></tr></thead><tbody><tr><td>CPU</td><td>2 CPU 이상</td></tr><tr><td>메모리</td><td>2 GB 이상</td></tr><tr><td>OS</td><td>CentOS 7, RHEL 7, Ubuntu 16.04+ etc.</td></tr></tbody></table><p>또한 각 서버는 다음 조건을 만족해야 합니다.</p><ul><li>각 노드가 서로 네트워크 연결되어 있어야 합니다.</li><li>각 노드는 다음 정보가 겹치지 않아야 합니다.<ul><li>hostname: <code>hostname</code></li><li>MAC address: <code>ip link</code> 또는 <code>ifconfig -a</code></li><li>product_uuid: <code>sudo cat /sys/class/dmi/id/product_uuid</code></li></ul></li></ul><p>마지막으로, 각 노드가 사용하는 포트입니다. 각 포트는 모두 열려 있어야 합니다.</p><table><thead><tr><th style="text-align:center">노드</th><th style="text-align:center">프로토콜</th><th style="text-align:center">방향</th><th>포트 범위</th><th>목적</th><th>누가 사용?</th></tr></thead><tbody><tr><td style="text-align:center">Master</td><td style="text-align:center">TCP</td><td style="text-align:center">Inbound</td><td>6443</td><td>Kubernetes API server</td><td>All</td></tr><tr><td style="text-align:center">Master</td><td style="text-align:center">TCP</td><td style="text-align:center">Inbound</td><td>2379-2380</td><td>etcd server client API</td><td>kube-apiserver, etcd</td></tr><tr><td style="text-align:center">Master</td><td style="text-align:center">TCP</td><td style="text-align:center">Inbound</td><td>10250</td><td>Kubelet API</td><td>Self, Control plane</td></tr><tr><td style="text-align:center">Master</td><td style="text-align:center">TCP</td><td style="text-align:center">Inbound</td><td>10251</td><td>kube-scheduler</td><td>Self</td></tr><tr><td style="text-align:center">Master</td><td style="text-align:center">TCP</td><td style="text-align:center">Inbound</td><td>10252</td><td>kube-controller-manager</td><td>Self</td></tr><tr><td style="text-align:center">Worker</td><td style="text-align:center">TCP</td><td style="text-align:center">Inbound</td><td>10250</td><td>Kubelet API</td><td>Self, Control plane</td></tr><tr><td style="text-align:center">Worker</td><td style="text-align:center">TCP</td><td style="text-align:center">Inbound</td><td>30000-32767</td><td>NodePort Services</td><td>All</td></tr></tbody></table><p>각 서버를 준비하는 방법은 여러 가지가 있겠지만 가장 쉽게 생각해볼 수 있는 건 VirtualBox 와 Vagrant 를 이용한 로컬 VM이나 AWS EC2 나 GCE 같은 퍼블릭 클라우드의 VM 을 사용하는 것입니다. 하지만 메모리가 넉넉하지 않으면 로컬에서 VM 세 개를 띄우는 건 부담일 수 있으므로, 이번 포스트에서는 GCE 를 사용해서 실습을 진행합니다.</p><h3 id="google-compute-engine">Google Compute Engine</h3><p>Compute Engine 은 <a href="https://cloud.google.com/?hl=ko" rel="external nofollow noopener noreferrer" target="_blank">Google Cloud Platform</a> 의 VM 입니다. GCP는 처음 가입 시 1년 동안 사용할 수 있는 $300 상당의 크레딧을 제공하기 때문에 학습이나 간단한 테스트를 할 때 유용합니다.</p><p><img src="create-gce-vm.png" alt="VM 생성하기"></p><p>먼저 <strong>만들기</strong>를 눌러 VM 을 생성합니다.</p><p><img src="create-gce-vm-instance-detail.png" alt="새로운 VM 설정하기"></p><p>위 내용을 참고해서 VM 을 설정합니다.</p><ul><li>지역: 어딜 해도 상관 없지만 가까운 도쿄로 하는 것이 속도가 빠릅니다.</li><li>영역: 지역에 문제 발생 시 피해를 최소화하기 위해 지역은 여러 영역으로 나뉘어져 있습니다. 각 노드를 다른 영역에 배치하는 것도 좋겠죠.</li><li>사양: 위에서 살펴 본 최소사양 이상이면 됩니다. 저는 무료 크레딧 사용이 이제 한 달도 안남아서 사양을 넉넉하게 잡았습니다.</li><li>부팅 디스크: CentOS 7을 선택합니다.</li><li>ID 및 API 서비스: AWS의 IAM 권한 설정처럼 GCP도 원하는 서비스 API 마다 권한을 오픈해야 합니다. 학습 및 테스트에만 사용할 것이므로 편의상 모든 Cloud API 액세스를 허용합니다.</li></ul><p><img src="gce-vm-list.png" alt="준비된 VM 리스트"></p><p><code>master</code>, <code>worker-1</code>, <code>worker-2</code> 총 세 개의 VM 을 생성합니다. 조금 기다리면 VM이 모두 준비됩니다.</p><p>각 VM 을 접속하는 방법은 로컬에 설치해서 사용하는 gcloud 나 웹 상에서 콘솔로 바로 접속할 수 있는 Cloud SSH 가 있습니다. 이번 실습에서는 별 다른 설정 없이 바로 접속이 가능한 Cloud SSH 를 사용합니다. VM 이 생성되길 기다리는 동안 크롬 확장 프로그램인 <a href="https://chrome.google.com/webstore/detail/ssh-for-google-cloud-plat/ojilllmhjhibplnppnamldakhpmdnibd" rel="external nofollow noopener noreferrer" target="_blank">SSH for Google Cloud Platform</a> 을 설치하면 더 편하게 사용하실 수 있습니다.</p><h2 id="설치하기">설치하기</h2><h3 id="사전-작업하기">사전 작업하기</h3><p>사전 작업은 <code>master</code>, <code>worker-1</code>, <code>worker-2</code> 모두 동일하게 진행합니다. 터미널 화면을 분할해서 동시에 작업할 수 있는 <a href="https://github.com/tmux/tmux/wiki" rel="external nofollow noopener noreferrer" target="_blank">tmux</a> 같은 유틸이 있으면 더 편하게 작업할 수 있습니다.</p><p>모든 설치 과정은 <code>root</code> 권한으로 진행합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo su -</span><br></pre></td></tr></table></figure><p>Swap 은 메모리가 부족하거나 절전 모드에서 디스크의 일부 공간을 메모리처럼 사용하는 기능입니다. Kubelet 이 정상 동작할 수 있도록 해당 기능을 swap 디바이스와 파일 모두 disable 합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/vm/swappiness</span><br><span class="line">sed -e <span class="string">'/swap/ s/^#*/#/'</span> -i /etc/fstab</span><br></pre></td></tr></table></figure><ul><li><code>swapoff -a</code>: paging 과 swap 기능을 끕니다.</li><li><code>/proc/sys/vm/swappiness</code>: 커널 속성을 변경해 swap을 disable 합니다.</li><li><code>/etc/fastab</code>: Swap을 하는 파일 시스템을 찾아 disable 합니다.</li></ul><p>각 노드의 통신을 원활하게 하기 위해 방화벽 기능을 해제합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><p>SELinux(Security-Enhanced Linux)는 리눅스 보안 모듈로 액세스 권한을 제어합니다. 쿠버네티스에서는 컨테이너가 호스트의 파일시스템에 접속할 수 있도록 해당 기능을 꺼야 합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=permissive/'</span> /etc/selinux/config</span><br></pre></td></tr></table></figure><p>RHEL 과 CentOS 7에서 <code>iptables</code> 관련 이슈가 있어서 커널 매개변수를 다음과 같이 수정하고 적용합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><p><code>br_netfilter</code> 모듈이 활성화되어 있어야 합니다. <code>modprobe br_netfilter</code> 명령어로 해당 모듈을 명시적으로 추가하고, <code>lsmod | grep br_netfilter</code> 명령어로 추가 여부를 확인할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modprobe br_netfilter</span><br></pre></td></tr></table></figure><p>컨테이너 실행 환경인 도커(Docker)를 설치하고 실행합니다. 쿠버네티스는 도커 외에도 여러가지 CRI(Container Runtime Interface) 구현체를 지원하기 때문에 도커에 종속적이지 않습니다.<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="https://kubernetes.io/docs/setup/cri/">[1]</span></a></sup></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install docker -y</span><br><span class="line">systemctl start docker.service</span><br></pre></td></tr></table></figure><h3 id="쿠버네티스-설치하기">쿠버네티스 설치하기</h3><p>이제 본격적인 설치 과정입니다. Kubeadm은 Kubelet 과 Kubectl 을 설치하지 않기 때문에 직접 설치해야 합니다. 리파지토리를 추가하고 설치 및 실행합니다. Kubectl 은 클러스터에게 명령을 내리기 위한 CLI 유틸입니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="line">exclude=kube*</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure><p>이제 Master 노드에 컨트롤 구성 요소를 설치할 차례입니다. 해당 작업은 <code>master</code> 에서만 실행합니다. 설치 시 사용할 이미지를 먼저 다운로드 합니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images pull</span><br></pre></td></tr></table></figure><p>마스터 노드를 초기화합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init</span><br></pre></td></tr></table></figure><p>그럼 설치가 진행되고 마지막에 다음과 비슷한 로그가 출력됩니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 10.146.0.25:6443 --token yuaea3.d7m8hkpvazrbv5yw --discovery-token-ca-cert-hash sha256:c6a7121c5d5207179f67d913fa654441137f76027ad0f4e23724f0202b280eec</span><br></pre></td></tr></table></figure><p>여기서 일반 사용자가 <code>kubectl</code> 을 사용할 수 있도록 로그 중간에 있는 명령어를 복사해서 실행합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>맨 마지막 라인의 명령어는 워커 노드를 해당 클러스터에 추가하는 명령어입니다. 해당 명령어를 복사해서 <code>worker-1</code>, <code>worker-2</code> 노드에서 수행합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 10.146.0.25:6443 --token yuaea3.d7m8hkpvazrbv5yw --discovery-token-ca-cert-hash sha256:c6a7121c5d5207179f67d913fa654441137f76027ad0f4e23724f0202b280eec</span><br></pre></td></tr></table></figure><p>만약 해당 커맨드를 복사해놓지 않고 지워진 경우에는 다음과 같이 토큰을 확인할 수 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm token list</span><br></pre></td></tr></table></figure><p>해당 토큰은 24시간 동안만 사용할 수 있습니다. 새 토큰이 필요한 경우는 다음 명령어를 실행하면 됩니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm token create</span><br></pre></td></tr></table></figure><h3 id="pod-network-add-on-설치하기">Pod network add-on 설치하기</h3><p>Pod 은 실제로 여러 노드에 걸쳐 배포되는데, Pod 끼리는 하나의 네트워크에 있는 것처럼 통신할 수 있습니다. 이를 오버레이 네트워크(Overlay Network)라고 합니다.</p><p>오버레이 네트워크를 지원하는 CNI(Container Network Interface) 플러그인을 설치해보겠습니다. CNI 에는 여러 종류가 있는데, 이번 실습에서는 Weave 를 이용합니다.</p><p>Master 노드에서 다음과 같이 설치합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f <span class="string">"https://cloud.weave.works/k8s/net?k8s-version=<span class="variable">$(kubectl version | base64 | tr -d '\n')</span>"</span></span><br></pre></td></tr></table></figure><p>CNI를 설치하면 CoreDNS Pod 이 정상적으로 동작하게 됩니다.</p><p>다음 명령어로 각 노드와 상태를 확인할 수 있습니다. 처음엔 상태가 <code>NotReady</code> 라고 나올 수 있지만 잠시 기다리면 모두 <code>Ready</code> 상태가 됩니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get no</span><br><span class="line">NAME       STATUS   ROLES    AGE     VERSION</span><br><span class="line">master     Ready    master   6m44s   v1.13.3</span><br><span class="line">worker-1   Ready    &lt;none&gt;   5m20s   v1.13.3</span><br><span class="line">worker-2   Ready    &lt;none&gt;   5m19s   v1.13.3</span><br></pre></td></tr></table></figure><h2 id="설치-확인하기">설치 확인하기</h2><p>다음 명령어로 쿠버네티스의 구성 요소가 모두 동작하는 것을 확인할 수 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get componentstatuses</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok                   </span><br><span class="line">controller-manager   Healthy   ok                   </span><br><span class="line">etcd-0               Healthy   &#123;<span class="string">"health"</span>: <span class="string">"true"</span>&#125;</span><br></pre></td></tr></table></figure><p>쿠버네티스의 구성 요소가 Pod 으로 어떤 노드에 떠있는지 확인할 수 있습니다. etcd, API server, Scheduler, Controller Manager, DNS Server 는 master 에서 실행됩니다. Kube proxy 와 Weave 는 각 worker 에서 실행됩니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">kubectl get po -o custom-columns=POD:metadata.name,NODE:spec.nodeName --sort-by spec.nodeName -n kube-system</span><br><span class="line">POD                              NODE</span><br><span class="line">kube-proxy-pz25z                 master</span><br><span class="line">etcd-master                      master</span><br><span class="line">kube-apiserver-master            master</span><br><span class="line">kube-controller-manager-master   master</span><br><span class="line">kube-scheduler-master            master</span><br><span class="line">weave-net-8npbk                  master</span><br><span class="line">coredns-86c58d9df4-r5qq5         worker-1</span><br><span class="line">weave-net-dbk8x                  worker-1</span><br><span class="line">kube-proxy-8mrkx                 worker-1</span><br><span class="line">coredns-86c58d9df4-tsdf4         worker-1</span><br><span class="line">weave-net-bds9l                  worker-2</span><br><span class="line">kube-proxy-7pn22                 worker-2</span><br></pre></td></tr></table></figure><p>이제 설치가 잘 되었는지 Pod 을 배포하고 동작을 확인해보겠습니다.</p><ul><li>간단한 Pod 배포하기</li><li>복잡한 Microservices 애플리케이션 배포하기</li></ul><h3 id="간단한-pod-배포하기">간단한 Pod 배포하기</h3><p>먼저 간단한 Pod 을 배포해서 동작을 확인해봅시다. 다음과 같은 <code>pod-test.yaml</code> 파일을 생성합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">myapp-pod</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">myapp-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'echo Hello Kubernetes! &amp;&amp; sleep 3600'</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>해당 Pod 이 실행되면 busybox 라는 경량 리눅스 이미지에 <code>Hello Kubernetes!</code> 라는 로그가 잠시 동안 출력되고 Pod 은 종료될겁니다.</p><p>이제 해당 Pod 을 배포합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f pod-test.yaml</span><br></pre></td></tr></table></figure><p>해당 Pod 이 정상적으로 실행된 것을 볼 수 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get po</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE</span><br><span class="line">myapp-pod   1/1     Running   0          6s</span><br></pre></td></tr></table></figure><p>로그도 확인해봅니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs myapp-pod</span><br><span class="line">Hello Kubernetes!</span><br></pre></td></tr></table></figure><h3 id="복잡한-microservices-애플리케이션-배포하기">복잡한 Microservices 애플리케이션 배포하기</h3><p>이번에는 Sock Shop 이라는 복잡한 마이크로서비스 애플리케이션을 배포해보겠습니다. 이 온라인 양말 가게 애플리케이션은 오픈 소스로 마이크로서비스 데모 애플리케이션입니다.<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="https://microservices-demo.github.io">[2]</span></a></sup></p><p><img src="sock-shop.png" alt="Sock Shop 소개"></p><p>다음 명령을 이용해 Namespace 를 만들고 각종 구성 요소를 배포합니다. <code>complete-demo.yaml</code> 파일 안에는 애플리케이션에 필요한 Deployment, Service  등이 정의되어 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create ns sock-shop</span><br><span class="line">kubectl apply -n sock-shop -f <span class="string">"https://github.com/microservices-demo/microservices-demo/blob/master/deploy/kubernetes/complete-demo.yaml?raw=true"</span></span><br></pre></td></tr></table></figure><p>다음 명령어로 새롭게 배포된 구성 요소를 모두 확인할 수 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n sock-shop</span><br></pre></td></tr></table></figure><p>모든 Pod 이 <code>Running</code> 상태가 되면 <code>front-end</code> 서비스의 NodePort 를 확인합니다. NodePort 는 해당 서버(노드)의 포트와 Pod 을 연결해서 사용하는 방식입니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc front-end -n sock-shop -o wide</span><br><span class="line">NAME        TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE     SELECTOR</span><br><span class="line">front-end   NodePort   10.105.37.122   &lt;none&gt;        80:30001/TCP   2m48s   name=front-end</span><br></pre></td></tr></table></figure><p>따라서 노드의 외부 IP와 포트 번호를 이용해서 접속할 수 있습니다. VM의 외부 IP는 VM 목록에서 확인할 수 있습니다. 그럼 <a href="http://34.85.95.211:30001" rel="external nofollow noopener noreferrer" target="_blank">http://34.85.95.211:30001</a> 와 같은 주소가 됩니다.</p><p>하지만 접속 전에 해당 포트가 열려 있어야 합니다. GCP 서비스 중 VPC 네트워크 &gt; 방화벽 규칙 메뉴로 들어가 방화벽 규칙을 새로 추가합니다. 메뉴 찾기는 상단의 검색창을 이용하면 쉽습니다.</p><p><img src="firewall-rules.png" alt="방화벽 규칙"></p><p>이름은 <code>http-sock-shop</code> 와 같이 적당히 주고 수신 방향으로 합니다. 대상은 편의상 '네트워크의 모든 인스턴스’를 선택하고, IP 범위는 <code>0.0.0.0/0</code> 으로 설정합니다. 프로토콜 및 포트는 <code>tcp</code> 를 선택하고 위에서 확인한 NodePort 를 설정합니다.</p><p><img src="sock-shop-main.png" alt="Sock Shop 메인 페이지"></p><p>그러면 <a href="http://34.85.95.211:30001" rel="external nofollow noopener noreferrer" target="_blank">http://34.85.95.211:30001</a> 로 접속할 수 있게 됩니다.</p><h2 id="마무리">마무리</h2><p>이번 포스트에서는 GCE 를 이용해서 간단하게 서버 자원을 확보하고 Kubeadm 을 이용해 클러스터를 구성했습니다. 그 전에 쿠버네티스의 구성 요소도 간단하게 살펴봤습니다.</p><p>물론 직접 컨트롤하지 않고 사용하는 것이 위주라면 GKE(Google Kubernetes Engine)와 같이 완전관리형(Fully-managed) 쿠버네티스 서비스를 이용하는 것도 좋습니다만, 직접 수정하면서 테스트할 수 있는 클러스터를 구축해보는 것도 좋겠습니다.</p><p>다음 포스트에서는 쿠버네티스 기본 개념을 상세하게 다뤄보려고 합니다.</p><h2 id="참고">참고</h2><ul><li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" rel="external nofollow noopener noreferrer" target="_blank">Creating a single master cluster with kubeadm</a></li><li><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" rel="external nofollow noopener noreferrer" target="_blank">Installing kubeadm</a></li><li><a href="https://microservices-demo.github.io" rel="external nofollow noopener noreferrer" target="_blank">Sock Shop - Microservices Demo Application</a></li></ul><h2 id="related-posts">Related Posts</h2><ul><li><a href="/2018/11/09/it-infrastructure-basics/" title="개발자를 위한 인프라 기초 총정리">개발자를 위한 인프라 기초 총정리</a></li><li><a href="/2018/11/16/docker-container-basics/" title="도커 Docker 기초 확실히 다지기">도커 Docker 기초 확실히 다지기</a></li><li><a href="/2019/01/19/spring-boot-containerization-and-ci-cd-to-kubernetes-cluster/" title="스프링 부트 컨테이너와 CI/CD 환경 구성하기">스프링 부트 컨테이너와 CI/CD 환경 구성하기</a></li><li><a href="/2019/02/27/kubernetes-object-yaml-auto-backup-using-git-and-cronjob/" title="Git과 CronJob을 활용한 쿠버네티스 오브젝트 YAML 자동 백업">Git과 CronJob을 활용한 쿠버네티스 오브젝트 YAML 자동 백업</a></li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">https://kubernetes.io/docs/setup/cri/<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">https://microservices-demo.github.io<a href="#fnref:2" rev="footnote"> ↩</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;이제 개발자가 컨테이너 기반으로 애플리케이션을 개발하면서 도커(Doc
      
    
    </summary>
    
      <category term="Cloud" scheme="https://futurecreator.github.io/categories/Cloud/"/>
    
    
      <category term="container" scheme="https://futurecreator.github.io/tags/container/"/>
    
      <category term="kubernetes" scheme="https://futurecreator.github.io/tags/kubernetes/"/>
    
      <category term="gce" scheme="https://futurecreator.github.io/tags/gce/"/>
    
      <category term="google_cloud_platform" scheme="https://futurecreator.github.io/tags/google-cloud-platform/"/>
    
      <category term="centos" scheme="https://futurecreator.github.io/tags/centos/"/>
    
      <category term="vm" scheme="https://futurecreator.github.io/tags/vm/"/>
    
  </entry>
  
  <entry>
    <title>스프링 부트 컨테이너와 CI/CD 환경 구성하기</title>
    <link href="https://futurecreator.github.io/2019/01/19/spring-boot-containerization-and-ci-cd-to-kubernetes-cluster/"/>
    <id>https://futurecreator.github.io/2019/01/19/spring-boot-containerization-and-ci-cd-to-kubernetes-cluster/</id>
    <published>2019-01-19T08:40:16.000Z</published>
    <updated>2019-02-27T15:46:04.890Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>이번 포스트에서는 간단한 스프링 부트(Spring Boot) 애플리케이션을 만들고 컨테이너화(Containerize)하는 방법을 알아봅니다. 그리고 다양한 툴을 이용해 도커 이미지를 지속적으로 빌드하고 배포할 수 있는 CI/CD 환경을 구성하고 쿠버네티스(Kubernetes) 클러스터에 배포하는 과정을 살펴봅니다.</p><p>살펴볼 내용은 다음과 같습니다.</p><ul><li>컨테이너화 Containerization</li><li>스프링 부트 컨테이너화하기</li><li>도커 이미지 기반 CI/CD 환경 구성하기</li><li>첫 번째 환경: Google Cloud Build</li><li>두 번째 환경: GitLab + GKE</li><li>정리</li></ul><h2 id="컨테이너화-containerization">컨테이너화 Containerization</h2><p><img src="virtual-machine-vs-container.png" alt="가상 머신과 컨테이너 비교"></p><p>컨테이너화는 애플리케이션을 컨테이너로 감싸는 작업을 말합니다. 컨테이너는 가상 머신(Virtual Machine)과는 다르게 게스트 OS 없이 호스트 OS 의 자원을 공유하므로 더 빠르고 리소스 사용이 효율적인 가상화 방식입니다. 이번 포스트에서는 대표적인 가상화 SW인 도커(Docker)로 컨테이너를 만듭니다. 도커로 애플리케이션과 해당 실행 환경을 감싸면 이미지 형태로 빌드할 수 있습니다. 따라서 도커만 설치되어 있으면 어디든 동일한 환경에서 애플리케이션을 실행할 수 있으므로 개발 및 배포, 운영 시 매우 용이합니다.</p><p>가상화와 도커에 대한 자세한 내용은 다음 포스트를 참고하세요.</p><ul><li><a href="/2018/11/09/it-infrastructure-basics/" title="개발자를 위한 인프라 기초 총정리">개발자를 위한 인프라 기초 총정리</a></li><li><a href="/2018/11/16/docker-container-basics/" title="도커 Docker 기초 확실히 다지기">도커 Docker 기초 확실히 다지기</a></li></ul><h2 id="스프링-부트-컨테이너화하기">스프링 부트 컨테이너화하기</h2><p>먼저 스프링 부트 애플리케이션을 만들고 컨테이너화 해봅시다.</p><h3 id="환경-준비">환경 준비</h3><p>실습에 사용할 리눅스 머신이 필요합니다. Mac, 가상 머신, AWS EC2 등 원하는 환경을 준비합니다. 이번 포스트에서는 로컬 환경에서 간단하게 VM을 사용할 수 있는  <a href="https://www.virtualbox.org" rel="external nofollow noopener noreferrer" target="_blank">VirtualBox</a> 와 <a href="https://www.vagrantup.com" rel="external nofollow noopener noreferrer" target="_blank">Vagrant</a> 로 실습 환경을 구성합니다. VirtualBox 는 VM을 만들고, Vagrant 는 VM 이미지와 설정 파일(<code>Vagrantfile</code>)로 가상 머신을 쉽게 설정하고 찍어낼 수 있습니다. 두 SW 를 설치한 후 실습을 진행합니다.</p><p>원하는 경로에 폴더를 만들고 초기화합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vagrant init</span><br><span class="line">A `Vagrantfile` has been placed <span class="keyword">in</span> this directory. You are now</span><br><span class="line">ready to `vagrant up` your first virtual environment! Please <span class="built_in">read</span></span><br><span class="line">the comments <span class="keyword">in</span> the Vagrantfile as well as documentation on</span><br><span class="line">`vagrantup.com` <span class="keyword">for</span> more information on using Vagrant.</span><br></pre></td></tr></table></figure><p>생성된 <code>Vagrantfile</code> 을 수정합니다.</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Vagrant.configure(<span class="string">"2"</span>) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  config.vm.box = <span class="string">"centos/7"</span></span><br><span class="line">  config.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">80</span>, <span class="symbol">host:</span> <span class="number">8000</span></span><br><span class="line">  config.vm.network <span class="string">"private_network"</span>, <span class="symbol">ip:</span> <span class="string">"192.168.33.10"</span></span><br><span class="line">  config.vm.synced_folder <span class="string">"."</span>, <span class="string">"/vagrant"</span>, <span class="symbol">disabled:</span> <span class="literal">true</span></span><br><span class="line">  config.vm.provision <span class="string">"docker"</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><ul><li><code>config.vm.box</code>: 가상 환경에서 사용할 박스 이미지를 설정합니다. CentOS 7을 사용합니다. <a href="https://app.vagrantup.com/boxes/search" rel="external nofollow noopener noreferrer" target="_blank">Vagrant Cloud</a> 에서 원하는 박스 이미지를 검색할 수 있습니다.</li><li><code>config.vm.network &quot;forwarded_port&quot;</code>: 게스트의 <code>80</code>과 호스트의 <code>8000</code> 포트를 연결합니다.</li><li><code>config.vm.network &quot;forwarded_port&quot;</code>: 게스트의 <code>80</code>과 호스트의 <code>8000</code> 포트를 연결합니다.</li><li><code>config.vm.provision &quot;docker&quot;</code>: 도커를 자동으로 설치합니다. 따라서 VM에 따로 도커를 설치할 필요가 없습니다.</li></ul><p><code>vagrant up</code> 으로 VM 을 실행합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br><span class="line">Bringing machine <span class="string">'default'</span> up with <span class="string">'virtualbox'</span> provider...</span><br><span class="line">==&gt; default: Importing base box <span class="string">'centos/7'</span>...</span><br><span class="line">==&gt; default: Matching MAC address <span class="keyword">for</span> NAT networking...</span><br><span class="line">==&gt; default: Checking <span class="keyword">if</span> box <span class="string">'centos/7'</span> is up to date...</span><br><span class="line">==&gt; default: A newer version of the box <span class="string">'centos/7'</span> <span class="keyword">for</span> provider <span class="string">'virtualbox'</span> is</span><br><span class="line">==&gt; default: available! You currently have version <span class="string">'1811.02'</span>. The latest is version</span><br><span class="line">==&gt; default: <span class="string">'1812.01'</span>. Run `vagrant box update` to update.</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><code>vagrant ssh</code> 로 VM에 SSH 접속할 수 있습니다. 접속 후에는  <code>sudo su -</code> 를 이용해 root 로 접속할 수 있습니다.</p><p>마지막으로 실습을 편하게 진행하기 위해 Java 와 Git 도 설치합시다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo su -</span><br><span class="line">yum update -y</span><br><span class="line">yum install -y java-1.8.0-openjdk-devel.x86_64</span><br><span class="line">yum install -y git</span><br></pre></td></tr></table></figure><p>이제 Docker, Java, Git이 설치된 VM 을 사용할 수 있습니다.</p><h3 id="스프링-부트-애플리케이션-만들기">스프링 부트 애플리케이션 만들기</h3><p>실습에 사용할 간단한 스프링 부트 애플리케이션을 작성합니다. <a href="https://start.spring.io" rel="external nofollow noopener noreferrer" target="_blank">Spring Initializr</a> 로 프로젝트를 만들면 필요한 초기 설정을 쉽게 구성할 수 있습니다.<br><img src="spring-initializr.png" alt="Spring Initalizr로 프로젝트 만들기"><br>위 그림과 같이 설정한 후 <strong>Generate Project</strong> 로 생성된 압축 파일을 다운로드합니다.</p><p>압축 파일을 풀고 해당 폴더에서 <code>mvnw spring-boot:run</code>으로 바로 실행해봅시다. 여기선 maven 을 사용하지만 gradle 을 사용해도 좋습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ./mvnw spring-boot:run</span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ----------------------&lt; com.docker.example:hello &gt;----------------------</span><br><span class="line">[INFO] Building hello 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] &gt;&gt;&gt; spring-boot-maven-plugin:2.1.1.RELEASE:run (default-cli) &gt; <span class="built_in">test</span>-compile @ hello &gt;&gt;&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><code>controller</code> 패키지를 만들고 <code>/</code> 요청을 받을 <code>HelloController</code> 를 만듭니다.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.docker.example.hello.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@RequestMapping</span>(<span class="string">"/"</span>)</span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"Hello, Docker!"</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>pom.xml</code> 파일에 플러그인 설정을 추가합니다. 해당 설정이 없으면 VM 이나 컨테이너 환경에서 빌드(테스트) 시 에러가 발생합니다.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">useSystemClassLoader</span>&gt;</span>false<span class="tag">&lt;/<span class="name">useSystemClassLoader</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>Vagrantfile</code> 에 파일을 옮기는 설정을 추가합니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.provision &quot;file&quot;, source: &quot;./hello&quot;, destination: &quot;$HOME/hello&quot;</span><br></pre></td></tr></table></figure><p>Vagrant 를 프로비저닝해서 소스를 옮깁니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vagrant up</span><br></pre></td></tr></table></figure><p>환경과 소스를 모두 준비했습니다.</p><h3 id="컨테이너로-감싸기">컨테이너로 감싸기</h3><p>이제 해당 애플리케이션을 감싸기 위한 실행 환경을 정의합니다. 이를 <code>Dockerfile</code> 에 정의합니다.</p><p><code>Dockerfile</code> 을 작성합니다.</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> openjdk:<span class="number">8</span>-jre-alpine</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> target/*.jar app.jar</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"java"</span>,<span class="string">"-jar"</span>,<span class="string">"/app.jar"</span>]</span></span><br></pre></td></tr></table></figure><p>도커는 베이스 이미지(<code>FROM</code>)를 기반으로 설정한 항목을 수행하면서 변경 사항을 이미지 레이어로 저장합니다.</p><ul><li><code>FROM</code>: 가벼운 리눅스인 alpine 에 openjdk 8 이 설치된 이미지입니다.</li><li><code>COPY</code>: 컨테이너 안으로 파일을 복사합니다.</li><li><code>ENTRYPOINT</code>: 컨테이너를 실행할 때 수행할 명령어 입니다.</li></ul><p>먼저 메이븐 빌드를 수행합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./mvnw install</span><br></pre></td></tr></table></figure><p>도커 이미지를 빌드합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t myorg/myapp .</span><br></pre></td></tr></table></figure><p>그러면 <code>myorg/myapp</code> 이라는 태그가 달린 이미지가 생성됩니다.</p><p>도커 이미지를 실행합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 8000:8080 myorg/myapp</span><br><span class="line">a6a7955807288a90943b95b5520466e66d7de3ff2bee07a611627fba85c1aae8</span><br></pre></td></tr></table></figure><ul><li><code>-d</code> : 백그라운드에서 실행합니다.</li><li><code>-p</code> : <code>&lt;호스트 포트&gt;:&lt;컨테이너 포트&gt;</code> 형식으로 작성합니다.</li><li><code>a6a795580728</code>: 실행 시 해당 컨테이너 ID가 출력됩니다.</li></ul><p>도커가 실행되는 컨테이너를 확인합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">a6a795580728        myorg/myapp         <span class="string">"java -jar /app.jar"</span>   5 seconds ago       Up 4 seconds        0.0.0.0:8000-&gt;8080/tcp   silly_merkle</span><br></pre></td></tr></table></figure><p>접속을 확인해봅시다. 고정 IP로 설정한 <code>http://192.168.33.10:8000</code> 로 접속하면 화면을 볼 수 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl localhost:8000</span><br><span class="line">Hello, Docker!</span><br></pre></td></tr></table></figure><p>컨테이너 내부로 들어가면 <code>app.jar</code> 를 확인할 수 있습니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --entrypoint /bin/sh myorg/myapp</span><br><span class="line">/ <span class="comment"># ls</span></span><br><span class="line">app.jar  dev      home     media    proc     run      srv      tmp      var</span><br><span class="line">bin      etc      lib      mnt      root     sbin     sys      usr</span><br></pre></td></tr></table></figure><h3 id="dockerfile-개선하기">Dockerfile 개선하기</h3><p>스프링 애플리케이션을 아주 쉽게 컨테이너로 만들었습니다. 하지만 지금 이미지는 조금 비효율적입니다. 도커가 이미지를 만드는 방식과 관련이 있습니다.</p><p>도커는 이미지를 빌드하는 과정을 이미지를 여러 겹의 레이어로 구성하고, 수정이 있는 레이어만 다시 작업합니다. 나머지 수정이 없는 레이어는 캐시해놓은 것을 사용하기 때문에 빠르게 빌드할 수 있습니다. 하지만 우리 JAR 파일 안에는 각종 디펜던시가 함께 들어가 있기 때문에 도커 이미지에는 하나의 레이어만 생성되고, 애플리케이션이 수정될 때마다 해당 레이어가 변경됩니다.</p><p>다음은 이미지의 레이어를 <code>docker inspect</code> 명령어로 확인한 모습입니다. 마지막 레이어가 우리 애플리케이션의 레이어입니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&quot;Layers&quot;: [</span><br><span class="line">&quot;sha256:7bff100f35cb359a368537bb07829b055fe8e0b1cb01085a3a628ae9c187c7b8&quot;,</span><br><span class="line">&quot;sha256:dbc783c89851d29114fb01fd509a84363e2040134e45181354051058494d2453&quot;,</span><br><span class="line">&quot;sha256:382d47ad6dc1ef98fc8d97372af64fc4f06c39de5edb9d6ba5a3315ce87def51&quot;,</span><br><span class="line">&quot;sha256:d180830db04728775d84bc906de568cb552bbfce823e835168c6e63b7905db4f&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>이제 하나로 구성된 레이어를 여러 개의 레이어로 나눠봅시다.</p><p>먼저 디펜던시를 각각 복사할 수 있도록 폴더를 생성하고 JAR 압축을 풉니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir target/dependency</span><br><span class="line"><span class="built_in">cd</span> target/dependency</span><br><span class="line">jar -xvf ../*.jar</span><br></pre></td></tr></table></figure><p><code>Dockerfile</code> 을 수정합니다. 각 디펜던시를 <code>COPY</code> 하는 작업이 하나의 레이어가 됩니다.</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> openjdk:<span class="number">8</span>-jre-alpine</span><br><span class="line"><span class="keyword">ARG</span> DEPENDENCY=target/dependency</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> <span class="variable">$&#123;DEPENDENCY&#125;</span>/BOOT-INF/lib /app/lib</span></span><br><span class="line"><span class="bash">COPY <span class="variable">$&#123;DEPENDENCY&#125;</span>/META-INF /app/META-INF</span></span><br><span class="line"><span class="bash">COPY <span class="variable">$&#123;DEPENDENCY&#125;</span>/BOOT-INF/classes /app</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"java"</span>,<span class="string">"-cp"</span>,<span class="string">"app:app/lib/*"</span>,<span class="string">"com.docker.example.hello.HelloApplication"</span>]</span></span><br></pre></td></tr></table></figure><p>다시 도커 이미지를 빌드합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t myorg/myapp .</span><br></pre></td></tr></table></figure><p>이미지를 확인해보면 레이어가 늘어난 것을 확인할 수 있습니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;Layers&quot;: [</span><br><span class="line">&quot;sha256:7bff100f35cb359a368537bb07829b055fe8e0b1cb01085a3a628ae9c187c7b8&quot;,</span><br><span class="line">&quot;sha256:dbc783c89851d29114fb01fd509a84363e2040134e45181354051058494d2453&quot;,</span><br><span class="line">&quot;sha256:382d47ad6dc1ef98fc8d97372af64fc4f06c39de5edb9d6ba5a3315ce87def51&quot;,</span><br><span class="line">&quot;sha256:b1d7f7bd343054042f9c7f2847822f97749b14541f867137a53aca86e68f5d41&quot;,</span><br><span class="line">&quot;sha256:c40aca1731d0acd8b9b885b5196e2bc0e697eee03f03322fb91cb6ec5ab4816f&quot;,</span><br><span class="line">&quot;sha256:c2d77979785785ac75e5151e80679c91299a08b7e3f24d2dd0a1914fa26741cd&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>이 방법은 압축을 해제하는 과정이 필요하므로, 이후 실습에서는 편의를 위해 첫 번째 방법으로 진행합니다.</p><h2 id="도커-이미지-기반-ci-cd-환경-구성하기">도커 이미지 기반 CI/CD 환경 구성하기</h2><p>이번에는 코드를 관리하고 도커 이미지 기반의 CI/CD 환경을 구성해봅시다.</p><h3 id="구성-요소">구성 요소</h3><ol><li>코드와 <code>Dockerfile</code> 을 함께 관리하고 CI 서버를 이용해 코드가 푸시될 때마다 해당 코드를 도커 이미지로 빌드합니다.</li><li>빌드한 이미지는 이미지 레지스트리(Image Registry)에 따로 저장해서 보관합니다.</li><li>빌드한 이미지를 컨테이너로 쿠버네티스(Kubernetes) 클러스터에 배포합니다.</li></ol><p>필요한 구성 요소는 다음과 같습니다.</p><table><thead><tr><th>도구</th><th>서비스</th></tr></thead><tbody><tr><td>소스 코드 관리</td><td><a href="https://github.com" rel="external nofollow noopener noreferrer" target="_blank">GitHub</a>, <a href="https://gitlab.com" rel="external nofollow noopener noreferrer" target="_blank">GitLab</a>, <a href="https://aws.amazon.com/ko/codestar/" rel="external nofollow noopener noreferrer" target="_blank">AWS CodeStar</a>, <a href="https://cloud.google.com/source-repositories/" rel="external nofollow noopener noreferrer" target="_blank">Google Cloud Source Repository</a>, etc.</td></tr><tr><td>코드를 push 할 때마다 자동으로 빌드하고 배포할 CI/CD 파이프라인</td><td><a href="https://aws.amazon.com/ko/codepipeline/" rel="external nofollow noopener noreferrer" target="_blank">AWS CodePipeline</a>, <a href="https://cloud.google.com/cloud-build/" rel="external nofollow noopener noreferrer" target="_blank">Google Cloud Build</a>, <a href="https://about.gitlab.com/product/continuous-integration/" rel="external nofollow noopener noreferrer" target="_blank">GitLab CI/CD</a>, <a href="https://jenkins.io" rel="external nofollow noopener noreferrer" target="_blank">Jenkins</a>, etc.</td></tr><tr><td>빌드한 이미지를 저장할 프라이빗 도커 레지스트리(Private Docker Registry)</td><td><a href="https://aws.amazon.com/ko/ecr/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Elastic Container Registry</a>, <a href="https://cloud.google.com/container-registry/" rel="external nofollow noopener noreferrer" target="_blank">Google Container Registry</a>, <a href="https://docs.gitlab.com/ee/user/project/container_registry.html" rel="external nofollow noopener noreferrer" target="_blank">GitLab Container Registry</a>, etc.</td></tr><tr><td>빌드 결과를 배포할 쿠버네티스(Kubernetes) 클러스터</td><td><a href="https://cloud.google.com/kubernetes-engine/" rel="external nofollow noopener noreferrer" target="_blank">Google Kubernetes Engine</a>, <a href="https://aws.amazon.com/ko/eks/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Elastic Container Service for Kubernetes</a>, etc.</td></tr></tbody></table><p>이를 구성하는 방법은 여러가지가 있습니다. 이번 포스트에서는 다양한 시나리오를 살펴보기 위해 다음과 같이 세 가지 방법으로 구성해보겠습니다.</p><ul><li>Google Cloud Build</li><li>GCP와 Dockerfile</li><li>GItLab + GKE</li></ul><h3 id="쿠버네티스-kubernetes">쿠버네티스 Kubernetes</h3><p><img src="kubernetes.png" alt="https://kubernetes.io"></p><p>도커 컨테이너는 도커만 설치되어 있으면 동작합니다. 하지만 분산 환경에서 많은 컨테이너를 관리하는 것은 쉽지 않습니다. 따라서 주로 도커 컨테이너를 그냥 사용하기보다는 쿠버네티스라는 컨테이너 플랫폼 위에서 실행합니다.</p><p>쿠버네티스는 분산 환경의 많은 컨테이너를 쉽게 관리할 수 있는 오케스트레이션(Orchestration) 툴로 알려져 있습니다. 하지만 쿠버네티스는 단순한 오케스트레이션 툴을 넘어 하나의 플랫폼으로 빠르게 발전했습니다. 이제는 많은 기업들이 컨테이너 운영 환경에 쿠버네티스를 도입해 사용하고 있습니다. 자세한 내용은 이후 쿠버네티스 관련 포스트에서 따로 다루도록 하겠습니다.</p><ul><li>여러 노드를 하나의 노드처럼 관리</li><li>노드의 부하를 확인해 컨테이너를 어디에 배포할 지 스케쥴링(scheduling)</li><li>컨테이너의 상태를 체크해 자동 복구(self healing)</li><li>부하에 따라 오토 스케일링(auto scaling)</li></ul><p>쿠버네티스는 구글에서 시작된 오픈소스로, 구글의 15년 이상의 컨테이너 운영 경험이 녹아 있습니다. Google Kubernetes Engine 은 <a href="https://cloud.google.com" rel="external nofollow noopener noreferrer" target="_blank">Google Cloud Platform</a> 에서 제공하는 완전관리형(fully-managed) 쿠버네티스 클러스터로 Google SRE 가 관리하며 쿠버네티스의 최신 버전을 자동으로 적용하기 때문에 다른 관리 없이 편하게 사용이 가능합니다.</p><p>이번 포스트는 쿠버네티스 클러스터를 구성하고 관리하는 것이 목적이 아니므로 GKE 로 애플리케이션을 배포하겠습니다.</p><h2 id="첫-번째-환경-google-cloud-build">첫 번째 환경: Google Cloud Build</h2><p>첫 번째로 구성해볼 환경은 GitHub 와 Google Cloud Build 를 이용한 구성입니다.</p><p><img src="github-cloudbuild.png" alt="GitHub 와 Cloud Build 를 이용한 CI/CD 구성"></p><ol><li>개발자가 코드를 작성하고 GitHub 으로 푸시합니다.</li><li>코드가 변경될 때마다 GitHub 와 연동된 Cloud Build 트리거가 실행됩니다.</li><li><code>cloudbuild.yaml</code> 에 정의된 빌드 작업을 수행합니다.</li><li>빌드 결과 생성된 도커 이미지를 컨테이너 레지스트리에 푸시합니다.</li><li>이미지를 GKE 클러스터에 배포합니다.</li></ol><h3 id="1-github-저장소-준비하기">1. GitHub 저장소 준비하기</h3><p>먼저 코드를 저장할 GitHub 부터 준비합시다.</p><p>GitHub에 새로운 저장소를 생성합니다.<br><img src="create-github-repository.png" alt="GitHub 저장소 생성하기"></p><p>소스에서 Git 을 초기화합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">Initialized empty Git repository <span class="keyword">in</span> /home/vagrant/hello/.git/</span><br></pre></td></tr></table></figure><p>새로 만든 저장소를 remote 저장소로 추가합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin https://github.com/futureCreator/spring-boot-container.git</span><br></pre></td></tr></table></figure><p>저장소의 내용을 커밋하고 푸시합니다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;# spring-boot-container&quot; &gt;&gt; README.md</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;first commit&quot;</span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure><p>코드는 모두 준비됐습니다.</p><h3 id="2-트리거-생성하기">2. 트리거 생성하기</h3><p><a href="https://cloud.google.com/cloud-build/?hl=ko" rel="external nofollow noopener noreferrer" target="_blank">Google Cloud Build</a>는 따로 빌드 환경을 구축할 필요 없이 간단하게 빌드할 수 있고, 구글의 서비스와 쉽게 통합할 수 있는 빌드 서비스입니다. GitHub와 연동해서 소스가 변경될 때 빌드를 트리거해서 시작하고, 빌드 과정을 <code>cloudbuild.yaml</code>에 정의하면 자동으로 빌드가 생성됩니다.</p><p>이후 실습에서 GCP 를 사용하면서 요금이 발생할 수 있습니다. GCP 는 가입 시 1년 동안 사용할 수 있는 $300 크레딧을 제공하므로 실습에는 큰 문제가 없을 겁니다. 회원 가입 후 새로운 프로젝트를 생성합니다.</p><p>GCP 는 사용하고자 하는 서비스의 API를 미리 활성화해야 합니다. API 매니저로 접속해서 Cloud Build API, Kubernetes Engine API, Container Registry API 등 실습하면서 필요할 때마다 해당 API 를 활성화하면 됩니다.</p><p>이제 빌드 트리거를 생성해봅시다. 먼저 GCP 검색 창에 ‘Cloud 빌드’를 검색하고 트리거 메뉴로 들어갑니다. <strong>트리거 만들기</strong>를 누르고 <strong>GitHub</strong> 를 선택합니다. 인증을 하면 해당 계정의 저장소가 나타나는데 위에서 만든 저장소를 선택합니다.</p><p>그리고 다음과 같이 트리거를 생성합니다. <code>cloudbuild.yaml</code> 파일로 빌드를 설정할 겁니다.</p><p><img src="cloud-build-trigger.png" alt="빌드 트리거 생성하기"></p><p>이제 모든 브랜치에 푸시될 경우 해당 트리거가 실행됩니다. 물론 콘솔에서 직접 수동으로 실행할 수도 있고 터미널에서 실행할 수도 있습니다.</p><h3 id="3-빌드하기">3. 빌드하기</h3><p>이제 빌드 작업을 <code>cloudbuild.yaml</code>에 작성할 차례입니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">steps:</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/mvn'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['install']</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/docker'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['build',</span> <span class="string">'-t'</span><span class="string">,</span> <span class="string">'gcr.io/spring-boot-container/spring-boot-container-test'</span><span class="string">,</span> <span class="string">'.'</span><span class="string">]</span></span><br><span class="line"><span class="attr">  timeout:</span> <span class="number">500</span><span class="string">s</span></span><br><span class="line"><span class="attr">options:</span></span><br><span class="line"><span class="attr">  machineType:</span> <span class="string">'N1_HIGHCPU_8'</span> <span class="comment"># HIGHCPU로 빌드 스피드 업</span></span><br><span class="line"><span class="attr">timeout:</span> <span class="number">1000</span><span class="string">s</span> <span class="comment"># 빌드 자체에 대한 타임 아웃</span></span><br></pre></td></tr></table></figure><ul><li>각 스텝의 <code>name</code>은 빌드에 사용하는 이미지를 나타냅니다(cloud-builders). 해당 이미지의 컨테이너에서 빌드가 수행됩니다.</li><li>먼저 <code>mvn</code> 이미지에서 <code>install</code> 작업이 수행되고 <code>docker</code> 이미지에서 빌드를 수행합니다.</li></ul><p>파일을 생성하고 푸시하면 트리거가 작동해서 빌드가 수행됩니다.</p><p><img src="build-phase.png" alt="Cloud Build 결과"></p><h3 id="4-container-registry-에-이미지-푸시하기">4. Container Registry 에 이미지 푸시하기</h3><p>컨테이너의 장점 중 하나는 해당 이미지를 재활용할 수 있다는 점입니다. 자주 사용하는 이미지를 저장해놓고 언제든 내려받아 컨테이너로 실행할 수 있습니다. 이러한 이미지 저장소를 Docker Registry 또는 Container Registry 라고 합니다. Docker Hub 는 도커에서 운영하는 대표적인 컨테이너 레지스트리입니다.</p><p>이 외에도 클라우드 프로바이더는 private한 레지스트리를 제공합니다. AWS 의 Elastic Container Registry, GCP 의 Google Container Registry 가 있습니다. 이러한 레지스트리는 취약점 스캔, 위험한 이미지 자동 잠금, 자사 서비스와의 통합 등 부가 기능을 제공합니다. 특히 컨테이너는 애플리케이션과 환경을 함께 저장하므로 보안에 취약한데 이를 보완해주는 기능을 제공합니다.</p><p>Container Registry 를 사용하는 방법은 간단합니다. 위에서 본 것처럼 도커 이미지 빌드 시에 <code>[HOSTNAME]/[PROJECT-ID]/[IMAGE]:[TAG]</code> 형태로 태그를 달게 되는데요, 기본적으로 도커 허브(<code>docker.io</code>)가 적용됩니다. 우리는 Google Container Registry 에 맞는 태그를 달고 푸시해주면 됩니다.</p><p><code>cloudbuild.yaml</code> 해당 작업을 추가합시다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">steps:</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/mvn'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['install']</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/docker'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['build',</span> <span class="string">'-t'</span><span class="string">,</span> <span class="string">'gcr.io/spring-boot-container/spring-boot-container-test'</span><span class="string">,</span> <span class="string">'.'</span><span class="string">]</span></span><br><span class="line"><span class="attr">  timeout:</span> <span class="number">500</span><span class="string">s</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/docker'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['push',</span> <span class="string">'gcr.io/spring-boot-container/spring-boot-container-test'</span><span class="string">]</span></span><br><span class="line"><span class="attr">options:</span></span><br><span class="line"><span class="attr">  machineType:</span> <span class="string">'N1_HIGHCPU_8'</span> <span class="comment"># HIGHCPU로 빌드 스피드 업</span></span><br><span class="line"><span class="attr">timeout:</span> <span class="number">1000</span><span class="string">s</span> <span class="comment"># 빌드 자체에 대한 타임 아웃</span></span><br></pre></td></tr></table></figure><ul><li>도커 빌드 시 태그명의 <code>gcr.io</code> 가 바로 Google Container Registry 입니다.</li><li><code>docker push</code> 를 하면 해당 태그에 맞춰서 저장소에 추가됩니다.</li></ul><p>빌드 작업 후 컨테이너 이미지가 추가된 것을 확인할 수 있습니다. 새로운 이미지는 <code>latest</code> 라는 태그가 자동으로 추가됩니다.</p><p><img src="container-registry-image.png" alt="컨테이너 이미지가 추가된 모습"></p><h3 id="5-kubernetes-engine-에-배포하기">5. Kubernetes Engine 에 배포하기</h3><p>지금까지 지속적인 통합(Continuous Integration) 환경을 구축했고 지속적인 배포(Continuous Deployment) 환경을 구축해봅시다.</p><p>빌드한 이미지를 쿠버네티스 클러스터에 Deployment 오브젝트로 배포합니다. 쿠버네티스의 Deployment 는 컨테이너 단위인 Pod 과 컨테이너의 개수를 유지해주는 ReplicaSet 을 포함하고, 배포 시 롤링 업데이트<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="롤링 업데이트(Rolling Update)란 기존 서비스를 유지하면서 업데이트하기 위한 방법으로, 여러 개의 인스턴스가 있을 때 하나씩 새로운 버전의 인스턴스로 교체하는 방법입니다.">[1]</span></a></sup> 을 지원합니다. 또한 Deployment 를 노출(expose)해서 외부에서 접근하는 서비스를 생성할 수 있습니다.</p><p>콘솔에서 GKE에 접속해 <strong>작업부하</strong> 메뉴에서 <strong>배포</strong>를 클릭해 새로운 배포를 생성합니다.</p><p><strong>Google Container Registry 이미지 선택</strong>을 클릭해 빌드한 이미지를 선택하고 <strong>완료</strong>를 클릭해 컨테이너를 추가합니다.</p><p>추가 정보를 작성합니다. 클러스터는 기존 클러스터를 생성해도 되지만 새로운 클러스터를 생성하겠습니다.<br><img src="create-k8s-deployment.png" alt="클러스터 정보"></p><p>클러스터가 생성되길 기다리면서 IAM에 권한을 추가합시다. Cloud Build의 서비스 계정이 클러스터에 접근해야 하므로 역할(권한)을 추가해줘야 합니다. <strong>IAM 및 관리자</strong> 메뉴에서 <strong>Cloud 빌드 서비스 계정</strong>의 권한에 <strong>Kubernetes Engine 관리자</strong> 역할을 추가합니다.<br><img src="iam-cloud-build-role.png" alt="Kubernetes Engine 관리자 역할 추가"></p><p><code>cloudbuild.yaml</code> 에 배포 작업을 추가합시다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">steps:</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/mvn'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['install']</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/docker'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['build',</span> <span class="string">'-t'</span><span class="string">,</span> <span class="string">'gcr.io/spring-boot-container/spring-boot-container-test'</span><span class="string">,</span> <span class="string">'.'</span><span class="string">]</span></span><br><span class="line"><span class="attr">  timeout:</span> <span class="number">500</span><span class="string">s</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/docker'</span></span><br><span class="line"><span class="attr">  args:</span> <span class="string">['push',</span> <span class="string">'gcr.io/spring-boot-container/spring-boot-container-test'</span><span class="string">]</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">'gcr.io/cloud-builders/kubectl'</span></span><br><span class="line"><span class="attr">  args:</span> </span><br><span class="line"><span class="bullet">  -</span> <span class="string">set</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">image</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">deployment/spring-boot-container</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">spring-boot-container-test=gcr.io/spring-boot-container/spring-boot-container-test</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">-n</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">spring-boot</span></span><br><span class="line"><span class="attr">  env:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'CLOUDSDK_COMPUTE_ZONE=us-central1-a'</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'CLOUDSDK_CONTAINER_CLUSTER=spring-boot-container-cluster'</span></span><br><span class="line"><span class="attr">options:</span></span><br><span class="line"><span class="attr">  machineType:</span> <span class="string">'N1_HIGHCPU_8'</span> <span class="comment"># HIGHCPU로 빌드 스피드 업</span></span><br><span class="line"><span class="attr">timeout:</span> <span class="number">1000</span><span class="string">s</span> <span class="comment"># 빌드 자체에 대한 타임 아웃</span></span><br></pre></td></tr></table></figure><ul><li><code>kubectl set image</code> 명령어를 이용해 컨테이너 이미지를 변경합니다.</li><li><code>CLOUDSDK_COMPUTE_ZONE</code>: 클러스터를 생성한 지역입니다.</li><li><code>CLOUDSDK_CONTAINER_CLUSTER</code>: 생성한 클러스터명입니다.</li><li><code>-n spring-boot</code>: 해당 Deployment 가 있는 namespace 를 지정합니다.</li></ul><p>이제 빌드 후 이미지가 새로 생성되면, 클러스터에서 새로운 이미지를 기반으로 Pod 이 새로 생성됩니다.<br><img src="cloud-build-result.png" alt="빌드 및 배포 결과"></p><p>새로운 이미지가 배포되어 Pod이 새로 생성된 것을 볼 수 있습니다.<br><img src="kubectl-deploy-result.png" alt="배포 결과 확인"></p><p>첫 번째 환경으로 GitHub와 Cloud Build를 이용해서 배포하는 환경을 구축해봤습니다. 각 단계별로 수정해볼만한 항목입니다.</p><ul><li>GitHub와 연동한 저장소는 Google Code Source Repository 에서도 확인할 수 있습니다. 물론 GitHub 대신 여기서 저장소를 생성해서 사용할 수도 있습니다.</li><li><code>cloudbuild.yaml</code> 에서 빌드 작업을 정의했습니다. 빌드 작업을 하나의 YAML 파일로 관리할 수 있어 편리했습니다. 메이븐 빌드는 <code>Dockerfile</code> 에서 수행하도록 수정할 수도 있습니다.</li><li>컨테이너 레지스트리는 다른 레지스트리를 사용할 수도 있지만 GCP 서비스와 연동이 잘 되는 Google Container Registry를 사용했습니다. 또한 취약점 검사를 적용해볼 수도 있고, 해당 이미지를 공개하면 다른 곳에서도 사용할 수 있습니다.</li><li>GKE는 쿠버네티스에 친숙하지 않더라도 쉽게 사용할 수 있도록 웹 UI에서 다양한 기능을 제공하고 있습니다. 이 외에도 Deployment 를 노출해 서비스를 만들 수도 있습니다.</li><li>빌드 과정에서 <code>mvn test</code> 를 수행하며 단위 테스트를 수행합니다. 실운영 환경에서는 빌드 과정에서 빌드 및 통합 테스트 스텝을 추가하는 것이 좋습니다.</li></ul><h2 id="두-번째-환경-gitlab-gke">두 번째 환경: GitLab + GKE</h2><p>이번에는 GitLab 위주의 환경을 구성해보겠습니다.</p><p><img src="gitlab-cicd.png" alt="GitLab 과 GKE 를 이용한 CI/CD 구성"></p><p>GitLab은 GitHub에 비해 많이 사용되진 않지만 상당히 유용한 도구입니다. GitHub 처럼 다른 도구와 연동을 많이 제공하진 않지만 GitLab 자체에서 CI/CD 기능을 지원하고 Container Registry 도 지원합니다. 또한 GKE 와 연동해 클러스터의 상태를 바로 확인할 수 있습니다. 코드 저장소에서 빌드 파이프라인과 배포 상태까지 확인하는 것은 상당히 유용합니다.</p><h3 id="1-gitlab-저장소-준비하기">1. GitLab 저장소 준비하기</h3><p>두 번째 환경은 대부분 GitLab에서 지원하는 기능을 사용하기 때문에 설정이 더 간단합니다.</p><p>GitLab 저장소를 새로 만듭니다. 그리고 위에서 사용한 소스에 origin 을 새로 추가하고 푸시합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote add gitlab_origin https://gitlab.com/futureCreator/spring-boot-container.git</span><br><span class="line">git push -u gitlab_origin master</span><br></pre></td></tr></table></figure><p>저장소는 간단하게 준비했습니다.</p><h3 id="2-메이븐-빌드하기">2. 메이븐 빌드하기</h3><p>먼저 메이븐 빌드를 먼저 정의합니다.</p><p>코드를 푸시하면 GitLab 대시보드에서 다음과 같은 화면을 볼 수 있습니다.<br><img src="gitlab-dashboard.png" alt="GitLab 대시보드"></p><p><strong>Set up CI/CD</strong> 를 클릭하면 <code>.gitlab-cicd.yml</code> 파일을 작성하는 화면으로 넘어갑니다. 위에서 작성한 <code>cloudbuild.yaml</code> 처럼 빌드 작업을 정의하는 파일입니다. 해당 파일을 작성하면 자동으로 CI/CD 가 적용됩니다.<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="빌드 설정이 친숙하지 않은 개발자를 위해 사전에 정의된 CI/CD 설정으로 빌드 작업을 자동화하는 [Auto DevOps](https://about.gitlab.com/product/auto-devops/)라는 기능도 있습니다. `Auto Build`, `Auto Test`, `Auto Deploy` 등 기능을 제공합니다. GitLab 11.3부터 모든 프로젝트에 Auto DevOps가 기본적으로 설정되어 있어 코드를 처음 올리면 파이프라인 작업이 수행됩니다. 물론 완벽히 구성하지 않은 상태여서 첫 번째 파이프라인 작업이 실패한다면 해당 설정은 disabled 됩니다.">[2]</span></a></sup></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="attr">docker:latest</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  - docker:</span><span class="string">dind</span></span><br><span class="line"></span><br><span class="line"><span class="attr">variables:</span></span><br><span class="line"><span class="attr">  DOCKER_DRIVER:</span> <span class="string">overlay</span></span><br><span class="line"><span class="attr">  SPRING_PROFILES_ACTIVE:</span> <span class="string">gitlab-ci</span></span><br><span class="line"></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">build</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">package</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">maven-build:</span></span><br><span class="line"><span class="attr">  image:</span> <span class="attr">maven:3-jdk-8</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">build</span></span><br><span class="line"><span class="attr">  script:</span> <span class="string">"mvn install"</span></span><br><span class="line"><span class="attr">  artifacts:</span></span><br><span class="line"><span class="attr">    paths:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">target/*.jar</span></span><br></pre></td></tr></table></figure><p>해당 커밋에 대해 빌드 파이프라인이 생성됩니다. <strong>CI/CD &gt; Pipeline</strong> 화면에서 파이프라인의 빌드와 잡을 확인할 수 있습니다.<br><img src="gitlab-maven-build.png" alt="GitLab 메이븐 빌드"></p><p><code>cloudbuild.yaml</code> 과 문법은 다르지만 어떤 내용인지는 쉽게 알아 볼 수 있습니다.</p><h3 id="3-도커-빌드하고-container-registry-에-푸시하기">3. 도커 빌드하고 Container Registry 에 푸시하기</h3><p>이번엔 도커 빌드 스테이지를 추가하고 GitLab 저장소에 자동으로 생성되는 컨테이너 레지스트리에 도커 이미지를 푸시하겠습니다.</p><p>컨테이너 레지스트리는 저장소의 <strong>Registry</strong> 메뉴에 있습니다. 간단한 사용법을 확인할 수 있습니다.</p><p><code>.gitlab-cicd.yml</code> 파일에 도커 빌드 작업을 추가합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="attr">docker:latest</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  - docker:</span><span class="string">dind</span></span><br><span class="line"></span><br><span class="line"><span class="attr">variables:</span></span><br><span class="line"><span class="attr">  DOCKER_DRIVER:</span> <span class="string">overlay</span></span><br><span class="line"><span class="attr">  SPRING_PROFILES_ACTIVE:</span> <span class="string">gitlab-ci</span></span><br><span class="line"></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">build</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">package</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">maven-build:</span></span><br><span class="line"><span class="attr">  image:</span> <span class="attr">maven:3-jdk-8</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">build</span></span><br><span class="line"><span class="attr">  script:</span> <span class="string">"mvn install"</span></span><br><span class="line"><span class="attr">  artifacts:</span></span><br><span class="line"><span class="attr">    paths:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">target/*.jar</span></span><br><span class="line">      </span><br><span class="line"><span class="attr">docker-build:</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">package</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">docker</span> <span class="string">build</span> <span class="bullet">-t</span> <span class="string">registry.gitlab.com/futurecreator/spring-boot-container</span> <span class="string">.</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">docker</span> <span class="string">login</span> <span class="bullet">-u</span> <span class="string">gitlab-ci-token</span> <span class="bullet">-p</span> <span class="string">$CI_BUILD_TOKEN</span> <span class="string">registry.gitlab.com</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">docker</span> <span class="string">push</span> <span class="string">registry.gitlab.com/futurecreator/spring-boot-container</span></span><br></pre></td></tr></table></figure><p>빌드 결과를 확인합니다.<br><img src="gitlab-docker-build.png" alt="GitLab 도커 빌드 결과"></p><p>컨테이너 레지스트리에서 빌드된 이미지를 확인할 수 있습니다.<br><img src="gitlab-registry-result.png" alt="컨테이너 레지스트리"></p><p>이제 코드가 변경될 때마다 빌드가 수행되고 이미지가 레지스트리에 추가됩니다.</p><h3 id="4-gke-에-배포하기">4. GKE 에 배포하기</h3><p>마지막으로 쿠버네티스 클러스터에 배포할 차례입니다. 클러스터는 이전 실습에서 생성한 클러스터를 활용하면 되겠네요.</p><p>배포 과정 자체는 비슷하지만 GitLab 이 외부 서비스이다 보니 조금 더 손이 갑니다. cloud-sdk 로 클러스터에 접속하기 때문에 인증 절차가 필요합니다.</p><p>먼저 GCP의 <strong>IAM Service Account Credentials API &gt; 사용자 인증 정보</strong> 에서 서비스 계정의 키를 JSON 으로 생성합니다.<br><img src="create-key.png" alt="비공개 키 생성"></p><p>그러면 JSON Key를 자동으로 내려받습니다. 해당 JSON Key 내용을 복사해서 GitLab 의 <strong>Settings &gt; CI/CD &gt; Environment variables</strong> 에 <code>GOOGLE_KEY</code> 로 추가합니다.</p><p>클러스터에서 사전 작업을 합시다. 먼저 해당 애플리케이션을 배포할 네임스페이스를 생성합니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace spring-boot-2</span><br></pre></td></tr></table></figure><p>GitLab 레지스트리에서 이미지를 받아오기 위한 계정 정보를 Secret 객체로 만들어야 합니다. 각 값은 여러분의 계정으로 작성하면 됩니다.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret docker-registry registry.gitlab.com --docker-server=https://registry.gitlab.com --docker-username=yourusername --docker-password=yourpassword --docker-email=youremail -n spring-boot-2</span><br></pre></td></tr></table></figure><p>이제 배포를 합시다. 첫 번째 환경을 구성할 때는 미리 배포가 되어 있어서 배포된 이미지를 교체하는 <code>kubectl set image</code> 명령어를 사용했습니다. 이번에는 변경 사항을 파일로 적용하는 <code>kubectl apply -f</code> 명령어를 이용하기 위해 소스 폴더 루트에 <code>deployment.yaml</code> 파일을 추가합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">spring-boot-container</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">spring-boot-2</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">spring-boot-container</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">spring-boot-container</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">spring-boot-container</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">spring-boot-container</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">registry.gitlab.com/futurecreator/spring-boot-container</span></span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">      imagePullSecrets:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">registry.gitlab.com</span></span><br></pre></td></tr></table></figure><ul><li>내용을 살펴보면 첫 번째 환경의 배포 YAML 과 비슷합니다.</li><li>다른 점은 배포할 네임스페이스, 이미지, 그리고 이미지를 내려받을 때 사용할 <code>imagePullSecrets</code> 설정입니다.</li></ul><p>이제 <code>.gitlab-cicd.yml</code> 파일에 배포 과정을 추가합니다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="attr">docker:latest</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  - docker:</span><span class="string">dind</span></span><br><span class="line"></span><br><span class="line"><span class="attr">variables:</span></span><br><span class="line"><span class="attr">  DOCKER_DRIVER:</span> <span class="string">overlay</span></span><br><span class="line"><span class="attr">  SPRING_PROFILES_ACTIVE:</span> <span class="string">gitlab-ci</span></span><br><span class="line"></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">build</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">package</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">maven-build:</span></span><br><span class="line"><span class="attr">  image:</span> <span class="attr">maven:3-jdk-8</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">build</span></span><br><span class="line"><span class="attr">  script:</span> <span class="string">"mvn install"</span></span><br><span class="line"><span class="attr">  artifacts:</span></span><br><span class="line"><span class="attr">    paths:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">target/*.jar</span></span><br><span class="line">      </span><br><span class="line"><span class="attr">docker-build:</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">package</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">docker</span> <span class="string">build</span> <span class="bullet">-t</span> <span class="string">registry.gitlab.com/futurecreator/spring-boot-container</span> <span class="string">.</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">docker</span> <span class="string">login</span> <span class="bullet">-u</span> <span class="string">gitlab-ci-token</span> <span class="bullet">-p</span> <span class="string">$CI_BUILD_TOKEN</span> <span class="string">registry.gitlab.com</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">docker</span> <span class="string">push</span> <span class="string">registry.gitlab.com/futurecreator/spring-boot-container</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">k8s-deploy:</span></span><br><span class="line"><span class="attr">  image:</span> <span class="string">google/cloud-sdk</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">deploy</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">echo</span> <span class="string">"$GOOGLE_KEY"</span> <span class="string">&gt; key.json</span></span><br><span class="line"><span class="string">  - gcloud auth activate-service-account --key-file key.json</span></span><br><span class="line"><span class="string">  - gcloud config set compute/zone us-central1-a</span></span><br><span class="line"><span class="string">  - gcloud config set project spring-boot-container</span></span><br><span class="line"><span class="string">  - gcloud container clusters get-credentials spring-boot-container-cluster</span></span><br><span class="line"><span class="string">  - kubectl apply -f deployment.yaml</span></span><br></pre></td></tr></table></figure><ul><li><code>gcloud</code> 를 이용해 클러스터에 접속합니다. 접속이 안될 경우 <code>GOOGLE_KEY</code>, 프로젝트명, 지역, 클러스터 이름 등 접속 정보를 확인합니다.</li><li>우리가 작성한 <code>deployment.yaml</code> 을 이용해 변경 사항을 배포합니다.</li></ul><p>빌드 결과를 확인합니다.<br><img src="gitlab-gke-deploy-result.png" alt="GitLab 빌드 결과 확인"></p><p>클러스터에 접속해 배포 결과를 확인합니다.<br><img src="gitlab-gke-deploy-kubectl.png" alt="GKE 배포 결과 확인"></p><p>이번에는 GitLab 의 서비스를 주로 이용해서 CI/CD  환경을 구성했습니다. Cloud Build 와 비교했을 때 서비스가 무료이고 GitLab 안에서 대부분 해결할 수 있다는 장점이 있습니다(물론 GitLab 도 특정 서비스는 유료입니다). 또한 해당 서비스를 시각적으로 파이프라인으로 볼 수 있는 것도 장점입니다.</p><h2 id="정리">정리</h2><p>이번 포스트에서는 간단한 스프링부트 애플리케이션을 작성해서 컨테이너로 만들고 CI/CD 환경을 구성했습니다. 코드가 수정될 때마다 빌드하고 원하는 환경에 배포까지 쉽게 할 수 있었습니다. 기존에 많이 사용하는 Jenkins 는 별도의 서버를 구성하거나 쿠버네티스 클러스터에 별도의 컨테이너를 띄워야 합니다. 그래서 최대한 쉽게 접근해서 구성할 수 있는 환경 위주로 실습했습니다.</p><p>실습에 사용한 코드는 다음 저장소에서 확인할 수 있습니다.</p><ul><li><a href="https://github.com/futureCreator/spring-boot-container" rel="external nofollow noopener noreferrer" target="_blank">https://github.com/futureCreator/spring-boot-container</a></li><li><a href="https://gitlab.com/futureCreator/spring-boot-container" rel="external nofollow noopener noreferrer" target="_blank">https://gitlab.com/futureCreator/spring-boot-container</a></li></ul><h2 id="참고">참고</h2><ul><li><a href="https://spring.io/blog/2018/11/08/spring-boot-in-a-container" rel="external nofollow noopener noreferrer" target="_blank">Spring Boot in Conatiner | Spring.io</a></li><li><a href="https://cloud.google.com/cloud-build/docs/" rel="external nofollow noopener noreferrer" target="_blank">Google Cloud Build Docs | Google Cloud Platform</a></li><li><a href="https://docs.gitlab.com/ee/ci/" rel="external nofollow noopener noreferrer" target="_blank">GItLab Continuous Intergration (GitLab CI/CD) | GitLab Docs</a></li></ul><h2 id="related-posts">Related Posts</h2><ul><li><a href="/2018/11/16/docker-container-basics/" title="도커 Docker 기초 확실히 다지기">도커 Docker 기초 확실히 다지기</a></li><li><a href="/2018/11/09/it-infrastructure-basics/" title="개발자를 위한 인프라 기초 총정리">개발자를 위한 인프라 기초 총정리</a></li><li><a href="/2018/07/04/aws-certified/" title="AWS 자격증 준비하기">AWS 자격증 준비하기</a></li><li><a href="/2018/12/15/aws-reinvent-2018-summary/" title="AWS re:Invent 2018 한 방에 정리하기">AWS re:Invent 2018 한 방에 정리하기</a></li><li><a href="/2019/02/25/kubernetes-cluster-on-google-compute-engine-for-developers/" title="개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)">개발자를 위한 쿠버네티스(Kubernetes) 클러스터 구성하기(Kubeadm, GCE, CentOS)</a></li></ul><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">롤링 업데이트(Rolling Update)란 기존 서비스를 유지하면서 업데이트하기 위한 방법으로, 여러 개의 인스턴스가 있을 때 하나씩 새로운 버전의 인스턴스로 교체하는 방법입니다.<a href="#fnref:1" rev="footnote"> ↩</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">빌드 설정이 친숙하지 않은 개발자를 위해 사전에 정의된 CI/CD 설정으로 빌드 작업을 자동화하는 <a href="https://about.gitlab.com/product/auto-devops/" rel="external nofollow noopener noreferrer" target="_blank">Auto DevOps</a>라는 기능도 있습니다. <code>Auto Build</code>, <code>Auto Test</code>, <code>Auto Deploy</code> 등 기능을 제공합니다. GitLab 11.3부터 모든 프로젝트에 Auto DevOps가 기본적으로 설정되어 있어 코드를 처음 올리면 파이프라인 작업이 수행됩니다. 물론 완벽히 구성하지 않은 상태여서 첫 번째 파이프라인 작업이 실패한다면 해당 설정은 disabled 됩니다.<a href="#fnref:2" rev="footnote"> ↩</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;이번 포스트에서는 간단한 스프링 부트(Spring Boot) 애플리케
      
    
    </summary>
    
      <category term="Cloud" scheme="https://futurecreator.github.io/categories/Cloud/"/>
    
    
      <category term="github" scheme="https://futurecreator.github.io/tags/github/"/>
    
      <category term="deploy" scheme="https://futurecreator.github.io/tags/deploy/"/>
    
      <category term="container" scheme="https://futurecreator.github.io/tags/container/"/>
    
      <category term="docker" scheme="https://futurecreator.github.io/tags/docker/"/>
    
      <category term="kubernetes" scheme="https://futurecreator.github.io/tags/kubernetes/"/>
    
      <category term="gcp" scheme="https://futurecreator.github.io/tags/gcp/"/>
    
      <category term="spring-boot" scheme="https://futurecreator.github.io/tags/spring-boot/"/>
    
      <category term="gke" scheme="https://futurecreator.github.io/tags/gke/"/>
    
      <category term="gitlab" scheme="https://futurecreator.github.io/tags/gitlab/"/>
    
      <category term="ci-cd" scheme="https://futurecreator.github.io/tags/ci-cd/"/>
    
      <category term="build" scheme="https://futurecreator.github.io/tags/build/"/>
    
  </entry>
  
  <entry>
    <title>AWS re:Invent 2018 한 방에 정리하기</title>
    <link href="https://futurecreator.github.io/2018/12/15/aws-reinvent-2018-summary/"/>
    <id>https://futurecreator.github.io/2018/12/15/aws-reinvent-2018-summary/</id>
    <published>2018-12-15T14:34:44.000Z</published>
    <updated>2019-02-27T15:45:53.934Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><a href="https://reinvent.awsevents.com/" rel="external nofollow noopener noreferrer" target="_blank">AWS re:Invent</a> 는 AWS(<em>Amazon Web Service</em>)의 대표적인 컨퍼런스로 새로운 서비스와 기능을 발표하는 행사입니다. 또한 클라우드 컴퓨팅 시장을 선도하는 회사답게 가장 규모가 크고 인기가 많은 행사입니다. 이번 행사에서는 4일간의 키노트 세션과 전야제에서 100개 이상의 서비스가 새로 출시되었습니다. 기존 서비스는 더 정교해지고, 새로운 서비스로 지원하는 영역은 더 넓어졌습니다.</p><p>물론 모든 서비스를 모두 알 필요는 없습니다. 이 많은 서비스를 모두 알고 잘 다룰 수도 없을 뿐더러 그럴 필요도 없기 때문입니다. 하지만 신규 서비스를 살펴보면서 AWS 가 어떤 방향으로 가고 있는지, 클라우드 컴퓨팅이 어떻게 발전할지 살펴보는 건 의미있는 일입니다.</p><p>이번 포스팅에서는 분야별로 새로 출시된 주요 AWS 서비스를 살펴보겠습니다.</p><ul><li>글로벌 인프라</li><li>컴퓨팅</li><li>스토리지</li><li>데이터베이스</li><li>머신 러닝과 인공 지능</li><li>보안 및 클라우드 하이브리드</li><li>차세대 산업 (IoT, 로봇, 우주 산업)</li></ul><h2 id="글로벌-인프라-global-infrastructure">글로벌 인프라 Global Infrastructure</h2><p>먼저 글로벌 인프라부터 살펴보겠습니다. AWS 는 단순 리전 확장 뿐 아니라 인프라 성능과 가용성을 높이고, 여러 네트워크를 쉽게 관리할 수 있는 서비스를 제공합니다.</p><ul><li>글로벌 리전 확장</li><li>AWS Global Accelerator</li><li>AWS Transit Gateway</li></ul><h3 id="글로벌-리전-확장">글로벌 리전 확장</h3><p><img src="https://d1.awsstatic.com/about-aws/Global%20Infrastructure/Global-Infrastructure-update_Stockholm.0dcd1b04b611082716971185b6963d224eef86ae.png" alt="https://aws.amazon.com/ko/about-aws/global-infrastructure/"></p><p>AWS 는 전 세계에 데이터 센터를 보유하고 있습니다. 이 데이터 센터는 리전(<em>Region</em>)과 가용 영역(<em>Availability Zone, AZ</em>)으로 나뉘어져 있는데요. 데이터 센터를 지역별 물리적인 위치로 나누고, 리전 안에서도 가용 영역을 나눕니다. 따라서 인스턴스의 장애가 다른 곳으로 퍼지는 것을 막고  글로벌 서비스 시 원하는 지역에 빠른 서비스가 가능합니다.</p><p><img src="https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/images/aws_regions.png" alt="https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/using-regions-availability-zones.html"></p><p>AWS 는 글로벌 리전을 확장해 19개의 리전과 57개의 가용 영역을 구축했습니다. 앞으로 바레인, 케이프타운, 홍콩, 스톡홀름 등 4개의 리전을 추가할 계획이라고 합니다. 우리나라에는 2016년부터 서비스된 아시아 태평양 서울 리전이 있습니다. 또한 AWS 는 전 세계 150개 이상의 글로벌 PoP와 89 Direct Connect 전용선 연결 지점, 100GbE 네트워크망을 운영 중입니다.</p><p>따라서 AWS 를 통해 더 빠르고 안전한 서비스를 제공할 수 있습니다. 물론 리전과 가용 영역을 최대한 활용할 수 있는 설계가 필요합니다. 비용은 더 들겠지만 멀티 리전으로 구축해야만 AWS 장애 시 피해를 최소화할 수 있습니다.</p><h3 id="aws-global-accelerator">AWS Global Accelerator</h3><p><img src="https://d1.awsstatic.com/r2018/b/ubiquity/global-accelerator-before.46be83fdc7c630457bba963c7dc928cb676d9046.png" alt="https://aws.amazon.com/ko/global-accelerator/?nc2=h_re"></p><p>글로벌 애플리케이션의 경우 사용자의 위치에 따라 여러 네트워크를 거치면서 성능에 영향을 줍니다. 또한 중간에 네트워크에 문제가 생길 경우 서비스가 제공되지 않을 수도 있죠.</p><p><img src="https://d1.awsstatic.com/r2018/b/ubiquity/global-accelerator-after.2e404ac7f998e501219f2614bc048bb9c01f46d4.png" alt="https://aws.amazon.com/ko/global-accelerator/?nc2=h_re"></p><p><a href="https://aws.amazon.com/ko/global-accelerator/?nc2=h_re" rel="external nofollow noopener noreferrer" target="_blank">AWS Global Accelerator</a> 는 AWS 글로벌 네트워크를 활용해 경로를 최적화해서 성능을 높이고, 지속적인 모니터링으로 가용성을 제공합니다. 따라서 재해 복구에 대응하고, 성능 개선과 네트워크 확장 등을 손쉽게 구성할 수 있습니다.</p><h3 id="aws-transit-gateway">AWS Transit Gateway</h3><p><img src="https://d1.awsstatic.com/r2018/b/transit-gateway/tgw-before.ad71b2b9e9d7cc759ac712e4919659ba619cca35.png" alt="https://aws.amazon.com/ko/transit-gateway/?nc2=h_re"></p><p>Amazon VPC(<em>Amazon Virtual Private Cloud</em>)는 사내 시스템과 같은 프라비잇 클라우드를  손쉽게 구축할 수 있는 서비스입니다. AWS 상에서 처리할 수 있는 워크로드가 많아지고 확장되면서 VPC 끼리 혹은 기존의 온프레미스 네트워크와 연결이 필요해지는데요. 기존에는 VPN 연결을 중앙에서 관리할 수 없어서 연결이 많아질수록 관리하기가 매우 복잡했습니다.</p><p><img src="https://d1.awsstatic.com/r2018/b/transit-gateway/tgw-after.a35c10feecbbbab677150eac358aa478dbf787fa.png" alt="https://aws.amazon.com/ko/transit-gateway/?nc2=h_re"></p><p><a href="https://aws.amazon.com/ko/transit-gateway/?nc2=h_re" rel="external nofollow noopener noreferrer" target="_blank">AWS Transit Gateway</a> 는 Amazon VPC와 온프레미스 네트워크를 손쉽게 연결하고 중앙에서 모니터링하고 관리하는 기능을 제공합니다. 따라서 확장하기 쉽고 아키텍처를 간소화할 수 있습니다.</p><h2 id="컴퓨팅-computing">컴퓨팅 Computing</h2><p>컴퓨팅 분야에서는 자체 칩셋을 이용한 인스턴스와 서버리스에 대한 지원이 돋보이네요. 아래 주제에 대해 살펴봅니다.</p><ul><li>EC2 Instance</li><li>Container</li><li>Serverless</li></ul><h3 id="ec2-instance">EC2 Instance</h3><p>Amazon Elastic Compute Clode(<em>EC2</em>)는 AWS 의 대표적인 서비스로 VM 인스턴스를 제공합니다. 인스턴스 타입을 다양하게 제공해서 사용자가 원하는 용도에 맞게 선택할 수 있습니다. 같은 인스턴스라도 vCPU, 메모리, 스토리지, 네트워크 성능 등에 따라 세부적으로 선택할 수 있습니다.<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="https://aws.amazon.com/ko/ec2/instance-types/">[1]</span></a></sup></p><table><thead><tr><th>용도</th><th>인스턴스 모델</th><th>설명</th></tr></thead><tbody><tr><td>범용</td><td>M5, M5a, M5d, M4</td><td>균형 있는 성능 제공</td></tr><tr><td>범용 + 버스팅</td><td>T3, T3a, T2</td><td>균형 있는 성능 + CPU 사용량 버스팅</td></tr><tr><td>컴퓨팅</td><td>C5, C5d, C4</td><td>컴퓨팅 집약적 워크로드에 최적화</td></tr><tr><td>메모리</td><td>R5, R5a, R5d, R4</td><td>메모리 사용에 최적화</td></tr><tr><td>대용량 메모리</td><td>X1, X1e</td><td>대규모 in-memory 사용에 최적화<br>RAM 요금이 가장 저렴</td></tr><tr><td>HPC 전용</td><td>Z1d</td><td>고성능 컴퓨팅 제공</td></tr><tr><td>범용 GPU</td><td>P3, P2</td><td>GPU 컴퓨팅 애플리케이션에 적합 (머신 러닝, 딥 러닝 등)</td></tr><tr><td>그래픽 최적화</td><td>G3</td><td>그래픽 집약적 워크로드에 최적화</td></tr><tr><td>FPGA</td><td>F1</td><td>FPGA(<em>Field Programmable Gate Array</em>)<br>용도에 따라 커스터마이징할 수 있는 칩</td></tr><tr><td>스토리지</td><td>D2</td><td>우수한 디스크 처리량 제공</td></tr><tr><td>빅데이터</td><td>H1</td><td>균형 있는 성능과 높은 디스크 처리량 제공</td></tr><tr><td>고속 I/O</td><td>I3</td><td>고성능 NVMe(<em>Non-Volatile Memory Express</em>) SSD 지원<br>NoSQL, In-memory DB, Elasticsearch 등에 적합</td></tr><tr><td>베어메탈</td><td>I3m</td><td>가상화 되지 않은 베어 메탈(<em>Bare Metal</em>) 인스턴스</td></tr></tbody></table><p>인스턴스를 보시면 a 또는 d 가 붙어 있는 모델을 확인할 수 있는데요, 뒤에 a 가 붙은 모델(<em>M5a, R5a</em>)은 AMD 기반으로 비용을 절감할 수 있는 모델입니다. 그리고 d 가 붙은 모델(<em>M5d, R5d, Z1d, C5d</em>)은 호스트 서버에 NVMe  SSD 를 연결해 빠른 입출력을 제공하는 모델입니다.</p><p>그리고 이번 행사에서 두 개의 새로운 인스턴스를 공개했습니다.</p><h4 id="ec2-a1-instance">EC2 A1 Instance</h4><p>AWS 는 비용을 절감할 수 있고 클라우드 컴퓨팅에 최적화된 칩을 직접 만들기로 합니다. 2015년 인수한 <a href="http://www.annapurnalabs.com/" rel="external nofollow noopener noreferrer" target="_blank">Annapurna Labs</a> 을 통해 Arm 기반의 맞춤형 CPU를 개발하고 이를 지원하는 첫 번째 인스턴스를 공개했습니다.</p><p><a href="https://aws.amazon.com/ko/ec2/instance-types/a1/" rel="external nofollow noopener noreferrer" target="_blank">EC2 A1 Instance</a> 는 웹 서버 및 컨테이너형 마이크로서비스에 최적화된 인스턴스로 인스턴스 확장 시 45%까지 비용을 절감할 수 있습니다.</p><h4 id="ec2-c5n-instance">EC2 C5n Instance</h4><p><a href="https://aws.amazon.com/ko/ec2/instance-types/c5/" rel="external nofollow noopener noreferrer" target="_blank">EC2 C5n Instance</a> 는 차세대 컴퓨팅 최적화 모델인 C5 인스턴스에 100Gbps 고성능 네트워킹을 추가한 인스턴스입니다. 따라서 대규모 작업을 신속하게 처리하고 네트워크 작업 부하의 비용을 절감할 수 있습니다.</p><h4 id="elastic-fabric-adapter">Elastic Fabric Adapter</h4><p>이 외에도 새로 출시된 <a href="https://aws.amazon.com/ko/about-aws/whats-new/2018/11/introducing-elastic-fabric-adapter/" rel="external nofollow noopener noreferrer" target="_blank">Elastic Fabric Adapter</a>(<em>EFA</em>)는 EC2 인스턴스를 위한 네트워크 인터페이스입니다. 애드온으로 인스턴스에 추가해서 사용할 수 있는 기능인데요. 전산 유체 역학, 기후 모델링, 저수지 시뮬레이션 등 인스턴스 간 통신이 필요한 고성능 컴퓨팅(<em>High-Performance Computing,HPC</em>) 애플리케이션을 지원합니다.</p><h3 id="container">Container</h3><p>현재 AWS에서는 컨테이너를 사용하는 몇 가지 옵션을 제공하고 있습니다.</p><h4 id="amazon-ecs">Amazon ECS</h4><p><img src="https://d1.awsstatic.com/diagrams/product-page-diagrams/product-page-diagram_ECS_1.86ebd8c223ec8b55aa1903c423fbe4e672f3daf7.png" alt="https://aws.amazon.com/ko/ecs/"></p><p><a href="https://aws.amazon.com/ko/ecs/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Elastic Container Service</a>(<em>ECS</em>)는 도커(<em>Docker</em>) 컨테이너를 관리하는 오케스트레이션 서비스로 컨테이너화한 애플리케이션을 쉽게 실행하고 확장 및 축소하는 기능을 제공합니다.</p><h4 id="aws-fargate">AWS Fargate</h4><p><img src="https://d1.awsstatic.com/diagrams/product-page-diagrams/product-page-diagram-Fargate_how-it-works.03c366c5aa4aa2cfb99aa91cbcd4d534f541bde2.png" alt="https://aws.amazon.com/ko/fargate/"></p><p><a href="https://aws.amazon.com/ko/fargate/" rel="external nofollow noopener noreferrer" target="_blank">AWS Fargate</a> 는 AWS EC2와 같은 컴퓨팅 엔진입니다. 위의 Amazon ECS 를 사용할 때 EC2와 Fargate 중 선택을 할 수 있는데요. Fargate를 사용하면 가상 머신 클러스터에 대한 프로비저닝, 구성, 확장 등 클러스터 관리를 자동으로 처리해주기 때문에 애플리케이션을 개발하는데 집중할 수 있습니다.</p><p>Fargate는 현재는 ECS 만 지원하지만 향후 EKS 도 지원할 예정이라고 합니다.</p><h4 id="aws-eks">AWS EKS</h4><p><img src="https://d1.awsstatic.com/diagrams/product-page-diagrams/product-page-diagram-AmazonEKS-v2.dd41321fd3aa0915b93396c13e739351d2160ba8.png" alt="https://aws.amazon.com/ko/eks/"></p><p><a href="https://aws.amazon.com/ko/eks/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Elastic Container Service for Kubernetes</a>(<em>EKS</em>)는 AWS 상에서 쿠버네티스(<em>Kubernetes</em>) 클러스터를 제공해주는 서비스로 제어 영역(<em>Control Plane</em>)을 자동으로 관리 및 업데이트 해줍니다. 따라서 사용자는 워커 노드를 프로비저닝하고 EKS의 엔드포인트에 연결하기만 하면 됩니다.</p><h4 id="aws-app-mesh">AWS App Mesh</h4><p>마이크로서비스 아키텍처는 장점도 많지만 작은 서비스간 연결이 많아지면서 복잡해지는 단점도 있습니다. 이를 극복하고 보완하기 위한 설계와 툴이 나오면서 마이크로서비스도 발전하고 있는데요. 그 중 하나가 서비스 메시(<em>Service Mesh</em>)라는 개념으로 마이크로서비스의 커뮤니케이션을 보다 쉽게 모니터링하고 관리할 수 있는 방법입니다.</p><p><img src="https://image.slidesharecdn.com/talk-microservices-170321085816/95/the-birth-and-evolution-of-a-microservices-architecture-lugano-tech-talk-0317-33-638.jpg?cb=1490257746" alt="https://www.slideshare.net/welld/the-birth-and-evolution-of-a-microservices-architecture"></p><p>마이크로서비스는 여러 서비스가 서로 호출하는 구조로 되어 있습니다. 문제의 시작은 이겁니다. 이 중 하나의 서비스에서 장애가 나면 어떻게 될까요? 장애는 해당 서비스 자체에서만 끝나는 것이 아니라 연쇄적으로 퍼지게 됩니다.</p><p><img src="https://www.nginx.com/wp-content/uploads/2016/11/Health-check-for-microservices-large.png" alt="https://www.nginx.com/blog/microservices-reference-architecture-nginx-circuit-breaker-pattern/"></p><p>해결책은 서비스간 호출을 바로 하는 것이 아니라 중간 다리를 거쳐서 호출하고, 장애 발생 시 중간 다리에서 연결을 끊어버리는 겁니다. 이를 <a href="https://microservices.io/patterns/reliability/circuit-breaker.html" rel="external nofollow noopener noreferrer" target="_blank">써킷 브레이커 패턴</a>(<em>Circuit Breaker Pattern</em>)이라고 합니다. 회로 차단기라는 뜻이죠.</p><p><img src="https://www.redhat.com/cms/managed-files/service-mesh-1680.png" alt="https://www.redhat.com/ko/topics/microservices/what-is-a-service-mesh"></p><p>이와 비슷한 작업을 인프라 레벨에서 풀 수 있는 것이 바로 서비스 메시입니다. 마이크로서비스는 각자 프록시를 옆에 두고 해당 프록시를 거쳐서 통신합니다. 이를 오토바이의 사이드카와 비슷하다고 해서 사이드카 패턴(<em>Sidecar Pattern</em>)이라고 합니다. 이렇게 서비스마다 프록시를 다 붙여놓으면서비스간 오고 가는 정보를 수집할 수 있고 라우팅, 헬스체킹, 로드 밸런싱, 써킷 브레이킹 등 다양한 작업을 할 수 있어 유용합니다. 프록시로는 <a href="https://www.envoyproxy.io/" rel="external nofollow noopener noreferrer" target="_blank">Envoy</a> 가 많이 사용됩니다.</p><p><img src="https://istio.io/docs/concepts/what-is-istio/arch.svg" alt="https://istio.io/docs/concepts/what-is-istio/"></p><p>문제는 마이크로서비스가 워낙 많다보니 프록시의 개수 또한 많아지고 관리가 어려워지는 점입니다. 그래서 프록시를 중앙에서 관리하도록 나온 툴이 <a href="https://istio.io/" rel="external nofollow noopener noreferrer" target="_blank">Istio</a> 입니다.</p><p><img src="https://d1.awsstatic.com/r2018/a/Product-Page-Diagram_Lattice_After.de0ef7327c19197e473f7bf59f4687cea53f01f3.png" alt="https://aws.amazon.com/ko/app-mesh/"></p><p>새로 출시된 <a href="https://aws.amazon.com/app-mesh/" rel="external nofollow noopener noreferrer" target="_blank">AWS App Mesh</a> 는 추가적인 도구 설치 없이 ECS 및 EKS 를 기반으로 서비스 메시를 제공합니다. 따라서 마이크로서비스 모니터링과 제어를 쉽게 할 수 있습니다.</p><h4 id="aws-cloud-map">AWS Cloud Map</h4><p><img src="https://d1.awsstatic.com/r2018/a/product-page-diagram_skymap_before-after.601791b8d5c69fb0c7e96bd6706cfd5320ca8f3d.png" alt="https://aws.amazon.com/ko/cloud-map/?nc1=h_ls"></p><p>새로 출시된 <a href="https://aws.amazon.com/ko/cloud-map/?nc1=h_ls" rel="external nofollow noopener noreferrer" target="_blank">AWS Cloud Map</a> 은 리소스 관리 서비스입니다. 마이크로서비스는 트래픽에 따라 동적으로 확장되거나 축소되다보니 리소스 이름과 위치를 수동으로 관리하기가 어렵습니다. AWS Cloud Map 은 이를 중앙에서 등록해 관리할 수 있어 애플리케이션 버전이나 배포 환경에 따라 맞춤형 리소스를 구성할 수 있습니다.</p><h3 id="serverless">Serverless</h3><p>AWS Lambda 는 서버리스(<em>Serverless</em>) 컴퓨팅의 선두주자입니다. 저도 처음에 써보고 놀랐던 기억이 나네요. 서버 관리 없이 코드만 올리면 각종 트리거(이벤트)를 기반으로 실행되는 간단한 방식입니다. 단순히 메시지 큐만 사용하는 것이 아니라 AWS 내 각종 서비스를 이벤트 소스로 사용할 수 있어서 큰 인기를 얻었습니다. 단점으로는 코드 실행 시 VM이 생성되어 런타임을 구성하고 코드가 실행되기 때문에 처음 실행 시 VM을 부팅하는 시간이 걸린다는 점이 있는데요.  이에 맞춰 AWS 에서도 Lambda 의 단점을 보완하고 기능을 대폭 강화했습니다.</p><ul><li>IDE</li><li>Language Support</li><li>Programming Models</li><li>Workflows</li><li>Firecracker</li></ul><h4 id="aws-toolkits-for-ides">AWS Toolkits for IDEs</h4><p><img src="aws-toolkits-for-ides.jpg" alt="https://www.slideshare.net/awskorea/aws-reinvent-2018-new-services-channy"></p><p>람다를 사용하면서 불편한 점 중 하나는 코드를 외부에서 작성 후 업로드 해야하는 점이었습니다. 자바스크립트 같은 경우는 람다 콘솔에서 바로 작성할 수 있지만 자바 같은 경우는 소스를 말아서 올려야했죠. 그래서 AWS 는 브라우저 기반의 IDE인 AWS Cloud 9 을 출시했습니다. 서버리스 개발에 유용하고 EC2 인스턴스에 쉽게 접근할 수 있는 터미널도 함께 제공되었습니다.</p><p>하지만 개발자들은 원래 익숙한 툴을 좋아하기 마련이죠. 그래서 AWS Toolkit for IDEs 라고 기존 개발 환경과 통합을 제공합니다. 기존에 제공하던 <a href="https://aws.amazon.com/ko/eclipse/" rel="external nofollow noopener noreferrer" target="_blank">AWS Toolkits for Eclipse</a> 와 <a href="https://aws.amazon.com/ko/visualstudio/" rel="external nofollow noopener noreferrer" target="_blank">AWS Toolkits for Visual Studio</a> 외에 새로 <a href="https://github.com/aws/aws-toolkit-jetbrains" rel="external nofollow noopener noreferrer" target="_blank">PyCharm</a>, <a href="https://github.com/aws/aws-toolkit-jetbrains" rel="external nofollow noopener noreferrer" target="_blank">IntelliJ</a>, <a href="https://github.com/aws/aws-toolkit-vscode" rel="external nofollow noopener noreferrer" target="_blank">Visual Studio Code</a>를 지원합니다. 이에 기존에 작업하던 환경 그대로 서버리스 개발을 하는 것이 더 쉬워졌습니다.</p><h4 id="커스텀-런타임-지원">커스텀 런타임 지원</h4><p>기존에 지원하는 자바, Node.js, C#, 파이썬, Go 외에도 커스텀 런타임을 지원합니다. Linux 호환 언어라면 런타임을 활용할 수 있습니다. 이번에 람다에 새로 추가된 Ruby 도 이런 방식으로 지원했다고 하네요. 따라서 Erlang, elixir, Cobol 등 다양한 언어를 지원할 수 있게 되었습니다.</p><h4 id="lambda-layers">Lambda Layers</h4><p>람다는 함수에서 사용하는 라이브러리와 디펜던시를 같이 말아 업로드해서 사용합니다. 그러다보니 마이크로서비스  애플리케이션을 구성할 경우 이러한 공유 코드, 라이브러리, 디펜던시가 각각 들어가 중복됩니다. 그러다보니 수정이 필요한 경우 모든 람다 함수를 수정해야하는 문제가 생겼는데요. 이런 부분을 별도의 레이어로 분리하는 Lambda Layers 기능을 지원합니다. 따라서 런타임 환경을 손쉽게 확장하고 관리할 수 있습니다.</p><h4 id="serverless-application-repository">Serverless Application Repository</h4><p><img src="https://d1.awsstatic.com/serverless/SAR/DeployApplications-Diagram.6756142e0376c98b3b94b166c766bdb7043ba12c.png" alt="https://aws.amazon.com/ko/serverless/serverlessrepo/"></p><p><a href="https://aws.amazon.com/ko/serverless/serverlessrepo/" rel="external nofollow noopener noreferrer" target="_blank">Serverless Application Repository</a> 는 서버리스 애플리케이션을 공유하고 판매하는 마켓 플레이스입니다. AWS 외에도 여러 사용자가 올린 애플리케이션을 확인할 수 있습니다.</p><h4 id="nested-applications">Nested Applications</h4><p>서버리스 아키텍처가 커지면서 생산성을 높일 방법이 필요해졌습니다. <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-template-nested-applications.html" rel="external nofollow noopener noreferrer" target="_blank">Nested Applications</a> 도 그런 방법 중 하나입니다. 서버리스 애플리케이션을 다른 서버리스 애플리케이션의 컴포넌트처럼 사용해 개발 중복을 줄이고 생산성을 높여줍니다.</p><h4 id="application-load-balancer-support-for-lambda">Application Load Balancer Support for Lambda</h4><p>람다의 이벤트 소스로 로드 밸런서가 추가되었습니다. 로드 밸런서가 컨텐츠 기반 라우팅 규칙을 지원하게 되면서 요청 내용에 따라 다른 람다 함수를 호출할 수 있게 된 것인데요. 따라서 기존에 로드 밸런서를 사용하는 웹 애플리케이션에도 쉽게 람다를 추가할 수 있습니다.</p><h4 id="web-socket-support-for-api-gateway">Web Socket support for API Gateway</h4><p><img src="https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/reinvent/websockets-chat-app.png" alt="https://serverless.com/blog/api-gateway-websockets-support/"></p><p><a href="https://aws.amazon.com/ko/api-gateway/" rel="external nofollow noopener noreferrer" target="_blank">Amazon API Gateway</a> 에서 Web Socket 을 지원하면서 웹 소켓 연결을 이용해 람다 함수를 호출할 수 있게 되었습니다. 따라서 실시간 양방향 통신 애플리케이션을 쉽게 구축할 수 있습니다.</p><h4 id="step-functions-api-connectors">Step Functions + API Connectors</h4><p><img src="https://d1.awsstatic.com/product-marketing/Step%20Functions/sfn_how-it-works.f795601e8338db32506b9abb01e71704f483fc81.png" alt="https://aws.amazon.com/ko/step-functions/"></p><p><a href="https://aws.amazon.com/ko/step-functions/" rel="external nofollow noopener noreferrer" target="_blank">AWS Step Functions</a> 는 람다 함수를 단계적으로나 병렬적으로 실행할 수 있도록 워크플로를 설계하고 모니터링할 수 있는 서비스입니다. 이번엔 워크플로를 지원하는 AWS 서비스가 확대되어 더 다양한 방식으로 사용할 수 있게 되었습니다.</p><h4 id="amazon-managed-streaming-for-kafka">Amazon Managed Streaming for Kafka</h4><p><img src="https://d1.awsstatic.com/product-marketing/Kinesis/diagram-kafka.08473d6874a142f0a629530688617780b73fb6e1.png" alt="https://aws.amazon.com/ko/kafka/"></p><p>카프카(<em>Kafka</em>)는 비동기 처리를 위한 대표적인 오픈 소스 분산 메시징 시스템입니다. 위 그림처럼 스트리밍 데이터를 읽어 버퍼링하고 필요한 애플리케이션에게 공급하는 역할을 하기도 합니다. AWS 에서 제공하는 카프카는 카프카를 사용하던 기존 코드를 변경 없이 적용할 수 있도록 호환성을 제공하고, 별도 주키퍼(<em>Zookeeper</em>) 노드 필요 없이 클러스터를 관리해줍니다. 또한 가용 영역 3개를 이용한 롤링 업그레이드로 패치도 지원합니다. 따라서 기존 카프카를 이용하던 애플리케이션이나 새로 구축하는 애플리케이션에서 관리에 대한 걱정 없이 카프카를 쉽게 사용할 수 있습니다.</p><h4 id="firecracker">Firecracker</h4><p><img src="https://firecracker-microvm.github.io/img/diagram-desktop@3x.png" alt="https://firecracker-microvm.github.io/"></p><p>위에서 말씀드린 것처럼 람다 함수를 실행 시 VM이 뜨면서 해당 코드를 실행하게 됩니다. VM은 컨테이너 기반보다 보안은 우수하지만 처음 부팅 시 느리고 비교적 리소스를 효율적으로 사용하기 어렵습니다. 람다 출시 이후 사용자들이 람다를 다양하게 사용하고 인기를 얻으면서 람다를 속도와 리소스 효율 면에서 개선할 필요가 생겼습니다.</p><p>이에 AWS는 기존의 컨테이너 방식이나 VM 방식이 아닌 새로운 가상화 기술을 오픈 소스로 공개했습니다. <a href="https://firecracker-microvm.github.io/" rel="external nofollow noopener noreferrer" target="_blank">Firecracker</a> 는 서버리스 컴퓨팅에 최적화된 microVM으로 VM 보안성은 유지하되 컨테이너의 빠른 확장과 리소스 효율성을 더했습니다. 가상화되지 않은 환경에서 1초 이내로 microVM을 시작할 수 있고 microVM 당 5MiB 메모리를 사용해 오버헤드가 낮습니다. 오픈 소스이지만 이미 AWS Lambda 와 AWS Fargate 에 적용되어 검증되었으며 앞으로도 많은 발전이 기대되는 프로젝트입니다.</p><h2 id="스토리지-storage">스토리지 Storage</h2><p>다음은 스토리지입니다. 스토리지는 용도를 다양화하고 데이터 이동에 편의성을 증가시켰습니다.</p><h4 id="s3-신규-클래스">S3 신규 클래스</h4><p>Amazon Simple Storage Service(<em>S3</em>)는 데이터를 저장하는 스토리지 서비스입니다. S3는 데이터를 저장하고 얼마나 자주 사용하는지에 따라서 클래스를 구분하고 비용을 정산하기 때문에 적절한 용도에 따른 스토리지 클래스를 선택하는 것이 좋습니다. 보통 자주 사용하지 않는 것은 싼 가격에 많은 데이터를 저장할 수 있지만 속도는 느리고, 자주 사용하는 것은 비용이 높지만 속도는 빠르게 구성되어 있습니다.</p><p>새롭게 추가된 신규 클래스로는 인공지능을 기반으로 사용 빈도에 따라 자동으로 클래스를 조정해 비용을 최적화하는 <a href="https://aws.amazon.com/ko/about-aws/whats-new/2018/11/s3-intelligent-tiering/" rel="external nofollow noopener noreferrer" target="_blank">S3 Intelligent-Tiering</a> 과 기존 백업용 클래스인 S3 Glacier 보다 더 저렴한 <a href="https://aws.amazon.com/ko/about-aws/whats-new/2018/11/s3-glacier-deep-archive/" rel="external nofollow noopener noreferrer" target="_blank">S3 Glacier Deep Archive</a> 가 있습니다. 따라서 총 6개의 스토리지 클래스를 제공합니다.</p><table><thead><tr><th>이름</th><th>설명</th></tr></thead><tbody><tr><td>S3 Standard</td><td>범용 스토리지</td></tr><tr><td>S3 Intelligent-Tiering</td><td>인공지능을 기반으로 사용 빈도에 따라 자동으로 클래스를 조정해 비용을 최적화</td></tr><tr><td>S3 Standrad-Infrequent Access</td><td>자주 사용은 안하지만 필요할 때는 빠르게 액세스</td></tr><tr><td>S3 One Zone-Infrequent Access</td><td>가용성을 위해 3AZ에 저장하는 스탠다드와 달리 하나의 AZ에 저장해 빠르게 작업 가능</td></tr><tr><td>S3 Glacier</td><td>자주 사용하지 않는 데이터를 보관하기 위한 아카이브용 스토리지</td></tr><tr><td>S3 Glacier Deep Archive</td><td>장기간 보관에 적합한 최저 비용 스토리지</td></tr></tbody></table><h4 id="amazon-fsx-for-windows-file-server">Amazon FSx for Windows File Server</h4><p><img src="https://d1.awsstatic.com/r2018/b/FSx-Windows/FSx_Windows_File_Server_How-it-Works.9396055e727c3903de991e7f3052ec295c86f274.png" alt="https://aws.amazon.com/ko/fsx/windows/"></p><p>퍼블릭 클라우드에서 Windows 워크로드를 사용하는 비율은 AWS(57.7%)가 Microsoft Azure(30.9%)보다도 높다고 합니다. 이에 완전 관리형 Windows 파일 시스템인 <a href="https://aws.amazon.com/ko/fsx/windows/" rel="external nofollow noopener noreferrer" target="_blank">Amazon FSx for Windows File Server</a> 가 새로 출시되었습니다. 따라서 기존에 보유한 애플리케이션 및 윈도우 환경과 완벽하게 호환되는 네트워크 파일 스토리지로 사용할 수 있습니다.</p><h4 id="amazon-fsx-for-lustre">Amazon FSx for Lustre</h4><p><img src="https://d1.awsstatic.com/r2018/b/FSX-Lustre/FSx_Lustre_diagram.9f3f9ca4ea7827b296033b17f885543d4c3ca778.png" alt="https://aws.amazon.com/ko/fsx/lustre/"></p><p>데이터 레이크, HPC(고성능 컴퓨팅), EDA(전자 설계 자동화) 등의 대규모 작업들은 피비바이트(<em>PiB, 125TB</em>) 단위로 데이터를 처리합니다. <a href="http://lustre.org/" rel="external nofollow noopener noreferrer" target="_blank">Lustre</a> 는 이런 고성능 작업을 지원하는 병렬 파일 시스템으로 오픈소스인데요. AWS 는 이를 기반으로 매니지드 파일 시스템인 <a href="https://aws.amazon.com/ko/fsx/lustre/" rel="external nofollow noopener noreferrer" target="_blank">Amazon FSx for Lustre</a> 를 출시했습니다. 또한 S3 와 통합해서 상대적으로 높은 처리량이 필요하지 않은 분석 전후의 데이터는 S3에 보관할 수 있습니다.</p><h4 id="aws-datasync">AWS DataSync</h4><p><img src="https://d1.awsstatic.com/r2018/b/product-page-diagram_Sync(Final).d10b7228ccf2256a072408532a4650720248e1c4.png" alt="https://aws.amazon.com/ko/datasync/"></p><p><a href="https://aws.amazon.com/ko/datasync/" rel="external nofollow noopener noreferrer" target="_blank">AWS DataSync</a> 는 데이터 이동을 자동 및 가속화해주는 서비스로 Amazon S3, Amazon Elastic File System(<em>EFS</em>), 온프레미스 간에 데이터를 쉽게 이동시키는 서비스입니다. 10Gbps의 빠른 속도로 데이터를 전송할 수 있어 마이그레이션이나 데이터 처리 작업, 재해 복구 등에 사용할 수 있습니다.</p><h4 id="aws-transfer-for-sftp">AWS Transfer for SFTP</h4><p><img src="https://d1.awsstatic.com/r2018/b/Product-Page-Diagram_Necco_How-it-works.f40e89ca89b3183769613d2407d54858265c43c2.png" alt="https://aws.amazon.com/ko/sftp/"></p><p><a href="https://aws.amazon.com/ko/sftp/" rel="external nofollow noopener noreferrer" target="_blank">AWS Transfer for SFTP</a> 는 S3에 데이터를 업로드하고 관리할 경우 SFTP(<em>Secure File Transfer Protocol</em>)를 제공하는 서비스입니다. 따로 SFTP 서버를 관리할 필요 없이 제공되는 엔드 포인트를 사용하면 됩니다.</p><h2 id="데이터베이스-database">데이터베이스 Database</h2><p>AWS는 여러가지 DB 서비스를 제공하고 있습니다. 필요에 따라 쉽게 구성할 수 있고 서버를 관리할 필요 없이 확장성, 가용성, 내구성 등을 누릴 수 있습니다.</p><ul><li><a href="https://aws.amazon.com/ko/rds/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Relational Database Service</a>(RDS) : Oracle, MySQL 등 관계형 DB 서비스를 제공.<br>특히 MySQL과 PostreSQL과 호환되는 클라우드 최적화 RDB인 <a href="https://aws.amazon.com/ko/rds/aurora/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Aurora</a> 서비스 제공.</li><li><a href="https://aws.amazon.com/ko/dynamodb/" rel="external nofollow noopener noreferrer" target="_blank">Amazon DynamoDB</a> : 완전 관리형 NoSQL(<em>Key/Value, Document</em>) DB 서비스</li><li><a href="https://aws.amazon.com/ko/elasticache/" rel="external nofollow noopener noreferrer" target="_blank">Amazon ElasticCache</a> : 인메모리 DB인 <a href="https://aws.amazon.com/redis/" rel="external nofollow noopener noreferrer" target="_blank">Redis</a> 와 <a href="https://aws.amazon.com/ko/memcached/" rel="external nofollow noopener noreferrer" target="_blank">Memcached</a> 를 완전관리형으로 제공</li><li><a href="https://aws.amazon.com/ko/neptune/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Neptune</a> : 완전 관리형 그래프 데이터베이스.</li></ul><p>이번 행사에서는 시계열 데이터와 블록체인 데이터를 처리할 수 있는 제품이 출시되어 더 다양한 데이터베이스를 선택할 수 있게 되었습니다.</p><h3 id="amazon-dynamodb-업데이트">Amazon DynamoDB 업데이트</h3><p>먼저 Amazon DynamoDB 에 몇 가지 기능이 추가되었는데요. 기존에 read/write 용량 산정 문제를 해결하기 위해 트래픽에 따라 자동으로 용량이 조절되는 <a href="https://aws.amazon.com/ko/blogs/korea/amazon-dynamodb-on-demand-no-capacity-planning-and-pay-per-request-pricing/" rel="external nofollow noopener noreferrer" target="_blank">DynamoDB On-Demand</a> 기능을 추가했습니다. 또한 <a href="https://aws.amazon.com/ko/blogs/aws/new-amazon-dynamodb-transactions/" rel="external nofollow noopener noreferrer" target="_blank">DynamoDB Transactions</a> 기능 추가로 비관계형 DB에서는 처음으로 ACID 트랜잭션을 지원합니다. 따라서 여러 테이블을 엮어 복잡한 비즈니스 로직을 구현할 수 있게 되었습니다.</p><h3 id="amazon-timestream">Amazon Timestream</h3><p>IoT 센서 데이터나 DevOps 로그 데이터 등 시간에 따른 변화를 측정하는 시계열(<em>time-series</em>) 데이터는 일반 RDB로 효율적인 처리가 어렵습니다. <a href="https://aws.amazon.com/ko/timestream/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Timestream</a> 은 RDB의 1/10 비용으로 하루에 수조 건의 이벤트를 저장하고 분석할 수 있는 완전관리형 시계열 데이터베이스 서비스입니다.</p><h3 id="amazon-qldb">Amazon QLDB</h3><p><img src="https://d1.awsstatic.com/r2018/h/99Product-Page-Diagram_AWS-Quantum.f03953678ba33a2d1b12aee6ee530e45507e7ac9.png" alt="https://aws.amazon.com/ko/qldb/"></p><p>AWS 를 활용해 블록체인을 사용하는 사례가 많아지면서 블록체인 원장을 관리하는 완전관리형 데이터베이스가 출시되었습니다. <a href="https://aws.amazon.com/ko/qldb/" rel="external nofollow noopener noreferrer" target="_blank">Amazon Quantum Ledger Database</a>(<em>QLDB</em>)는 기존 RDB를 이용해 원장을 관리할 경우 구축하기 어려운 감사 기능을 제공합니다. 투명하고 변경 불가능하며 암호화 방식으로 검증 가능한 트랜잭션 로그를 제공하고 이러한 로그는 신뢰할 수 있는 중앙 기관에서 소유합니다. 애플리케이션 데이터의 내역을 정확하게 유지 관리할 피룡가 있는 은행 트랜잭션, 보험 청구 계보 확인, 공급망 네트워크에서의 품목 이동 추적 등에 사