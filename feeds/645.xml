<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>ratsgo's blog</title>
 <link href="http://ratsgo.github.io/atom.xml" rel="self"/>
 <link href="http://ratsgo.github.io/"/>
 <updated>2018-10-14T07:59:37+00:00</updated>
 <id>http://ratsgo.github.io</id>
 <author>
   <name>ratsgo</name>
   <email></email>
 </author>

 
 <entry>
   <title>이탈리아 여행</title>
   <link href="http://ratsgo.github.io/daily/2018/02/11/italy/"/>
   <updated>2018-02-11T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/daily/2018/02/11/italy</id>
   <content type="html">&lt;p&gt;지난 4일부터 1주일 간 로마를 시작으로 피렌체, 아시시, 베니스, 밀라노 5개 도시를 방문했다. 이 느낌을 오래 간직하기 위해 짧은 인상 위주로 정리해 둔다. &lt;em&gt;(2018년 2월 11일 밀라노 말펜사 공항)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;#01. 환승하기 위해 잠시 들렀던 터키 이스탄불 소재 아타튀르(Atatürk) 국제공항 서비스는 형편없었다. 환승 게이트 안내는 비행기 탑승 1시간 전에야 이뤄져서 환승객들이 공항 곳곳에서 갈팡질팡했다. 비행기 탑승 30분 전 게이트가 오픈된 것까지는 좋았다. 승객들을 게이트에서 스텝카(탑승용 계단차량)까지 실어나르는 버스에 가둬두고는 탑승시각이 넘어서까지 출발도 않고 대기하는 것 아닌가. 게이트를 관리하는 직원은 단 한 명. 항공편이 특별히 지연(delay)되어야 할 물리적 이유가 하나도 없었는데 이날 이스탄불발-로마행 TK1861편은 30여분 가까이 늑장 출발했다. 그에 반하면 인천공항은 정말이지 세계 최고 수준이다.&lt;/p&gt;

&lt;p&gt;#02. TK1861편 창가에 비친 이탈리아의 첫 인상은 ‘따스한 햇살이 비치는 평온한 대평원’이었다. 날씨가 좋아서 로마 주변을 전체적으로 조망할 수 있었다. 드넓은 초지가 펼쳐져 있고 군데군데 조그마한 촌락들이 있으며 그 촌락들 사이를 거미줄처럼 잇는 길이 나 있었다. 자료를 찾아보니 테베레 강 유역, 아펜니노 산맥과 티레니아해 사이에 있는 넓은 평야지대를 ‘라티움(Latium)’이라고 한단다. 초기 고대 로마가 이곳을 중심으로 성장했다고 한다. 역시 그러면 그렇지. 라티움 같은 배후 생산지역이 없었다면 로마 같은 소비 도시는 탄생하기 어려웠을 것이다. 로마는 예나 지금이나 향락이 중심이다.&lt;/p&gt;

&lt;p&gt;#03. 짐을 숙소에 내팽겨치다시피해서 처음 방문한 곳은 ‘콜로세움(Colosseum)’. 고대 로마 시대를 대표하는 원형 경기장이다. 테르미니역에 있는 숙소에서 멀지 않아서 우연히 Parco Del Colle Oppio 공원을 거쳐 가게 됐다. 그런데 공원에서 콜로세움을 후면에서 볼 수 있는 것 아닌가! 그것도 한적한 벤치까지 마련돼 있다. 지중해 따뜻한 겨울햇살을 내리쬐며 벤치에 앉아 한가로이 콜로세움을 바라보는 경험은 황홀함 그 자체였다. 이 글을 쓰는 지금도 그 때 그 감동을 잊을 수가 없다.&lt;/p&gt;

&lt;p&gt;#04. 콜로세움을 기점으로 베네치아 광장(Piazza Venezia)에 이르는 거리 ‘Via dei Fori Imperiali’는 일요일이면 차없는 거리로 변신한다. 덕분에 온갖 행위예술인들이 세계 관광객들의 이목을 끈다. 특히 포룸 로마눔(Forum Romanum) 앞에서 공연하던 라틴 형제 3인방이 기억에 남는다. 기타 2, 콘트라베이스 1로 구성된 이들은 연주도 연주지만 한때 번성했지만 흔적만 남아있는 로마 중심 시가지를 배경으로 빼어난 실력을 뽐내고 있어 무척 아이러니하게 느껴졌다. 맥수지탄(麥秀之歎)이나 산 사람은 어찌됐든 살아야 한다. 3인방 중 한 명이 공짜로 주겠다며 CD 두 장을 내게 건넸다. 공짜인데 어찌 마다하겠는가. 그런데 노래 두 곡이 끝나고 나서 20유로를 달란다. 허허.. 주머니를 뒤집어 돈 없다는 시늉을 했다. 대신 노랫값만 내고 슬그머니 빠져나왔다. 역시 산 사람은 살아야 한다.&lt;/p&gt;

&lt;p&gt;#05. 바티칸 시국 남동쪽에 있는 ‘성 베드로 대성당(Basilica di San Pietro)’과 바티칸 궁전 내 시스티나 성당(Aedicula Sixtina)은 이탈리아 여행 전체를 통틀어 최고라 할 만 하다. 규모도 웅장하고 장식과 그림 하나하나 정성이 깃들어 있다. 신자가 아니라도 절로 경외감이 들 정도로. 미켈란젤로가 시스티나 성당 벽에 그린 그림들이 압권이다. 1시간 넘게 ‘아담의 창조(천장)’, ‘최후의 심판(제단 쪽 벽면 전체)’을 구석구석 보느라 목 빠지는 줄 알았다. 당시 그들은 어떤 마음으로 프레스코화를 그렸을까. 그 신앙심이 존경스럽다.&lt;/p&gt;

&lt;p&gt;#06. 로마에서 기차로 2시간여 거리인 소도시 아시시(Assisi). 평생 세속과는 멀리 하고 길거리에서 복음을 전파한 성 프란치스코(San Francesco, 1181-1226)가 이곳에 잠들어 있다. 프란치스코의 유해가 안치된 성 프란치스코 대성당 지하엔 성음악이 흐르고 있다. 거리는 적막할 정도로 조용하다. 그의 추종자들은 지금까지도 이 촌락에서 금욕적인 삶을 추구하며 수도 생활을 하고 있다. 그러나 상술 하나만큼은 철저히 세속적이다. 토마토와 치즈를 곁들인 피아디나(piadina)와 콜라 한 캔에 12유로(우리돈 1만7000원 가량)나 한다. 놀랍다.&lt;/p&gt;

&lt;p&gt;#07. 피렌체에 있는 우피치 미술관(Galleria degli Uffizi)는 실로 대단하다. 그 빼어나고 방대한 작품들 모두 한 가문(메디치)이 기증한 것이라니. 미술에는 그다지 조예가 없어서 사람들이 많이들 감상하고 있는 작품들을 위주로 유심히 살펴보았다. 어떤 작품이든 자세히 들여다보면 그 디테일에 감탄하지 않을 수 없었다. 나중에 블로그 대문사진이나 휴대폰 잠금화면으로 쓰려고 그림 사진을 많이 찍어두었다.&lt;/p&gt;

&lt;p&gt;#08. 비 갠 후 노을 진 피렌체 시내 겨울 풍광은 무척 아름답다. 피렌체 대성당의 쿠폴라(cupola)를 오르는 463개의 계단이 조금 버겁기는 하지만. 비가 주륵주륵 오는데도 기다린 보람이 있었다.&lt;/p&gt;

&lt;p&gt;#09. 베니스엔 차가 없다. 바다와 운하를 오가는 곤돌라(gondola)들뿐이다. 경찰차, 구급차도 모두 곤돌라다. 버스도 물 위를 다닌다. 예전 베니스 귀족들은 곤돌라 치장에 꽤 많은 돈을 썼다 한다. 차 대신에 말이다. 어쨌든 저렴하고 탈 만한 지상 교통수단이 없어 베니스 시내 전체를 계속 걸어다닐 수밖에 없었다.&lt;/p&gt;

&lt;p&gt;#10. 운좋게 베니스 2월 축제를 볼 수 있었다. 생각지도 못한 수확이었다. 춤과 노래는 언제나 흥겹다. 형형색색의 옷과 가면으로 치장한 사람들은 국적과 관계없이 거리에서 모두 친구가 됐다.&lt;/p&gt;

&lt;p&gt;#11. 밀라노는 세계 패션 중심이다. 명품 상점들이 즐비하다. 행인들도 꽤 멋쟁이들인 것 같다. 하지만 밀라노는 화장실 인심이 박하다. 크디큰 쇼핑몰 안에 공용 화장실 하나 찾을 수가 없다. 가끔 찾는다 해도 0.5~1.5유로를 내야 한다. 그런데 저 수많은 사람들은 어디서 똥 누고 오줌을 싸는 걸까. 패션보다 중한 건 용변 해결일텐데. 용무가 급해서 공용 화장실을 찾느라 밀라노 중심가를 이리저리 뛰어다니다 든 생각이다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>밀라노의 상점들</title>
   <link href="http://ratsgo.github.io/daily/2018/02/10/milano/"/>
   <updated>2018-02-10T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/daily/2018/02/10/milano</id>
   <content type="html">&lt;p&gt;지난 4일부터 1주일 간 이탈리아를 여행하고 있다. 마지막 행선지는 ‘세계 패션 중심’ 밀라노(Milano). 명성에 걸맞게 내로라할 만한 명품 브랜드 상점들이 거리에 즐비했다. 간판과 쇼윈도부터 행인들의 눈길을 확 끈다. 물건 그 자체보다는 감성과 경험을 내세운다. (내 입장에서)처음 보는 브랜드인데도 쇼윈도만 유심히 보면 이 가게가 뭘 팔고 뭘 내세울지 한 눈에 이해할 수 있었다. 책 한 권 팔더라도 고급지다(서점 &lt;em&gt;Rizzoli&lt;/em&gt;). 브랜딩이니, 마케팅이니, 플랫폼이니 고민해야 하는 순간이 온다면 오늘 거닐었던 밀라노 거리 상점들을 잊지 말아야겠다. &lt;em&gt;(2018년 2월 10일 밀라노)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ratsgo.github.io/public/img/mil1.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ratsgo.github.io/public/img/mil2.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ratsgo.github.io/public/img/mil3.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ratsgo.github.io/public/img/mil4.jpeg&quot; /&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Auto Regressive Models</title>
   <link href="http://ratsgo.github.io/generative%20model/2018/01/31/AR/"/>
   <updated>2018-01-31T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2018/01/31/AR</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;em&gt;Auto Regressive Model&lt;/em&gt;(AR)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;concept&quot;&gt;concept&lt;/h2&gt;

&lt;p&gt;자기 자신을 입력으로 하여 자기 자신을 예측하는 모형을 &lt;em&gt;Auto Regressive Model&lt;/em&gt;(AR)이라고 합니다. 그 개념도와 likelihood 식은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/tcApyOc&quot;&gt;&lt;img src=&quot;https://i.imgur.com/tcApyOc.png&quot; width=&quot;300px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
p\left( x \right) =&amp;\coprod _{ i }^{  }{ p\left( { { x }_{ i } }|{ { x }_{ 1 },...,{ x }_{ i-1 } } \right)  } \\ =&amp;p\left( { x }_{ 1 } \right) p\left( { x }_{ 2 }|{ x }_{ 1 } \right) ...p\left( { { x }_{ i } }|{ { x }_{ 1 },...,{ x }_{ i-1 } } \right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;저해상도 이미지/영상을 고해상도로 변환하는 작업을 &lt;em&gt;Super Resolution&lt;/em&gt;(SR)이라고 합니다. SR을 AR modeling 관점에서 이해할 수 있습니다. 아래 그림처럼 고해상도 이미지/영상을 픽셀 단위로 예측하는 경우, $x_i$를 예측할 때는 이전의 모든 픽셀 예측 결과를 활용하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/8tbMCVx&quot;&gt;&lt;img src=&quot;https://i.imgur.com/8tbMCVx.png&quot; width=&quot;200px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;앞으로 설명해드릴 PixelRNN과 PixelCNN은 SR을 AR modeling으로 해결해 보려는 시도들입니다.&lt;/p&gt;

&lt;h2 id=&quot;pixelrnn&quot;&gt;PixelRNN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Recurrent Neural Network&lt;/em&gt;(RNN)는 시퀀스 데이터 처리에 특화된 아키텍처이므로 SR을 AR modeling으로 풀 때 적용해 봄직한 시도입니다. 아래 그림의 빨간색 픽셀을 예측할 때 이전의 모든 시퀀스 정보를 RNN 아키텍처에 넣어서 예측이 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/S1vAlSR&quot;&gt;&lt;img src=&quot;https://i.imgur.com/S1vAlSR.png&quot; width=&quot;300px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;pixelcnn&quot;&gt;PixelCNN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Convolutional Neural Network&lt;/em&gt;(CNN)는 본래 시퀀스 데이터 처리와는 직접 관련이 없으나 아래 그림처럼 &lt;em&gt;Masked Convolution Filter&lt;/em&gt;를 사용하면 AR modeling이 가능합니다. 예측해야 하는 시점의 픽셀(아래 행렬의 정중앙 픽셀)과 아직 예측하지 않은 시점의 픽셀에 해당하는 필터 값을 0으로 설정해 두고, 이를 일반적인 &lt;em&gt;conv layer&lt;/em&gt;에 적용하면 CNN을 가지고 AR modeling을 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/HVdp5tc&quot;&gt;&lt;img src=&quot;https://i.imgur.com/HVdp5tc.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;wavenet&quot;&gt;WaveNet&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;WaveNet&lt;/em&gt;은 음성 생성에 &lt;em&gt;Masked Convolution Filter&lt;/em&gt;를 활용한 사례입니다. &lt;em&gt;conv filter&lt;/em&gt;를 아래처럼 설정해 두면 현 시점 예측 때 과거 다양한 시점의 데이터를 사용하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/289PXST&quot;&gt;&lt;img src=&quot;https://i.imgur.com/289PXST.png&quot; width=&quot;450px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>generative model 응용 사례</title>
   <link href="http://ratsgo.github.io/generative%20model/2018/01/30/genmodels/"/>
   <updated>2018-01-30T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2018/01/30/genmodels</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;em&gt;Generative model&lt;/em&gt;, 특히 Generative Adversarial Network(GAN)의 다양한 응용 연구들에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. PyTorch 코드는 &lt;a href=&quot;https://github.com/InsuJeon/Hello-Generative-Model&quot;&gt;이곳&lt;/a&gt;을 참고하였습니다. GAN과 관련해서는 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/20/gan/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;enhancenet&quot;&gt;EnhanceNet&lt;/h2&gt;

&lt;p&gt;EnhanceNet은 GAN의 손실함수를 적용해 &lt;em&gt;Super Resolution&lt;/em&gt; 기법의 성능을 높였습니다. &lt;em&gt;Super Resolution&lt;/em&gt;(SR)이란 아래 그림처럼 저해상도의 이미지/영상을 고해상도로 변환하는 작업을 가리킵니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/VxuNxlQ&quot;&gt;&lt;img src=&quot;https://i.imgur.com/VxuNxlQ.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;EnhanceNet이 SR 문제에 GAN 구조를 적용한 아이디어는 이렇습니다. 생성자 $G$의 인풋으로 노이즈 대신 저해상도의 이미지를 입력합니다. 판별자 $D$는 $G$가 생성한 가짜 고해상도 이미지와 실제 고해상도 이미지를 구분하는 역할을 합니다. $G$는 $D$를 속이도록 고해상도 이미지를 생성하도록 학습됩니다. 이처럼 EnhanceNet은 어떤 task이든 GAN 손실함수를 사용하여 원하는 결과를 얻어낼 수 있다는 점에서 눈길을 끕니다.&lt;/p&gt;

&lt;p&gt;GAN 손실함수의 효과를 직관적으로 나타낸 그림은 아래와 같습니다. 원본 고해상도 이미지 $I_{HR}$에서 인위적으로 해상도를 낮춘 이미지 $I_{LR}$이 있다고 칩시다. $I_{LR}$을 인풋, $I_{HR}$을 정답으로 놓고 학습시킬 때 평균제곱오차(Mean Squared Error)를 손실함수로 많이들 씁니다. MSE는 아래 그림처럼 입력값과 정답을 평균(average)하려는 성향이 강하다(MSE와 관련해서는 &lt;a href=&quot;https://ratsgo.github.io/linear%20algebra/2017/10/20/projection/&quot;&gt;이곳&lt;/a&gt; 참고)는 점이 단점입니다. 그런데 GAN 손실함수(adversarial loss)를 썼더니 $I_{HR}$을 제법 잘 근사하는 걸 확인했다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/95muNZL&quot;&gt;&lt;img src=&quot;https://i.imgur.com/95muNZL.png&quot; width=&quot;300px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;simgan&quot;&gt;SimGAN&lt;/h2&gt;

&lt;p&gt;SimGAN의 목적은 현실감 있는 인공데이터를 만들어내는 데 있습니다. 이 때 GAN을 씁니다. 아이디어는 이렇습니다. 기존 GAN의 생성자 역할을 하는 Refiner $R$은 인공데이터를 받아서 실제 데이터로 변환하는 역할을 합니다. 판별자 $D$는 $R$이 생성한 가짜(refined) 데이터와 실제(real) 데이터를 구분하는 역할을 합니다. $R$이 $D$를 속이려고 하는 과정에서 $R$이 학습됩니다. 이 과정을 도식적으로 나타내면 다음 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/1EiwI8F&quot;&gt;&lt;img src=&quot;https://i.imgur.com/1EiwI8F.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SimGAN에서는 다른 연구에 참고가 될 만한 몇 가지 기술들이 포함돼 있습니다. 우선 Self-Regularization입니다.  $R$을 학습시킬 때 기존 GAN 손실함수만 사용할 경우, $R$이 그저 $D$를 속이는 데만 집중하게 되면서 $R$이 생성한 데이터가 실제 데이터와 완전히 동떨어지게 될 염려가 크기 때문입니다. $R$의 입력값인 인공데이터도 조악하나마 실제 데이터의 특징을 담고 있으므로 $R$의 손실함수에 다음과 같은 regularization 항을 추가했습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ L }_{ reg }={ \left\| \psi \left( R\left( x \right)  \right) -\psi \left( x \right)  \right\|  }_{ 1 }&lt;/script&gt;

&lt;p&gt;위와 같은 항을 손실함수에 추가하게 되면 $R$에 입력되는 인공데이터 $x$와 $R$이 산출한 데이터 $R(x)$ 사이의 오차가 줄어들게 됩니다. 결과적으로 $R$이 생성하는 데이터가 입력데이터에서 너무 벗어나지 않게 되는 셈이죠. 단 여기에서 $ψ$는 입력값의 &lt;em&gt;feature&lt;/em&gt;를 뽑는 함수인데요. 논문에서는 &lt;em&gt;identity mapping&lt;/em&gt;을 사용했다고 합니다.&lt;/p&gt;

&lt;p&gt;또 한가지 기법은 Local patch-Discriminator입니다. 기존 GAN에서 $D$는 입력데이터 전체를 보고 real/fake 여부를 판별합니다. 이 때문에 $G$는 대개 $D$를 속이기 위해 데이터의 일부 특징을 과장하려는 경향이 있습니다. 이 문제를 완화하기 위해 다음 그림과 같이 $D$가 데이터의 일부 영역만 보도록 하고, 전체적인 판단은 이들 패치의 평균이라든지 가중합이라든지 하는 방식으로 취하도록 했습니다. 그 결과 $D$의 능력을 어느 정도 제한하면서 $R$의 성능을 높일 수 있었다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/s7LygPQ&quot;&gt;&lt;img src=&quot;https://i.imgur.com/s7LygPQ.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 언급할 부분은 History Buffer입니다. 기존 GAN에선 $D$를 학습시키는 과정에서 최근 학습샘플에만 적합하는 문제가 있었습니다. 이를 &lt;em&gt;continual learning issue&lt;/em&gt; 내지 &lt;em&gt;catastrophic forgetting problem&lt;/em&gt;이라고도 합니다. 이 문제를 해결하기 위해 도입된 것이 바로 History Buffer입니다. buffer에 예전 학습 데이터를 모아뒀다가 최신 데이터와 함께 학습시키자는 아이디어입니다. 결과적으로 $D$로 하여금 $R$이 예전에 생성한 데이터를 지속적으로 기억할 수 있게 도와줍니다. SimGAN에서는 아래와 같이 적용됐습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/uTXIhEh&quot;&gt;&lt;img src=&quot;https://i.imgur.com/uTXIhEh.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;학습 도중 $R$이 생성한 데이터가 가운데 랜덤하게 반을 선택하여 buffer에 넣는다.&lt;/li&gt;
  &lt;li&gt;각 step에서 buffer에서 랜덤하게 선택한 반과 $R$이 현재 생성한 데이터 반을 $D$에 전달한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pix2pix&quot;&gt;Pix2Pix&lt;/h2&gt;

&lt;p&gt;Pix2Pix는 다음과 같이 &lt;em&gt;image to image translation&lt;/em&gt;을 하는 데 GAN을 접목한 연구입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/iH3KG4T&quot;&gt;&lt;img src=&quot;https://i.imgur.com/iH3KG4T.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;아키텍처는 다음과 같습니다. 우선 $G$는 소스 도메인의 데이터를 입력 받아 타겟 도메인의 데이터를 생성합니다. $G$는 소스 도메인의 데이터와 생성된 타겟 도메인의 데이터를 쌍으로 묶어 $D$에 전달합니다. $D$는 $G$가 생성한 가짜 데이터 pair와 실제 데이터 pair를 구분합니다. $G$는 $D$를 속이도록 하는 과정에서 데이터를 더 잘 생성하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/jigPX5b&quot;&gt;&lt;img src=&quot;https://i.imgur.com/jigPX5b.png&quot; width=&quot;450px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;$G$는 다음과 같이 오토인코더(autoencoder)에 &lt;em&gt;Unet&lt;/em&gt;을 결합한 아키텍처를 썼다고 합니다. &lt;em&gt;encoder&lt;/em&gt;, &lt;em&gt;decoder&lt;/em&gt; 사이에 발생할 수 있는 정보손실을 &lt;em&gt;skip-connection&lt;/em&gt;을 이용해 완화한 겁니다. Pix2Pix 역시 SimGAN의 Local Patch Disciriminator를 사용했다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/FSGh3or&quot;&gt;&lt;img src=&quot;https://i.imgur.com/FSGh3or.png&quot; width=&quot;300px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;cyclegan&quot;&gt;CycleGAN&lt;/h2&gt;

&lt;p&gt;Pix2Pix의 단점은 학습데이터가 항상 pair로 존재해야 한다는 겁니다. CycleGAN은 이러한 문제를 해결하기 위해 제안됐습니다. 이를 도식적으로 나타낸 그림은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/cgynmJJ&quot;&gt;&lt;img src=&quot;https://i.imgur.com/cgynmJJ.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CycleGAN의 기본 프레임워크는 다음과 같습니다. 두 개의 생성자 $G$, $F$와 두 개의 판별자 $D_X$, $D_Y$를 씁니다. $G$는 $X$ 도메인의 데이터를 $Y$ 도메인으로 변환하는 역할을 합니다. $F$는 $Y$ 도메인의 데이터를 $X$ 도메인으로 변환합니다. $D_X$는 $F$가 생성한 가짜 데이터와 $X$ 도메인의 실제 데이터를 구분합니다. $D_Y$는 $G$가 생성한 가짜 데이터와 $Y$ 도메인의 실제 데이터를 구분합니다. $G$와 $F$는 반대 도메인의 구분자를 속이도록 적대적으로 학습됩니다. 이렇게 학습이 진행되면서 굳이 데이터가 pair 형태로 존재하지 않아도 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/ZWjYGVU&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ZWjYGVU.png&quot; width=&quot;200px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CycleGAN에는 기존 GAN loss 이외에 &lt;em&gt;cycle-consitency loss&lt;/em&gt;라는 것이 추가됐습니다. 아래 그림처럼 도메인을 변경했다가 다시 돌아왔을 때 모습이 원래 입력값과 비슷한 형태가 되도록 regularization을 걸어주는 것입니다. 이렇게 되면 도메인을 넘나들 때 더욱 현실감 있는 데이터가 생성될 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/ZhUHD2i&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ZhUHD2i.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CycleGAN을 PyTorch로 구현한 코드를 살펴보겠습니다. 우선 두 개의 $G$와 두 개의 $D$를 정의합니다. (일반적인 &lt;em&gt;generator&lt;/em&gt;, &lt;em&gt;discriminator&lt;/em&gt; 사용)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Generator arguments : input_dim, num_filter, output_dim, num_resnet&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G_A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ngf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_resnet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;G_B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ngf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_resnet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Discriminator arguments : input_dim, num_filter, output_dim&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;D_B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$G$의 loss를 구하는 코드는 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# A -&amp;gt; B&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fake_B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_B_fake_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G_A_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MSE_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_B_fake_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_B_fake_decision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# forward cycle loss&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;recon_A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cycle_A_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L1_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;real_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lambdaA&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# B -&amp;gt; A&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fake_A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_A_fake_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G_B_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MSE_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_A_fake_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_A_fake_decision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# backward cycle loss&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;recon_B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cycle_B_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L1_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;real_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lambdaB&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Back propagation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G_A_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G_B_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cycle_A_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cycle_B_loss&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$D$의 loss를 구하는 코드는 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Train discriminator D_A&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_A_real_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_A_real_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MSE_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_A_real_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_A_real_decision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fake_A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fake_A_pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_A_fake_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_A_fake_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MSE_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_A_fake_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_A_fake_decision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_A_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_A_real_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_A_fake_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Train discriminator D_B&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_B_real_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_B_real_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MSE_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_B_real_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_B_real_decision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fake_B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fake_B_pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_B_fake_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_B_fake_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MSE_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_B_fake_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_B_fake_decision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_B_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_B_real_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_B_fake_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;stargan&quot;&gt;StarGAN&lt;/h2&gt;

&lt;p&gt;StarGAN은 CycleGAN의 단점을 보완한 연구입니다. CycleGAN은 도메인 수가 늘어나게 되면 필요한 $G$의 수가 기하급수적으로 증가하고, $D$는 선형적으로 증가합니다. 아래 그림의 (a)의 경우 도메인 수가 4개가 되자, $G$는 12개, $D$는 4개가 필요한 것을 확인할 수 있습니다. 반면 StarGAN은 (b)와 같이 생겼습니다. $D$와 $G$는 각각 하나만 있으면 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/vuvKH72&quot;&gt;&lt;img src=&quot;https://i.imgur.com/vuvKH72.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;StarGAN의 학습 방식을 저자가 든 예시 기준으로 설명해 보겠습니다. &lt;em&gt;CelebA&lt;/em&gt; 데이터셋과 &lt;em&gt;RaFD&lt;/em&gt; 데이터 셋이 있고 각각의 레이블은 아래 그림과 같이 주황색, 녹색 박스라고 칩시다. &lt;em&gt;Mask Vector&lt;/em&gt;는 모델이 현재 다루는 데이터가 &lt;em&gt;CelebA&lt;/em&gt;에 속하는지, &lt;em&gt;RaFD&lt;/em&gt;에 속하는지 나타내는 one-hot-vector입니다.&lt;/p&gt;

&lt;p&gt;우선 (b)의 $G$에 입력되는 데이터를 보겠습니다. 이 데이터는 검은색 머리의 젊은 여성인데요, 타겟 도메인을 검은색 머리의 젊은 남자로 설정하였습니다. $G$의 입력데이터는 소스 도메인의 원래 이미지, 레이블 벡터, &lt;em&gt;Mask Vector&lt;/em&gt; 셋을 합친 형태입니다. 어쨌든 $G$는 이 데이터를 검은색 머리의 젊은 남자로 변환해야 합니다. 이 데이터를 (d)의 $D$에 보내서 $D$가 실제 데이터로 구분하도록, 그리고 검은색 머리의 젊은 남자($[1,0,0,1,1]$)로 분류하도록 속여야 하니까요. $G$는 $D$를 잘 속일 수 있도록 학습됩니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/O1VrGT1&quot;&gt;&lt;img src=&quot;https://i.imgur.com/O1VrGT1.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(b)의 $G$가 생성한 데이터는 다시 $G$에 보내집니다. 이번에 $G$에 입력되는 데이터는 방금 전 $G$가 생성한 타겟 도메인의 이미지, 원 데이터의 레이블 벡터(검은색 머리의 젊은 여성, $[0,0,1,0,1]$), &lt;em&gt;Mask Vector&lt;/em&gt; 셋을 합친 형태입니다. $G$는 이렇게 만든 데이터가 원래 이미지와 유사하도록 학습됩니다. 이는 CycleGAN의 &lt;em&gt;cycle-consitency loss&lt;/em&gt;를 그대로 차용했습니다. 결과적으로 $G$는 하나의 이미지 데이터로 $D$를 속이는 과정에서, &lt;em&gt;cycle-consitency loss&lt;/em&gt;를 줄이는 과정에서 두 번 학습되는 셈이죠. StarGAN의 목적함수는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/EwPxI06&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EwPxI06.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;anormaly-detection-with-gan&quot;&gt;Anormaly detection with GAN&lt;/h2&gt;

&lt;p&gt;GAN을 이상치 탐지, 즉 &lt;em&gt;Novelty Detection&lt;/em&gt;에 활용한 연구도 있습니다. GAN은 $G$가 노이즈 $z$를 받아 현실감 있는 데이터를 생성하도록 학습되는데요. $G$가 생성한 데이터를 역추적해 latent space를 분석하면 이 latent space 내에서 특정 영역이 이상치에 해당할 것이라는 전제가 깔려 있습니다. 이를 도식적으로 나타낸 그림은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/zl0xWyh&quot;&gt;&lt;img src=&quot;https://i.imgur.com/zl0xWyh.png&quot; width=&quot;250px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;triplegan&quot;&gt;TripleGAN&lt;/h2&gt;

&lt;p&gt;TripleGAN은 GAN으로 새롭게 생성한 데이터를 활용해 성능이 좋은 분류기(classifier)를 만들어내는 게 목표입니다. 아키텍처와 목적함수를 도식화한 그림은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/D7lm8MW&quot;&gt;&lt;img src=&quot;https://i.imgur.com/D7lm8MW.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;차근차근 살펴보겠습니다. 우선 생성자 $G$는 노이즈 $z$를 받아서 인공데이터 $x$를 산출하고 $y$는 실제 데이터로부터 샘플링합니다. $G$가 만든 데이터는 판별자 $D$와 분류기 $C$로 보내집니다. $D$는 이 데이터가 진짜인지 가짜인지 구분하며, $C$는 $G$가 만든 $x$를 입력으로 하고 역시 $G$가 만든 $y$를 출력으로 하는 classification task를 수행합니다.&lt;/p&gt;

&lt;p&gt;레이블이 있는 실제 데이터($x_l, y_l$)는 분류기 $C$를 학습하는 데 사용됩니다(supervised learning). 이 데이터는 $D$에도 들어가 $D$가 진짜인지 가짜인지 구분하도록 학습됩니다. 마지막으로 레이블이 없는 실제 데이터($x_c$)가 분류기 $C$에 입력되면 $C$는 이 데이터의 레이블을 예측합니다. $C$가 잘 학습되어 있다면 $x_c$ 역시 레이블이 있는 데이터처럼 역할을 하게 되겠지요. 어쨌든 이렇게 레이블이 추가된 $x_c$ 역시 $D$에 입력돼 진짜/가짜 여부를 판별합니다.&lt;/p&gt;

&lt;p&gt;TripleGAN에서는 $G$가 $D$를 속이는 과정에서 생성한 데이터가 $C$ 학습에 활용돼 $C$의 성능을 높일 수 있습니다. 뿐만 아니라 $C$는 레이블이 없는 데이터 $x_c$의 레이블을 예측할 때 $D$가 가짜라고 구분하지 않도록 그럴듯한 레이블을 달도록 학습이 진행됩니다. 결과적으로 TripleGAN의 학습이 잘 되면 기존 데이터만 가지고 학습한 것보다 성능이 좋은 분류기 $C$가 도출되리라고 기대할 수 있습니다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Normalizing Flow</title>
   <link href="http://ratsgo.github.io/generative%20model/2018/01/29/NF/"/>
   <updated>2018-01-29T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2018/01/29/NF</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Normalizaing Flow&lt;/strong&gt;(NF) 개념에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다.&lt;/p&gt;

&lt;h2 id=&quot;목적&quot;&gt;목적&lt;/h2&gt;

&lt;p&gt;변분추론(Variational Inference)의 목적은 계산이 어려운 사후확률 분포 $p(z$|$x)$를 계산이 쉬운 $q(z$|$x)$로 근사하는 것입니다. 우리는 &lt;em&gt;evidence&lt;/em&gt;인 $p(x)$를 최대화하는 모델, 즉 데이터 $x$의 분포를 잘 설명하는 확률모형을 학습시키고자 합니다. 몇 가지 수식 정리 과정을 거치면 &lt;strong&gt;Evidence Lower Bound&lt;/strong&gt;(ELBO)를 다음과 같이 도출할 수 있습니다. (수식 유도 과정에 대해서는 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/19/vi/&quot;&gt;이곳&lt;/a&gt; 참고)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ELBO={ E }_{ z\sim q\left( z |x\right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z |x\right) ||p\left( z|x\right)  \right)&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://ratsgo.github.io/generative%20model/2018/01/27/VAE/&quot;&gt;Variational AutoEncoder(VAE)&lt;/a&gt;에서는 근사 대상 확률함수 $q$를 다음과 같이 정의합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q\left( z|x \right) =N\left( { \mu  }_{q}\left( x \right) ,\Sigma_{q} \left( x \right) \right)&lt;/script&gt;

&lt;p&gt;VAE에서 사후확률분포 $q$를 위와 같이 정한 이유는 샘플링과 계산의 용이성 때문입니다. 그런데 이보다 더 복잡한 형태의 사후확률분포를 만들어낼 수는 없을까요? 예컨대 $q$에서 뽑은 잠재변수를 $z_0$라 둡시다. 그런데 VAE는 $q$를 단순한 가우시안 분포로 가정하기 하기 때문에 아래와 같이 $z_0$에 특정한 형태의 함수 $f_k$들을 반복 적용하여 모델이 더욱 복잡한 형태의 잠재변수를 표현하게끔 만들어주자는 것입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ z }_{ K }={ f }_{ K }\circ ...\circ { f }_{ 2 }\circ { f }_{ 1 }\left( { z }_{ 0 } \right)&lt;/script&gt;

&lt;p&gt;이것이 바로 NF가 노리는 바입니다.&lt;/p&gt;

&lt;h2 id=&quot;change-of-variables&quot;&gt;Change of Variables&lt;/h2&gt;

&lt;p&gt;$z’=f(z)$일 때 역함수가 존재하는 $f$와 임의의 확률분포 $q(z)$에 대해 다음 공식이 성립한다고 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q\left( z' \right) =q\left( z \right) \left| det\frac { \partial { f }^{ -1 } }{ \partial z' }  \right| =q\left( z \right) { \left| det\frac { \partial f }{ \partial z }  \right|  }^{ -1 }&lt;/script&gt;

&lt;p&gt;따라서 $f$를 $K$번 적용한 $z_K$의 로그확률 $q_K(z_K)$값을 다음과 같이 표현할 수 있다고 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log { { q }_{ K }\left( { z }_{ K } \right)  } =\log { { q }_{ 0 }\left( { z }_{ 0 } \right)  } -\sum _{ k=1 }^{ K }{ \log { det\left| \frac { \partial { f }_{ k } }{ \partial { z }_{ k } }  \right|  }  }&lt;/script&gt;

&lt;h2 id=&quot;normalizing-flow&quot;&gt;Normalizing Flow&lt;/h2&gt;

&lt;p&gt;그런데 이때 특정 함수 $f$를 사용하면 위 식의 행렬식(determinant) 부분을 쉽게 계산할 수 있다고 합니다. 그 종류는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/DtOLSdZ&quot;&gt;&lt;img src=&quot;https://i.imgur.com/DtOLSdZ.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;$f$를 &lt;em&gt;planar&lt;/em&gt;로 정했다고 칩시다. 이 경우 행렬식 부분은 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;det\left| \frac { \partial { f }_{ k } }{ \partial { z }_{ k } }  \right| =\left| 1+{ u }^{ T }\psi \left( { z }_{ k } \right)  \right|\\,where\quad \psi \left( { z }_{ k } \right) =h'\left( { w }^{ T }z+b \right) w&lt;/script&gt;

&lt;p&gt;$K$를 키울 수록 잠재변수를 더 복잡하게 모델링할 수 있습니다. 예컨대 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/H6nvMHh&quot;&gt;&lt;img src=&quot;https://i.imgur.com/H6nvMHh.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Advanced VAEs</title>
   <link href="http://ratsgo.github.io/generative%20model/2018/01/28/VAEs/"/>
   <updated>2018-01-28T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2018/01/28/VAEs</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Variational AutoEncoder&lt;/strong&gt;(VAE)의 발전된 모델들에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. PyTorch 코드는 &lt;a href=&quot;https://github.com/GunhoChoi/PyTorch-FastCampus&quot;&gt;이곳&lt;/a&gt;을 참고하였습니다. VAE의 기본적 내용에 대해서는 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2018/01/27/VAE/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;conditional-vae&quot;&gt;Conditional VAE&lt;/h2&gt;

&lt;p&gt;Conditional VAE(CVAE)란 다음 그림과 같이 기존 VAE 구조를 지도학습(supervised learning)이 가능하도록 바꾼 것입니다. &lt;em&gt;encoder&lt;/em&gt;와 &lt;em&gt;decoder&lt;/em&gt;에 정답 레이블 $y$가 추가된 형태입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/uhYATU8&quot;&gt;&lt;img src=&quot;https://i.imgur.com/uhYATU8.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;encoder&lt;/em&gt;에서 $z$를 만들 때 $y$ 정보가 추가됩니다. PyTorch 코드는 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;# (X,y)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_var&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;decoder&lt;/em&gt;에서 $x$를 복원할 때 $y$ 정보가 필요합니다. PyTorch 코드는 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# (Z,y)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;CVAE의 손실함수는 $y$의 추가로 수식은 달라지지만, 코드상으로는 기존 VAE와 동일합니다. 마지막 아웃풋에 VAE처럼 $x$만 있기 때문입니다. 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mb_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Forward&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Loss&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;recon_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;functional&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binary_cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size_average&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb_size&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recon_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kl_loss&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;학습된 CVAE에 아래 그림과 같이 실제 손으로 3이라고 쓴 그림과 함께 label 정보를 바꿔가며 입력하게 되면 다음과 같이 출력된다고 합니다. 다시 말해 CVAE 모델이 데이터 분포를 학습할 때 범주 정보까지 함께 고려하게 된다는 의미입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/wcAwFWe&quot;&gt;&lt;img src=&quot;https://i.imgur.com/wcAwFWe.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;adversarial-autoencoder&quot;&gt;Adversarial Autoencoder&lt;/h2&gt;

&lt;p&gt;Adversarial Autoencoder(AAE)란 VAE에 GAN를 덧입힌 구조입니다. 다음 그림과 같습니다. GAN과 관련 자세한 내용은 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/20/gan/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/LnDYyPj&quot;&gt;&lt;img src=&quot;https://i.imgur.com/LnDYyPj.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AAE에서는 기존 VAE 구조가 기존 GAN에서의 생성자(generator) 역할을 합니다. 생성자의 &lt;em&gt;encoder&lt;/em&gt;는 데이터 $x$를 받아서 잠재변수 $z$를 샘플링하고, 생성자의 &lt;em&gt;decoder&lt;/em&gt;는 이로부터 다시 $x$를 복원합니다. AAE가 기존 VAE와 다른 점은 기존 GAN의 구분자(discriminator) 역할을 하는 네트워크가 추가되었다는 점입니다. 이 구분자는 생성자의 &lt;em&gt;encoder&lt;/em&gt;가 샘플링한 가짜 $z$와 $p(z)$로부터 직접 샘플링한 진짜 $z$를 구분하는 역할을 합니다.&lt;/p&gt;

&lt;p&gt;이렇게 복잡한 네트워크를 만든 이유는 VAE 특유의 단점 때문입니다. VAE는 사전확률 분포 $p(z)$를 표준정규분포로 가정하고, $q(z$|$x)$를 이와 비슷하게 맞추는 과정에서 학습이 이루어집니다. VAE 아키텍처가 이처럼 구성되어 있는 이유는 표준정규분포와 같이 간단한(?) 확률함수여야 샘플링에 용이하고, KLD 계산을 쉽게 할 수 있기 때문입니다. (자세한 내용은 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2018/01/27/VAE/&quot;&gt;이곳&lt;/a&gt; 참고) 그런데 실제 데이터 분포가 정규분포를 따르지 않거나 이보다 복잡할 경우 VAE 성능에 문제가 발생할 수 있습니다.&lt;/p&gt;

&lt;p&gt;그런데 GAN의 경우 모델에 특정 확률분포를 전제할 필요가 없습니다. GAN은 데이터가 어떤 분포를 따르든, 데이터의 실제 분포와 생성자(모델)가 만들어내는 분포 사이의 차이를 줄이도록 학습되기 때문입니다. (자세한 내용은 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/20/gan/&quot;&gt;이곳&lt;/a&gt; 참고) VAE의 &lt;em&gt;regularization term&lt;/em&gt;을 GAN Loss로 대체할 경우 사전확률과 사후확률 분포를 정규분포 이외에 다른 분포를 쓸 수 있게 돼 모델 선택의 폭이 넓어지는 효과를 누릴 수 있습니다. 어쨌든 개별 데이터 샘플 $x_i$와 사전확률분포 $p(z)$에서 뽑은 $z_i$에 대해 AAE의 학습과정은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/5S0GPMe&quot;&gt;&lt;img src=&quot;https://i.imgur.com/5S0GPMe.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AAE의 PyTorch 코드는 다음과 같습니다. 우선 생성자(&lt;em&gt;encoder, decoder&lt;/em&gt;)와 구분자를 정의합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Encoder&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Decoder&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Discriminator&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Step1의 &lt;em&gt;reconstruction error&lt;/em&gt;를 계산하는 과정은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; Reconstruction phase &quot;&quot;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z_sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;recon_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binary_cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Step2의 구분자 학습을 위한 손실을 구하는 과정은 다음과 같습니다. 생성자의 &lt;em&gt;encoder&lt;/em&gt;가 샘플링하는 $z$는 가짜, $p(z)$로부터 직접 뽑는 $z$는 진짜라고 레이블을 부여합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Discriminator&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mb_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Step3의 생성자 학습을 위한 손실을 구하는 과정은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Generator&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;gan-vs-vae&quot;&gt;GAN vs VAE&lt;/h2&gt;

&lt;p&gt;GAN과 VAE의 차이점을 도식적으로 나타낸 표는 다음과 같습니다&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Optimization&lt;/th&gt;
      &lt;th&gt;Converge&lt;/th&gt;
      &lt;th&gt;Image Quality&lt;/th&gt;
      &lt;th&gt;Generalization&lt;/th&gt;
      &lt;th&gt;비고&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;VAE&lt;/td&gt;
      &lt;td&gt;Stochastic Gradient Descent&lt;/td&gt;
      &lt;td&gt;Local Minimum&lt;/td&gt;
      &lt;td&gt;부드럽고 흐리다&lt;/td&gt;
      &lt;td&gt;오버피팅 경향이 상대적으로 큼&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GAN&lt;/td&gt;
      &lt;td&gt;Alternating Stochastic Gradient Descent&lt;/td&gt;
      &lt;td&gt;Saddel points&lt;/td&gt;
      &lt;td&gt;선명하나 아티팩트가 많다&lt;/td&gt;
      &lt;td&gt;새로운 영상을 잘 생성해냄&lt;/td&gt;
      &lt;td&gt;Mode collapsing 문제 발생, 수렴이 어렵다&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;GAN과 VAE의 장점을 모두 취해 만든 연구로는 Energy-based GAN(EBGAN), Stack GAN 등이 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;sketch-rnn&quot;&gt;Sketch RNN&lt;/h2&gt;

&lt;p&gt;Sketch RNN은 VAE에 RNN 구조를 덧입힌 아키텍처입니다. &lt;em&gt;encoder&lt;/em&gt;와 &lt;em&gt;decoder&lt;/em&gt;에 RNN를 썼습니다. 다음 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/qssmRdT&quot;&gt;&lt;img src=&quot;https://i.imgur.com/qssmRdT.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Variational AutoEncoder</title>
   <link href="http://ratsgo.github.io/generative%20model/2018/01/27/VAE/"/>
   <updated>2018-01-27T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2018/01/27/VAE</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Variational AutoEncoder&lt;/strong&gt;(VAE)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아, 그리고 &lt;a href=&quot;https://jaan.io/what-is-variational-autoencoder-vae-tutorial/&quot;&gt;이곳&lt;/a&gt; 등을 정리했음을 먼저 밝힙니다. PyTorch 코드는 &lt;a href=&quot;https://github.com/GunhoChoi/PyTorch-FastCampus&quot;&gt;이곳&lt;/a&gt;을 참고하였습니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;concept&quot;&gt;concept&lt;/h2&gt;

&lt;p&gt;VAE는 데이터가 생성되는 과정, 즉 데이터의 확률분포를 학습하기 위한 두 개의 뉴럴네트워크로 구성되어 있습니다. VAE는 잠재변수(latent variable) $z$를 가정하고 있는데요. 우선 &lt;em&gt;encoder&lt;/em&gt;라 불리는 뉴럴네트워크는 관측된 데이터 $x$를 받아서 잠재변수 $z$를 만들어 냅니다. &lt;em&gt;decoder&lt;/em&gt;라 불리는 뉴럴네트워크는 &lt;em&gt;encoder&lt;/em&gt;가 만든 $z$를 활용해 $x$를 복원해내는 역할을 합니다. VAE 아키텍처는 다음 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/PhHb2aF&quot;&gt;&lt;img src=&quot;https://i.imgur.com/PhHb2aF.jpg&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그렇다면 여기에서 잠재변수 $z$는 어떤 의미인 걸까요? 고양이 그림 예시를 들어 생각해보겠습니다. 수많은 고양이 사진이 있다고 칩시다. 사람은 고양이 사진들이 저마다 다르게 생겼다 하더라도 이들 사진이 고양이임을 단박에 알아낼 수 있습니다. 사람들은 고양이 사진을 픽셀 단위로 자세하게 보고 고양이라고 판단하는게 아니라, 털 색깔, 눈 모양, 이빨 개수 등 추상화된 특징을 보고 고양이라는 결론을 냅니다.&lt;/p&gt;

&lt;p&gt;이를 잠재변수 $z$와 VAE 아키텍처 관점에서 이해해 보자면, &lt;em&gt;encoder&lt;/em&gt;는 입력 데이터를 추상화하여 잠재적인 특징을 추출하는 역할, &lt;em&gt;decoder&lt;/em&gt;는 이러한 잠재적인 특징을 바탕으로 원 데이터로 복원하는 역할을 한다고 해석해볼 수 있겠습니다. 실제로 잘 학습된 VAE는 임의의 $z$값을 &lt;em&gt;decoder&lt;/em&gt;에 넣으면 다양한 데이터를 생성할 수 있다고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;latent-vector-만들기&quot;&gt;latent vector 만들기&lt;/h2&gt;

&lt;p&gt;VAE의 &lt;em&gt;decoder&lt;/em&gt; 파트는 다음과 같이 정규분포를 전제로 하고 있습니다. 다시 말해 &lt;em&gt;encoder&lt;/em&gt;가 만들어낸 $z$의 평균과 분산을 모수로 하는 정규분포입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p\left( { x }|{ z } \right) =N\left( { x }|{ { f }_{ \mu  }\left( z \right)  },{ { f }_{ \sigma  }\left( z \right)  }^{ 2 }\times I \right)&lt;/script&gt;

&lt;p&gt;최대우도추정(MLE) 방식으로 VAE 모델의 파라메터를 추정하려면 다음과 같이 정의된 &lt;em&gt;marginal log-likelihood&lt;/em&gt; $\log{p(x)}$를 최대화하면 됩니다. 아래 식을 최대화하면 모델이 데이터를 그럴싸하게 설명할 수 있게 됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log { p\left( x \right)  } =\log { \sum _{ z }^{  }{ p\left( { x }|{ { { f }_{ \mu  }\left( z \right)  },{ { f }_{ \sigma  }\left( z \right)  }^{ 2 }\times I } \right)  } p\left( z \right)  }&lt;/script&gt;

&lt;p&gt;위 식은 최적화하기 어렵습니다. $z$는 무수히 많은 경우가 존재할 수 있는데 가능한 모든 $z$에 대해서 고려해야 하기 때문입니다. 이럴 때 써먹는 것이 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/19/vi/&quot;&gt;변분추론(Variational Inference)&lt;/a&gt;입니다. 변분추론은 계산이 어려운 확률분포를, 다루기 쉬운 분포 $q(z)$로 근사하는 방법입니다. 한편 $p(x)$는 베이즈 정리에서 &lt;em&gt;evidence&lt;/em&gt;라고 이름이 붙여진 항인데요. 몇 가지 수식 유도 과정을 거치면 &lt;em&gt;evidence&lt;/em&gt;의 하한(ELBO)을 다음과 같이 구할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log { p\left( x \right)  } \ge { E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right)&lt;/script&gt;

&lt;p&gt;계산이 쉬운 위 부등식 우변, 즉 ELBO를 최대화하면 $\log{p(x)}$를 최대화할 수 있을 것입니다. 일반적인 변분추론에서는 $q(z)$를 정규분포로 정합니다. 예컨대 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q\left( z \right) =N\left( { \mu  }_{ q },{ \sigma  }_{ q }^{2} \right)&lt;/script&gt;

&lt;p&gt;그런데 데이터 $x$가 고차원일 때는 $q$를 위와 같이 정하게 되면 학습이 대단히 어렵다고 합니다. 그도 그럴 것이 모든 데이터에 대해 동일한 평균과 분산, 즉 단 하나의 정규분포를 가정하게 되는 셈이니, 데이터가 복잡한 데 비해 모델이 너무 단순하기 때문인 것 같습니다. VAE에서는 이 문제를 해결하기 위해 $q$의 파라메터를 $x$에 대한 함수로 둡니다. 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q\left( z|x \right) =N\left( { \mu  }_{q}\left( x \right) ,\Sigma_{q} \left( x \right) \right)&lt;/script&gt;

&lt;p&gt;$q$를 위와 같이 설정하고 ELBO를 최대화하는 방향으로 $q$를 잘 학습하면, $x$가 달라질 때마다 $q$의 분포도 계속 달라지게 됩니다. $x$에 따라 $q$의 모수(평균, 분산)가 바뀌게 되니까요. VAE의 &lt;em&gt;encoder&lt;/em&gt;에는, $x$를 받아서 $z$의 평균과 분산을 만들어내는 뉴럴네트워크 두 개($f_μ$, $f_σ$)가 포함되어 있습니다. 이 덕분에 복잡한 데이터에 대해서도 모델이 적절하게 대응할 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;어쨌든 노이즈를 &lt;em&gt;zero-mean Gaussian&lt;/em&gt;에서 하나 뽑아 $f_μ$, $f_σ$가 산출한 평균과 분산을 더하고 곱해줘서 sampled latent vector $z$를 만듭니다. 수식은 다음과 같으며, 이같은 과정을 &lt;em&gt;reparameterization trick&lt;/em&gt;이라고 부릅니다. 다시 말해 $z$를 직접 샘플링하는게 아니고 노이즈를 샘플링하는 방식입니다. 이렇게 되면 역전파를 통해 &lt;em&gt;encoder&lt;/em&gt;가 산출하면 평균과 분산을 업데이트할 수 있게 됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z={ \mu  }{ (x) }+{ \sigma  }{ (x) } \times\epsilon ,\quad \epsilon \sim N\left( 0,1 \right)&lt;/script&gt;

&lt;p&gt;VAE는 코드로 보는 것이 훨씬 잘 이해가 되는데요. 지금까지 설명한 내용이 아래 코드에 함축돼 있습니다(pytorch).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                        
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_var&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reparametrize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;VAE는 latent vector $z$를 위와 같이 만들기 때문에 데이터 $x$가 동일하다 하더라도 $z$는 얼마든지 달라질 수 있고, &lt;em&gt;decoder&lt;/em&gt;의 최종 결과물 역시 변종이 발생할 가능성이 있습니다. $z$ 생성 과정에 &lt;em&gt;zero-mean Gaussian&lt;/em&gt;으로 뽑은 노이즈가 개입되기 때문입니다. 데이터 $x$를 넣어 다시 $x$가 출력되는 구조의 &lt;em&gt;autoencoder&lt;/em&gt;이지만, 맨 앞에 &lt;em&gt;variational&lt;/em&gt;이 붙은 이유가 바로 여기에 있는 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;vae의-목적함수&quot;&gt;VAE의 목적함수&lt;/h2&gt;

&lt;p&gt;VAE의 &lt;em&gt;decoder&lt;/em&gt;는 데이터의 사후확률 $p(x$|$z)$을 학습합니다. 하지만 사후확률은 계산이 어렵기 때문에 다루기 쉬운 분포 $q(z)$로 근사하는 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/19/vi/&quot;&gt;변분추론&lt;/a&gt; 기법을 적용하게 됩니다. 변분추론은 $p(x$|$z)$와 $q(z)$ 사이의 KL Divergence를 계산하고, KLD가 줄어드는 쪽으로 $q(z)$를 조금씩 업데이트해서 $q(z)$를 얻어냅니다. KLD 식을 조금 변형하면 다음과 같은 식을 유도할 수 있습니다. (자세한 내용은 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/19/vi/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) ={ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right]&lt;/script&gt;

&lt;p&gt;그런데 우리는 전 챕터에서 $q$를 정규분포로 두고, $q$의 평균과 분산을 $x$에 대한 함수로 정의한 바 있습니다. 이를 반영하고, &lt;em&gt;evidence&lt;/em&gt;인 $\log{p(x)}$ 중심으로 식을 다시 쓰면 아래와 같습니다. 이 식을 $A$라고 두겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\log { p\left( x \right)  } =&amp;{ E }_{ z\sim q\left( z|x \right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right)  \right) +{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z|x \right)  \right)\\=&amp;ELBO+{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z|x \right)  \right) 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;동일한 확률변수에 대한 KLD 값(위 식 우변 세번째 항)은 항상 양수이므로 아래와 같은 부등식이 항상 성립합니다. 아래 식을 $B$라고 두겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log { p\left( x \right)  } \ge { E }_{ z\sim q\left( z|x \right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right)  \right)=ELBO&lt;/script&gt;

&lt;p&gt;따라서 위 부등식 우변, 즉 ELBO를 최대화하면 우리의 목적인 &lt;em&gt;marginal log-likelihood&lt;/em&gt; $\log{p(x)}$를 최대화할 수 있게 됩니다. 아울러 $A$와 $B$를 비교하면서 보면 ELBO를 최대화한다는 것은 $q(z$|$x)$와 $p(z$|$x)$ 사이의 KLD를 최소화하는 의미가 됩니다.&lt;/p&gt;

&lt;p&gt;딥러닝 모델은 보통 손실함수를 목적함수로 쓰는 경향이 있으므로 위 부등식의 우변에 음수를 곱한 식이 &lt;em&gt;loss function&lt;/em&gt;이 되고, 이 함수를 최소화하는 게 학습 목표가 됩니다. 손실함수는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L=-{ E }_{ z\sim q\left( z|x \right)  }\left[ \log { p(x|z) }  \right] +{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right)  \right)&lt;/script&gt;

&lt;p&gt;위 식 우변 첫번째 항은 &lt;em&gt;reconstruction loss&lt;/em&gt;에 해당합니다. &lt;em&gt;encoder&lt;/em&gt;가 데이터 $x$를 받아서 $q$로부터 $z$를 뽑습니다. &lt;em&gt;decoder&lt;/em&gt;는 &lt;em&gt;encoder&lt;/em&gt;가 만든 $z$를 받아서 원 데이터 $x$를 복원합니다. 위 식 우변 첫번째 항은 이 둘 사이의 크로스 엔트로피를 가리킵니다.&lt;/p&gt;

&lt;p&gt;위 식 우변 두번째 항은 &lt;em&gt;KL Divergence Regularizer&lt;/em&gt;에 해당합니다. VAE는 $z$가 &lt;em&gt;zero-mean Gaussian&lt;/em&gt;이라고 가정합니다. 정규분포끼리의 KLD는 분석적인 방식으로 도출 가능합니다. 계산이 쉽다는 말이지요. 따라서 위 식 우변 두번째 항을 다음과 같이 다시 쓸 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
{ D }_{ KL }\left( q\left( z|x \right) ||p\left( z \right)  \right) =&amp;{ D }_{ KL }\left[ N\left( { \mu  }_{ q }\left( x \right) ,\Sigma _{ q }\left( x \right)  \right) ||N\left( 0,1 \right)  \right] \\ =&amp;\frac { 1 }{ 2 } \sum _{ k }^{  }{ \left\{ exp\left( \Sigma _{ q }\left( x \right)  \right) +{ { \mu  }_{ q }\left( x \right)  }^{ 2 }-1-\Sigma _{ q }\left( x \right)  \right\}  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식 우변 두번째 항을 최소화한다는 말은 $q$를 &lt;em&gt;zero-mean Gaussian&lt;/em&gt;에 가깝게 만든다는 의미입니다. 지금까지 말씀드린 내용을 종합해 VAE의 손실함수를 도식적으로 나타내면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/JnoyZIN&quot;&gt;&lt;img src=&quot;https://i.imgur.com/JnoyZIN.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;KLD를 아래처럼 분해해서 다음과 같이 해석하는 것도 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/HRtHPkp&quot;&gt;&lt;img src=&quot;https://i.imgur.com/HRtHPkp.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;VAE의 목적함수를 PyTorch 코드로 구현한 결과는 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# the Binary Cross Entropy between the target and the output&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reconstruction_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size_average&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;BCE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reconstruction_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;KLD_element&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mul_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;KLD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KLD_element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mul_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BCE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KLD&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;vae의-장단점&quot;&gt;VAE의 장단점&lt;/h2&gt;

&lt;p&gt;VAE는 GAN에 비해 학습이 안정적인 편이라고 합니다. 손실함수에서 확인할 수 있듯 &lt;em&gt;reconstruction error&lt;/em&gt;과 같이 평가 기준이 명확하기 때문입니다. 아울러 데이터뿐 아니라 데이터에 내재한 잠재변수 $z$도 함께 학습할 수 있다는 장점이 있습니다(&lt;em&gt;feature learning&lt;/em&gt;). 하지만 출력이 선명하지 않고 평균값 형태로 표시되는 문제, &lt;em&gt;reparameterization trick&lt;/em&gt;이 모든 경우에 적용되지 않는 문제 등이 단점으로 꼽힌다고 합니다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>KKT 조건</title>
   <link href="http://ratsgo.github.io/convex%20optimization/2018/01/26/KKT/"/>
   <updated>2018-01-26T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/convex%20optimization/2018/01/26/KKT</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;KKT 조건&lt;/strong&gt;을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 &lt;a href=&quot;http://www.stat.cmu.edu/~ryantibs/convexopt/&quot;&gt;강의&lt;/a&gt;를 기본으로 하되 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;concept&quot;&gt;concept&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Karush-Kuhn-Tucker&lt;/em&gt; 조건은 &lt;em&gt;primal, dual solution&lt;/em&gt;과의 관계에서 도출된 조건인데요. 최적화 이론과 실제 구현에서 핵심적인 역할을 합니다. &lt;em&gt;duality&lt;/em&gt;와 관련해서는 &lt;a href=&quot;https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다. 어쨌든 KKT 조건의 구체적인 내용은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/Sq8DddQ&quot;&gt;&lt;img src=&quot;https://i.imgur.com/Sq8DddQ.png&quot; width=&quot;550px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;necessity&quot;&gt;Necessity&lt;/h2&gt;

&lt;p&gt;다음과 같은 명제가 성립합니다. &lt;em&gt;primal, dual, duality gap, lagrange dual function&lt;/em&gt; 등 개념과 관련해서는 &lt;a href=&quot;https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/9btM4wy&quot;&gt;&lt;img src=&quot;https://i.imgur.com/9btM4wy.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;zero duality라면 $f^*=g$입니다. 그런데 $x$-star는 primal problem의 목적함수 $f$의 optimal value입니다. 또한 $u$-star, $v$-star는 dual problem의 목적함수 $g$의 optimal value입니다. 따라서 다음 식처럼 쓸 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f\left( { x }^{ * } \right) =g\left( { u }^{ * },{ v }^{ * } \right)&lt;/script&gt;

&lt;p&gt;위 식 우변을 라그랑지안 듀얼 함수 $g$의 정의대로 쓰면 다음 식과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g\left( { u }^{ * },{ v }^{ * } \right) =\min _{ x }{ L\left( x,{ u }^{ * },{ v }^{ * } \right)  }&lt;/script&gt;

&lt;p&gt;$L$은 우리가 구하려는 미지수 $x$로 편미분한 식을 0으로 만드는 지점에서 최소값을 지닙니다. 그런데 전제조건에서 이미 언급했듯 primal problem의 해는 $x$-star이기 때문에 $L$을 $x$로 편미분한 결과를 0으로 만드는 지점은 바로 $x$-star가 될 것입니다. 이는 KKT 조건의 &lt;em&gt;stationary condition&lt;/em&gt;을 만족한다는 이야기입니다. 이를 식으로 쓰면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\min _{ x }{ L\left( x,{ u }^{ * },{ v }^{ * } \right)  } =L\left( { x }^{ * },{ u }^{ * },{ v }^{ * } \right)&lt;/script&gt;
primal problem과 라그랑지 함수 $L$, 라그랑지안 듀얼 함수 $g$ 사이에는 다음 부등식이 성립합니다. (왜 아래 식이 도출되는지는 &lt;a href=&quot;https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/&quot;&gt;이곳&lt;/a&gt; 참고)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f\left( { x }^{ * } \right) \ge \min _{ x\in C }{ L\left( x,u,v \right)  } \ge \min _{ x }{ L\left( x,u,v \right)  } =g\left( u,v \right)&lt;/script&gt;

&lt;p&gt;이를 우리가 들여다보던 식에 맞춰서 다시 적으면 다음 식을 유도할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;L\left( { x }^{ * },{ u }^{ * },{ v }^{ * } \right) \\ &amp;\le f\left( { x }^{ * } \right) +\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right)  } +\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right)  } \\ &amp;\le f\left( { x }^{ * } \right) 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;결과적으로 처음 항, 즉 $f(x^*)$가 마지막에 다시 유도된 걸 확인할 수 있습니다. 다시 말해 우리가 논의하고 있는 명제의 전제조건을 만족할 경우 위 모든 부등식이 사실상 등식과 같다는 이야기입니다. 이 경우 다음 식이 모두 0이 되어야 등식을 만족하게 됩니다. 그렇다면 모든 식에 등호가 붙으려면 다음 두 개 항이 모두 0이 되어야 함을 확인할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;A:\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right)  } =0\\ &amp;B:\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right)  } =0
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;그런데 &lt;em&gt;primal problem&lt;/em&gt;를 다시 살펴보면 $l_j$는 모두 0이기 때문에 $B$에 관련된 항들은 본래 모두 0입니다. 문제는 $A$인데요. $A$의 경우에도 모두 0이 되어야 등식을 만족합니다. 다시 말해 KKT 조건의 &lt;em&gt;complementary slackness&lt;/em&gt;를 만족한다는 이야기입니다.&lt;/p&gt;

&lt;p&gt;따라서 결과적으로 위 명제의 전제조건이 만족된다면 KKT 조건 또한 만족하게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;sufficiency&quot;&gt;Sufficiency&lt;/h2&gt;

&lt;p&gt;다음과 같은 명제가 성립합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/oJOBWNS&quot;&gt;&lt;img src=&quot;https://i.imgur.com/oJOBWNS.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;$g$를 정의대로 적으면 아래 식의 첫 줄이 됩니다. 아울러 $x$-star, $u$-star, $v$-star는 KKT 조건을 만족한다고 했으므로 KKT 조건의 &lt;em&gt;stationarity condition&lt;/em&gt;에 의해 $L(x,u^&lt;em&gt;,v^&lt;/em&gt;)$는 $x$-star에서 최소값을 가집니다. 따라서 다음이 성립합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
g\left( { u }^{ * },{ v }^{ * } \right) =&amp;\min _{ x }{ L\left( x,{ u }^{ * },{ v }^{ * } \right)  } \\ =&amp;f\left( { x }^{ * } \right) +\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right)  } +\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right)  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;KKT 조건의 &lt;em&gt;complementary slackness&lt;/em&gt;에 따라 아래 식 좌변의 두번째 항이 모두 0입니다. &lt;em&gt;primal problem&lt;/em&gt;을 다시 살펴보면 $l_j$ 역시 모두 0입니다. 따라서 아래 식이 성립합니다. 바꿔 말해 $x$-star는 &lt;em&gt;primal problem&lt;/em&gt;의 해, $u$-star, $v$-star는 &lt;em&gt;dual problem&lt;/em&gt;의 해라는 이야기입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f\left( { x }^{ * } \right) +\sum _{ i=1 }^{ m }{ { u }_{ i }^{ * }{ h }_{ i }\left( { x }^{ * } \right)  } +\sum _{ j=1 }^{ r }{ { v }_{ j }^{ * }l_{ j }\left( { x }^{ * } \right)  } =f\left( { x }^{ * } \right)&lt;/script&gt;

&lt;h2 id=&quot;정리&quot;&gt;정리&lt;/h2&gt;

&lt;p&gt;지금까지 말씀드린 내용을 정리하면 아래 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/A5HYngz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/A5HYngz.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;strong duality&lt;/em&gt;를 만족하는 경우 위 두 명제가 동치 관계를 갖습니다. (&lt;em&gt;strong duality&lt;/em&gt;, &lt;em&gt;slater’s condition&lt;/em&gt; 등은 &lt;a href=&quot;https://ratsgo.github.io/convex%20optimization/2018/01/25/duality/&quot;&gt;이곳&lt;/a&gt; 참고)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/LW5vHOE&quot;&gt;&lt;img src=&quot;https://i.imgur.com/LW5vHOE.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;svm에-적용&quot;&gt;SVM에 적용&lt;/h2&gt;

&lt;p&gt;마진(margin) 내 관측치를 허용하는 C-SVM을 기준으로 설명해 보겠습니다. C-SVM과 관련해서는 &lt;a href=&quot;https://ratsgo.github.io/machine%20learning/2017/05/29/SVM2/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다. 어쨌든 C-SVM의 &lt;em&gt;primal problem&lt;/em&gt;은 다음과 같습니다. 아래 제약식을 만족하면서 목적함수를 최소화하는 $w, b, ξ$을 찾아야 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\min _{ w,b,{ \xi  } }&amp;&amp;{ \frac { 1 }{ 2 } { \left\| w \right\|  }_{ 2 }^{ 2 }+C\sum _{ i=1 }^{ n }{ { \xi  }_{ i } }  } \\ &amp;subject\quad to\quad &amp;&amp;{ \xi  }_{ i }\ge 0,\quad i=1,...,n\\ &amp;&amp;&amp;{ y }_{ i }({ w }^{ T }{ x }_{ i }+b)\ge 1-{ \xi  }_{ i },\quad i=1,...,n
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 &lt;em&gt;primal problem&lt;/em&gt;을 바탕으로 라그랑지안 함수 $L$을 만듭니다. 제약식에 라그랑지안 승수를 곱해 목적식에 합치면 됩니다. 여기에서 라그랑지안 승수 $α, μ$를 &lt;em&gt;dual variable&lt;/em&gt;이라고 합니다. 단 여기에서 $α, μ$는 0 이상의 부등식에 적용되는 라그랑지안 승수이므로 0 이상의 제약을 갖습니다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;L(w,b,{ { \xi  }_{ i },\alpha  }_{ i },{ \mu  }_{ i })=\frac { 1 }{ 2 } { \left\| w \right\|  }_{ 2 }^{ 2 }+C\sum _{ i=1 }^{ n }{ { \xi  }_{ i } } -\sum _{ i=1 }^{ n }{ { \alpha  }_{ i }({ y }_{ i }({ w }^{ T }{ x }_{ i }+b)-1+{ \xi  }_{ i }) } -\sum _{ i=1 }^{ n }{ { { \mu  }_{ i }\xi  }_{ i } }&lt;/script&gt;
여기에서 우리가 사용할 조건은 KKT의 충분조건입니다. $w, b, ξ, α, μ$가 KKT 조건을 만족한다면, $w, b, ξ$는 primal problem의 최적해, $α, μ$는 dual problem의 최적해가 된다는 이야기입니다. 다시 말해 약간 풀기 어려운 primal problem을 풀기 쉬운 dual problem으로 바꿔 풀어도 최적해를 구한다는 점에선 같은 의미라는 뜻이 되는거죠.&lt;/p&gt;

&lt;p&gt;KKT 조건 가운데 &lt;em&gt;stationarity&lt;/em&gt; 조건은, 최적화하려는 미지수로 편미분한 식이 0이 된다는 조건입니다. 아래 세 개 식을 만족하게끔 $α, μ$를 구하면 &lt;em&gt;stationarity&lt;/em&gt; 조건이 클리어됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac { \partial L }{ \partial w } =0\quad &amp;\rightarrow \quad w=\sum _{ i=1 }^{ n }{ { \alpha  }_{ i }{ y }_{ i }{ x }_{ i } } \\ \frac { \partial L }{ \partial b } =0\quad &amp;\rightarrow \quad \sum _{ i=1 }^{ n }{ { \alpha  }_{ i }{ y }_{ i } } =0\\\frac { \partial L }{ \partial { \xi  }_{ i } } =0\quad &amp;\rightarrow \quad C-{ \alpha  }_{ i }-{ \mu  }_{ i }=0
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;KKT 조건 가운데 &lt;em&gt;complementary slackness&lt;/em&gt; 조건을 클리어하려면 아래 식을 만족해야 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
{ { \mu  }_{ i }\xi  }_{ i }=0,\quad i=1,...n\\ { \alpha  }_{ i }({ y }_{ i }({ w }^{ T }{ x }_{ i }+b)-1+{ \xi  }_{ i })=0,\quad i=1,...n
\end{align*}&lt;/script&gt;

&lt;p&gt;&lt;em&gt;dual problem&lt;/em&gt;의 목적식은 다음과 같습니다. 즉 &lt;em&gt;stationarity&lt;/em&gt; 조건으로 도출된 식을 라그랑지안 함수 $L$에 넣어 정리해준 결과입니다. &lt;em&gt;dual problem&lt;/em&gt;의 목적식과 제약식 도출과 관련한 자세한 내용은 &lt;a href=&quot;https://ratsgo.github.io/machine%20learning/2017/05/29/SVM2/&quot;&gt;이곳&lt;/a&gt;을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
g({\alpha}_{i},{\mu}_{i})=&amp;{ \min_{w,b,\xi} { L(w,b,{ { \xi  }_{ i },\alpha  }_{ i },{ \mu  }_{ i }) }  }
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;$w, b, ξ, α, μ$가 KKT 조건을 만족하도록 정했기 때문에, dual problem의 최적해인 $α, μ$를 구하는 것만으로도 primal problem을 푸는 것과 같은 효과를 낼 수 있습니다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Duality</title>
   <link href="http://ratsgo.github.io/convex%20optimization/2018/01/25/duality/"/>
   <updated>2018-01-25T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/convex%20optimization/2018/01/25/duality</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Duality&lt;/strong&gt;와 관련된 개념들을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 &lt;a href=&quot;http://www.stat.cmu.edu/~ryantibs/convexopt/&quot;&gt;강의&lt;/a&gt;를 기본으로 하되 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;concept&quot;&gt;concept&lt;/h2&gt;

&lt;p&gt;최적화 이론에서 &lt;strong&gt;쌍대성&lt;/strong&gt;(雙對性; duality)이란 어떤 최적화 문제가 &lt;strong&gt;원초문제(the primal problem)&lt;/strong&gt;와 &lt;strong&gt;쌍대문제(the dual problem)&lt;/strong&gt;의 두 가지 관점에서 볼 수 있다는 원칙입니다. 쌍대문제의 상한은 &lt;em&gt;primal problem&lt;/em&gt;의 하한(a lower bound)이 됩니다. 선형계획법(linear programming)를 예로 들어보겠습니다. 다음과 같이 주어진 선형 조건을 만족시키면서 선형인 목적함수 $c^Tx$를 최소화하는 문제입니다. ($c$는 $n$차원. $b$는 $m$차원, $h$는 $r$차원 벡터, $A$는 $m×n$, $G$는 $r×n$ 행렬)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\min_{ x }&amp;&amp;{ { c }^{ T }x } \\ &amp;subject\quad to\quad &amp;&amp;Ax=b\\ &amp;&amp;&amp;Gx\le h
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식은 행렬-벡터 형식인데요. 이를 스칼라 형태의 식으로 살펴보면 등식 형태의 제약식이 $m$개, 부등식 형태의 제약식이 $r$개가 있고, 이를 만족하면서 목적함수를 최대화시키는 $n$개의 미지수를 찾는 문제라고도 이해할 수 있습니다. 제약식 양변에 $u$, $v$라는 벡터를 곱해 봅시다. 여기에서 $v≥0$, 즉 벡터 $v$의 모든 요소는 0 이상의 값을 지닙니다. 따라서 위 식에서 부등식 형태의 제약식은 부등호 방향이 바뀌지 않습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ u }^{ T }Ax={ u }^{ T }b\\ { v }^{ T }Gx\le { v }^{ T }h&lt;/script&gt;

&lt;p&gt;위 두 개 식을 더하고, 정리해 주면 다음과 같은 형태가 됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
{ u }^{ T }Ax+{ v }^{ T }Gx&amp;\le { u }^{ T }b+{ v }^{ T }h\\ \left( { u }^{ T }A+{ v }^{ T }G \right) x&amp;\le { u }^{ T }b+{ v }^{ T }h\\ { \left( { A }^{ T }u+{ G }^{ T }v \right)  }^{ T }x&amp;\le { u }^{ T }b+{ v }^{ T }h\\ { \left( -{ A }^{ T }u-{ G }^{ T }v \right)  }^{ T }x&amp;\ge -{ u }^{ T }b-{ v }^{ T }h\\ \therefore \quad { c }^{ T }x&amp;\ge -{ u }^{ T }b-{ v }^{ T }h
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식에서 볼 수 있듯 $-A^Tu-G^Tv$가 $c$가 되도록 하면, &lt;em&gt;primal problem&lt;/em&gt;의 목적함수 $c^Tx$의 하한(a lower bound)은 $-u^Tb-v^Th$가 됩니다. 따라서 $-A^Tu-G^Tv=c$, $v≥0$이라는 제약식을 만족시키면서, $-u^Tb-v^Th$를 최대화하는 문제가 &lt;em&gt;primal problem&lt;/em&gt;과 동일해질 겁니다. 결론적으로 말해 아래와 같은 형태가 &lt;em&gt;primal problem&lt;/em&gt;와 쌍을 이루는 &lt;em&gt;dual problem&lt;/em&gt;이 됩니다. &lt;em&gt;primal problem&lt;/em&gt;에서는 주어진 식을 만족하는 벡터 $x$를 찾는 것이었으나 &lt;em&gt;dual problem&lt;/em&gt;에서는 벡터 $u, v$를 찾는 문제가 됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\max_{ u,v }&amp;&amp;{ -{ b }^{ T }{ u }-{ h }^{ T }{ v } } \\ &amp;subject\quad to\quad &amp;&amp; -{ A }^{ T }{ u }-{ G }^{ T }{ v } = c\\ &amp;&amp;&amp;v\ge 0
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;라그랑지안적-접근&quot;&gt;라그랑지안적 접근&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;primal problem&lt;/em&gt;과 &lt;em&gt;dual problem&lt;/em&gt;을 &lt;strong&gt;라그랑주 승수법&lt;/strong&gt;(Lagrange multiplier method)과 연관지어 살펴볼 수도 있습니다. 라그랑주 승수법이란 최적화하려는 값에 형식적인 라그랑주 승수(multiplier) 항을 더하여, 제약된 문제를 제약이 없는 문제로 바꾸는 방법입니다. 라그랑주 승수법 관련 자세한 내용은 &lt;a href=&quot;https://m.blog.naver.com/mindo1103/90154212128&quot;&gt;이곳&lt;/a&gt;이나 &lt;a href=&quot;http://untitledtblog.tistory.com/96&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다. 전 챕터에 이어 선형계획법 예시를 가지고 &lt;em&gt;primal&lt;/em&gt;과 &lt;em&gt;dual&lt;/em&gt; 문제를 살펴보겠습니다. &lt;em&gt;primal problem&lt;/em&gt;을 다시 살펴보겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\min_{ x }&amp;&amp;{ { c }^{ T }x } \\ &amp;subject\quad to\quad &amp;&amp;Ax=b\\ &amp;&amp;&amp;Gx\le h
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 &lt;em&gt;primal problem&lt;/em&gt;을 라그랑주 승수 벡터 $u$와 $v$를 도입해 라그랑주 함수 $L$을 만들면 다음과 같은 형태가 됩니다. 단 여기에서 $v≥0$, 즉 벡터 $v$의 모든 요소는 0 이상의 값을 지닙니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L\left( x,u,v \right) ={ c }^{ T }x+{ u }^{ T }\left( Ax-b \right) +{ v }^{ T }\left( Gx-h \right)\le{c}^{T}x&lt;/script&gt;

&lt;p&gt;그런데 위 식 우변의 두번째 항은 항상 0입니다($∵Ax=b$). 세번째 항은 항상 0 이하의 값을 갖습니다($∵Gx≤h, v≥0$) 따라서 $L$은 목적함수 $c^Tx$보다 항상 작거나 같습니다. 여기에서 $C$를 원초문제의 제약식을 만족하는 $x$의 집합, $f^*$를 우리가 찾으려는 최적값이라고 할 때 다음 식이 성립합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ f }^{ * }\ge \min _{ x\in C }{ L\left( x,u,v \right)  } \ge \min _{ x }{ L\left( x,u,v \right)  }&lt;/script&gt;

&lt;p&gt;위 부등식의 의미는 이렇습니다. 제약조건이 있는 것보다는, 없는 환경에서 해당 식의 값을 더 작게 만들 수 있을 겁니다. 위 부등식 가운데 오른쪽 마지막 항을 $g(u,v)$라 두겠습니다. $g(u,v)$를 &lt;strong&gt;라그랑지 듀얼 함수&lt;/strong&gt;(Lagrange dual function)이라고도 부릅니다. 그러면 $g(u,v)$는 어떤 값을 지닐까요? 차근차근 구해보겠습니다.&lt;/p&gt;

&lt;p&gt;우선 $g(u,v)$는 그 정의상 $L$의 최소값 즉, $min_x{L(x,u,v)}$입니다. $L$은 우리가 알고 싶은 미지수로 편미분한 결과가 0이 되는 지점에서 최소값을 갖습니다. $L$을 $x$로 편미분한 결과는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac { \partial L }{ \partial x } ={ c }^{ T }+{ u }^{ T }A+v^{ T }G=0\\ \therefore \quad c=-{ A }^{ T }u-{ G }^{ T }v&lt;/script&gt;

&lt;p&gt;따라서 위 식을 $L$에 대입해 풀면 $g(u,v)$를 구할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
L\left( x,u,v \right)&amp;= { c }^{ T }x+{ u }^{ T }\left( Ax-b \right) +{ v }^{ T }\left( Gx-h \right)\\&amp;\Rightarrow { \left( -{ A }^{ T }u-{ G }^{ T }v \right)  }^{ T }x+{ u }^{ T }\left( Ax-b \right) +{ v }^{ T }\left( Gx-h \right) \\ &amp;=-u^{ T }Ax-v^{ T }Gx+u^{ T }Ax-u^{ T }b+v^{ T }Gx-{ v }^{ T }h\\ &amp;=-u^{ T }b-{ v }^{ T }h\\&amp;=g(u,v)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;우리는 이미 $f^*≥g(u,v)$라는 관계를 확인했으므로, primal problem의 최소값을 찾는 것은 $g(u,v)$를 최대화하는 문제와 동일하다는 걸 확인할 수 있습니다. 단 라그랑주 승수법을 적용하는 과정에서 가정한 두 가지 조건, 즉  $-A^Tu-G^Tv=c$, $v≥0$을 만족해야 합니다.&lt;/p&gt;

&lt;p&gt;따라서 우리는 다음과 같이 &lt;em&gt;dual problem&lt;/em&gt;으로 다시 쓸 수 있습니다.  이는 당초 &lt;em&gt;primal problem&lt;/em&gt;과 쌍을 이룹니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\max_{ u,v }&amp;&amp;{ -{ b }^{ T }{ u }-{ h }^{ T }{ v } } \\ &amp;subject\quad to\quad &amp;&amp; -{ A }^{ T }{ u }-{ G }^{ T }{ v } = c\\ &amp;&amp;&amp;v\ge 0
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;라그랑지안적 접근의 장점은 지금까지 설명해드렸던 선형계획법 이외에도 임의의 최적화 문제에 대해 모두 적용할 수가 있다는 점입니다. 다시 말해 라그랑주 승수법을 적용해 다양한 유형의 &lt;em&gt;primal problem&lt;/em&gt;를 &lt;em&gt;dual problem&lt;/em&gt;으로 바꿔풀 수가 있습니다. 이제 최적화 문제를 일반적인 케이스에 적용해 봅시다. 다음과 같은 &lt;em&gt;primal problem&lt;/em&gt;이 주어졌다고 칩시다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\min _{ x }&amp;&amp;{ f\left( x \right)  } \\ &amp;subject\quad to\quad &amp;&amp;{ h }_{ i }\left( x \right) \le 0,\quad i=1,...,m\\ &amp;&amp;&amp;{ l }_{ j }\left( x \right) =0,\quad j=1,...,r
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;라그랑지안 함수 $L$과 라그랑지 듀얼함수 $g$를 각각 정의합니다. 이미 살펴봤듯이 부등식 형태의 제약식에 붙는 라그랑주 승수(multiplier) $u_i$는 모두 0 이상의 값을 지녀야 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
L\left( x,u,v \right) =&amp;f\left( x \right) +\sum _{ i=1 }^{ m }{ { u_{ i }h }_{ i }\left( x \right)  } +\sum _{ j=1 }^{ r }{ { v_{ i }l }_{ j }\left( x \right)  } \\ g\left( u,v \right) =&amp;\min _{ x }{ L\left( x,u,v \right)  }
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;$f^*≥g(u,v)$이므로 dual problem은 다음과 같이 쓸 수 있습니다. primal problem에서는 주어진 식을 만족하는 벡터 $x$를 찾는 것이었으나 dual problem에서는 벡터 $u, v$를 찾는 문제가 됩니다. 아울러 최소 문제가 최대 문제로 바뀌었습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\max_{ u,v }&amp;&amp;{ { g }(u,v) } \\ &amp;subject\quad to\quad &amp;&amp;u\ge 0
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;한편 &lt;em&gt;dual problem&lt;/em&gt;은 항상 &lt;em&gt;convex&lt;/em&gt; 문제가 됩니다. $g(u,v)$를 아래와 같이 자세히 뜯어보면 &lt;em&gt;convexity&lt;/em&gt;를 보존하는 연산만 수행이 되기 때문입니다. &lt;em&gt;convexity&lt;/em&gt;를 보존하는 연산에 대해서는 &lt;a href=&quot;https://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/&quot;&gt;이곳&lt;/a&gt;을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/3Wi5yWE&quot;&gt;&lt;img src=&quot;https://i.imgur.com/3Wi5yWE.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;duality-gap&quot;&gt;duality gap&lt;/h2&gt;

&lt;p&gt;$g(u,v)$는 $f$-star의 하한(a lower bound)입니다. 이를 바꾸어 말하면 &lt;em&gt;dual problem&lt;/em&gt;의 목적함수 $g(u,v)$를 최대화하는 것은 &lt;em&gt;primal problem&lt;/em&gt;의 목적함수를 최소화하는 문제가 됩니다. 그런데 &lt;em&gt;primal problem&lt;/em&gt;의 해와 &lt;em&gt;dual problem&lt;/em&gt;의 해가 반드시 같지는 않습니다. 아래 부등식에서 $f$의 최적값과 $g(u,v)$ 사이에 차이가 존재할 수 있음을 확인할 수 있습니다. 이를 &lt;em&gt;duality gap&lt;/em&gt;이라고 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ f }^{ * }\ge \min _{ x }{ L\left( x,u,v \right)  }=g(u,v)&lt;/script&gt;

&lt;p&gt;$f$의 최적값과 $g(u,v)$ 사이에 위와 같은 관계를 지니면 &lt;em&gt;weak dual&lt;/em&gt;이라고 합니다. 그런데 아래와 같은 관계를 지니면 &lt;em&gt;strong dual&lt;/em&gt;이라고 합니다. &lt;em&gt;duality gap&lt;/em&gt;이 없음을 확인할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ f }^{ * }=g(u,v)&lt;/script&gt;

&lt;p&gt;&lt;em&gt;primal problem&lt;/em&gt;의 목적함수와 제약식이 특정 조건을 만족하면 &lt;em&gt;strong duality&lt;/em&gt; 속성을 지니게 된다고 합니다. 이것이 &lt;em&gt;Slater’s condition&lt;/em&gt;입니다. 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/BYkYE9D&quot;&gt;&lt;img src=&quot;https://i.imgur.com/BYkYE9D.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Convex Functions</title>
   <link href="http://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/"/>
   <updated>2017-12-26T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Convex Function(볼록함수)&lt;/strong&gt;와 관련된 개념들을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 &lt;a href=&quot;http://www.stat.cmu.edu/~ryantibs/convexopt/&quot;&gt;강의&lt;/a&gt;를 기본으로 하되 저희 연구실의 김해동 석사과정이 만든 자료를 정리했음을 먼저 밝힙니다. 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;convex-function&quot;&gt;convex function&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex function&lt;/em&gt;이란 임의의 두 점 $x$, $y$와 $[0,1]$ 사이의 값 $t$에 대해 다음이 항상 성립하는 함수 $f$를 가리킵니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f\left( tx+\left( 1-t \right) y \right) \le tf\left( x \right)+\left( 1-t \right) f\left( y \right)&lt;/script&gt;

&lt;p&gt;이를 그림으로 도시하면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/RQLtUko&quot;&gt;&lt;img src=&quot;https://i.imgur.com/RQLtUko.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;convex-function-유형&quot;&gt;convex function 유형&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;strict convex&lt;/strong&gt;란 임의의 두 점 $x$, $y$와 $[0,1]$ 사이의 값 $t$에 대해 다음이 항상 성립하는 함수 $f$를 가리킵니다. 다시 말해 $f$는 &lt;em&gt;convex function&lt;/em&gt;이면서, 선형함수(linear function)보다 큰 곡률을 가집니다. (등호는 $f$가 선형함수일 때 성립하므로)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
f\left( tx+\left( 1-t \right) y \right) &lt; tf\left( x \right)+\left( 1-t \right) f\left( y \right) %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;strong convex&lt;/strong&gt;란 &lt;em&gt;convex function&lt;/em&gt; 가운데 0이 아닌 양수 $m$에 대해 다음이 항상 성립하는 함수 $f$를 가리킵니다. 다시 말해 $f$는 적어도 &lt;em&gt;quadratic function&lt;/em&gt;만큼 &lt;em&gt;convex&lt;/em&gt;하다는 걸 뜻합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f-\frac { m }{ 2 } { \left\| x \right\|  }_{ 2 }^{ 2 }\quad is\quad convex&lt;/script&gt;

&lt;p&gt;따라서 다음과 같은 포함관계가 성립합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;strong convex&lt;/em&gt; ⊂ &lt;em&gt;strict convex&lt;/em&gt; ⊂ &lt;em&gt;convex&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;concave function(오목함수)&lt;/strong&gt;란 &lt;em&gt;convex function&lt;/em&gt;에 음수를 취한 함수를 가리킵니다. 따라서 우리는 &lt;em&gt;convex function&lt;/em&gt;에 집중해서 분석합니다.&lt;/p&gt;

&lt;h2 id=&quot;convex-function의-예시&quot;&gt;convex function의 예시&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex function&lt;/em&gt;의 대표적 예시는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/A55z9iF&quot;&gt;&lt;img src=&quot;https://i.imgur.com/A55z9iF.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/8ssp0YF&quot;&gt;&lt;img src=&quot;https://i.imgur.com/8ssp0YF.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/3K0g3O3&quot;&gt;&lt;img src=&quot;https://i.imgur.com/3K0g3O3.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;convexity를-보존하는-연산&quot;&gt;convexity를 보존하는 연산&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex function&lt;/em&gt;에 대해 다음 연산은 &lt;em&gt;convexity&lt;/em&gt;를 보존합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/grqWYO0&quot;&gt;&lt;img src=&quot;https://i.imgur.com/grqWYO0.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/RL6OArO&quot;&gt;&lt;img src=&quot;https://i.imgur.com/RL6OArO.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/Mlg0oh8&quot;&gt;&lt;img src=&quot;https://i.imgur.com/Mlg0oh8.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;convex-function의-특성&quot;&gt;convex function의 특성&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex function&lt;/em&gt;은 다음 세 가지 중요한 특성이 있습니다. 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/PNi83lL&quot;&gt;&lt;img src=&quot;https://i.imgur.com/PNi83lL.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이 가운데 &lt;em&gt;second-order characterization&lt;/em&gt;을 활용해 소프트맥스 함수가 &lt;em&gt;convex function&lt;/em&gt;임을 증명해 보겠습니다. 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/qSTSjn5&quot;&gt;&lt;img src=&quot;https://i.imgur.com/qSTSjn5.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Convex Sets</title>
   <link href="http://ratsgo.github.io/convex%20optimization/2017/12/25/convexset/"/>
   <updated>2017-12-25T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/convex%20optimization/2017/12/25/convexset</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Convex Set(볼록집합)&lt;/strong&gt;과 관련된 개념들을 살펴보도록 하겠습니다. 이 글은 미국 카네기멜런대학 &lt;a href=&quot;http://www.stat.cmu.edu/~ryantibs/convexopt/&quot;&gt;강의&lt;/a&gt;를 기본으로 하되 저희 연구실의 김해동 석사과정이 만든 자료를 정리했음을 먼저 밝힙니다. 영문 위키피디아 또한 참고하였습니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;벡터-결합하기&quot;&gt;벡터 결합하기&lt;/h2&gt;

&lt;p&gt;벡터 $x_1$, $x_2$, …, $x_n$이 주어졌을 때 이들을 결합하는 것은 다음 세 가지 방식이 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://ratsgo.github.io/linear%20algebra/2017/03/24/Ldependence/&quot;&gt;Linear combination&lt;/a&gt;&lt;/strong&gt; : $α_1x_1+…+α_nx_n$ ($α_i$는 실수)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Affine combination&lt;/strong&gt; : $α_1x_1+…+α_nx_n$ ($Σ_iα_i=1$)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convex combination&lt;/strong&gt; : $α_1x_1+…+α_nx_n$ ($Σ_iα_i=1$이고, $0≤α_i≤1$)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;affine combination&lt;/em&gt;에 대해 &lt;strong&gt;닫힌(closed)&lt;/strong&gt; 집합을 &lt;strong&gt;Affine set&lt;/strong&gt;이라고 합니다. 예컨대 벡터 $x_1$, $x_2$가 집합 $A$에 속해 있고, 이들의 &lt;em&gt;affine combination&lt;/em&gt; 또한 $A$에 속할 때 $A$는 &lt;em&gt;affine set&lt;/em&gt;이 됩니다. 마찬가지로 &lt;em&gt;convex combination&lt;/em&gt;에 대해 닫힌 집합을 &lt;em&gt;convex set&lt;/em&gt;이라고 합니다.&lt;/p&gt;

&lt;p&gt;2차원 벡터 두 개(즉 $x_1$, $x_2$)를 세 가지 방식으로 결합해 각각 나타내면 다음 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/ANZXnOV&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ANZXnOV.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;linear combination&lt;/em&gt; 결과 $x_1$과 $x_2$를 포함하는 $R^2$의 평면이 &lt;strong&gt;생성(span)&lt;/strong&gt;된다.&lt;/li&gt;
  &lt;li&gt;2차원 공간의 &lt;em&gt;affine set&lt;/em&gt;은 $x_1$과 $x_2$를 지나는 직선이다.&lt;/li&gt;
  &lt;li&gt;2차원 공간의 &lt;em&gt;convex set&lt;/em&gt;은 $x_1$과 $x_2$를 연결하는 선분이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;벡터 $x_1$과 $x_2$의 &lt;em&gt;affine set&lt;/em&gt;이 직선, &lt;em&gt;convex set&lt;/em&gt;이 선분이 되는 것과 관련해서는 고1 수학 과정의 &lt;a href=&quot;http://mathbang.net/439&quot;&gt;내분과 외분&lt;/a&gt;과 연관성이 있을 거란 생각이 듭니다. 다시 말해 벡터 앞에 붙는 계수의 부호가 중요하다는 이야기이죠.&lt;/p&gt;

&lt;h2 id=&quot;convex-set&quot;&gt;Convex Set&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex set&lt;/em&gt; $C$는 다음과 같이 정의됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x$와 $y$가 $C$에 속한다면, $tx+(1-t)y$ 또한 $C$에 포함된다. ($0≤t≤1$)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;직관적으로 따져보겠습니다. 어떤 집합 $C$에 속한 임의의 두 점을 골랐을 때 둘을 연결하는 선분 또한 $C$에 포함될 경우 $C$를 &lt;em&gt;convex set&lt;/em&gt;이라고 합니다. 따라서 다음 도형은 &lt;em&gt;convex set&lt;/em&gt;입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/0Gec7Rf&quot;&gt;&lt;img src=&quot;https://i.imgur.com/0Gec7Rf.png&quot; width=&quot;150px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;다음은 &lt;em&gt;convex set&lt;/em&gt;이 아닙니다. 아래 두 점을 잇는 선분의 일부가 해당 집합 바깥에 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/PToXoC0&quot;&gt;&lt;img src=&quot;https://i.imgur.com/PToXoC0.png&quot; width=&quot;170px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;마찬가지로 다음은 &lt;em&gt;convex set&lt;/em&gt;이 아닙니다. 임의의 두 점이 경계에 있을 경우 해당 점을 잇는 선분의 일부가 집합에 포함되어 있지 않습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/cWdQQtc&quot;&gt;&lt;img src=&quot;https://i.imgur.com/cWdQQtc.png&quot; width=&quot;150px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;convex-set의-종류&quot;&gt;Convex set의 종류&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex set&lt;/em&gt;의 예는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/wq0WY58&quot;&gt;&lt;img src=&quot;https://i.imgur.com/wq0WY58.png&quot; width=&quot;450px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Norm ball&lt;/em&gt;의 예시는 다음과 같습니다. ($x_1, x_2$의 L2 norm, &lt;em&gt;radius&lt;/em&gt; $y$에 대한 집합) $y$축을 기준으로 잘라보면 그 모양이 원 모양이고 볼록해 &lt;em&gt;convex set&lt;/em&gt;을 만족하리라고 직관적으로 추론해볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/GKHpfjL&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GKHpfjL.png&quot; width=&quot;250px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Hyperplane&lt;/em&gt; $a^Tx=b$ 위의 임의의 두 점 $x_1$, $x_2$ 사이를 잇는 선분은 다시 $a^Tx=b$에 포함됩니다. 따라서 &lt;em&gt;Hyperplane&lt;/em&gt;은 &lt;em&gt;convex set&lt;/em&gt;입니다. 마찬가지 이유로 &lt;em&gt;Halfspace&lt;/em&gt;, &lt;em&gt;Affine space&lt;/em&gt; 또한 &lt;em&gt;convex set&lt;/em&gt;이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Polyhedron&lt;/em&gt;은 다음과 같이 정의되며 그 예시는 다음 그림과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;{$x$|$Ax≤b$}&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/tGrzXL3&quot;&gt;&lt;img src=&quot;https://i.imgur.com/tGrzXL3.png&quot; width=&quot;300px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;행렬 $A$에 벡터 $x$를 내적한 결과인 $b$는 벡터일 것입니다. 이를 잠시 다시 생각해보면 선형부등식 여러 개가 한꺼번에 적용된 거라고 보아도 될 것 같습니다. 예를 들어 ‘행렬 $A$의 첫번째 벡터와 $x$를 내적한 결과는 벡터 $b$의 첫번째 스칼라값보다 작거나 같다’는 식으로 말이죠.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Polyhedron&lt;/em&gt;은 &lt;strong&gt;선형계획법(linear)&lt;/strong&gt;에서 중요하게 다뤄진다고 하는데요. 각각의 선형부등식이 제약식 역할을 수행하며 결과적으로 &lt;em&gt;Polyhedron&lt;/em&gt;은 해당 제약 조건 하의 가능해(possible solutions) 영역이 된다는 것입니다. 어쨌거나 &lt;em&gt;Polyhedron&lt;/em&gt; 또한 &lt;em&gt;convex set&lt;/em&gt;입니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;simplex&lt;/em&gt;는 삼각형 또는 사면체(tetrahedron)의 일반화 버전이라고 합니다. &lt;em&gt;simplex&lt;/em&gt; 역시 &lt;em&gt;convex set&lt;/em&gt;입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/uLioyc4&quot;&gt;&lt;img src=&quot;https://i.imgur.com/uLioyc4.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;convex-set의-성질&quot;&gt;convex set의 성질&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex set&lt;/em&gt;과 관련해 두 가지 중요한 정리가 있습니다. 첫번째는 &lt;em&gt;sepaating hyperplane theorem&lt;/em&gt;입니다. 두 개의 겹치지 않는(disjoint) &lt;em&gt;convex set&lt;/em&gt;을 분리해주는 하이퍼플레인(hyperplane)이 존재한다는 것입니다. 아래 그림에서 $D$와 $C$를 가르는 벡터 $a$가 바로 그러한 역할을 하는 하이퍼플레인입니다.&lt;/p&gt;

&lt;p&gt;단 여기에서 $D$와 $C$는 &lt;strong&gt;닫힌집합&lt;/strong&gt;(closed set, 스스로의 경계를 모두 포함하는 위상공간의 부분집합)이어야 하며, 둘 중 하나가 &lt;strong&gt;유계집합&lt;/strong&gt;(bounded set, 유한한 영역을 가지는 집합)이어야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/AXf0pbp&quot;&gt;&lt;img src=&quot;https://i.imgur.com/AXf0pbp.png&quot; width=&quot;300px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;두번째는 &lt;em&gt;supporting hyperplane theorem&lt;/em&gt;입니다. &lt;em&gt;convex set&lt;/em&gt;의 경계 점을 지나는 접선이 항상 존재한다는 것입니다. 다음 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/NGqIA7I&quot;&gt;&lt;img src=&quot;https://i.imgur.com/NGqIA7I.png&quot; width=&quot;250px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;convexity를-보존하는-연산&quot;&gt;convexity를 보존하는 연산&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;convex set&lt;/em&gt; $C$와 $D$에 대해 다음 연산(operation)은 &lt;em&gt;convexity&lt;/em&gt;를 보존합니다. 다시 말해 $C$와 $D$가 &lt;em&gt;convex set&lt;/em&gt;이라는 사실이 증명돼 있고, 다음 연산을 수행한다면 연산 수행 결과로 나타난 새로운 집합은 별도의 증명 없이도 &lt;em&gt;convex set&lt;/em&gt;이라는 겁니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;intersection&lt;/strong&gt;(교집합)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;scaling and translation&lt;/strong&gt;(스칼라곱, bias 더하기) : $C$가 &lt;em&gt;convex set&lt;/em&gt;이라면 $aC+b$ 또한 &lt;em&gt;convex set&lt;/em&gt; ($a,b$는 스칼라)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;affine images and preimages&lt;/strong&gt; : $f(x)=Ax+b$이고 $C$가 &lt;em&gt;convex set&lt;/em&gt;이라면 $f(C)$ 또한 &lt;em&gt;convex set&lt;/em&gt;, $f(x)=Ax+b$이고 $D$가 &lt;em&gt;convex set&lt;/em&gt;이라면 $f^{-1}(D)$ 또한 &lt;em&gt;convex set&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이밖에 다음 연산도 &lt;em&gt;convexity&lt;/em&gt;를 보존합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/CKJWcgD&quot;&gt;&lt;img src=&quot;https://i.imgur.com/CKJWcgD.png&quot; width=&quot;450px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>일본이 근대화에 성공한 이유</title>
   <link href="http://ratsgo.github.io/daily/2017/12/24/japan/"/>
   <updated>2017-12-24T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/daily/2017/12/24/japan</id>
   <content type="html">&lt;p&gt;여러 지인이 추천한 올해의 책 가운데 하나가 바로 &lt;a href=&quot;http://book.naver.com/bookdb/book_detail.nhn?bid=12333229&quot;&gt;학교에서 가르쳐주지 않는 일본사&lt;/a&gt;였다. 요지는 이렇다.&lt;/p&gt;

&lt;p&gt;‘일본은 1868년 메이지유신이 선포된 지 40여 년만에 세계 질서를 주도하는 열강의 대열에 오르는 기염을 토했다. 하지만 일본이 순식간에 그런 기적을 일궈냈다고 보는 건 오해다. 17세기 초반 에도 막부 성립에서 19세기 중반 메이지유신 이전까지 에도시대 260여년동안 권위와 시장 간의 긴장, 경제의 분화와 전문화, 인적/물적 이동성의 확대 등 드라마틱하고 익사이팅한 축적을 거쳐 포텐이 터진 결과다.’&lt;/p&gt;

&lt;p&gt;저자는 20여 년 간 외교관 생활을 하다가 한일관계에 기여할 수 있는 자신만의 영역을 개척해보고 싶다는 생각으로 외교부를 그만두고 최근 서울에서 우동집을 하고 있다. 독특한 저자 이력만큼이나 책 제목도, 논지도 눈길을 끌기에 충분했다. &lt;del&gt;다소 일본 중심적인 시각인 것 같다, 그래서 ‘우리나라 학교에서 가르쳐 주지 않는 일본 역사’라는 느낌도 들지만..&lt;/del&gt; 인상적인 구절 몇 개 정리해본다. (&lt;em&gt;2017. 12. 24. 전주&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;한국의 역사 교과서에 등장하는 에도시대의 일본은 임진왜란 때 납치한 도공이나 조선통신사에게 한 수 배우며 선진 문물을 습득한 문명의 변방국이다. 고대 중화문명 확산 경로의 선후관계에서 비롯된 한국인들의 일본에 대한 문화적 우월감은 에도시대로까지 자연스럽게 연장되고 고정관념화되어 있다. 단언컨대, 일본의 근세 260여 년을 그런 식으로 바라보는 나라는 한국뿐이다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;천하보청&lt;/strong&gt;의 묘미는 국가에서 거두는 국부(國富)가 고스란히 인프라로 전환되었다는 것이다. 만약 쇼군이 중앙의 군주로서 징세, 즉 화폐나 현물의 형태로 생산량의 일정 부분을 거두어 갔다면 그 과정에서 많은 비효율과 왜곡된 자본 축적/잉여가 발생하였을 것이다. 일본은 천하보청에 따라 세금 징수가 아니라 ‘결과물’ 형태로 의무를 부과했기 대문에 관리비용 등의 매몰비용(sunk cost)이나 착복으로 인한 증발 없이 모든 투입이 실물 인프라로 이어졌다. (중략) 현대 경제학으로 말하면 승수효과가 매우 높은 재정정책이 절묘한 타이밍에 시행된 것이다. (중략) 말단에서 세금의 형태로 걷히는 생산물은 천하보청을 거치면서 노임, 자재 대금 형태로 재분배되었다. 이러한 직접적인 자원 투입의 결과로 높은 수준의 공공인프라가 창출되자 한층 더 경제활동이 촉진되고, 이는 다시 말단 세금 납부자의 생활 개선으로 이어졌다.&lt;/p&gt;

    &lt;p&gt;* 천하보청(天下普請) : 쇼군이 다이묘들에게 부과하는 공공사업 역무(役務). 에도 막부 초대 쇼군 도쿠가와 이에아스는 에도성, 하천 정비 및 농수로/운하망/상하수도 건설 등 인프라 건설에 다이묘들을 동원했다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;참근교대&lt;/strong&gt;에는 막대한 비용이 소요된다. 적게는 100명에서 많게는 500명 이상의 대규모 인원이 수백 킬로미터가 넘는 거리를 이동하는데, 소요되는 비용은 전적으로 다이묘가 부담해야 했다. (중략) 가장 큰 혜택을 본 것은 교통, 숙박의 요지와 에도, 오사카 등 대도시의 상공인과 노동자였다. (중략) 많은 천하보청이 참근교대와 연계되어 시행되었다. 참근교대에 수반하여 고카이도(五街道)라 불리는 간선도로가 대대적으로 확충되고, 에도성을 비롯한 도시기반 건설에 필요한 자재의 운송을 위하여 해로와 수로가 정비되었다. 18세기 초엽에 미곡을 비롯한 각종 물자의 집산지인 오사카로부터 에도를 연결하는 복수의 민영 정기항로가 개설되었고, 18세기 말엽에는 전국을 연결하는 상업 해운망이 완성되었다. 해운망의 발달은 미곡, 술, 간장, 각종 생필품, 지역 특산물이 오사카로 집산되었다가 에도에 공급되면서 전국적으로 유통되는 데 기여하였고.. (중략) 다이묘라는 재향 지배층의 의무적 소비 지출 증가가 상인 및 도시노동자 계층의 소득으로 흡수되는 현상은 현대적으로 말하면 일종의 낙수효과(trickle down effect)가 발생했다고 할 수 있다.&lt;/p&gt;

    &lt;p&gt;* 참근교대제(參勤交代制) : 쇼군이 모든 번(藩)의 다이묘들로 하여금 1년 단위로 정기적으로 에도와 그들의 영지를 오가게 하는 일종의 ‘인질 제도’.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;안게리아겐고와게에는 ‘handkerchief’가 하나후키로 번역되어 있다. 한국말로 하면 ‘코닦기’ 정도의 의미이다. 일본에는 없는 물건이지만 그 용도를 파악하여 적절한 대역어를 조어한 것이다. 이보다 더 관념적인 단어에 대해서는 더 많은 고민이 필요하다. ‘liberty’를 자유(自由)로, ‘economy’를 경제(經濟)로, ‘physics’를 물리(物理)로, ‘chemistry’를 화학(化學)으로 번역한 것에서 볼 수 있듯이 일본에 없는 관념을 번역하기 위해 사전의 편찬자들은 서양의 개념을 수용한 후 그를 자국어로 변용하는 언어의 재창조 작업에 몰두하였다. 최초로 그러한 임무가 맡겨진 사람들 입장에서는 단어 하나하나가 문화의 충돌이었고 문명의 이양이었다. 일본의 근대화 과정에서 번역이 갖는 의미는 각별하다. 일본의 근대화에는 서구의 관념을 일본의 관념으로 변환시키고 내재화하는 과정이라 할 수 있다. 개항 이후 이루어진 일본의 급속한 근대화는 그보다 100년 전 부터 수많은 지식인들의 고뇌가 담긴 ‘언어의 통로’가 있었기에 가능한 것이었다. (최초의 &lt;u&gt;영일사전은 1814년 일본 막부 주도&lt;/u&gt;로 만들어졌다는 점 언급) (중략) 참고로, 최초의 &lt;strong&gt;영한사전은&lt;/strong&gt; (선교사) &lt;u&gt;언더우드(H. G. Underwood)가 집필&lt;/u&gt;한 ‘한영 영한자전’이다. 조선에는 마땅한 인쇄시설이 없어 &lt;u&gt;1890년 요코하마&lt;/u&gt;에서 발행되었다. (괄호 안 및 강조표시는 인용자)&lt;/p&gt;

    &lt;p&gt;* 안게리아겐고와게(諳厄利亞言語和解) : 1811년 나가사키에서 만들어진 영어의 기본체계와 기초 어휘가 정리된 책자(사전).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;중국은 그 부당한 처사(불평등 상호 조약)를 영국에게 당했고, 일본은 미국에게 당했고, 조선은 일본에게 당했다. 한국의 역사 교육은 이러한 불평등의 강요가 얼마나 천인공노할 짓인지를 만천하에 드러내는 데에 초점이 맞춰져 있다. 강요의 주체인 일본의 정의롭지 못함과 무도함을 밝히는 것을 교육의 목표로 삼는다. 그것은 그것대로 각국의 가치관과 교육관에 따라 그럴 수 있다. 일본도 한국과 마찬가지로 구미 열강 세력에 당한 불평등에 대해 분개하고 분노한다. 그러나 일본의 역사 교육은 거기에서 머무르지 않는다. ‘유럽으로부터 불평등한 조항을 강요당한 것은 일본의 사법제도가 그들로부터 인정받지 못한 탓이다. 그들로부터 인정을 받을 수 있는 사법제도를 구축하고 불평등을 해소해야 한다.’ 당시 일본의 위정자들은 그렇게 생각했다. 1854년 개국 이래 불평등조약의 개정은 일본 사회의 지상과제가 되었다. 내로라하는 뜻있는 지식인들이 구미로 건너가 그들의 법제를 습득하고 외국의 전문가를 초빙해 지도를 청하고 국가 지성의 총력을 기울여 법제의 근대화에 매진한다. 이러한 노력의 결과, 1880년 형법과 형사소송법 제정을 필두로 1889년 헌법, 1896년 민법 등 소위 ‘법전’이라 불리는 6법 체계가 완성되었다. 유럽의 법제를 철저히 연구하여 제정한 법률들이다. 유럽국들이 더 이상 법체계의 이질성, 미성숙성을 이유로 불평등을 강요할 수 없도록 준비를 단단히 한 일본은 당당하게 기존의 불평등 조항의 파기와 개정을 요구한다. 일본 정부는 1892년 포르투갈의 영사재판권을 포기시키고, 1894년 청일전쟁의 승리를 기화로 영국을 강하게 몰아붙여 기존의 불평등조약을 개정한 ‘일영통상항해조약’을 체결하고 사법 주권을 회복하였다. 유럽세력의 좌장인 영국과 조약을 개정하면 그다음부터는 일사천리이다. 20세기가 되기 전에 일본은 구미 국가들과의 관계에서 사법 주권을 회복하였다. 불평등조약을 강요당한 분함을 계기로 대등한 관계로 인정받겠다는 집념이 기어코 불평등조약의 폐기를 이끌어냈고, 그러한 굴욕이 오히려 조기 근대화의 자극제로 작용한 것이다. 이러한 집단 지성 축적의 스토리와 그 기틀을 닦은 지식인들의 고뇌와 성취의 에피소드가 후세에 전해져 일본인들의 역사관과 세계관을 형성하였다. 일본인들은 그렇게 역사를 바라보고, 가르치고, 배운다. 그리고 그것이 가장 깨끗한 설욕이라고 생각한다. 스스로 강요당한 불평등을 조선에 다시 강요한 일본을 부도덕하고 악한 나라라고 비판하는 것은 자유이다. 그러나 일본은 스스로 주권을 회복하였고 조선은 회복하지 못하였다. 그 역사로부터 배워야 할 것은 없는가? 이것이 한국의 역사관이 답을 찾아야 할 올바른 질문이라고 생각한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Advanced GANs</title>
   <link href="http://ratsgo.github.io/generative%20model/2017/12/21/gans/"/>
   <updated>2017-12-21T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2017/12/21/gans</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Generative Adversarial Network&lt;/strong&gt;(이하 GAN)의 발전된 모델들에 대해 살펴보도록 하겠습니다. GAN은 학습이 어려운 점이 최대 단점으로 꼽히는데, 아키텍처나 목적함수를 바꿔서 성능을 대폭 끌어올린 모델들입니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;vanilla-gan&quot;&gt;vanilla GAN&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/20/gan/&quot;&gt;GAN&lt;/a&gt;이란 생성자(generator, $G$)와 구분자(discirimiator, $D$), 두 네트워크를 적대적(adversarial)으로 학습시키는 비지도 학습 기반 생성모델(unsupervised generative model)입니다. $G$는 &lt;em&gt;Zero-Mean Gaussian&lt;/em&gt;으로 생성된 노이즈 $z$를 받아서 실제 데이터와 비슷한 데이터를 만들어내도록 학습됩니다. $D$는 실제 데이터와 $G$가 생성한 가짜 데이터를 구별하도록 학습됩니다. GAN의 궁극적인 목적은 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/17/compare/&quot;&gt;실제 데이터의 분포&lt;/a&gt;에 가까운 데이터를 생성하는 것입니다. GAN을 도식화한 그림은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/jNAXwhE&quot;&gt;&lt;img src=&quot;https://i.imgur.com/jNAXwhE.png&quot; width=&quot;200px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GAN의 목적함수는 다음과 같습니다. 게임이론 타입의 목적함수로 두 명의 플레이어($G$와 $D$)가 싸우면서 서로 균형점(nash equilibrium)을 찾아가도록 하는 방식입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min _{ G }{ \max _{ D }{ V\left( D,G \right)  }  } ={ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { D\left( x \right)  }  \right] +{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( G\left( z \right)  \right)  \right\}  }  \right]&lt;/script&gt;

&lt;p&gt;실제 학습을 진행할 때는 두 네트워크를 동시에 학습시키지 않고 따로따로 업데이트를 합니다. 각각의 목적함수는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max _{ D }{ V\left( D \right)  } =&amp;{ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { D\left( x \right)  }  \right] +{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( z \right)  \right\}  }  \right] \\ =&amp;\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { D\left( { x }^{ i } \right)  }  } +\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ i } \right)  \right)  \right\}  }  } \\ \min _{ G }{ V\left( G \right)  } =&amp;{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( G\left( z \right)  \right)  \right\}  }  \right] \\ =&amp;\frac { 1 }{ m } \sum _{ j=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ j } \right)  \right)  \right\}  }  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;dcgan&quot;&gt;DCGAN&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Deep Convolutional GAN&lt;/strong&gt;(DCGAN)은 GAN을 개선한 모델입니다. GAN은 학습이 어렵다는 점이 최대 단점인데요. DCGAN은 대부분의 상황에서 안정적으로 학습이 되는 아키텍처로, Deep Generative Model 연구는 DCGAN 등장 이전과 이후로 나뉠 정도로 파급력이 컸습니다. DCGAN 이후 소개된 GAN 논문은 DCGAN 아키텍처에서 크게 벗어나지 않습니다. DCGAN 특징과 아키텍처 개요는 다음과 같습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;구분&lt;/th&gt;
      &lt;th&gt;Generator&lt;/th&gt;
      &lt;th&gt;Discriminator&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pooling Layers&lt;/td&gt;
      &lt;td&gt;Not Used. But use strided convolutions instead.&lt;/td&gt;
      &lt;td&gt;same&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Batch Normalization&lt;/td&gt;
      &lt;td&gt;Use except output layer&lt;/td&gt;
      &lt;td&gt;Use except input layer&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Fully connected hidden layers&lt;/td&gt;
      &lt;td&gt;Not used&lt;/td&gt;
      &lt;td&gt;Not used&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Activation function&lt;/td&gt;
      &lt;td&gt;ReLU for all layers except for the output, which uses Tanh&lt;/td&gt;
      &lt;td&gt;LeakyReLU for all layers&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/Aoe2KSc&quot;&gt;&lt;img src=&quot;https://i.imgur.com/Aoe2KSc.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;disentangled-latent-code&quot;&gt;disentangled latent code&lt;/h2&gt;

&lt;p&gt;DCGAN 논문에서는 $G$의 인풋 역할을 하는 $z$ 벡터를 활용해 &lt;em&gt;semantic&lt;/em&gt; 연산이 가능하다는 점을 언급해 주목을 받았습니다. 예컨대 선글라스를 낀 남자들을 발생시키는 $z_1$에 선글라스를 안 낀 남자에 해당하는 $z_2$를 빼고, 여기에 선글라스를 안 낀 여자들을 발생시키는 $z_3$를 더해 선글라스를 낀 여자들과 관련한 사진을 생성한 것입니다. 이밖에 $z$로 &lt;em&gt;rotation&lt;/em&gt; 등 다양한 효과를 내어서 이목을 사로 잡았습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/5TtAY5v&quot;&gt;&lt;img src=&quot;https://i.imgur.com/5TtAY5v.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;하지만 위 그림이 나타내는 바와 같이 $z$가 속한 벡터공간의 각 차원별 특징은 해석하기 어렵습니다(&lt;em&gt;entangled&lt;/em&gt;). 위의 DCGAN의 경우 생성된 이미지를 사람이 일일이 확인해 찾은 결과입니다. 이후 해석하기 쉬운(&lt;em&gt;disentangled&lt;/em&gt;) 특징량(&lt;em&gt;latent code&lt;/em&gt;)에 의존하는 &lt;em&gt;Deep Generative Model&lt;/em&gt;이 잇달아 제안됐습니다. 앞으로 설명해 드릴 &lt;em&gt;conditional GAN&lt;/em&gt;, &lt;em&gt;InfoGAN&lt;/em&gt;, &lt;em&gt;ACGAN&lt;/em&gt; 등이 바로 여기에 속합니다.&lt;/p&gt;

&lt;h2 id=&quot;conditional-gan&quot;&gt;conditional GAN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;conditional GAN&lt;/em&gt;에서는 $x$뿐 아니라 데이터의 정답 레이블 정보 $y$를 GAN에 적용한 최초의 시도입니다. 아키텍처는 아래 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/pSICG3J&quot;&gt;&lt;img src=&quot;https://i.imgur.com/pSICG3J.png&quot; width=&quot;200px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/OpTO0Z3&quot;&gt;&lt;img src=&quot;https://i.imgur.com/OpTO0Z3.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;conditional GAN&lt;/em&gt;의 목적함수를 &lt;em&gt;vanilla GAN&lt;/em&gt;과 비교해서 보면 $y$가 $D$와 $G$에 추가된 것 외에 같은 점을 확인할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min _{ G }{ \max _{ D }{ V\left( D,G \right)  }  } ={ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { D\left( x,y \right)  }  \right] +{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( G\left( z,y \right), y\right)  \right\}  }  \right]&lt;/script&gt;

&lt;p&gt;&lt;em&gt;conditional GAN&lt;/em&gt;과 같이 아키텍처를 구성할 경우 &lt;em&gt;Zero-Mean Gaussian&lt;/em&gt;으로 생성한 $z$와, 우리가 생성하고 싶은 범주의 레이블 정보에 해당하는 벡터 $y$를 함께 넣어 원하는 데이터를 생성할 수 있게 됩니다. $G$는 $z$뿐 아니라 $y$의 정보도 함께 고려하여 데이터를 생성하기 때문에 $z$가 속한 벡터공간을 해석하기 쉬워졌다는 의미로 받아들여도 되지 않을까 싶습니다.&lt;/p&gt;

&lt;h2 id=&quot;semi-supervised-gan&quot;&gt;semi-supervised GAN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;semi-supervised GAN&lt;/em&gt;은 $D$를 &lt;em&gt;multinomial classifier&lt;/em&gt;로 구성했습니다. 정답이 있는 실제 데이터는 해당 정답을 맞추도록 $D$가 학습됩니다. 정답이 없는 실제 데이터의 경우 &lt;em&gt;fake&lt;/em&gt;를 제외하고, 거기에 제일 비슷한 범주가 예측되도록 합니다(예컨대 $K$개 범주가 있다면 예측된 범주 y-hat은 {$1,2,…K$} 가운데 하나가 됨). $G$가 생성한 가짜 데이터의 경우 $D$는 &lt;em&gt;fake class&lt;/em&gt;로 예측하게 됩니다. 이 아키텍처는 레이블 정보가 일부 데이터에 한정된 &lt;em&gt;semi-supervised&lt;/em&gt; 환경에서 작동할 수 있고, 범주 정보로 $z$ 공간을 해석할 수 있다는 장점이 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/YgIWCEf&quot;&gt;&lt;img src=&quot;https://i.imgur.com/YgIWCEf.png&quot; width=&quot;200px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;acgan&quot;&gt;ACGAN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Auxiliary Classifier GAN(ACGAN)&lt;/em&gt;은 $D$를 두 개의 &lt;em&gt;classifier&lt;/em&gt;로 구성했습니다. 하나는 데이터가 실제인지 가짜인지 판별합니다. 나머지 하나는 해당 데이터의 범주를 분류합니다. 이 덕분에 &lt;em&gt;ACGAN&lt;/em&gt;로 생성된 데이터는 다른 분류기에 넣어도 범주 분류가 잘 된다고 합니다. 바꿔 말해 이치에 맞는 데이터를 만들어낼 수 있다는 얘기죠. $G$는 &lt;em&gt;conditional GAN&lt;/em&gt;처럼 레이블 정보와 $z$를 합쳐 가짜 데이터를 생성합니다. 아키텍처는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/IUR0e8Q&quot;&gt;&lt;img src=&quot;https://i.imgur.com/IUR0e8Q.png&quot; width=&quot;200px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;ACGAN&lt;/em&gt;의 목적함수는 다음과 같습니다. $L_S$는 기존 GAN의 $D$ 목적함수와 동일합니다. 다시 말해 해당 데이터가 진짜인지 가짜인지 판별해내는 것과 관련이 있습니다. $L_D$는 해당 데이터의 범주를 분류하는 것에 해당합니다. $D$는 $L_S+L_C$를, $G$는 $L_C-L_S$를 최대화하도록 학습됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;{ L }_{ S }=E\left[ \log { p\left( S=real|{ X }_{ real } \right)  }  \right] +E\left[ \log { p\left( S=fake|{ X }_{ fake } \right)  }  \right] \\ &amp;{ L }_{ C }=E\left[ \log { p\left( C=c|{ X }_{ real } \right)  }  \right] +E\left[ \log { p\left( C=c|{ X }_{ fake } \right)  }  \right] 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;catgan&quot;&gt;catGAN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;categorical GAN(catGAN)&lt;/em&gt;은 다음과 같은 &lt;strong&gt;조건부 엔트로피(conditional entropy)&lt;/strong&gt;를 목적함수로 활용합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
H\left( X|Y \right) &amp;\equiv \sum _{ x\in \chi  }^{  }{ p\left( x \right) H\left( Y|X=x \right)  } \\ &amp;=-\sum _{ x\in \chi  }^{  }{ p\left( x \right) \sum _{ y\in \Psi  }^{  }{ p\left( y|x \right) \log { p\left( y|x \right)  }  }  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;em&gt;catGAN&lt;/em&gt;의 학습 목표를 직관적으로 나타낸 그림은 다음과 같습니다. 우선 $D$ 입장에서 살펴보겠습니다. $D$는 다음 세 가지 과업을 잘 수행하도록 학습됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$(i)$ 실제 데이터($x$)의 경우 $D$ 스스로 범주 구분을 확실하게 한다. 즉 조건부 &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/09/22/information/&quot;&gt;엔트로피(entropy)&lt;/a&gt; $H[p(y$|$x,D)$를 최소화한다.&lt;/li&gt;
  &lt;li&gt;$(ii)$ 가짜 데이터($G(z)$)의 경우 $D$ 스스로 범주 구분을 잘 하지 못하게 한다. 즉 조건부 엔트로피 $H[p(y$|$x,G(z))$를 최대화한다.&lt;/li&gt;
  &lt;li&gt;$(iii)$ $D$ 스스로 $N$개 전체 진짜 데이터를 $K$개 범주에 균등하게 할당하도록 한다. 즉 주변확률 엔트로피 $H[p(y$|$D)]$를 최대화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$G$는 다음 두 가지 과업을 잘 수행하도록 학습됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$(ii)$ 가짜 데이터($G(z)$)라도 $D$가 범주 구분을 확실하게 하도록 한다. 즉 조건부 엔트로피 $H[p(y$|$x,G(z))$를 최소화한다.&lt;/li&gt;
  &lt;li&gt;$(iii)$ $D$가 $M$개 전체 가짜 데이터를 $K$개 범주에 균등하게 할당하도록 한다. 즉 주변확률 엔트로피 $H[p(y$|$D)]$를 최대화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/dpr276J&quot;&gt;&lt;img src=&quot;https://i.imgur.com/dpr276J.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;catGAN&lt;/em&gt;의 목적함수는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
{ L }_{ D }=&amp;\max _{ D }{ { H }_{ \chi  }\left[ p\left( y|D \right)  \right] -{ E }_{ x\sim \chi  }\left[ H\left[ p\left( y|x,D \right)  \right]  \right] +{ E }_{ z\sim p\left( z \right)  }\left[ H\left[ p\left( y|G\left( z \right) ,D \right)  \right]  \right]  } \\ { L }_{ G }=&amp;\min _{ G }{ -H_{ G }\left[ p\left( y|D \right)  \right] +{ E }_{ z\sim p\left( z \right)  }\left[ H\left[ p\left( y|G\left( z \right) ,D \right)  \right]  \right]  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식 가운데 $L_D$의 우변 두번째 항은 실제로 다음과 같이 계산됩니다. 다시 말해 레이블이 없는 실제 데이터 $N$개를 $D$에 넣고 계산한 조건부 엔트로피를 가리킵니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
{ E }_{ x\sim \chi  }\left[ H\left[ p\left( y|x,D \right)  \right]  \right] =&amp;\frac { 1 }{ N } \sum _{ i=1 }^{ N }{ H\left[ p\left( y|x,D \right)  \right]  } \\ =&amp;\frac { 1 }{ N } \sum _{ i=1 }^{ N }{ -\sum _{ k=1 }^{ K }{ p\left( y=k|{ x }^{ i },D \right) \log { p\left( y=k|{ x }^{ i },D \right)  }  }  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;레이블이 있는 데이터를 보유하고 있을 경우 위 항과 별도로 아래와 같은 &lt;strong&gt;크로스엔트로피&lt;/strong&gt;(cross entropy)를 추가할 수도 있습니다. 다시 말해 &lt;em&gt;catGAN&lt;/em&gt;은 (&lt;em&gt;semi&lt;/em&gt;)&lt;em&gt;supervised learning&lt;/em&gt; 과업 또한 수행할 수 있다는 이야기입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;CE\left[ y,p\left( y|x,D \right)  \right] =-\sum _{ i=1 }^{ K }{ { y }_{ i }\log { p\left( y={ y }_{ i }|x,D \right)  }  }&lt;/script&gt;

&lt;p&gt;$L_D$ 우변 세번째 항은 실제로 다음과 같이 계산됩니다. 모든 $z$에 대해 조건부 엔트로피를 구할 수 없기 때문에 &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/05/31/gibbs/&quot;&gt;몬테카를로 방법&lt;/a&gt;을 활용합니다. 즉 $p(z)$로부터 $M$개 $z$를 뽑은 뒤 이를 $G$에 넣어 조건부 엔트로피를 구하는 것입니다. 이 다음부터는 위 항 계산 방식과 동일합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ E }_{ z\sim p\left( z \right)  }\left[ H\left[ p\left( y|G\left( z \right) ,D \right)  \right]  \right] \approx \frac { 1 }{ M } \sum _{ i=1 }^{ M }{ H\left[ p\left( y|G\left( { z }^{ i } \right) ,D \right)  \right]  }&lt;/script&gt;

&lt;p&gt;주변확률 엔트로피는 다음과 같이 계산합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ H }_{ \chi  }\left[ p\left( y|D \right)  \right] =H\left[ \frac { 1 }{ N } \sum _{ i=1 }^{ N }{ p\left( y|x^{ i },D \right)  }  \right] \\ H_{ G }\left[ p\left( y|D \right)  \right] \approx H\left[ \frac { 1 }{ M } \sum _{ i=1 }^{ M }{ p\left( y|G\left( { z }^{ i } \right) ,D \right)  }  \right]&lt;/script&gt;

&lt;h2 id=&quot;infogan&quot;&gt;InfoGAN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Information GAN(InfoGAN)&lt;/em&gt;은 기존 GAN 목적함수에 &lt;strong&gt;상호정보량(mutual information)&lt;/strong&gt;을 추가한 형태입니다. 상호정보량이란 두 확률변수들이 얼마나 의존적(&lt;em&gt;dependent&lt;/em&gt;)인지 측정하는 지표로, 두 확률변수의 독립성을 &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/09/23/MLE/&quot;&gt;쿨백-라이블러 발산(KLD)&lt;/a&gt;으로 측정합니다. 서로 독립일 경우 그 값이 0이 됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I\left( X;Y \right) ={ D }_{ KL }\left( p\left( x,y \right) ||p\left( x \right) p\left( y \right)  \right)&lt;/script&gt;

&lt;p&gt;기존 GAN 목적함수를 $V(D,G)$라고 했을 때 &lt;em&gt;InforGAN&lt;/em&gt;의 목적함수는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min _{ G }{ \max _{ D }{ { V }_{ I }\left( D,G \right)  }  } =V\left( D,G \right) -\lambda I\left( c;G\left( z,c \right)  \right)&lt;/script&gt;

&lt;p&gt;&lt;em&gt;InfoGAN&lt;/em&gt;에서는 $G$의 입력 노이즈 $z$를 두 개로 분리했습니다. 노이즈 종류에 대한 설명과 아키텍처를 나타낸 그림은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$c$ : &lt;em&gt;latent code&lt;/em&gt;, 즉 설명 가능한 피처(&lt;em&gt;semantic features&lt;/em&gt;)&lt;/li&gt;
  &lt;li&gt;$z$ : &lt;em&gt;incompressible noise&lt;/em&gt;, 즉 나머지 모든 부분&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/8hxZ3qc&quot;&gt;&lt;img src=&quot;https://i.imgur.com/8hxZ3qc.png&quot; width=&quot;200px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;목적함수에서 확인할 수 있듯 $c$와 $G(z,c)$ 사이의 상호정보량을 최대화한다는 것은, $c$에 의존적인 데이터를 $G$가 생성하도록 한다는 의미입니다. 다시 말해 $c$가 변함에 따라 가짜 데이터 또한 여기에 맞춰 바뀔 수 있도록 학습을 진행한다는 겁니다.&lt;/p&gt;

&lt;p&gt;그러나 상호정보량을 단박에 최대화하는 것은 어렵습니다. 이에 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/19/vi/&quot;&gt;변분추론(Variational Inference)&lt;/a&gt;을 수행해 $I(c;G(z,c))$의 하한(lower bound)를 구하여 이렇게 구한 하한을 최대화하는 방식으로 학습을 진행하게 됩니다. 구체적인 전개 과정에 대해서는 &lt;a href=&quot;https://i.imgur.com/BAKuCtc.png&quot;&gt;이곳&lt;/a&gt;을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;least-squares-gan&quot;&gt;Least Squares GAN&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;vanilla GAN&lt;/em&gt;에서는 $p(x)$와 $p(z)$ 간의 거리를 KLD로 측정했습니다. 그런데 &lt;em&gt;Least Squares GAN(LSGAN)&lt;/em&gt;은 이름 그대로 거리 측정 지표로 &lt;em&gt;least Square&lt;/em&gt;를 씁니다. LSGAN의 목적함수는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min _{ D }{ { V }_{ LSGAN }\left( D \right)  } =&amp;\frac { 1 }{ 2 } { E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ { \left( D\left( x \right) -b \right)  }^{ 2 } \right] +\frac { 1 }{ 2 } { E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ { \left( D\left( G\left( z \right)  \right) -a \right)  }^{ 2 } \right] \\ \min _{ G }{ { V }_{ LSGAN }\left( G \right)  } =&amp;\frac { 1 }{ 2 } { E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ { \left( D\left( G\left( z \right)  \right) -c \right)  }^{ 2 } \right] 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;목적함수를 이렇게 만들면 $D$는 진짜 데이터 $x$를 입력받았을 때 $b$를 출력하도록, 가짜 데이터 $G(z)$의 경우 $a$가 되도록 합니다. $G$는 $D$가 가짜 데이터를 받았을 때 $c$를 출력하도록 유도합니다. 이 말은 어떤 의미일까요? 다음 그림을 보면서 생각해 보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/nQMYfGT&quot;&gt;&lt;img src=&quot;https://i.imgur.com/nQMYfGT.png&quot; width=&quot;400px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 KLD를 거리 함수로 쓰게 되면 진짜 데이터의 분포 중심과 가짜 데이터의 중심이 같아서 더 이상 최적화하기 어렵습니다. 하지만 가짜 데이터들 가운데서도 실제 데이터와 멀리 떨어져 있는 것이 있을 수 있습니다. 예컨대 핑크색 포인트들이 바로 그런 경우입니다. &lt;em&gt;least Square&lt;/em&gt;를 쓰게 되면 이러한 데이터들도 실제 데이터의 분포 쪽으로 가깝게 끌어올 수 있게 됩니다. &lt;em&gt;least Square&lt;/em&gt;는 $x$가 &lt;em&gt;loss&lt;/em&gt;에 대해 &lt;em&gt;strictly convex&lt;/em&gt;하기 때문(함수 꼴이 빗살무늬 토기 모양의 그림이 됨)에 유일한 최적해를 가지며 이 점 덕분에 LSGAN이 좀 더 안정적인 학습이 가능하다고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;wasserstein-gan&quot;&gt;Wasserstein GAN&lt;/h2&gt;

&lt;p&gt;GAN을 학습하면 $G$가 생성하는 분포 $p_g(x)$가 실제 데이터 분포 $p_{data}(x)$에 근사합니다. 그 이유는 최적의 $D$를 가정했을 때 $G$에 대한 GAN의 목적함수는 $p_g(x)$와 $p_{data}(x)$ 사이의 젠슨-섀넌 다이버전스(Jensen Shannon Divergence) 최소화와 동일하기 때문입니다. 이와 관련해서는 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/20/gan/&quot;&gt;이곳&lt;/a&gt;을 참고하시면 좋을 것 같습니다.&lt;/p&gt;

&lt;p&gt;어쨌거나 젠슨-섀넌 다이버전스는 두 확률 분포 간 차이를 측정하는 함수인데요. 불행하게도 언제나 잘 작동하는 건 아닙니다. 다음 예시를 보겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ p }_{ real }=\left( 0,y \right) ,y\sim U\left[ 0,1 \right] \\ { p }_{ fake }=\left( \theta ,y \right) ,y\sim U\left[ 0,1 \right]&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/c5SoOxZ&quot;&gt;&lt;img src=&quot;https://i.imgur.com/c5SoOxZ.png&quot; width=&quot;300px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;다소 극단적인 설정이긴 하지만 위와 같은 상황에서 젠슨-셰넌 다이버전스는 $θ$가 0일 때만 0, $θ$가 0이 아닌 모든 지점에서 $\log2$의 값을 갖습니다. $θ$가 0에 가까울 수록 두 확률 분포 사이의 차이가 줄어드는 건 분명한데 젠슨-섀넌 다이버전스라는 측정 기법은 이러한 변화를 포착해내지 못한다는 뜻이지요. 이것이 GAN 학습이 잘 안되는 한 원인이 될 수 있겠습니다. 그러나 WGAN에서 제시하는 &lt;strong&gt;Wasserstein Distance&lt;/strong&gt;(이하 WDist)는 두 분포 간 차이가 |$θ$| 꼴이 되어서 이러한 변화 캐치에 능동적입니다. 다음 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/xpFHjNu&quot;&gt;&lt;img src=&quot;https://i.imgur.com/xpFHjNu.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;WDist&lt;/em&gt;를 직관적으로 설명하면 이렇습니다. $P_r$과 $P_θ$ 사이의 &lt;em&gt;WDist&lt;/em&gt;는 $P_r$을 $P_θ$로 옮길 때 필요한 양과 거리의 곱을 가리킵니다. 산등성이 전체를 옮기는 것 같다고 하여 &lt;em&gt;Earth Mover Distance&lt;/em&gt;라고도 불립니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/JQkxQKV&quot;&gt;&lt;img src=&quot;https://i.imgur.com/JQkxQKV.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;하지만 &lt;em&gt;WDist&lt;/em&gt;를 바로 계산하는 것은 어렵기 때문에 몇 가지 수학적 증명 과정을 통해 &lt;em&gt;WDist&lt;/em&gt;를 근사하게 됩니다. 결과적으로 도출된 목적함수는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\max _{ D }{ { V }_{ WGAN }\left( D \right)  } ={ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ D\left( x \right)  \right] -{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ D\left( G\left( z \right)  \right)  \right] \\ &amp;\max _{ G }{ { V }_{ WGAN }\left( G \right)  } ={ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ D\left( G\left( z \right)  \right)  \right] \\ &amp;{ \theta  }_{ D }\leftarrow clip\left( -0.01,0.01 \right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 목적함수가 기존 GAN과의 차이를 보이는 점은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;log(sigmoid(logits))&lt;/em&gt; 대신 &lt;em&gt;logits&lt;/em&gt;를 그대로 사용한다.&lt;/li&gt;
  &lt;li&gt;$D$는 임의의 $k$-lipschitz function이어야 한다. 이에 $D$의 모든 파라메터들을 임의의 $[-c,c]$로 클리핑한다. 이 때 $c$는 작은 상수값.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WGAN은 거의 모든 GAN 데이터셋에서 학습이 잘 돼 많은 주목을 받았습니다. WGAN은 $D$와 $G$ 사이의 균형 문제를 걱정할 필요 없이 $D$가 수렴할 때까지 학습을 진행해도 될 정도로 안정적이라고 합니다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Generative Adversarial Network</title>
   <link href="http://ratsgo.github.io/generative%20model/2017/12/20/gan/"/>
   <updated>2017-12-20T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2017/12/20/gan</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Generative Adversarial Network&lt;/strong&gt;(이하 GAN)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;concept&quot;&gt;concept&lt;/h2&gt;

&lt;p&gt;Ian Goodfellow가 2014년 제안한 GAN은 생성자(generator, $G$)와 구분자(discirimiator, $D$), 두 네트워크를 적대적(adversarial)으로 학습시키는 비지도 학습 기반 생성모델(unsupervised generative model)입니다. $G$는 &lt;em&gt;Zero-Mean Gaussian&lt;/em&gt;으로 생성된 $z$를 받아서 실제 데이터와 비슷한 데이터를 만들어내도록 학습됩니다. $D$는 실제 데이터와 $G$가 생성한 가짜 데이터를 구별하도록 학습됩니다. GAN의 궁극적인 목적은 &lt;a href=&quot;https://ratsgo.github.io/generative%20model/2017/12/17/compare/&quot;&gt;실제 데이터의 분포&lt;/a&gt;에 가까운 데이터를 생성하는 것입니다. GAN을 도식화한 그림은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/6ZPdsM8&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6ZPdsM8.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;목적함수&quot;&gt;목적함수&lt;/h2&gt;

&lt;p&gt;GAN의 목적함수는 다음과 같습니다. 게임이론 타입의 목적함수로 두 명의 플레이어($G$와 $D$)가 싸우면서 서로 균형점(nash equilibrium)을 찾아가도록 하는 방식입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min _{ G }{ \max _{ D }{ V\left( D,G \right)  }  } ={ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { D\left( x \right)  }  \right] +{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( G\left( z \right)  \right)  \right\}  }  \right]&lt;/script&gt;

&lt;p&gt;우선 $D$ 입장에서 살펴보겠습니다. 실제 데이터($x$)를 입력하면 높은 확률이 나오도록 하고($D(x)$를 높임), 가짜 데이터($G(z)$)를 입력하면 확률이 낮아지도록($1-D(G(z))$를 낮춤=$D(G(z))$를 높임) 학습됩니다. 다시 말해 $D$는 실제 데이터와 $G$가 만든 가상데이터를 잘 구분하도록 조금씩 업데이트됩니다.&lt;/p&gt;

&lt;p&gt;이번엔 $G$를 살펴보겠습니다. &lt;em&gt;Zero-Mean Gaussian&lt;/em&gt;으로 뽑은 노이즈 $z$를 받아 생성된 가짜 데이터($G(z)$)를 $D$에 넣었을 때, 실제 데이터처럼 확률이 높게 나오도록($1-D(G(z))$를 높임=$D(G(z))$를 낮춤) 학습됩니다. 다시 말해 $G$는 $D$가 잘 구분하지 못하는 데이터를 생성하도록 조금씩 업데이트됩니다.&lt;/p&gt;

&lt;p&gt;실제 학습을 진행할 때는 두 네트워크를 동시에 학습시키지 않고 따로따로 업데이트를 합니다. $D$를 학습시킬 때는 $G$를 고정한 상태에서, $G$를 학습시킬 때는 $D$를 고정한 상태에서 진행한다는 이야기이죠.&lt;/p&gt;

&lt;p&gt;우선 $D$를 학습하기 위한 목적함수는 다음과 같이 다시 쓸 수 있습니다. 즉 $G$의 파라메터를 고정한 상태에서 실제 데이터 $m$개, $G$가 생성한 가짜 데이터 $m$개를 $D$에 넣고 $V$를 계산한 뒤, $D$에 대한 $V$의 그래디언트를 구하고 $V$를 높이는 방향으로 $D$의 파라메터를 업데이트합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\max _{ D }{ V\left( D \right)  } =&amp;{ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { D\left( x \right)  }  \right] +{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( z \right)  \right\}  }  \right] \\ =&amp;\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { D\left( { x }^{ i } \right)  }  } +\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ i } \right)  \right)  \right\}  }  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;$G$의 목적함수는 다음과 같습니다. $D$의 파라메터를 고정한 상태에서 가짜 데이터 $m$개를 생성해 $V$을 계산한 뒤, $G$에 대한 $V$의 그래디언트를 구하고 $V$를 낮추는 방향으로 $G$의 파라메터를 업데이트합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min _{ G }{ V\left( G \right)  } =&amp;{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( G\left( z \right)  \right)  \right\}  }  \right] \\ =&amp;\frac { 1 }{ m } \sum _{ j=1 }^{ m }{ \log { \left\{ 1-D\left( G\left( { z }^{ j } \right)  \right)  \right\}  }  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;학습 초기에 $G$가 생성하는 데이터의 품질은 조악할 것입니다. 이 경우 $D$는 확실하게 가짜 데이터라고 잘 구분하게 되겠죠. $D(G(z))$가 0에 가까울 것이라는 이야기입니다.&lt;/p&gt;

&lt;p&gt;그런데 목적함수를 잘 보면 &lt;em&gt;expectation&lt;/em&gt; 안쪽이 $\log{(1-x)}$ 꼴임을 알 수 있습니다. 이 경우 $x$가 0일 때 기울기가 작습니다. 학습 초기 $G$의 파라메터를 팍팍 업데이트해줘야 하는데 그러지 못할 가능성이 크다는 말입니다.&lt;/p&gt;

&lt;p&gt;이에 $G$의 목적함수를 아래처럼 살짝 바꿔서 초기 $G$ 학습을 가속화합니다. $\log(x)$의 경우 $x$가 0일 때 기울기가 매우 큽니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min _{ G }{ V\left( G \right)  } ={ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( G\left( z \right)  \right)  \right\}  }  \right] \\ \Rightarrow -{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { D\left( G\left( z \right)  \right)  }  \right]&lt;/script&gt;

&lt;h2 id=&quot;학습&quot;&gt;학습&lt;/h2&gt;

&lt;p&gt;몇 가지 수식을 통해 GAN 학습 과정을 좀 더 살펴보도록 하겠습니다. 이상적인 경우, 즉 $G$가 매우 학습이 잘 되었다면 $G$가 &lt;em&gt;Zero-Mean Gaussian&lt;/em&gt;으로 뽑은 노이즈 $z$를 받아 생성한 데이터와 실제 데이터가 일치할 것입니다($G(z)=x$, $p_g(x)=p_{data}(x)$). 이 경우 최적의 구분자 $D$는 다음과 같이 식을 쓸 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
D^{ * }=&amp;\max _{ D }{ V\left( D \right)  } \\ =&amp;{ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { D\left( x \right)  }  \right] +{ E }_{ z\sim { p }_{ z }\left( z \right)  }\left[ \log { \left\{ 1-D\left( G\left( z \right)  \right)  \right\}  }  \right] \\ =&amp;{ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { D\left( x \right)  }  \right] +{ E }_{ x\sim { p }_{ g }\left( x \right)  }\left[ \log { \left\{ 1-D\left( x \right)  \right\}  }  \right] \\ =&amp;\int _{ x }^{  }{ { p }_{ data }\left( x \right) \log { D\left( x \right)  } dx } +\int _{ x }^{  }{ { p }_{ g }\left( x \right) \log { \left\{ 1-D\left( x \right)  \right\}  } dx } \\ =&amp;\int _{ x }^{  }{ { p }_{ data }\left( x \right) \log { D\left( x \right)  } +{ p }_{ g }\left( x \right) \log { \left\{ 1-D\left( x \right)  \right\}  } dx } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식이 최대화되는 지점은 위 식을 우리가 알고자 하는 $D(x)$로 미분한 값이 0이 되는 지점입니다. 식을 $D(x)$로 미분한 결과를 0으로 만든 식을 $D(x)$로 정리하면 다음과 같습니다. 아래 식에 원래 가정($p_g(x)=p_{data}(x)$)을 대입해 풀면 최적의 구분자 $D$는 1/2로 수렴합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D^{ * }\left( x \right)=\frac { { p }_{ data }\left( x \right)  }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }&lt;/script&gt;

&lt;p&gt;$D$는 데이터 $x$가 주어졌을 때 실제 데이터($y=1$)일 확률을 의미합니다. 이를 베이즈룰을 이용해 정리하면 최적의 $D$는 사전확률 $p(y=1)$와 $p(y=0)$이 1/2로 서로 같을 때 도출됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
p\left( y=1|x \right) =&amp;\frac { p\left( x,y=1 \right)  }{ p\left( x \right)  } \\ =&amp;\frac { p\left( x,y=1 \right) /p\left( y=1 \right)  }{ \left\{ p\left( x,y=1 \right) +p\left( x,y=0 \right)  \right\} /p\left( y=1 \right)  } \\ =&amp;\frac { p\left( x|y=1 \right)  }{ p\left( x|y=1 \right) +p\left( x|y=0 \right)  } \\ =&amp;\frac { p\left( x|y=1 \right) { 1 }/{ 2 } }{ p\left( x|y=1 \right) { 1 }/{ 2 }+p\left( x|y=0 \right) { 1 }/{ 2 } } \\ =&amp;\frac { p\left( x|y=1 \right) p\left( y=1 \right)  }{ p\left( x|y=1 \right) p\left( y=1 \right) +p\left( x|y=0 \right) p\left( y=0 \right)  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;GAN의 목적함수를 최적의 구분자 $D$를 전제하고 식을 정리하면 다음과 같습니다. 다시 말해 최적의 $D$가 전제된 상황이라면 GAN의 목적함수를 최적화하는 과정은 $p_{data}$와 $p_g$ 사이의 &lt;a href=&quot;https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence&quot;&gt;젠슨-섀넌 다이버전스(Jensen-Shannon divergence)&lt;/a&gt;를 최소화하는 것과 같습니다. 젠슨-섀넌 다이버전스는 두 확률 분포 간 차이를 재는 함수의 일종인데요. &lt;strong&gt;데이터의 분포와 $G$가 생성하는 분포 사이의 차이를 줄인다&lt;/strong&gt;고 해석할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\min _{ G }{ V\left( { D }^{ * },G \right)  } =&amp;{ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { { D }^{ * }\left( x \right)  }  \right] +{ E }_{ x\sim { p }_{ g }\left( x \right)  }\left[ \log { \left\{ 1-{ D }^{ * }\left( x \right)  \right\}  }  \right] \\ =&amp;{ E }_{ x\sim { p }_{ data }\left( x \right)  }\left[ \log { \frac { { p }_{ data }\left( x \right)  }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }  }  \right] +{ E }_{ x\sim { p }_{ g }\left( x \right)  }\left[ \log { \frac { { p }_{ g }\left( x \right)  }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }  }  \right] \\ =&amp;\int _{ x }^{  }{ { p }_{ data }\left( x \right) \log { \frac { { p }_{ data }\left( x \right)  }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }  } dx } +\int _{ x }^{  }{ { p }_{ g }\left( x \right) \log { \frac { { p }_{ g }\left( x \right)  }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }  } dx } \\ =&amp;-\log { 4 } +\int _{ x }^{  }{ { p }_{ data }\left( x \right) \log { \frac { 2\cdot { p }_{ data }\left( x \right)  }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }  } dx } +\int _{ x }^{  }{ { p }_{ g }\left( x \right) \log { \frac { 2\cdot { p }_{ g }\left( x \right)  }{ { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }  } dx } \\ =&amp;-\log { 4 } +\int _{ x }^{  }{ { p }_{ data }\left( x \right) \log { \frac { { p }_{ data }\left( x \right)  }{ \frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }{ 2 }  }  } dx } +\int _{ x }^{  }{ { p }_{ g }\left( x \right) \log { \frac { { p }_{ g }\left( x \right)  }{ \frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }{ 2 }  }  } dx } \\ =&amp;-\log { 4 } +KLD\left( { p }_{ data }\left( x \right) ||\frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }{ 2 }  \right) +KLD\left( { p }_{ g }\left( x \right) ||\frac { { p }_{ data }\left( x \right) +{ p }_{ g }\left( x \right)  }{ 2 }  \right) \\ =&amp;-\log { 4 } +2\cdot JSD\left( { p }_{ data }\left( x \right) ||{ p }_{ g }\left( x \right)  \right) 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;GAN의 학습과정을 도식화한 그림은 다음과 같습니다. 학습이 진행될 수록 $p_g$(녹색 실선)는 $p_{data}$(검정 점선), $D$(파란 점선)는 1/2로 수렴하는 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/m4EiZPk&quot;&gt;&lt;img src=&quot;https://i.imgur.com/m4EiZPk.png&quot; width=&quot;600px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;단점과-극복방안&quot;&gt;단점과 극복방안&lt;/h2&gt;

&lt;p&gt;GAN의 이론적 배경은 탄탄하지만, 실제 적용에는 많은 문제가 있습니다. 대표적으로 학습이 어렵다는 점을 꼽을 수 있겠습니다. 차례대로 살펴보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;mode-collapsing&quot;&gt;mode collapsing&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;mode collapsing&lt;/em&gt;이란 우리가 학습시키려는 모형이 실제 데이터의 분포를 모두 커버하지 못하고 다양성을 잃어버리는 현상을 가리킵니다. 그저 손실(loss)만을 줄이려고 학습을 하기 때문에 $G$가 전체 데이터 분포를 찾지 못하고, 아래 그림처럼 한번에 하나의 &lt;em&gt;mode&lt;/em&gt;에만 강하게 몰리게 되는 경우입니다. 예컨대 MNIST를 학습한 $G$가 특정 숫자만 생성한다든지 하는 사례가 바로 여기에 속합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/l9sDQK6&quot;&gt;&lt;img src=&quot;https://i.imgur.com/l9sDQK6.png&quot; width=&quot;500px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;진동&quot;&gt;진동&lt;/h3&gt;

&lt;p&gt;$G$와 $D$가 서로 진동하듯 수렴하지 않는 문제 역시 &lt;em&gt;mode collapsing&lt;/em&gt; 문제와 관련이 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/AkrWyyG&quot;&gt;&lt;img src=&quot;https://i.imgur.com/AkrWyyG.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;mode-collapsing-해결방안&quot;&gt;mode collapsing 해결방안&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;mode collapsing&lt;/em&gt; 해결방안 가운데 간단하면서 효과적인 것으로 알려진 세 가지는 다음과 같습니다. 모델이 전체 데이터 분포의 경계를 골고루 학습하게 하고, 그것을 계속 기억할 수 있도록 하는 것이 핵심입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;feature matching&lt;/strong&gt; : 가짜 데이터와 실제 데이터 사이의 &lt;em&gt;least square error&lt;/em&gt;를 목적함수에 추가&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;mini-batch discrimination&lt;/strong&gt; : 미니배치별로 가짜 데이터와 실제 데이터 사이의 거리 합의 차이를 목적함수에 추가&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;historical averaging&lt;/strong&gt; : 배치 단위로 파라메터를 업데이트하면 이전 학습은 잘 잊히게 되므로, 이전 학습 내용을 기억하는 방식으로 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;힘의-균형&quot;&gt;힘의 균형&lt;/h3&gt;

&lt;p&gt;$D$보다 $G$를 학습시키는 것이 일반적으로 어렵습니다. $G$가 학습이 잘 안되어서 둘 사이의 힘의 균형이 깨지는 경우 GAN 학습이 더 이상 진전될 수 없습니다. GAN 연구 초기에는 $G$를 $k$번 업데이트시키고, $D$를 한번 업데이트시키거나, 목적함수 비율을 조절하는 등 밸런스를 맞추기 위해 다양한 방식을 시도하였으나 뾰족한 대안이 되진 못했습니다. 그러나 최근엔 LSGAN, WGAN, F-GAN, EBGAN 등 손실함수를 바꿔서 이 문제를 해결한 연구가 여럿 제안되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;평가&quot;&gt;평가&lt;/h3&gt;

&lt;p&gt;GAN은 데이터 생성이 목적이기 때문에 정량적인 평가가 어렵습니다. 그럼에도 다음과 같은 세 가지 방식이 널리 쓰입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;정성평가&lt;/strong&gt; : 사람이 직접 평가&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;학습된 분류기를 이용&lt;/strong&gt; : 기존 뉴럴네트워크를 활용해 &lt;em&gt;label&lt;/em&gt;이 있는 데이터 셋을 학습시킨다. 동일한 데이터로 GAN을 학습한 후 $G$를 이용해서 새로운 데이터를 생성하고 미리 학습시켜둔 분류기 모델에 넣어 분류를 시행한다. 이 때 (1)생성된 새로운 데이터가 한 범주에 높은 확률로 분류되거나 (2)전체적으로 다양한 범주의 데이터가 생성됐다면 GAN의 성능을 높다고 평가할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;inception score&lt;/strong&gt; : $G$가 생성한 데이터의 다양성(개성)을 측정하는 지표로 클 수록 좋다.&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>변분추론(Variational Inference)</title>
   <link href="http://ratsgo.github.io/generative%20model/2017/12/19/vi/"/>
   <updated>2017-12-19T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2017/12/19/vi</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;Variational Inference&lt;/strong&gt;(변분추론, 이하 VI)에 대해 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의와 위키피디아 등을 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;concept&quot;&gt;concept&lt;/h2&gt;

&lt;p&gt;VI란 사후확률(posterior) 분포 $p(z$|$x)$를 다루기 쉬운 확률분포 $q(z)$로 근사(approximation)하는 걸 말합니다. 사후확률 분포를 계산하는게 불가능에 가까울 정도로 어려운 경우가 많기 때문입니다. 가령 다음과 같은 경우입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;marginal probability&lt;/em&gt;, 즉 사후확률의 분모인 $p(x)=Σ_zp(x,z)$를 계산하기 힘든 경우&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;likelihood&lt;/em&gt;, 즉 $p(x$|$z)$를 더 복잡하게 모델링하고 싶은 경우&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;prior&lt;/em&gt;, 즉 $p(z)$를 더 복잡하게 모델링하고 싶은 경우&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;VI를 도식화한 그림은 아래와 같습니다. 사후확률 분포를 우리가 익히 알고 있는 정규분포로 근사한 케이스입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/05LNq0o&quot;&gt;&lt;img src=&quot;https://i.imgur.com/05LNq0o.png&quot; width=&quot;350px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;kl-divergence&quot;&gt;KL Divergence&lt;/h2&gt;

&lt;p&gt;사후확률에 근사한 $q(z)$를 만들기 위해 &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/09/22/information/&quot;&gt;쿨백-라이블러 발산(Kullback-Leibler divergence, 이하 KLD)&lt;/a&gt; 개념을 활용합니다. KLD는 두 확률분포의 차이를 계산하는 데 사용하는 함수인데요. 사후확률 분포 $p(z$|$x)$와 $q(z)$ 사이의 KLD를 계산하고, KLD가 줄어드는 쪽으로 $q(z)$를 조금씩 업데이트하는 과정을 반복하면 사후확률을 잘 근사하는 $q^*(z)$를 얻게 될 것이라는 게 VI의 핵심 아이디어입니다. KLD 식을 조금 변형하면 다음과 같이 유도할 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&amp;\int { q\left( z \right) \log { \frac { q\left( z \right)  }{ p\left( z|x \right)  }  } dz } \\ =&amp;\int { q\left( z \right) \log { \frac { q\left( z \right) p\left( x \right)  }{ p\left( x|z \right) p\left( z \right)  }  } dz } \\ =&amp;\int { q\left( z \right) \log { \frac { q\left( z \right)  }{ p\left( z \right)  }  } dz } +\int { q\left( z \right) \log { p\left( x \right)  } dz } -\int { q\left( z \right) \log { p(x|z) } dz } \\ =&amp;{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;이후 이 글에서는 동전던지기 예제를 바탕으로 VI를 설명하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;conjugate-distribution&quot;&gt;conjugate distribution&lt;/h2&gt;

&lt;p&gt;동전던지기 실험은 &lt;strong&gt;이항분포&lt;/strong&gt;를 따릅니다. 이항분포란 성공확률이 $p$이고, 그 결과가 성공 혹은 실패뿐인 실험을 $n$번 반복시행할 때 성공횟수의 분포를 가리킵니다. 이항분포 파라메터 $p$의 사전확률과 사후확률 모두 베타분포를 따르는데요. 이처럼 사전확률 분포와 사후확률 분포가 같은 가족군으로 묶일 때 그 사후확률/사전확률을 모두 묶어 &lt;strong&gt;켤레분포(conjugate distributions)&lt;/strong&gt;라고 합니다.&lt;/p&gt;

&lt;p&gt;$q(z)$를 $α_q$, $β_q$를 파라메터로 하는 베타분포, 앞면이 관측된 수를 $n_h$, 뒷면을 $n_t$로 둡시다. 이를 아래 식에 대입해 풀면 사후확률 분포 $p(z$|$x)$에 가장 잘 근사한 $q(z)$는 $α_q+n_h$, $β_q+n_t$를 파라메터로 하는 베타분포가 된다고 합니다. 이와 관련해서는 &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/06/30/bayesinfer/&quot;&gt;이 글&lt;/a&gt;, 수식 유도와 관련해서는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Beta_distribution&quot;&gt;위키피디아&lt;/a&gt;를 참고하시면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;variational-inference-with-monte-carlo-sampling&quot;&gt;Variational Inference with Monte Carlo sampling&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://ratsgo.github.io/statistics/2017/05/31/gibbs/&quot;&gt;몬테카를로 방법(Monte Carlo Method)&lt;/a&gt;이란 랜덤 표본을 뽑아 함수의 값을 확률적으로 계산하는 알고리즘을 가리킵니다. 수학이나 물리학 등에 자주 사용되며 계산하려는 값이 &lt;strong&gt;닫힌 형식&lt;/strong&gt;(closed form)으로 표현되지 않거나 복잡한 경우에 그 값을 근사적으로 계산하려고 할 때 쓰입니다. 예컨대 특정 확률 분포를 따르는 $x$의 함수값의 기대값은 다음과 같이 $k$개 샘플로 근사하는 것입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int { p\left( x \right) f\left( x \right) dx } ={ E }_{ x\sim p\left( x \right)  }\left[ f(x) \right] \approx \frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ f({ x }_{ i }) \right]  }_{ { x }_{ i }\sim p\left( x \right)  } }&lt;/script&gt;

&lt;p&gt;몬테카를로 방법을 KLD에 적용해 식을 정리하면 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&amp;{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] \\ =&amp;{ E }_{ z\sim q\left( z \right)  }\left[ \log { \frac { q\left( z \right)  }{ p\left( z \right)  }  }  \right] +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] \\ \approx &amp;\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { \frac { q\left( { z }_{ i } \right)  }{ p\left( { z }_{ i } \right)  }  }  \right]  }_{ { z }_{ i }\sim q\left( z \right)  } } +\log { p\left( x \right)  } -\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { p\left( x|{ z }_{ i } \right)  }  \right]  }_{ { z }_{ i }\sim q\left( z \right)  } } \\ =&amp;\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { q\left( { z }_{ i } \right)  } -\log { p\left( { z }_{ i } \right)  } -\log { p\left( x|{ z }_{ i } \right)  }  \right]  }_{ { z }_{ i }\sim q\left( z \right)  } } +\log { p\left( x \right)  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;이렇게 되면 $q(z)$를 설정하는 것이 자유롭게 됩니다. 동전던지기 예제에서는 $q(z)$를 베타분포로 정하는 것이 자연스럽지만, 실제 문제에서는 사후확률 분포에 대해 아무런 정보가 없기 때문에 이렇게 VI를 진행하기 어렵습니다. 하지만 몬테카를로 방법을 이용하게 되면 $q(z)$를 어떤 분포든 사용할 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;예컨대 사후분포에 대한 정보가 없어서 $q(z)$를 정규분포로 정했다고 칩시다. 이 정규분포에서 $K$개의 $z$들을 뽑으면 위 식, 즉 KLD의 근사값을 계산할 수 있게 됩니다. 정규분포의 파라메터는 평균과 분산이므로, 이들을 조금씩 바꿔가면서 KLD 근사값을 최소로 하는 평균과 분산을 구할 수 있을 것입니다. 이렇게 구해진 정규분포가 바로 VI의 결과가 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;variational-inference-with-sgd&quot;&gt;Variational Inference with SGD&lt;/h2&gt;

&lt;p&gt;VI에 &lt;a href=&quot;https://ratsgo.github.io/deep%20learning/2017/09/25/gradient/&quot;&gt;그래디언트 디센트(Gradient Descent)&lt;/a&gt;를 이용할 수도 있습니다. KLD를 줄이는 쪽으로 파라메터를 업데이트한다는 게 핵심 아이디어죠. 이를 &lt;strong&gt;Stochastic Variational Inference&lt;/strong&gt;(SVI)라고도 합니다. 어쨌든 이 방식으로 VI를 하려면 KLD 식이 미분 가능해야 합니다. $q(z)$는 정규분포($θ_q={μ_q, σ_q}$), $p(z)$는 베타분포($α$, $β$)라고 두고 KLD 식을 $θ_q$에 대해 미분해 보겠습니다. (추론 대상 파라메터는 $θ_q$)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac { \partial  }{ \partial { \theta  }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&amp;\frac { \partial  }{ \partial { \theta  }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\frac { \partial  }{ \partial { \theta  }_{ q } } \log { p\left( x \right)  } -\frac { \partial  }{ \partial { \theta  }_{ q } } { E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] \\ =&amp;\frac { \partial  }{ \partial { \theta  }_{ q } } { E }_{ z\sim q\left( z \right)  }\left[ \log { q\left( z \right)  } -\log { p\left( z \right)  } -\log { p(x|z) }  \right] 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식 미분을 완료하려면 $d/dθ_q$가 &lt;em&gt;expectaion&lt;/em&gt; 안으로 들어가야 합니다. 그런데 $q(z)$는 $θ_q$에 의존하는 분포이고 $z$는 $q$에서 뽑기 때문에 $d/dθ_q$가 &lt;em&gt;expectaion&lt;/em&gt; 안으로 들어갈 수 없음을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이렇게 하면 어떨까요? &lt;strong&gt;$z$ 대신 노이즈($ε$)를 뽑고, 노이즈로부터 $z$를 계산한다.&lt;/strong&gt; $q(z)$는 정규분포라고 가정했으므로, $z$는 다음과 같이 쓸 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z={ \mu  }_{ q }+{ \sigma  }_{ q }\epsilon ,\quad \epsilon \sim N\left( 0,1 \right)&lt;/script&gt;

&lt;p&gt;따라서 위의 식은 다음과 같이 전개할 수 있습니다. $E_{ε~N(0,1)}$은 더 이상 $θ_q$에 의존하지 않으므로 $d/dθ_q$가 &lt;em&gt;expectaion&lt;/em&gt; 안으로 들어갈 수 있습니다. SVI 역시 몬테카를로 방법을 써서 $K$개 샘플로 KLD 함수의 그래디언트를 근사할 수 있습니다. 이 그래디언트의 반대 방향으로 파라메터 $θ_q$를 조금씩 업데이트하면 KLD를 줄일 수 있게 되고, 이를 반복하게 되면 사후확률 분포 $p(z$|$x)$에 근사하는 $q(z)$를 찾을 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac { \partial  }{ \partial { \theta  }_{ q } } { D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) =&amp;\frac { \partial  }{ \partial { \theta  }_{ q } } { E }_{ \varepsilon \sim N\left( 0,1 \right)  }\left[ \log { q\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p(x|z={ \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon ) }  \right] \\ =&amp;{ E }_{ \varepsilon \sim N\left( 0,1 \right)  }\left[ \frac { \partial  }{ \partial { \theta  }_{ q } } \left\{ \log { q\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p\left( { \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon  \right)  } -\log { p(x|z={ \mu  }_{ q }+{ \sigma  }_{ q }\varepsilon ) }  \right\}  \right] \\ \approx &amp;\frac { 1 }{ K } \sum _{ i=0 }^{ K }{ { \left[ \log { q\left( { \mu  }_{ q }+{ \sigma  }_{ q }{ \varepsilon  }_{ i } \right)  } -\log { p\left( { \mu  }_{ q }+{ \sigma  }_{ q }{ \varepsilon  }_{ i } \right)  } -\log { p(x|z={ \mu  }_{ q }+{ \sigma  }_{ q }{ \varepsilon  }_{ i }) }  \right]  }_{ { \varepsilon  }_{ i }\sim N\left( 0,1 \right)  } } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;노이즈($ε$)를 뽑아 VI를 하는 방식은 $z$를 직접 샘플링하는 방식보다 분산(variance)이 적어 유용하다고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;vatiational-em-algorithm&quot;&gt;Vatiational EM algorithm&lt;/h2&gt;

&lt;p&gt;지금까지는, 사전확률함수 $p(z)$와 우도함수 $p(x$|$z)$를 이미 알고 있다는 전제 하에 VI 과정을 설명해 드렸습니다. 하지만 실제 문제에서는 사전확률과 우도의 파라메터 또한 알고 있지 못하는 경우가 많습니다. 그런데 VI는 사후확률 $p(z$|$x)$에 근사한 $q(z)$를 찾는 것이 목적이므로 $p(z)$의 파라메터는 임의로 고정시켜도 관계 없다고 합니다. (아래 식에서 상수항인 $\log{p(x)}$에 해당)&lt;/p&gt;

&lt;p&gt;따라서 우리는 사후확률 $p(z$|$x)$에 근사한 $q(z)$의 파라메터를 찾는 것과 동시에, 우도함수 $p(x$|$z)$의 파라메터 또한 추정해야 합니다. 하지만 이를 단박에 찾기 어렵습니다. 이 때 유용한 방법론이 바로 &lt;strong&gt;EM algorithm&lt;/strong&gt;입니다. $q(z)$의 파라메터를 $θ_q$, 우도함수의 파라메터를 $θ_l$라고 둘 때 EM algorithm은 다음과 같은 과정을 수렴할 때까지 반복합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Expectaion&lt;/strong&gt; : $D_{KL}(q(z)$||$p(z$|$x))$를 줄이는 $θ_q$를 찾는다. (몬테카를로 방법을 활용한 VI, SVI 등 적용)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Maximization&lt;/strong&gt; : &lt;em&gt;E-step&lt;/em&gt;에서 찾은 $θ_q$를 고정한 상태에서 $\log{p(x)}$의 하한(lower bound)을 최대화하는 $p(x$|$z)$의 파라메터 $θ_l$를 찾는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기에서 생소한 내용이 &lt;em&gt;M-step&lt;/em&gt;입니다. 우선 KLD는 다음 식의 우변과 같이 세 개 요소로 분해될 수 있습니다. &lt;em&gt;E-step&lt;/em&gt;에서는 KLD를 줄이기 위해 $q$만을 업데이트하므로 이 과정에서 $\log{p(x)}$는 변하지 않습니다. 그런데 KLD를 줄이기 위해선 $\log{p(x)}$ 또한 줄여야 할 것입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) ={ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +\log { p\left( x \right)  } -{ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right]&lt;/script&gt;

&lt;p&gt;위 식을 $\log{p(x)}$를 중심으로 정리하면 다음과 같이 쓸 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log { p\left( x \right)  } ={ E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right) +{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right)&lt;/script&gt;

&lt;p&gt;KLD는 항상 양수입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{ D }_{ KL }\left( q\left( z \right) ||p\left( z|x \right)  \right) \ge 0&lt;/script&gt;

&lt;p&gt;따라서 $\log{p(x)}$의 하한은 다음과 같습니다. $p(x)$는 베이즈 정리에서 &lt;em&gt;evidence&lt;/em&gt;라고 이름이 붙여진 항인데요. 이 때문에 아래 부등식의 우변을 &lt;strong&gt;Evidence Lower Bound&lt;/strong&gt;(ELBO)라고도 부릅니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log { p\left( x \right)  } \ge { E }_{ z\sim q\left( z \right)  }\left[ \log { p(x|z) }  \right] -{ D }_{ KL }\left( q\left( z \right) ||p\left( z \right)  \right)&lt;/script&gt;

&lt;p&gt;위 부등식 우변의 값을 줄이게 된다면 $\log{p(x)}$를 줄이게 되고, 결과적으로 KLD를 줄일 수 있게 됩니다. 따라서 $θ_q$를 고정시킨 채 위 부등식 우변의 값을 줄이는 방향으로 우도함수의 파라메터 $θ_l$를 업데이트하면 우리가 원하는 결과를 얻을 수 있습니다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>unsupervised generative models</title>
   <link href="http://ratsgo.github.io/generative%20model/2017/12/18/unsugen/"/>
   <updated>2017-12-18T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2017/12/18/unsugen</id>
   <content type="html">&lt;p&gt;이번 글에서는 비지도학습(unsupervised learning) 기반의 &lt;strong&gt;generative model&lt;/strong&gt;을 가우시안믹스처모델(Gaussian Mixture Model, GMM) 중심으로 살펴보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;generative-model&quot;&gt;generative model&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;generative model&lt;/em&gt;이란 데이터 $X$가 생성되는 과정을 두 개의 확률모형, 즉 $p(Y)$, $p(X$|$Y)$으로 정의하고, 베이즈룰을 사용해 $p(Y$|$X)$를 간접적으로 도출하는 모델을 가리킵니다. &lt;em&gt;generative model&lt;/em&gt;은 레이블 정보가 있어도 되고, 없어도 구축할 수 있습니다. 이 글에서는 레이블 정보 없이 구축하는 비지도학습 기반의 &lt;em&gt;generative model&lt;/em&gt;을 살펴보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;gaussian-mixtrue-model&quot;&gt;Gaussian Mixtrue Model&lt;/h2&gt;

&lt;p&gt;GMM은 &lt;a href=&quot;&quot;&gt;선형판별분석&lt;/a&gt;의 일반화된 버전입니다. GMM을 &lt;em&gt;generative modeling&lt;/em&gt; 관점에서 분석하면 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p\left( { z }^{ (i) } \right) \sim Multinomial(\phi )\\ p\left( { x }^{ (i) }|{ z }^{ (i) }=j \right) \sim N\left( { \mu  }_{ j },{ \Sigma  }_{ j } \right)&lt;/script&gt;

&lt;p&gt;선형판별분석과 가장 큰 차이점은 레이블 $y$가 없는 비지도학습이라는 사실입니다. $y$ 대신 $z$가 등장했습니다. 그런데 $z$는 학습데이터로 주어지지 않은 잠재변수(latent variable)입니다. $z$는 &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/05/28/binomial/&quot;&gt;다항분포&lt;/a&gt;를 따른다고 가정합니다. 이렇게 뽑힌 $z$가 $j$번째 id일 때 $x$가 나타날 확률은 $j$번째 평균과 분산을 모수로 갖는 정규분포를 따를 것이라 가정합니다.&lt;/p&gt;

&lt;p&gt;GMM의 로그우도 함수는 다음과 같습니다. 단 여기에서 파라메터 $θ$는 (1)$z$와 관련된 다항분포 파라메터 $Φ$ (2)각 정규분포의 평균 $μ$ (3)정규분포의 분산 $Σ$ 세 가지를 가리킵니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
l(\theta )=\sum _{ i }^{  }{ \log { \sum _{ { z }_{ i } }^{  }{ p\left( { x }^{ i },{ z }^{ i },\theta  \right)  }  }  } 
\end{align*}&lt;/script&gt;

&lt;p&gt;$z$가 학습데이터로 주어진 상황이라면, 우리가 구하고자 하는 각각의 파라메터들에 대해 위 로그우도 함수를 편미분한 결과가 0인 지점에서, 쉽게 파라메터를 추정할 수 있을 것입니다. 그러나 $z$는 잠재변수이기 때문에 위의 로그우도 함수를 최대화하는 파라메터를 단박에 구할 수 없습니다. 이 때문에 &lt;strong&gt;EM 알고리즘&lt;/strong&gt;을 다음과 같이 적용합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Expectation&lt;/strong&gt; : 로그우도 함수값의 하한(lower bound)을 구한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Maximization&lt;/strong&gt; : E-step에서 구한 로그우도 함수값을 최대화하는 파라메터를 찾는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면 로그우도 함수의 하한은 어떻게 구할까요? &lt;strong&gt;Jensen’s inequality&lt;/strong&gt;를 이용해 봅시다. 임의의 함수 $f$가 &lt;a href=&quot;https://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/&quot;&gt;볼록함수(convex function)&lt;/a&gt;이고 $x$가 확률변수(random variable)이면 다음이 성립한다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;E\left[ f\left( x \right)  \right] \ge f\left( E\left[ x \right]  \right)&lt;/script&gt;
&lt;a href=&quot;https://imgur.com/5HREVDw&quot;&gt;&lt;img src=&quot;https://i.imgur.com/5HREVDw.png&quot; width=&quot;350px&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그런데 로그 함수($f$)는 오목함수(concave function)이므로 위의 부등식 방향이 반대로 적용될 겁니다. 또 여기에서 $z^i$에 대한 임의의 확률분포 $Q_i(z^i)$를 상정해 둡시다. Jensen’s inequality와 $Q$를 활용해 GMM의 로그우도함수를 다음과 같이 다시 적을 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
l(\theta )=&amp;\sum _{ i }^{  }{ \log { \sum _{ { z }_{ i } }^{  }{ p\left( { x }^{ i },{ z }^{ i },\theta  \right)  }  }  } \\ =&amp;\sum _{ i }^{  }{ \log { \sum _{ { z }_{ i } }^{  }{ { Q }_{ i }\left( { z }^{ i } \right) \frac { p\left( { x }^{ i },{ z }^{ i },\theta  \right)  }{ { Q }_{ i }\left( { z }^{ i } \right)  }  }  }  } \\ \ge&amp; \sum _{ i }^{  }{ \sum _{ { z }_{ i } }^{  }{ { Q }_{ i }\left( { z }^{ i } \right) \log { \frac { p\left( { x }^{ i },{ z }^{ i },\theta  \right)  }{ { Q }_{ i }\left( { z }^{ i } \right)  }  }  }  } 
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;그런데 실제 로그우도는 $Q_i$와 상관이 없기 때문에 가급적 위 부등식이 ‘=’에 가깝게 정할 수 있으면 좋을 겁니다. Jensen’s inequality에서 등호는 $f(x)$가 선형(linear)일 때 성립한다고 합니다. 아울러 $Q_i$ 또한 확률분포이므로 그 합이 1이 되어야 합니다. 따라서 다음 두 가지 속성을 만족하도록 $Q_i$를 정하면 좋을 겁니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac { p\left( { x }^{ i },{ z }^{ i },\theta  \right)  }{ { Q }_{ i }\left( { z }^{ i } \right)  } =c\leftrightarrow { Q }_{ i }\left( { z }^{ i } \right) \propto p\left( { x }^{ i },{ z }^{ i },\theta  \right) \\ \sum _{ z }^{  }{ { Q }_{ i }\left( { z } \right)  } =1&lt;/script&gt;

&lt;p&gt;그런데 $Q_i$를 $z$에 대한 사후확률(posterior)로 정하면 위 두 개 가정을 만족시킬 수 있다고 합니다. 다시 말해 $Q_i(z^i)=p(x^i,z^i,θ)/p(x^i,θ)=p(z^i$|$x^i,θ)$로 둡니다. 요컨대 GMM의 EM 알고리즘은 고정된 $θ$ 하에서 $Q_i(z^i)$를 구하고, E-step에서 구한 $Q_i(z^i)$ 하에서 로그우도 함수를 최대화하는 $θ$를 구하는 과정을 반복합니다. 이와 관련해 고려대 강필성 교수님의 비즈니스어낼리틱스 강의노트를 참고용으로 올려둡니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://imgur.com/bv462aT&quot;&gt;&lt;img src=&quot;https://i.imgur.com/bv462aT.png&quot; title=&quot;source: imgur.com&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;latent-dirichlet-allocation&quot;&gt;Latent Dirichlet Allocation&lt;/h2&gt;

&lt;p&gt;일명 토픽모델링으로도 유명한 &lt;a href=&quot;https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/&quot;&gt;잠재디리클레할당(Latent Dirichlet Allocation, LDA)&lt;/a&gt; 또한  비지도학습 기반의 &lt;em&gt;generative model&lt;/em&gt;입니다. LDA가 가정하는 문서생성과정은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Draw each per-corpus topic distributions $ϕ_k$~$Dir(β)$ for $i∈${$1,2,…K$}&lt;/li&gt;
  &lt;li&gt;For each document, Draw per-document topic proportions $θ_d$~$Dir(α)$&lt;/li&gt;
  &lt;li&gt;For each document and each word, Draw per-word topic assignment $z_{d,n}$~$Multi(θ_d)$&lt;/li&gt;
  &lt;li&gt;For each document and each word, Draw observed word $w_{d,n}$~$Multi(ϕ_{z_{d,n},n})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;LDA에서는 파라메터 추정 과정에서 &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/05/28/binomial/&quot;&gt;켤레사전분포&lt;/a&gt;를 가정하고, &lt;a href=&quot;https://ratsgo.github.io/statistics/2017/05/31/gibbs/&quot;&gt;깁스 샘플링&lt;/a&gt;을 사용합니다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>discriminative vs generative</title>
   <link href="http://ratsgo.github.io/generative%20model/2017/12/17/compare/"/>
   <updated>2017-12-17T00:00:00+00:00</updated>
   <id>http://ratsgo.github.io/generative%20model/2017/12/17/compare</id>
   <content type="html">&lt;p&gt;이번 글에서는 &lt;strong&gt;discriminative model&lt;/strong&gt;과 &lt;strong&gt;generative model&lt;/strong&gt;을 비교해보도록 하겠습니다. 이 글은 전인수 서울대 박사과정이 2017년 12월에 진행한 패스트캠퍼스 강의를 정리했음을 먼저 밝힙니다. 그럼 시작하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;discriminative-model&quot;&gt;discriminative model&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;discriminative model&lt;/em&gt;이란 데이터 $X$가 주어졌을 때 레이블 $Y$가 나타날 조건부확률 $p(Y$|$X)$를 직접적으로 반환하는 모델을 가리킵니다. 레이블 정보가 있어야 하기 때문에 지도학습(supervised learning) 범주에 속하며 $X$의 레이블을 잘 구분하는 &lt;strong&gt;결정경계(decision boundary)&lt;/strong&gt;를 학습하