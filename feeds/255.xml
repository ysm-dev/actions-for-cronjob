<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TaeohKim</title>
    <link>https://taeoh-kim.github.io/</link>
    <description>Recent content on TaeohKim</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Aug 2018 16:11:10 +0900</lastBuildDate>
    
	<atom:link href="https://taeoh-kim.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bayesian Deep Learning: Introduction</title>
      <link>https://taeoh-kim.github.io/blog/bayesian-deep-learning-introduction/</link>
      <pubDate>Tue, 07 Aug 2018 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/bayesian-deep-learning-introduction/</guid>
      <description>들어가며 
Deep Learning의 범주는 넓지만 보통은 파라미터로 구성되어 있는 Neural Network를 떠올리게 된다. 그리고 수많은 Training Data가 주어져 있다. 뭘 해야 할까?
지금의 Deep Learning (아래 나오는 Bayesian Deep Learning이 아닌 것)은 데이터를 완벽히 신뢰하고, 데이터만을 보고 파라미터를 찾게 된다. 이러면 문제는 없을까?
요즘들어 관심사는 Uncertainty에 대한 탐구이다. Uncertainty는 네트워크가 입력에 대해서 모른다고 말하는 것이다. 이미지 분류 문제를 생각해 봐도, 물체 검출 문제를 생각해 봐도 모른다라는 정보는 매우 중요한 정보이다.</description>
    </item>
    
    <item>
      <title>GAN을 이용한 Image to Image Translation: Pix2Pix, CycleGAN, DiscoGAN</title>
      <link>https://taeoh-kim.github.io/blog/gan%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-image-to-image-translation-pix2pix-cyclegan-discogan/</link>
      <pubDate>Thu, 26 Oct 2017 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/gan%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-image-to-image-translation-pix2pix-cyclegan-discogan/</guid>
      <description>Computer Vision and Machine Learning Study Post 6 GAN을 이용한 Image to Image Translation: Pix2Pix, CycleGAN, DiscoGAN 
줄기가 되는 Main Reference Paper입니다.
 Pix2Pix: Image-to-Image Translation with Conditional Adversarial Networks, Phillip Isola, Jun-Yan Zhu, Tinghui Zhou and Alexei A. Efros, CVPR 2017 CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, Jun-Yan Zhu, Taesung Park, Phillip Isol a and Alexei A. Efros, ICCV 2017 DiscoGAN: Learning to Discover Cross-Domain Relations with Generative Adversarial Networks, Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee and Jiwon Kim, ICML 2017  각 Paper의 Github입니다, 모두 Pytorch로 구현되었습니다.</description>
    </item>
    
    <item>
      <title>Cross Entropy의 정확한 확률적 의미</title>
      <link>https://taeoh-kim.github.io/blog/cross-entropy%EC%9D%98-%EC%A0%95%ED%99%95%ED%95%9C-%ED%99%95%EB%A5%A0%EC%A0%81-%EC%9D%98%EB%AF%B8/</link>
      <pubDate>Tue, 26 Sep 2017 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/cross-entropy%EC%9D%98-%EC%A0%95%ED%99%95%ED%95%9C-%ED%99%95%EB%A5%A0%EC%A0%81-%EC%9D%98%EB%AF%B8/</guid>
      <description>Computer Vision and Machine Learning Study Post 6 Cross Entropy의 정확한 확률적 의미 
김성훈 교수님의 딥러닝 강의를 듣다 보면, Logistic Regression으로 넘어가면서 Cross Entropy라는 Loss Function을 사용하게 된. 하지만, 이 부분에 대해서 깊은 고찰이 없이 넘어가게 되고, 나중에 왜 Cross Entropy를 사용하나요? 그게 Convex한가요? 에 대한 대답은 명쾌하지가 않았다.
이번 글에서는 의미론적인, 즉 정보 이론(Information Theory)에서 다루는 Entropy로서의 Cross Entropy가 아니라, 확률적으로 정확하게 유도되는 Cross Entropy식의 의미와, Logistic Regression의 해를 구하는 과정에 대해서 다뤄보고자 한다.</description>
    </item>
    
    <item>
      <title>Bayes Theorem과 Sigmoid와 Softmax사이의 관계</title>
      <link>https://taeoh-kim.github.io/blog/bayes-theorem%EA%B3%BC-sigmoid%EC%99%80-softmax%EC%82%AC%EC%9D%B4%EC%9D%98-%EA%B4%80%EA%B3%84/</link>
      <pubDate>Fri, 22 Sep 2017 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/bayes-theorem%EA%B3%BC-sigmoid%EC%99%80-softmax%EC%82%AC%EC%9D%B4%EC%9D%98-%EA%B4%80%EA%B3%84/</guid>
      <description>Computer Vision and Machine Learning Study Post 5 Bayes Theorem과 Sigmoid와 Softmax사이의 관계 
Reference는 다음과 같습니다.
 Pattern Recognition and Machine Learning, Bishop, 2006  
1. Bayes Theorem 
$$ P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)} $$
위 식에서 좌변은 사후 확률 Posterior라고 부르고, P(X|Y)는 Likelihood 또는 Class-conditional Data Distribution, P(Y)는 Prior 그리고 P(X)는 Evidence라고 부른다.
여기서 X를 Data, Y를 Classifiaction 문제의 Class로 본다면, Prior라는 것은 그 Class들의 분포가 어떻게 되어있는지에 대한 사전 지식을 의미하고, P(X|Y)는 각 Class에 속해 있는 Data의 확률 분포, 그리고 사후 확률 P(Y|X)는 새로운 데이타가 들어 왔을 경우 Y의 분포로, 이것으로 어떤 Class Y에 속할 지를 정할 수 있다.</description>
    </item>
    
    <item>
      <title>머신러닝에서의 확률 분포, 랜덤 변수 그리고 Maximum Likelihood</title>
      <link>https://taeoh-kim.github.io/blog/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%97%90%EC%84%9C%EC%9D%98-%ED%99%95%EB%A5%A0-%EB%B6%84%ED%8F%AC-%EB%9E%9C%EB%8D%A4-%EB%B3%80%EC%88%98-%EA%B7%B8%EB%A6%AC%EA%B3%A0-maximum-likelihood/</link>
      <pubDate>Wed, 20 Sep 2017 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%97%90%EC%84%9C%EC%9D%98-%ED%99%95%EB%A5%A0-%EB%B6%84%ED%8F%AC-%EB%9E%9C%EB%8D%A4-%EB%B3%80%EC%88%98-%EA%B7%B8%EB%A6%AC%EA%B3%A0-maximum-likelihood/</guid>
      <description>Computer Vision and Machine Learning Study Post 4 머신러닝에서의 확률 분포, 랜덤 변수 그리고 Maximum Likelihood 
Reference는 다음과 같습니다.
 Pattern Recognition and Machine Learning, Bishop, 2006 https://aai.kaist.ac.kr  
1. 우리는 왜 확률을 배우는가? 
머신 러닝 정의는, 관측된 Data(=Training Sample)로부터 Model을 설계하는 것이다.
확률적 개념이 들어간다면, 관측된 Data는 진짜 Data가 아니라 진짜 Data로부터 Random하게 Sampling된 Data일 뿐이다. 진짜 Data는 무한하며, 연속적이다. 진짜 Data가 관측된 Data로 오기 위해서는 Sampling이 필요하다.</description>
    </item>
    
    <item>
      <title>Tensorflow로 50줄짜리 Original GAN Code 구현하기</title>
      <link>https://taeoh-kim.github.io/blog/tensorflow%EB%A1%9C-50%EC%A4%84%EC%A7%9C%EB%A6%AC-original-gan-code-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/</link>
      <pubDate>Thu, 10 Aug 2017 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/tensorflow%EB%A1%9C-50%EC%A4%84%EC%A7%9C%EB%A6%AC-original-gan-code-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/</guid>
      <description>CVML Post 3 GAN Implementation in 50 Lines of Tensorflow Code 
코드는 이형민군의 깃허브 코드를 참조하였습니다. 맨 처음 GAN을 공부하실 때 도움이 될 것으로 희망합니다. Pytorch 코드는 여기를 참조하세요.
우선 Full-code는 맨 아래에서 정리하도록 하겠습니다.

1. GAN Easy Review 
여기서는 이론적인 내용은 전혀 없으며 100% 구현 중심의 설명이다. GAN을 간단하게만 Review해 보면, 결국 다음 두 Network를 정의한다.
 Noise z를 받아서 Fake Data를 만드는 Generator Real Data와 Fake Data를 구분하는 Discriminator  결국 중요한 것은 Loss Function과 Training 방법일 것이다.</description>
    </item>
    
    <item>
      <title>Generative Models Part 2: ImprovedGAN,InfoGAN,EBGAN</title>
      <link>https://taeoh-kim.github.io/blog/generative-models-part-2-improvedganinfoganebgan/</link>
      <pubDate>Thu, 27 Jul 2017 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/generative-models-part-2-improvedganinfoganebgan/</guid>
      <description>Computer Vision and Machine Learning Study Post 2 Generative Models Part 2: ImprovedGAN/InfoGAN/EBGAN 
Reference는 다음과 같습니다.
 Salimans, Tim, et al. &amp;ldquo;Improved techniques for training gans.&amp;rdquo; Advances in Neural Information Processing Systems. 2016. Chen, Xi, et al. &amp;ldquo;Infogan: Interpretable representation learning by information maximizing generative adversarial nets.&amp;rdquo; Advances in Neural Information Processing Systems. 2016. Zhao, Junbo, Michael Mathieu, and Yann LeCun. &amp;ldquo;Energy-based generative adversarial network.&amp;rdquo; arXiv preprint arXiv:1609.03126 (2016).</description>
    </item>
    
    <item>
      <title>Generative Models Part 1: VAE,GAN,DCGAN</title>
      <link>https://taeoh-kim.github.io/blog/generative-models-part-1-vaegandcgan/</link>
      <pubDate>Thu, 06 Jul 2017 16:11:10 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/generative-models-part-1-vaegandcgan/</guid>
      <description>Computer Vision and Machine Learning Study Post 1 Generative Models Part 1: VAE/GAN/DCGAN 
Reference는 다음과 같습니다.
 VAE: Kingma, Diederik P., and Max Welling. &amp;ldquo;Auto-encoding variational bayes.&amp;rdquo; arXiv preprint arXiv:1312.6114 (2013). GAN: Goodfellow, Ian, et al. &amp;ldquo;Generative adversarial nets.&amp;rdquo; Advances in neural information processing systems. 2014. DCGAN: Radford, Alec, Luke Metz, and Soumith Chintala. &amp;ldquo;Unsupervised representation learning with deep convolutional generative adversarial networks.&amp;rdquo; arXiv preprint arXiv:1511.06434 (2015).  정리에는 다음 자료들이 큰 도움이 되었습니다.</description>
    </item>
    
    <item>
      <title>첫 포스팅</title>
      <link>https://taeoh-kim.github.io/blog/%EC%B2%AB-%ED%8F%AC%EC%8A%A4%ED%8C%85/</link>
      <pubDate>Thu, 06 Jul 2017 15:38:25 +0900</pubDate>
      
      <guid>https://taeoh-kim.github.io/blog/%EC%B2%AB-%ED%8F%AC%EC%8A%A4%ED%8C%85/</guid>
      <description>실험 포스팅.</description>
    </item>
    
    <item>
      <title>contact</title>
      <link>https://taeoh-kim.github.io/contact/</link>
      <pubDate>Thu, 09 Mar 2017 13:23:28 +0800</pubDate>
      
      <guid>https://taeoh-kim.github.io/contact/</guid>
      <description>Contact Me. :)</description>
    </item>
    
    <item>
      <title>about</title>
      <link>https://taeoh-kim.github.io/about/</link>
      <pubDate>Thu, 09 Mar 2017 13:19:25 +0800</pubDate>
      
      <guid>https://taeoh-kim.github.io/about/</guid>
      <description>I am Taeoh Kim.
Since 2017, I&amp;rsquo;m a Ph.D. student at Yonsei university, Seoul, South Korea.
My Research Interests are Image Processing, Computer Vision and Machine Learning.
More Information: Curriculum Vitae

Updates 
Oct, 2018. International Conference on Image Processing (ICIP) 2018 in Greece, One Paper will be Presented.
Jan, 2018. International Conference on Electronics, Information and Communication (ICEIC) 2018 in USA, Two Papers were Presented.
Oct, 2017. Joined PR12, Youtube Deep Learning Paper Study in Korean.</description>
    </item>
    
  </channel>
</rss>