<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>꿈꾸는 태태태의 공간</title>
  
  <subtitle>taetaetae</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://taetaetae.github.io/"/>
  <updated>2019-05-12T15:15:54.915Z</updated>
  <id>https://taetaetae.github.io/</id>
  
  <author>
    <name>taetaetae</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  <image>
    <url>
      https://taetaetae.github.io/assets/images/profile.png
    </url>
  </image>
  
  <entry>
    <title>자바, 성능, 모니터링 테크세미나 정리 및 후기 (by 우아한 형제들)</title>
    <link href="https://taetaetae.github.io/2019/05/12/got-of-java-seminar/"/>
    <id>https://taetaetae.github.io/2019/05/12/got-of-java-seminar/</id>
    <published>2019-05-12T11:04:01.000Z</published>
    <updated>2019-05-12T15:15:54.915Z</updated>
    
    <content type="html"><![CDATA[<p>실무에서 자바 기반으로 개발을 하고 서비스를 운영을 하다보면 처음엔 아무런 문제가 없다가 사용자가 몰리는 등 이벤트성으로 트래픽이 많아질 경우 꼭 문제가 생기기 마련이다. 그럴때면 뒤늦게 부랴부랴 원인을 찾고 개선하기 바빠지게 된다.  <a id="more"></a> (아마 윗분들에게 혼나면서?ㅠㅠ)<br>평소에 이런 성능문제를 개선하고 미리 모니터링 할수있는 부분에 대해 관심을 갖고 있었던 찰나, 우아한 형제들에서 <a href="https://www.facebook.com/woowahanTech/photos/a.1925530564354206/2280664485507477" target="_blank" rel="noopener">5월 우아한 테크 세미나</a>를 한다기에 부랴부랴 장문의 글로 신청을 하였고 운이 좋아 당첨이 되었다.<br>한창 회사에서 새로운 서비스 출시, 그리고 잠을 줄여가며 별도로 진행하고 있던 토이프로젝트 등 여러가지로 바쁜 시기였지만 특히 예전부터 뵙고싶던 이상민님께서 직접 강의를 해주신다기에 피곤한 심신을 이끌고 세미나에 참석하였고 그 후기를 적어보고자 한다.</p><blockquote><p>두레이로 만드신 발표자료를 공유해 주셨지만 저작권 문제도 있고 해서 필자기준에서 이해한 부분에 대해서만 공유하고자 한다. 더불어 그냥 듣고 앵무새처럼 발표내용 그대로를 공유하는건 의미가 없다고 생각되어…</p></blockquote><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="1.jpg" title="포스터만 봐도 벌써부터 가슴이 뛴다(?)." data-caption="포스터만 봐도 벌써부터 가슴이 뛴다(?)." data-fancybox="default"><img class="fig-img" src="1.jpg" alt="포스터만 봐도 벌써부터 가슴이 뛴다(?)."><span class="image-caption">포스터만 봐도 벌써부터 가슴이 뛴다(?).</span></a><span class="caption">포스터만 봐도 벌써부터 가슴이 뛴다(?).</span></div><div style="clear:both;"></div><h3 id="성능"><a href="#성능" class="headerlink" title="# 성능"></a># 성능</h3><p>구글에서 작성한 <a href="https://developers.google.com/web/fundamentals/performance/why-performance-matters/" target="_blank" rel="noopener">성능이 중요한 이유</a> 라는 아티클을 공유해 주셨다. (시간이 된다면 한번 읽어보길 강추, 무려 한글!) 어플리케이션에서 성능은 사용자의 증가, 이탈율, 응답속도에 영향이 있고 이는 결국 추구하는 가치(이를 테면 수익)에 직면한다고 한다.<br>사용자는 어느 관점에서 바라보는가에 따라 달라지고 각 관점에 따라 성능을 챙겨야 하는 부분이 달라진다. 수강신청을 하는 시점에서의 사용자와 뉴스 페이지를 읽는 시점에서의 사용자는 각 성격이 엄연히 다른것처럼. </p><ul><li>시스템 관리자<ul><li>등록된 / 등록되지 않은 사용자</li></ul></li><li>서버 관점<ul><li>로그인된 / 로그인 하지 않은 사용자</li></ul></li><li>성능 테스터 관점<ul><li>Active User<ul><li>서버에 부하를 주는 사용자</li><li>메뉴나 링크를 누르고 결과가 나오기를 기다리는 사용자</li><li>성능테스트시 Vuser와 거의 동일 ( Vuser : 가상사용자(virtual user) )</li></ul></li><li>Concurrent user<ul><li>서버에 부하를 주고 있거나, 줄 가능성이 매우높은 서비스에 접속중인 사용자</li><li>웹 페이지를 띄워놓은 사용자</li></ul></li></ul></li></ul><p>TPS(Transaction Per Seconds)는 초당 얼마나 많은 요청을 처리할수 있는지에 대한 시스템의 절대적인 수치로 볼수있다. (개발자는 어느상황에서든지 대충 감으로 이야기 하지말고 정확한 수치로 이야기 해야한다는 뼈를 때리는 조언과 함께…)  TPS는 Scale out/up을 통해 증가시킬수 있지만 Response Time 은 불가능하다. 물론 어플리케이션을 튜닝하면 두 수치 모두 개선이 가능하다. 이러한 TPS와 Response Time의 최대치는 출시전에 반드시 테스트를 통해 알고 있어야 이슈발생시 대응하는데 유용하다.<br>Bottleneck 즉 병목은 장비, 어플리케이션, 저장소, 설정 등 다양한 상황에서 발생할수 있다. 그중에 “아주 일반적”으로 가장 병목이 많이 발생하는 구간은 DB이고 그 다음으로 클라이언트(Web page, App), Network이 있을 수 있다.<br>결론은 <strong>Performance engineering is “Composite Art” of IT</strong> 라는 하나의 문장으로 정리를 해주셨다. 아무리 이쁜 디자인과 어렵고 복잡한 기능이 있을지라도 성능이 뒷받침 안된다면 대용량 트래픽 상황에서는 무의미해지기 때문이라고 생각한다.</p><h2 id="자바"><a href="#자바" class="headerlink" title="# 자바"></a># 자바</h2><p>자바의 역사에 대해 설명해 주셨다. ( 역사에 대한 보다 자세한 설명은 <a href="https://www.whatap.io/blog/12/" target="_blank" rel="noopener">https://www.whatap.io/blog/12/</a> 참고 ) 언제부터인가 JDK 라이센스 이슈가 많았었는데 실무에서 개발하는 입장에서는 java 8 에서는 문제가 안되고 java 11부터 라이센스 문제가 복잡하게 생길수 있다고 한다. 이부분은 공식문서(?)를 찾아보는게 좋을듯 하다. (개인 또는 회사에서 사용할 경우 상황에 따라 법적 이슈가 생길수도, 안생길수도 있는 복잡한 문제가 있어보여서… 필자도 제대로 이해하지는 못했다ㅠ)</p><p>그리고 각 자바 버전에서 발표한 새로운 기능에 대해 설명해주셨다.</p><ul><li>Java 8<ul><li>lambda, stream, default method, LocalDate / LocalTime 추가</li><li>stream 과 foreach 의 성능은 거의 차이 없음 (오히려 가독성이 나빠질수도 있다.)</li><li>ParallelStream 은 해당 장비의 cpu 개수만큼 스레드 풀을 만들어 사용 (오히려 독이 될수 있으니 잘 알아보고 사용할것)</li></ul></li><li>Java 9<ul><li>Compact Strings : char[] &gt; byte[]</li><li>G1 default GC : <a href="https://www.oracle.com/technetwork/tutorials/tutorials-1876574.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/tutorials/tutorials-1876574.html</a></li><li>Collections of (불변) : List.of, Set.of, Map.of</li></ul></li><li>Java 10<ul><li>var 의 등장</li><li>Application Class-Data Sharing(AppCDS)</li></ul></li><li>Java 11<ul><li>Oracle JDK의 유료화</li><li>Http Client. 기본 설정값들을 제대로 알고 써야한다. ( <a href="https://golb.hplar.ch/2019/01/java-11-http-client.html" target="_blank" rel="noopener">https://golb.hplar.ch/2019/01/java-11-http-client.html</a> )</li></ul></li><li>Java 12<ul><li>Switch expressions</li><li>Shenandoah : <a href="https://www.youtube.com/watch?v=E1M3hNlhQCg" target="_blank" rel="noopener">https://www.youtube.com/watch?v=E1M3hNlhQCg</a></li></ul></li></ul><h2 id="모니터링"><a href="#모니터링" class="headerlink" title="# 모니터링"></a># 모니터링</h2><p>유명한 상용 APM들을 설명해 주셨다. 각각의 장점에 대해 설명해 주셨는데 정말 회사에 요청해 구매할수만 있다면 사서 해보고 싶을정도로 신기한 기능이 많았다. 그중 dynatrace 는 에이전트만 설치해두면 별도의 설정 필요없이 알아서 해준다고…</p><ul><li>dynatrace (<a href="https://www.dynatrace.com/" target="_blank" rel="noopener">https://www.dynatrace.com/</a>)</li><li>new relic (<a href="https://newrelic.com/" target="_blank" rel="noopener">https://newrelic.com/</a>)</li><li>AppDynamics (<a href="https://www.appdynamics.com/" target="_blank" rel="noopener">https://www.appdynamics.com/</a>)</li><li>WhaTap (<a href="https://www.whatap.io/" target="_blank" rel="noopener">https://www.whatap.io/</a>)</li></ul><p>오픈소스로는 스카우터와 핀포인트를 설명해 주셨다. 필자는 핀포인트로 회사 서비스를 모니터링 중에 있는데 스카우터에도 좋은 기능이 많아 보여 기회가 된다면 개발서버에 설치해서 핀포인트와 각각 장단점을 비교해 보고 싶어질 정도로 스카우터 자랑을 엄청 해주셨다. (NHN에서는 스카우터로 모니터링 하고 있다고 하니 더욱더 관심이 가게 되었다.)</p><ul><li>scouter (<a href="https://github.com/scouter-project/scouter" target="_blank" rel="noopener">https://github.com/scouter-project/scouter</a>)</li><li>pinpoint (<a href="https://github.com/naver/pinpoint" target="_blank" rel="noopener">https://github.com/naver/pinpoint</a>)</li></ul><p>APM 즉, Application Performance Management의 핵심은 바로 <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.instrument/java/lang/instrument/package-summary.html" target="_blank" rel="noopener">java.lang.instrument</a> package 와 <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.instrument/java/lang/instrument/ClassFileTransformer.html" target="_blank" rel="noopener">Java ClassFileTransformer</a> 에 있다고 하셨다. 마치 Spring의  AOP처럼.</p><p>이번 세션의 결론은 처음에 이야기 하신 부분과 비슷한 “절대로 단정짓지 마라 ! 데이터로 이야기 하자 !” 라는 문장으로 정리를 해주셨다. 그만큼 테스트를 많이 해보고 평소에 모니터링을 자주 해가며 서비스의 안정성을 높여야 한다는 뜻으로 이해했다.<br>끝으로 Q&amp;A가 있어 평소에 궁금했던 질문을 드렸고 너무 친절하게 화이트보드에 그래프를 그려주시면서 (원래 강의시간보다 30분정도 더 하게 만든 장본인…ㅠㅠ) 답변을 해주셨다.</p><p>Q. Application의 상태를 확인하기 위해 각종 모니터링 툴을 활용하는데, 오히려 모니터링이 과하다 보면 Application 성능에 영향을 주게 된다. 어떻게 해야하는가?</p><p>A. 모니터링툴을 홍보하는 쪽에서는 당연히 성능에 영향이 없다고 한다. 하지만 먼저 개발서버에서 테스트를 해봐서 모니터링툴이 있고 없고의 서비 리소스의 차이를 확인해보고 조금씩 적용범위를 늘려가는 식으로 해보는것도 하나의 방법이 될 수 있다. 또한 샘플링을 통해 일부분만 확인하는 방법도 있다. (필자가 이용하는 pinpoint는 request의 20% 이런식으로 샘플링을 하고 있었는데 scouter에서는 response time기준으로 샘플링이 되나보다?ㄷㄷ)</p><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="2.jpg" title="너무 두서없이 적었나..." data-caption="너무 두서없이 적었나..." data-fancybox="default"><img class="fig-img" src="2.jpg" alt="너무 두서없이 적었나..."><span class="image-caption">너무 두서없이 적었나...</span></a><span class="caption">너무 두서없이 적었나...</span></div><div style="clear:both;"></div><p>그리고 필자의 질문 때문이였는지 실무에서 있었던 장애시 그래프 사례를 보여주시며 끔찍한(?) 상황까지 재밌게 표현해 주시며 약 3시간여 진행된 세미나가 마무리 되었다.</p><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><p>자바로 Application개발을 하면서 성능과 모니터링은 마치 삼겹살엔 소주, 치킨에 맥주처럼 정말 떼려야 뗄 수 없는 사이인것 같다. 우아한 형제들에서 주최한 이번 기술 세미나는 필자에게 정말 많은것을 배우게 해준 좋은 행사였다. 그리고 회사에 가면 짬나는 시간을 활용해서 스카우터로 성능테스트를 해볼 계획이다. (라고 말하면 안되고 점심에 졸려서 성능테스트를 해봤다고 말해야 직장 상사가 좋아하신다 라고 말씀해주셨다 ㅎㅎ)</p><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="3.jpg" title="질문을 해야 내것이 된다는 나와의 약속을 이번에도 지킬수 있었다! (질문하고 받은 배달의 민족 쿠폰!)" data-caption="질문을 해야 내것이 된다는 나와의 약속을 이번에도 지킬수 있었다! (질문하고 받은 배달의 민족 쿠폰!)" data-fancybox="default"><img class="fig-img" src="3.jpg" alt="질문을 해야 내것이 된다는 나와의 약속을 이번에도 지킬수 있었다! (질문하고 받은 배달의 민족 쿠폰!)"><span class="image-caption">질문을 해야 내것이 된다는 나와의 약속을 이번에도 지킬수 있었다! (질문하고 받은 배달의 민족 쿠폰!)</span></a><span class="caption">질문을 해야 내것이 된다는 나와의 약속을 이번에도 지킬수 있었다! (질문하고 받은 배달의 민족 쿠폰!)</span></div><div style="clear:both;"></div><p>1,2 회 모두 탈락해서 못들었지만 다음에도 이런 기술관련 행사가 있으면 꼭 듣고 싶고 마지막으로 필자에 질문에 너무 성실하게 답변해 주시고 재밌고 귀에 쏙쏙 들어오는 강연을 해주신 이상민님께 이 포스팅으로나마 다시한번 감사의 말씀을 전하고 싶다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;실무에서 자바 기반으로 개발을 하고 서비스를 운영을 하다보면 처음엔 아무런 문제가 없다가 사용자가 몰리는 등 이벤트성으로 트래픽이 많아질 경우 꼭 문제가 생기기 마련이다. 그럴때면 뒤늦게 부랴부랴 원인을 찾고 개선하기 바빠지게 된다.
    
    </summary>
    
      <category term="review" scheme="https://taetaetae.github.io/categories/review/"/>
    
    
      <category term="java" scheme="https://taetaetae.github.io/tags/java/"/>
    
      <category term="performance" scheme="https://taetaetae.github.io/tags/performance/"/>
    
      <category term="monitoring" scheme="https://taetaetae.github.io/tags/monitoring/"/>
    
  </entry>
  
  <entry>
    <title>spring-boot에서 mybatis로 mysql 연동하기</title>
    <link href="https://taetaetae.github.io/2019/04/21/spring-boot-mybatis-mysql-xml/"/>
    <id>https://taetaetae.github.io/2019/04/21/spring-boot-mybatis-mysql-xml/</id>
    <published>2019-04-21T13:47:04.000Z</published>
    <updated>2019-04-21T16:17:03.045Z</updated>
    
    <content type="html"><![CDATA[<p>실무에서 개발을 하다보면 과거 누군가 잘 구성해 놓은 밥상(legacy)에 숟가락만 얹는 느낌으로 <code>로직 구현</code>만 할때가 있다. 그러다보면 각종 레이어가 어떻게 구성(설정)되어있는지도 모르고 <a id="more"></a> 간혹 설정에서 문제가 발생하면 “아 내가 이것도 모르고 이제까지 개발을 해왔나” 하는 자괴감이 들며 몇시간을 삽질하는 경우가 있다. 그게 지금의 필자인것 같다. (눙물…)<br><div class="figure center" style="width:;"><a class="fancybox" href="mung.jpg" title="<br>출처 : http://blog.naver.com/PostView.nhn?blogId=ondo_h&logNo=221437452142" data-caption="<br>출처 : http://blog.naver.com/PostView.nhn?blogId=ondo_h&logNo=221437452142" data-fancybox="default"><img class="fig-img" src="mung.jpg" alt="<br>출처 : http://blog.naver.com/PostView.nhn?blogId=ondo_h&logNo=221437452142"><span class="image-caption"><br>출처 : http://blog.naver.com/PostView.nhn?blogId=ondo_h&logNo=221437452142</span></a><span class="caption"><br>출처 : http://blog.naver.com/PostView.nhn?blogId=ondo_h&logNo=221437452142</span></div><div style="clear:both;"></div></p><p>사이드 프로젝트 초기셋팅을 하며 호기롭게 spring boot 최신버전에서 db를 연동하려 했는데 막상 완전 바닥부터 해본 경험이 적다보니 (spring boot 2 버전에서는 더욱더…) 어디서부터 뭘 설정을 해야할지… 그리고 <code>이럴때 보는</code> 도큐먼트를 봐도 잘 이해가 안되어 삽질을 해가며 당황하기 일쑤였다.<br>이번 포스팅에서는 아래와 같은 구성을 하는데 목표를 두고자 한다.</p><ul><li>Spring Boot 2 프로젝트를 처음 만들고 </li><li>mybatis 를 사용해서</li><li>mysql 을 연동하는것 (AWS 의 RDS를 사용, 추후 RDS사용법에 대해 블로깅 예정)</li></ul><p>위와 같은 상황을 처음 접하는 분들께 도움이 되었으면 하는 바램으로 짧게나마 필자의 삽질기를 여행해보자.</p><h3 id="Spring-boot-2-프로젝트-만들기"><a href="#Spring-boot-2-프로젝트-만들기" class="headerlink" title="# Spring boot 2 프로젝트 만들기"></a># Spring boot 2 프로젝트 만들기</h3><p>필자는 IntelliJ를 사용하고 있어서 새로 프로젝트를 만들려고 할때 클릭 몇번만으로 dependency 설정까지 다 해주기 때문에 편하고 좋았다. 혹 이클립스나 다른 IDE를 사용하고 있다면 <a href="https://start.spring.io/" target="_blank" rel="noopener">https://start.spring.io/</a> 을 참고하면 도움이 될것같다. 여기서도 클릭 몇번으로 IntelliJ 에서 해주는 것처럼 내가 사용할 모듈을 선택하고 generate 를 누르면 프로젝트가 생성되어 다운로드 받아진다. (참 좋은 세상…)<br>우선 File → New → Project 를 눌러서 아래 창을 열어보자. 그리고 뭔가 다 해줄것 같은 (개발도 해주면 안되나…) <code>Spring Initializr</code>을 선택후 아래와 같은 설정을 적어준 뒤 다음을 눌러준다.</p><div class="figure center" style="width:;"><a class="fancybox" href="1.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="1.jpg" alt=""></a></div><div style="clear:both;"></div><p>사용할 모듈을 선택해주자. 필자는 이것저것(?)을 도와주는 <code>lombok</code>과 <code>Mybatis</code>, <code>MySQL</code>을 선택하고 프로젝트를 생성하였다. 그러면 이쁜(?) pom.xml 과 함께 당장 개발을 시작할 수 있는 환경이 제공된다.<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.spring.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></p><div class="figure center" style="width:;"><a class="fancybox" href="2.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="2.jpg" alt=""></a></div><div style="clear:both;"></div><p>우선 여기까지 잘 되었는제 확인해보기 위해 Controller 에 현재시간을 출력하는걸 만들어 보고<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ApiController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping</span>(path = <span class="string">"/helloWorld"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">helloWorld</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> LocalDateTime.now().format(DateTimeFormatter.ISO_LOCAL_DATE_TIME);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>톰켓을 실행해보면 정상적으로 접속과 출력이 되는것을 확인할 수 있다.</p><div class="figure center" style="width:;"><a class="fancybox" href="3.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="3.jpg" alt=""></a></div><div style="clear:both;"></div><h3 id="MySQL-연동하기"><a href="#MySQL-연동하기" class="headerlink" title="# MySQL 연동하기"></a># MySQL 연동하기</h3><p>필자가 허둥지둥 했던점 중 하나는 MyBatis와 MySQL을 동시에 연동하려고 하다보니 문제가 발생해도 어디서의 문제인지를 제대로 파악하지 못하고 삽질했다는 점이다. 여기서 정확히 짚고 넘어가면 우선 데이터를 연결해주는 ORM인 MyBatis를 셋팅해준 다음 MySQL을 연동해주는 식으로 분리해서 설정을 하면 햇갈리지 않고 (돌아가지 않고) 보다 빠르게 설정이 가능할것 같다. (여기서 순서는 중요하지 않고 별도로 설정해야 한다는 관점이 중요한것 같다.)<br>우선 <code>src/main/resources</code>폴더에 있는 <code>application.properties</code> 에 다음처럼 작성해주자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spring.datasource.hikari.driver-class-name=com.mysql.cj.jdbc.Driver</span><br><span class="line">spring.datasource.hikari.jdbc-url=jdbc:mysql://&#123;url&#125;:&#123;port&#125;/&#123;db&#125;</span><br><span class="line">spring.datasource.hikari.username=&#123;id&#125;</span><br><span class="line">spring.datasource.hikari.password=&#123;password&#125;</span><br></pre></td></tr></table></figure></p><p>위의 jdbc-url 항목에서 AWS에서 제공하는 RDS를 사용하는 경우 RDS에서 제공해주는 엔드포인트와 포트를 적어주면 된다. (추후 AWS - RDS에 대해 블로깅 예정이다.)<br>Spring Boot 2.0 이후부터 기본적으로 사용되는 커넥션 풀이 HikariCP로 변경되었다고 한다. (<a href="https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-2.0-Release-Notes#hikaricp" target="_blank" rel="noopener">링크</a>) 커넥션 풀 종류중 성능이 좋다고 하는데 <a href="https://github.com/brettwooldridge/HikariCP" target="_blank" rel="noopener">링크</a>를 가보면 다른 커넥션 풀 라이브러리와 성능을 비교한 벤치마크 결과를 확인할 수 있다.<br>위처럼 <code>spring.datasource.hikari</code> 가 prefix로 붙고 각종 정보들을 적어주어 config 에서 인식될수 있도록 해주자. 그 다음 DataSource 설정을 해준다.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@PropertySource</span>(<span class="string">"classpath:/application.properties"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DatabaseConfiguration</span> </span>&#123;</span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="meta">@ConfigurationProperties</span>(prefix = <span class="string">"spring.datasource.hikari"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> HikariConfig <span class="title">hikariConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> HikariConfig();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> DataSource <span class="title">dataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">DataSource dataSource = <span class="keyword">new</span> HikariDataSource(hikariConfig());</span><br><span class="line">log.info(<span class="string">"datasource : &#123;&#125;"</span>, dataSource);</span><br><span class="line"><span class="keyword">return</span> dataSource;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>위 내용은 DataSource 를 hikariConfig에서 설정한 정보로 만들어 준다는 의미이다. 이렇게만 하고 프로젝트를 다시 실행시켜보면 logger 에 의해 datasource 의 정보를 볼수가 있다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-04-22 00:27:35.048  INFO 23040 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...</span><br><span class="line">2019-04-22 00:27:36.221  INFO 23040 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.</span><br><span class="line">2019-04-22 00:27:36.222  INFO 23040 --- [           main] c.e.m.config.DatabaseConfiguration       : datasource : HikariDataSource (HikariPool-1)</span><br><span class="line">2019-04-22 00:27:36.527  INFO 23040 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService &apos;applicationTaskExecutor&apos;</span><br></pre></td></tr></table></figure></p><p>여기까지 우선 Datasource 설정이 끝났다.<br>Q : <code>com.mysql.cj.jdbc.Driver</code> 에서 <code>cj</code>가 뭐지?<br>A : 해당 클래스는 더이상 사용하지 않아 <code>com.mysql.jdbc.Driver</code>로 설정하고 실행시켜보면 아래 문구를 볼수가 있다.</p><blockquote><p>Loading class `com.mysql.jdbc.Driver’. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver’. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.</p></blockquote><p>당황하지 말고 클래스를 바꿔주자.</p><h3 id="MyBatis-연동하기"><a href="#MyBatis-연동하기" class="headerlink" title="# MyBatis 연동하기"></a># MyBatis 연동하기</h3><p>DB를 연동했으니 이제 쿼리를 작성하고 원하는 결과를 얻기위해 MyBatis를 활용할 차례다. 위에서 작성한 <code>DatabaseConfiguration</code>에 추가로 다음과 같이 작성해주자.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DatabaseConfiguration</span> </span>&#123;</span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> ApplicationContext applicationContext;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> SqlSessionFactory <span class="title">sqlSessionFactory</span><span class="params">(DataSource dataSource)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">SqlSessionFactoryBean sqlSessionFactoryBean = <span class="keyword">new</span> SqlSessionFactoryBean();</span><br><span class="line">sqlSessionFactoryBean.setDataSource(dataSource);</span><br><span class="line">sqlSessionFactoryBean.setMapperLocations(applicationContext.getResources(<span class="string">"classpath:/mapper/**/*.xml"</span>));</span><br><span class="line"><span class="keyword">return</span> sqlSessionFactoryBean.getObject();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> SqlSessionTemplate <span class="title">sqlSessionTemplate</span><span class="params">(SqlSessionFactory sqlSessionFactory)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> SqlSessionTemplate(sqlSessionFactory);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>이 설정은 위에서 설정한 datasource를 사용하고 쿼리가 작성되는 xml위치를 지정해 줌으로써 추후 <code>Mapper</code> or <code>DAO</code> 레벨에서 사용되는 쿼리를 인식해주는 과정이다. 여기서 <code>classpath</code>는 <code>src/main/resourcs</code>이고 해당 쿼리가 있는 xml 위치는 본인의 취향대로 위치키시고 그에 맞도록 설정해주면 된다.<br>이렇게 한뒤 MySQL Workbench 로 DB에 접속후 임의의 데이터를 생성한 다음<br><div class="figure center" style="width:;"><a class="fancybox" href="4.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="4.jpg" alt=""></a></div><div style="clear:both;"></div><br>DAO 를 만들어 주고 이를 호출해보면 정상적으로 데이터를 읽어오는것이 확인된다.</p><ul><li><p>DAO</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.express.magarine.api;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Repository;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ApiDao</span> </span>&#123;</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="keyword">final</span> String NAMESPACE = <span class="string">"com.express.magarine.api."</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> SqlSession sqlSession;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">selectName</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> sqlSession.selectOne(NAMESPACE + <span class="string">"selectName"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>query xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;</span><br><span class="line"><span class="meta">&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "mybatis-3-mapper.dtd"&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">"com.express.magarine.api"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"selectName"</span> <span class="attr">resultType</span>=<span class="string">"string"</span>&gt;</span></span><br><span class="line">SELECT name</span><br><span class="line">FROM test</span><br><span class="line">LIMIT 1</span><br><span class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>Controller</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ApiController</span> </span>&#123;</span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> ApiDao apiDao;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping</span>(path = <span class="string">"/helloWorld"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">helloWorld</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> String.format(<span class="string">"%s %s"</span>, apiDao.selectName(), LocalDateTime.now().format(DateTimeFormatter.ISO_LOCAL_DATE_TIME));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>결과</p><div class="figure center" style="width:;"><a class="fancybox" href="5.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="5.jpg" alt=""></a></div><div style="clear:both;"></div></li></ul><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><div class="figure center" style="width:;"><a class="fancybox" href="gvsc.png" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="gvsc.png" alt=""></a></div><div style="clear:both;"></div><p>이 코드를, 그리고 이 포스팅을 작성하기 직전까지만 해도 “그냥 하면 되는거 아니야?”라고 생각했지만 알고있는 지식과 막상 해보는건 정말 하늘과 땅차이 라는걸 다시한번 느끼게 되었다. (자괴감의 연속…) 더불어 Spring Boot 의 간편함에 놀라웠고 이제 회사일이 조금 잠잠해졌으니 (과연?) Spring Boot로 이것저것 만들며 스터디를 해야겠다고 다짐해본다.<br>참고 URL</p><ul><li><a href="https://spring.io/guides/gs/accessing-data-mysql/" target="_blank" rel="noopener">https://spring.io/guides/gs/accessing-data-mysql/</a></li><li><a href="http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/" target="_blank" rel="noopener">http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;실무에서 개발을 하다보면 과거 누군가 잘 구성해 놓은 밥상(legacy)에 숟가락만 얹는 느낌으로 &lt;code&gt;로직 구현&lt;/code&gt;만 할때가 있다. 그러다보면 각종 레이어가 어떻게 구성(설정)되어있는지도 모르고
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="mybatis" scheme="https://taetaetae.github.io/tags/mybatis/"/>
    
      <category term="spring-boot" scheme="https://taetaetae.github.io/tags/spring-boot/"/>
    
      <category term="mysql" scheme="https://taetaetae.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>AWS 프리티어 발급부터 EC2 접속까지</title>
    <link href="https://taetaetae.github.io/2019/04/14/aws-freetier-create-and-ssh-access/"/>
    <id>https://taetaetae.github.io/2019/04/14/aws-freetier-create-and-ssh-access/</id>
    <published>2019-04-14T08:39:03.000Z</published>
    <updated>2019-04-14T15:57:47.700Z</updated>
    
    <content type="html"><![CDATA[<p>IT 쪽에 일을 하고 있거나 관심을 가지고 있는 사람이라면 한번쯤을 들어봤을 AWS(Amazon Web Services). 이름에서도 알수있는 것처럼 아마존에서 제공하는 각종 원격 컴퓨팅 웹서비스이다. <a id="more"></a> 아마존은 이러한 서비스를 누구나 쉽게 접근해볼수 있도록 <a href="https://aws.amazon.com/ko/free/" target="_blank" rel="noopener">AWS 프리티어</a>를 제공해 주는데 이 프리티어 만으로도 과금없이 (또는 최소화 하여) 웹서비스를 구성할수 있다. 필자가 운영하고 있는 <a href="http://daily-devblog.com" target="_blank" rel="noopener">기술블로그 구독서비스</a>또한 AWS 프리티어로 운영되고 있다.<br>최근 GDG Seoul, P-typer, Sketch Seoul 에서 주최한 <a href="https://www.meetup.com/ko-KR/GDG-Seoul/events/259463050/" target="_blank" rel="noopener">D.light 345 투게더톤</a>에 참가하며 사이드 프로젝트를 하고 있는데 마침 AWS를 사용하게 되었다. 예전에 사용했을때는 장님 코끼리 만지듯이 설정을 했었는데 이번기회를 통해 다시한번 정리를 해본다.<br>본 포스팅에서는 AWS 계정을 발급받고 신용카드 확인까지 된 계정에서 EC2 서버를 발급받고 putty를 활용하여 서버에 접근을 해보는것을 목표로 둔다. </p><blockquote><p>(사이드 프로젝트를 하면서) 아마도 웹서비스를 개발하면서 AWS를 활용하는 부분에 대해 시리즈물로 포스팅을 하게 될것 같다.<br>사실 너무 간단해서 이런걸 글로 쓰나? 라고 할수도 있지만 눈으로만 보는것과 직접 해보는 것이 다르고, 이걸 다시 글로써 정리를 하는것 또한 완전 다른 부분이기 때문에 포스팅을 해본다.</p></blockquote><h3 id="EC2-생성하기"><a href="#EC2-생성하기" class="headerlink" title="# EC2 생성하기"></a># EC2 생성하기</h3><p>EC2? Amazon Elastic Compute Cloud의 약자로 물리서버가 아닌 클라우드 서버를 제공하고 있다. EC2의 장점은 서버의 스펙을 쉽고 자유롭게 조정할 수 있는점이 가장 매력있게 생각한다. 우선 콘솔에 들어가 EC2를 검색후 접속을 하고 <code>인스턴스 시작</code>을 눌러서 인스턴스 생성 화면으로 들어간다.<br><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="ec2-1.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="ec2-1.jpg" alt=""></a></div><div style="clear:both;"></div></p><p>AMI 즉 생성할 이미지를 선택하는 부분인데 여기서 주의할점은 잘못선택 했다간 계정 만들었을때의 카드로 생각지도 못할 금액이 결제가 되버릴수도 있다. (실제로 필자도 AWS를 처음 만져볼때 아무생각없이 좋아보이는걸로 했다가 한 30달러 정도를 지불했어야만 했다…) 좌측에 보면 <code>프리 티어만</code>이라는 체크박스를 체크하고 자신이 원하는 이미지를 선택하자. 일반적인 리눅스 서버를 발급받고 싶기 때문에 빨간 영역의 이미지를 선택하고 선택한 이미지의 스팩을 다시한번 확인하자. (cpu 1개에 메모리도 1기가… 너무 짜지만 무료니까…)<br><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="ec2-2.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="ec2-2.jpg" alt=""></a></div><div style="clear:both;"></div></p><p>마지막으로 <code>시작하기</code> 를 누르면 키 페어를 선택 또는 생성하도록 안내가 나오는데 당연히 아무것도 안한 상태라 <code>새 키 페어 생성</code>을 선택해 주고 이름을 지정한뒤 키 파일을 받아준다. 이 부분에서도 조심해야할 점이 키 페어를 한번 다운 받으면 다시 동일한 키 페어를 다운받을수가 없게 된다. (나중에 다시 발급을 받아야 하는 번거로운 문제가…) 다운을 받고 잊어버리지 않도록 잘 보관해두자.<br><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="ec2-3.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="ec2-3.jpg" alt=""></a></div><div style="clear:both;"></div></p><p>키 페어를 다운 받으면 생성중이라는 메세지와 함께 결과화면이 나온다. 여기서도 중요한 부분! <code>프리티어</code>라는 달콤한 키워드 때문에 들뜬 마음으로 성급하게 빨리 서버를 받아보고 싶다고 <code>다음다음 신공</code>을 하다보면 자칫 간과할수가 있는데 화면을 보면 <code>결제 알림 생성</code>이라는 다행스러운 기능이 있다. 별 어려운 설정이 아니니 꼭 설정을 해서 필자같이 기부(?)를 하는 일이 발생하지 않았으면 한다…<br><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="ec2-4.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="ec2-4.jpg" alt=""></a></div><div style="clear:both;"></div></p><p>EC2 인스턴스가 생성이 되었다. 인스턴스의 각종 정보를 확인할수가 있는데 public IP, public DNS 까지 제공되는것을 확인할 수 있다. (추후 DNS를 구입하게 되다면 이 IP에 연결을 시켜 도메인으로 해당 서버에 접속을 할수가 있게 된다.)<br><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="ec2-5.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="ec2-5.jpg" alt=""></a></div><div style="clear:both;"></div></p><h3 id="putty-로-발급받은-EC2-인스턴스에-접속을-해보자"><a href="#putty-로-발급받은-EC2-인스턴스에-접속을-해보자" class="headerlink" title="# putty 로 발급받은 EC2 인스턴스에 접속을 해보자."></a># putty 로 발급받은 EC2 인스턴스에 접속을 해보자.</h3><p>이제 발급받은 EC2 인스턴스에 접속을 해볼 차례이다. 다양한 서버 접속툴이 있지만 필자는 putty를 가장 선호한다. 디자인은 구닥다리처럼 보일지 모르겠지만 개인적으로 직관적인 UI에 가벼운 프로그램이라 생각이 든다. 우선 putty를 <a href="https://www.putty.org/" target="_blank" rel="noopener">다운</a> 받고 <code>putty.exe</code>를 실행시킨뒤에 바로 ssh 접속을 하면 너무 간단하게 서버 접속에 성공을 할수 있지만 위에서 받은 키 페어 파일을 다시 private key 로 전환해야 하는데 putty를 다운받으면 동일한 폴더에 <code>puttygen.exe</code>라는 파일을 실행시켜주자.<br>그다음 <code>pem</code>파일을 불러와서 마우스를 움직여서 게이지(?)를 다 채우고 <code>save private key</code>를 줄러 저장을 하는데 여기서 주의할점은 <code>ppk</code>파일명을 <code>pem</code>파일명과 동일하게 저장해야 한다는 것이다. (안그러면 서버 접속시 실패가 남… 삽질…)<br><div class="figure center" style="width:;"><a class="fancybox" href="putty-1.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="putty-1.jpg" alt=""></a></div><div style="clear:both;"></div> </p><p><code>putty.exe</code>를 실행시킨뒤 <code>Connection</code> &gt; <code>SSH</code> &gt; <code>Auth</code> 탭에서 방금 만들어 놓은 <code>ppk</code>파일을 불러오고, 다시 <code>Session</code>탭에서 host name 을 입력해주고 적당한 이름으로 저장을 눌러준다. 여기서 host name은 위에서 EC2 생성시 <code>Amazon Linux AMI</code>를 선택했기 때문에 사용자의 이름은 <code>ec2-user</code>가 되고 인스턴스의 정보중 public DNS와 함께 조합하여 다음과 같은 url을 적어준다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ec2-user@&#123;public DNS&#125;</span><br><span class="line">e.g. ec2-user@ec2-###.compute.amazonaws.com</span><br></pre></td></tr></table></figure></p><div class="figure center" style="width:;"><a class="fancybox" href="putty-2.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="putty-2.jpg" alt=""></a></div><div style="clear:both;"></div> <p>이렇게 하고 해당 세션을 더블클릭 또는 하단에 <code>Open</code>을 누르게 되면 해당 서버로 접속이 되는것을 확인할 수 있다.<br><div class="figure center" style="width:;"><a class="fancybox" href="putty-3.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="putty-3.jpg" alt=""></a></div><div style="clear:both;"></div><br>사실 기술을 배움에 있어 가장 훌륭한 도구는 제공되는 도큐먼트만한게 없다고 생각한다. 그에 필자의 블로그도 좋지만(?) 도큐먼트를 보면서 좀더 자세한 설명을 봐야 한다는 것을 강조하며 이번 포스팅을 마무리 해본다.<br>※ putty로 AWS EC2 접속하기 : <a href="https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/putty.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/putty.html</a></p><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><p>다양한 클라우드 서비스들중에 너무나도 신기할정도로 간편하게 클릭 몇번만으로 서버를 띄우고, 서버 접속없이 이또한 클릭 몇번만으로 어플리케이션을 운영할수도 있는 서비스들이 많다. 하지만 필자는 시스템 아키텍쳐를 구성할때엔 버튼 하나로 설치 및 셋팅되는 것보다 직접 설정을 건드려가며 소스로 설치하는 것을 선호한다. 그럼에 AWS의 EC2라는 서비스는 필자의 취향에 너무 알맞는 서비스라며 매력을 느끼고 있는 중이다.<br>사이즈 프로젝트를 진행하면서 보다 다양한 AWS 프리티어 활용기를 포스팅 할 수 있을것 같아 벌써부터 설렌다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;IT 쪽에 일을 하고 있거나 관심을 가지고 있는 사람이라면 한번쯤을 들어봤을 AWS(Amazon Web Services). 이름에서도 알수있는 것처럼 아마존에서 제공하는 각종 원격 컴퓨팅 웹서비스이다.
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="aws" scheme="https://taetaetae.github.io/tags/aws/"/>
    
      <category term="ec2" scheme="https://taetaetae.github.io/tags/ec2/"/>
    
      <category term="putty" scheme="https://taetaetae.github.io/tags/putty/"/>
    
  </entry>
  
  <entry>
    <title>KafkaKRU(Kafka 한국사용자 모임) 밋업 후기</title>
    <link href="https://taetaetae.github.io/2019/03/31/kafka-meetup-2019/"/>
    <id>https://taetaetae.github.io/2019/03/31/kafka-meetup-2019/</id>
    <published>2019-03-30T16:49:30.000Z</published>
    <updated>2019-04-01T01:39:51.177Z</updated>
    
    <content type="html"><![CDATA[<p>필자는 ElasticStack을 사용하면서 처음 카프카를 접하게 되었다. 메세징 큐 라는 개념도 전혀 모르는 상태에서 설치부터 ElasticStack 연동까지 사용하며 정말 <code>강제로</code> 카프카에 대해 공부를 하게 되었다. 카프카를 자주 다루고 메커니즘에 대해 자세히 살펴보다 잠깐 해이해질 무렵 카프카 한국 사용자 모임에서 밋업을 한다고 하길래 빛의 속도로 신청, 아마도 1등으로 신청했지 않았을까 싶다.<a id="more"></a><br>사실 작년 카프카 밋업을 못간게 너무 한(?)이 되어 이번엔 회사 업무 등 여러가지로 한창 바쁘지만 “지금이 아니면 안돼” 라는 생각으로 밋업을 다녀왔고, 짧지만 후기를 작성해 보고자 한다.</p><blockquote><p>(요즘 왜 이렇게 바쁜지 모르겠지만… 신기하게도 그 바쁜 일정들이 하나도 겹치지 않는게 더 신기하다… )</p></blockquote><div class="figure center" style="width:;"><a class="fancybox" href="first.jpg" title="삼성 SDS 건물에서 진행된 카프카 밋업" data-caption="삼성 SDS 건물에서 진행된 카프카 밋업" data-fancybox="default"><img class="fig-img" src="first.jpg" alt="삼성 SDS 건물에서 진행된 카프카 밋업"><span class="image-caption">삼성 SDS 건물에서 진행된 카프카 밋업</span></a><span class="caption">삼성 SDS 건물에서 진행된 카프카 밋업</span></div><div style="clear:both;"></div><p>참고로 필자는 카프카에 대해 아주 조금 건드려본 수준이라 발표하시는 분들의 전부를 습득하기엔 다소 그릇이 작아서 일부 세션은 거의 “그런가보다~” 하고 들을 수 밖에 없었다. 후기도 아마 그런 맥락으로 작성할듯 싶다.</p><ul><li>Kafka 한국 사용자 모임 링크 : <a href="https://www.facebook.com/groups/kafka.kru" target="_blank" rel="noopener">https://www.facebook.com/groups/kafka.kru</a></li></ul><h3 id="카프카를-활용한-캐시-로그-처리-김현준-카카오"><a href="#카프카를-활용한-캐시-로그-처리-김현준-카카오" class="headerlink" title="# 카프카를 활용한 캐시 로그 처리 - 김현준(카카오)"></a># 카프카를 활용한 캐시 로그 처리 - 김현준(카카오)</h3><ul><li>이미지 등 캐시서버의 로그를 분석하기 위한 시스템을 구축하는데 ElasticStack 을 활용</li><li>Elasticsearch 로 늦게 들어와서 사례를 찾아보니 대용량 로깅 처리시 앞단에 메세징 큐를 둬야 한다고 했고 그게 카프카</li><li>카프카 모니터링은 그라파나로 활용</li><li>lag이 자꾸 생김<ul><li>파티션을 쪼개거나, 컨슈머를 늘리는 방법이 있음</li><li>auto.commit.interval.ms 와 enable.auto.commit=true 로 조정</li><li>interval을 줄이니 lag이 줄어듬</li></ul></li><li>현재는 수백대 캐시서버의 로그를 초당 15만건 이상 처리중</li></ul><p>질문을 했다. 필자도 lag이 높아지면 어쩌지 하는 불안감과 높아지면 컨슈머를 늘리면 되겠지 하는 막연함이 있었는데 commit interval을 줄이면 lag이 줄어든다고 해서 무조건 줄이면 좋은가에 답변은 카프카를 관리하는 주키퍼쪽에 무리가 간다고 설명해 주셨다. 역시 만병통치약은 없고 상황에 따라 적절하게 시스템 관리자가 조정해가며 운영해야 하는점을 느꼈다.</p><ul><li>참고 URL : <a href="https://kafka.apache.org/documentation/#adminclientconfigs" target="_blank" rel="noopener">https://kafka.apache.org/documentation/#adminclientconfigs</a></li></ul><h3 id="카프카를-활용한-엘라스틱서치-실무프로젝트-소개-이은학-메가존"><a href="#카프카를-활용한-엘라스틱서치-실무프로젝트-소개-이은학-메가존" class="headerlink" title="# 카프카를 활용한 엘라스틱서치 실무프로젝트 소개 - 이은학(메가존)"></a># 카프카를 활용한 엘라스틱서치 실무프로젝트 소개 - 이은학(메가존)</h3><ul><li>카드사의 프로젝트를 약 3개월간 개발하였고 전체 아키텍쳐 중에 일부분을 kakfa를 활용</li><li>Elasticsearch 데이터를 hadoop에 백업 형태로 옮기며 관리</li><li>filebeat &gt; kafka &gt; spark streaming 을 활용하여 데이터의 검증처리가 가능 (특정 상황에서의 관리자에게 알림 등)</li><li>logstash 의 ruby 필터를 활용하여 일정의 작업을 해주는 데이터 파이프라인 구성 가능 (개인정보 식별 등)</li><li>logstash 는 cron형태의 배치로도 가능</li></ul><p>또 질문을 하였다. (카프카 밋업과는 무관했지만…) logastsh 를 사용하면서 필터쪽에 로직이 들어가면 성능상 괜찮냐는 질문에 하루에 15억건을 처리하고있고 문제가 없었다고 한다. 필자는 아파치 엑세스 로그를 logstash로 처리하면서 간혹 뻗거나 에러가 발생했는데 아마 파일을 logstash가 직접 바라보고 처리도 하게해서 그런것 같다. (지금은 filebeat가 shipper 역활을 수행하고 있고 큰 무리 없이 운영중)</p><h3 id="카프카를-활용한-rabbitMQ-로그처리-정원빈-카카오"><a href="#카프카를-활용한-rabbitMQ-로그처리-정원빈-카카오" class="headerlink" title="# 카프카를 활용한 rabbitMQ 로그처리 - 정원빈 (카카오)"></a># 카프카를 활용한 rabbitMQ 로그처리 - 정원빈 (카카오)</h3><ul><li>레빗엠큐는 erlang으로 구현된 AMQP 메시지 브로커이고 TCP기반으로 구성</li><li>Kafka 는 게으르지만 메우 효율성이 뛰어남, 반면 RabbitMQ 는 똑똑하지만 보다 느림</li><li>Kafka 에서 Elasticsearch 로의 ingset 는 NIFI를 활용</li><li>레빗엠큐와 카프카의 차이</li></ul><table><thead><tr><th></th><th>Kafka</th><th>RabbitMQ</th></tr></thead><tbody><tr><td>컨슈머 추가</td><td>여러 컨슈머가 하나의 메세지를 동시에 할수 있어 확장에 용이함</td><td>확장할때마다 큐를 추가 생성해야함</td></tr><tr><td>메세지 저장</td><td>로그기반으로 디스크에 저장, 리텐션 이후 삭제</td><td>큐 기반으로 메모리에 저장 컨슈머가 메세지 수신시 즉시 삭제</td></tr><tr><td>메세지 처리</td><td>발송확인 가능 / 수신확인 불가능</td><td>발송확인/수신확인 가능</td></tr></tbody></table><h3 id="카프카를-마이크로서비스-아키텍쳐에-활용하기-이동진-아파치-소프트웨어-파운데이션"><a href="#카프카를-마이크로서비스-아키텍쳐에-활용하기-이동진-아파치-소프트웨어-파운데이션" class="headerlink" title="# 카프카를 마이크로서비스 아키텍쳐에 활용하기 - 이동진 (아파치 소프트웨어 파운데이션)"></a># 카프카를 마이크로서비스 아키텍쳐에 활용하기 - 이동진 (아파치 소프트웨어 파운데이션)</h3><ul><li>카프카 스트림즈 소개 (Interactive Query)</li><li>카프카를 활용하여 마이크로서비스에서 사용하려면 데이터를 임시 공간에 넣어두고 (redis 같은?) 빼서 사용하는 형태가 아니라 Interactive Query 또는 Queryable Store 로 활용 가능</li></ul><p>사실 이부분은 필자가 제대로 못따라간 세션중에 하나이다. 용어나 메커니즘도 다소 생소했고 대략 어떤 부분을 발표해주시는지 느낌은 있었으나 제대로 이해를 못해서 …  부끄럽지만 카프카 스트림즈의 공식링크로 대체한다. </p><p><a href="https://kafka.apache.org/documentation/streams/" target="_blank" rel="noopener">https://kafka.apache.org/documentation/streams/</a></p><h3 id="카프카-프로듀서-amp-컨슈머-강한구-카카오-모빌리티"><a href="#카프카-프로듀서-amp-컨슈머-강한구-카카오-모빌리티" class="headerlink" title="# 카프카 프로듀서 &amp; 컨슈머 - 강한구 (카카오 모빌리티)"></a># 카프카 프로듀서 &amp; 컨슈머 - 강한구 (카카오 모빌리티)</h3><ul><li>프로듀서<ul><li>메세지를 생산 및 전송</li><li>Accumulator : 사용자가 send한 record를 메모리 쌓는 역활</li><li>Network thread : 전송</li><li>각 옵션 활용법 (도큐먼트 문서로 대체)<ul><li><a href="https://docs.confluent.io/current/installation/configuration/producer-configs.html#linger-ms" target="_blank" rel="noopener">linger.ms</a></li><li><a href="https://docs.confluent.io/current/installation/configuration/producer-configs.html#max-request-size" target="_blank" rel="noopener">max.request</a></li><li><a href="https://docs.confluent.io/current/installation/configuration/producer-configs.html#max-in-flight-requests-per-connection" target="_blank" rel="noopener">max.in.flight.requests.per.connection</a></li></ul></li></ul></li><li>브로커<ul><li>메세지를 저장</li><li>topic name - partition 폴더 구조</li><li>세그먼트 단위로 저장 (*.index, *.log, *.timeindex)</li></ul></li><li>컨슈머<ul><li>Fetcher : 네트워크 스레드와 비슷한 역할</li><li>Coordinator : 어떤 토픽의 어떤 파티션을 comsume할지, 브로커의 그룹 코디네이터와 통신 (hearbeat, offset comit, consumer group join)</li></ul></li></ul><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><div class="figure center" style="width:;"><a class="fancybox" href="meetup.jpg" title="발표자 분들과 질문 두번에서 받은 책선물" data-caption="발표자 분들과 질문 두번에서 받은 책선물" data-fancybox="default"><img class="fig-img" src="meetup.jpg" alt="발표자 분들과 질문 두번에서 받은 책선물"><span class="image-caption">발표자 분들과 질문 두번에서 받은 책선물</span></a><span class="caption">발표자 분들과 질문 두번에서 받은 책선물</span></div><div style="clear:both;"></div><p>확실히 수박 겉핥기 식으로  보다보니 지식에 대한 깊이도 얕아 발표자분이 전달하시고자 하는 내용을 100% 다 수용하기엔 힘들었다. 다음엔 가기전에 미리 밋업 발표에 대한 공부를 조금이라도 하고 들을 준비를 한 뒤에 참여하는것으로… 하지만 카프카를 활용해서 다양한 시스템 구성 방법론에 대해 간접으로라도 배울수 있었고, 현재 필자가 운영하고 있는 카프카의 설정값들을에 대해 잘 설정이 되어있나 (막연히 기본값들로만 설정되어 있지는 않은가) 살펴볼 계기가 만들어진것 같다. 이번에도 <code>다행히</code> “행사에 참여하면 꼭 질문을 하나이상 하자!” 라는 나와의 약속을 지킬수 있어 다행이었다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;필자는 ElasticStack을 사용하면서 처음 카프카를 접하게 되었다. 메세징 큐 라는 개념도 전혀 모르는 상태에서 설치부터 ElasticStack 연동까지 사용하며 정말 &lt;code&gt;강제로&lt;/code&gt; 카프카에 대해 공부를 하게 되었다. 카프카를 자주 다루고 메커니즘에 대해 자세히 살펴보다 잠깐 해이해질 무렵 카프카 한국 사용자 모임에서 밋업을 한다고 하길래 빛의 속도로 신청, 아마도 1등으로 신청했지 않았을까 싶다.
    
    </summary>
    
      <category term="review" scheme="https://taetaetae.github.io/categories/review/"/>
    
    
      <category term="kafka" scheme="https://taetaetae.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Write The Docs 서울 밋업 후기 (개발자 강추!)</title>
    <link href="https://taetaetae.github.io/2019/03/24/write-the-docs-seoul-2019-review/"/>
    <id>https://taetaetae.github.io/2019/03/24/write-the-docs-seoul-2019-review/</id>
    <published>2019-03-24T12:43:14.000Z</published>
    <updated>2019-03-25T01:51:33.407Z</updated>
    
    <content type="html"><![CDATA[<p>필자는 평소 개발자에게 가장 중요한 덕목 중 하나가 <code>글쓰기</code>라고 생각하고 있다. 마침 글쓰기와 기술의 접점을 고민하고 이야기하는 “Write The Docs 서울 밋업”(<a href="https://festa.io/events/191" target="_blank" rel="noopener">링크</a>) 이 있다고 하여 쉬고 싶던 주말이지만 만사를 집어치우고 참석하게 되었다. <a id="more"></a>사실 연예인 개발자분들을 직접 만날 수 있다는 기대감도 있었기 때문이다. (발표하시는 바로 앞자리에 앉았는데 정작 한마디도 못 건넸지만…)</p><div class="figure fig-75 center" style="width:;"><a class="fancybox" href="intro.jpg" title="밋업 가능길 문득 나를 사로잡았던 문구와 밋업 장소 마루 180" data-caption="밋업 가능길 문득 나를 사로잡았던 문구와 밋업 장소 마루 180" data-fancybox="default"><img class="fig-img" src="intro.jpg" alt="밋업 가능길 문득 나를 사로잡았던 문구와 밋업 장소 마루 180"><span class="image-caption">밋업 가능길 문득 나를 사로잡았던 문구와 밋업 장소 마루 180</span></a><span class="caption">밋업 가능길 문득 나를 사로잡았던 문구와 밋업 장소 마루 180</span></div><div style="clear:both;"></div><p>발표에 앞서 “이 발표 자료는 공개할 예정이니 필기하실 필요가 없다”라고 하셨다. 하지만 뒤통수를 (좋은 의미) 몇 대 아니 몇십대 맞은 느낌이라 정리를 하지 않을 수가 없었고 오늘 느끼고 배운 마음을 쭉 유지하고 싶어(내 것으로 만들고 싶어) 후기를 작성해 본다. 더불어 제목에 감히 개발자 강추!라고 적을만큼 최근 밋업 행사 중에 손꼽을 정도로 좋았기 때문이다.</p><div class="figure center" style="width:;"><a class="fancybox" href="action.gif" title="이정도로 쌔게 맞은건 아니다...<br>출처 : https://namu.moe/w/뒤통수" data-caption="이정도로 쌔게 맞은건 아니다...<br>출처 : https://namu.moe/w/뒤통수" data-fancybox="default"><img class="fig-img" src="action.gif" alt="이정도로 쌔게 맞은건 아니다...<br>출처 : https://namu.moe/w/뒤통수"><span class="image-caption">이정도로 쌔게 맞은건 아니다...<br>출처 : https://namu.moe/w/뒤통수</span></a><span class="caption">이정도로 쌔게 맞은건 아니다...<br>출처 : https://namu.moe/w/뒤통수</span></div><h3 id="변성윤-소카-글쓰는-개발자-모임-글또"><a href="#변성윤-소카-글쓰는-개발자-모임-글또" class="headerlink" title="# 변성윤(소카) - 글쓰는 개발자 모임, 글또"></a># 변성윤(소카) - 글쓰는 개발자 모임, 글또</h3><div class="figure fig-50 center" style="width:;"><a class="fancybox" href="session-1.jpg" title="변성윤 님" data-caption="변성윤 님" data-fancybox="default"><img class="fig-img" src="session-1.jpg" alt="변성윤 님"><span class="image-caption">변성윤 님</span></a><span class="caption">변성윤 님</span></div><div style="clear:both;"></div><p>필자도 가입만 하고 활동은 안 하는 중인 “글 쓰는 개발자 모임 - 글또” 모임에 대해 소개해주셨다. 글을 꾸준히 작성하기 위해 만들었고, 일정에 예치금을 내고 정해진 규칙에 의해 블로그에 글을 올리면 다시 돈을 환급받는 반강제적인 모임이라고 한다. 그뿐만 아니라 다른 분들이 글을 써서 공유를 하면 성윤님이 직접 피드백을 주며 개발 시 리팩토링을 하듯 더 나은 품질의 글을 쓸 수 있도록 도움을 주고 있다고 하신다. 이러한 피드백 문화가 1:N이 아닌 N:N이 되면 또 다른 동기부여가 될 것 같은데 … 하는 아쉬움을 느꼈다.<br>사실 “글을 꾸준히 작성”하는 부분이 필자도 매우 공감이 된다. 바쁘고, 귀찮고, 글을 쓰려면 욕심이 생기고 그러다 미루고… 그 동기부여가 “돈” 일수밖에 없는 현실이 아쉽긴 한데 오히려 그 “돈”만큼 동기부여가 잘 되는 것도 없을것 같다. (헬스장 1년 권 계약하고 돈이 아까워서라도 나가는 느낌으로…)<br>올해 새로운 기수를 모집한다고 하니 그때는 꼭 지원해서 글을 꾸준히 쓰는 습관을 길러보고 싶다.</p><h3 id="김대권-당근마켓-기술-블로그-생존-전략-구글-시대의-글쓰기"><a href="#김대권-당근마켓-기술-블로그-생존-전략-구글-시대의-글쓰기" class="headerlink" title="# 김대권(당근마켓) - 기술 블로그 생존 전략 : 구글 시대의 글쓰기"></a># 김대권(당근마켓) - 기술 블로그 생존 전략 : 구글 시대의 글쓰기</h3><div class="figure fig-50 center" style="width:;"><a class="fancybox" href="session-2.jpg" title="김대권 님" data-caption="김대권 님" data-fancybox="default"><img class="fig-img" src="session-2.jpg" alt="김대권 님"><span class="image-caption">김대권 님</span></a><span class="caption">김대권 님</span></div><div style="clear:both;"></div><p>얼마 전에 한번 쓱 보고 정독할 수밖에 없던 포스팅인 <a href="[https://www.44bits.io/ko/post/8-suggestions-for-tech-programming-blog](https://www.44bits.io/ko/post/8-suggestions-for-tech-programming-blog">좋은 기술 블로그를 만들어 나가기 위한 8가지 제언</a> 을 작성하시고, 해당 기술블로그 를 운영하시고 계시는 김대권 님께서 글을 왜 쓰는지, 그리고 어떻게 하면 사람들에게 잘 읽힐 수 있을지에 대해 구글 검색엔진 관점에서 정리해주셨다.<br>우리는 보통 읽히기 위해 공개된 글을 쓰기 때문에 좋은 글을 쓰는 게 선행되어야 하지만 반대로 어떻게 하면 잘 읽힐 수 있을지에 대해 고민이 필요한 부분 같다.  요즘은 소셜미디어나 검색을 통해 글이 공유되고 검색되는데 장기적으로 봤을 때는 검색엔진에 노출이 돼야 한다고 하신다.  또한 검색엔진은 백과사전처럼 정답을 알려주는것이 아닌 “거대한 추천 시스템”의 관점으로 접근해야 하며, 글의 양이 너무 크거나 적으면 안 되고 적당한(?) 수준을 지켜야 이를 검색엔진이 알아서 판단한다고 한다.<br>또한 <a href="[http://blog.weirdx.io/post/60414](http://blog.weirdx.io/post/60414">What nobody tells you about documentation (번역본)</a> 이라는 것도 소개해주시며 결국엔 글 내용의 자체가 좋아야 한다고 재차 강조하셨다. (매우 공감, SEO 아무리 잘 설정해봤자 내용이 안 좋으면 말짱 꽝)</p><h3 id="홍연의-LINE-To-지식-공유를-시작하려는-개발자-From-당신의-든든한-서포터-Developer-Relations팀"><a href="#홍연의-LINE-To-지식-공유를-시작하려는-개발자-From-당신의-든든한-서포터-Developer-Relations팀" class="headerlink" title="# 홍연의(LINE) - To. 지식 공유를 시작하려는 개발자, From. 당신의 든든한 서포터 Developer Relations팀"></a># 홍연의(LINE) - To. 지식 공유를 시작하려는 개발자, From. 당신의 든든한 서포터 Developer Relations팀</h3><div class="figure fig-50 center" style="width:;"><a class="fancybox" href="session-3.jpg" title="홍연의 님" data-caption="홍연의 님" data-fancybox="default"><img class="fig-img" src="session-3.jpg" alt="홍연의 님"><span class="image-caption">홍연의 님</span></a><span class="caption">홍연의 님</span></div><div style="clear:both;"></div><p>다소 생소한 Developer Relations 팀에 대해 소개를 해주시며 꼭 기술 관점이 아닌 다양한 분야에서 해당 팀이 어떤 지원을 해주고 있는지에 대해 알려주셨다. 기술 블로그 운영, 소셜 페이지 관리, 개발 컨퍼런스, 세미나, 커뮤니티 후원 등등 개발자와 개발 문화를 알리는 모든 일을 하고 있다고 한다.<br>옆 회사(?)이지만 저런 개발자의 문화를 만드는 팀이 있다는 게 부럽기도 하였고, 가끔 세미나가 있는 걸로 아는데 공개적으로 하면 어떨까 하는 아쉬움이 있지만… 점차 private에서 public으로 확대될 꺼라 기대를 해본다.<br>발표를 내가 직접 들으며 이러한 문화를 만들 수도 있겠구나 하는 생각도 해봤다. 작게는 팀 단위부터 시작해서 서버/앱 등 개발자들을 모아두고 관심 있는 사람들끼리 공유하는 자리를 정기적으로 만드는… 중요한 건 “정기적”으로… 일단 나부터라도 시작을 해보자.</p><h3 id="조은별-시큐아이-사용자를-외면하지-않는-릴리스-노트"><a href="#조은별-시큐아이-사용자를-외면하지-않는-릴리스-노트" class="headerlink" title="# 조은별(시큐아이) - 사용자를 외면하지 않는 릴리스 노트"></a># 조은별(시큐아이) - 사용자를 외면하지 않는 릴리스 노트</h3><div class="figure fig-50 center" style="width:;"><a class="fancybox" href="session-4.jpg" title="조은별 님" data-caption="조은별 님" data-fancybox="default"><img class="fig-img" src="session-4.jpg" alt="조은별 님"><span class="image-caption">조은별 님</span></a><span class="caption">조은별 님</span></div><div style="clear:both;"></div><p>테크니컬 라이터가 무슨 일을 하고 어떤 부분에서 고민을 하는지에 대해 소개를 해주셨다. 하나의 예로 앱스토어에서 릴리즈 노트를 보면 A라는 앱은 단순 “기능 개선”, “버그 수정” 인데 B라는 앱은 개발과 무관한 일반 사용자가 보더라도 상세히 적힌 걸 볼 수 있다. 이것만 봐도 그 앱에 대한 신뢰가 높아질 수 있는 부분이라고 생각할 수 있다는 점에서 나는 commit message, PR 등 너무 의미 없는 메세지들로 일관한 건 아닐까 하는 반성을 할 수 있었다. (뜬금스럽지만…)<br>프로야구의 더블플레이 룰이 올해부터 개정되는 것을 예로 들어주며 누가 읽고, 어떻게 읽으며 무엇을 읽는가에 대해 관점을 가지고 해당 사용자 시선에서 이해할 수 있도록 하는 게 가장 좋다고 설명해 주셨다. (이 분야 또한 리펙토링의 반복… )</p><h3 id="이동욱-우아한형제들-개발자는-왜-블로그를-해야하나요"><a href="#이동욱-우아한형제들-개발자는-왜-블로그를-해야하나요" class="headerlink" title="# 이동욱(우아한형제들) - 개발자는 왜 블로그를 해야하나요?"></a># 이동욱(우아한형제들) - 개발자는 왜 블로그를 해야하나요?</h3><div class="figure fig-50 center" style="width:;"><a class="fancybox" href="session-5.jpg" title="이동욱 님" data-caption="이동욱 님" data-fancybox="default"><img class="fig-img" src="session-5.jpg" alt="이동욱 님"><span class="image-caption">이동욱 님</span></a><span class="caption">이동욱 님</span></div><div style="clear:both;"></div><p>기술블로그를 어떻게 써야 하고 어떤 식으로 관리를 해야 하는지가 아닌 조금 더 강한 느낌의 “개발자는 기술블로그를 해야 한다” 의 이유를 설명해주셨다. 동욱님은 블로그를 통해 이직도 하고 기고&amp;집필 요청도 받으시고 인터뷰 요청도 받고…심지어 광고수입으로 매월 70~100달러가 들어온다고 한다. (필자의 몇 배인지 가늠도 안 간다…)<br>다양한 분야에서 얻은 이득이 많기 때문에 기술블로그를 해야 한다고 말하고 있고, 연봉/회사/직위/재산을 빼고 나를 표현할 수 있는 것이라고는 기술블로그밖에 없다고 한다. (극 공감) 필자도 서두에 말했던 것처럼 개발자는 글을 써야 한다고 하는 사람 중에 한 명이다 보니 동욱님의 발표 하나하나가 너무 몸 쪽 깊숙이 들어와서 글을 좀더 자주 + 잘 써야겠다고 다짐을 하게 되었다. 그리고 마지막에 말씀하신 중국 속담 하나가 아직까지 필자의 뒤통수를 계속 때리고 있다.<br><code>아무리 흐린 잉크라도 좋은 기억력보다 낫다</code></p><h3 id="변정훈-BlockchainOS-개발-관련-기술-블로그-운영하기"><a href="#변정훈-BlockchainOS-개발-관련-기술-블로그-운영하기" class="headerlink" title="# 변정훈(BlockchainOS) - 개발 관련 기술 블로그 운영하기"></a># 변정훈(BlockchainOS) - 개발 관련 기술 블로그 운영하기</h3><div class="figure fig-50 center" style="width:;"><a class="fancybox" href="session-6.jpg" title="변정훈 님" data-caption="변정훈 님" data-fancybox="default"><img class="fig-img" src="session-6.jpg" alt="변정훈 님"><span class="image-caption">변정훈 님</span></a><span class="caption">변정훈 님</span></div><div style="clear:both;"></div><p>국내에 몇 안되는, 오랫동안 기술블로그를 운영해오시는 개발자 중에 한분인 아웃사이더 변정훈님께서 어떤 식으로 기술블로그를 운영해야 하는가에 대해 발표해주셨다. 필자와는 다르게 (워낙 많이 쓰셔서 일것 같지만) 퇴고는 잘 안 하시고 항상 글을 작성할 것을 생각하며 개인 노트에 메모하고 글을 쓴다고 하신다. (필자도 얼마 전부터 <a href="https://notion.so/" target="_blank" rel="noopener">노션</a>이라는 것을 활용해서 관리하고 있는데… 잘 따라 하고 있는 것 같아 나름 뿌듯함을 느꼈다.)<br>이 세션에서도 뒤통수를 때리는 멘트가 많았는데… 괜히 유명하신 분이 아니구나 싶을 정도였다. (심지어 멘트마저…)</p><ul><li>공부할 시간도 적은데 블로그는 또 언제 쓰는가 &gt; 공부할게 많으니까 블로그를 쓴다. (캬~ 1)</li><li>글을 지속적으로 쓰려면 어떻게 해야 하는가 &gt; 꾸준히 쓰다 보니 이제는 근육처럼 되었다. (캬~ 2)</li><li>문제가 생겨 검색해보고 해결한다고 해서 내 것이 되는 것은 아님 &gt; 내가 직접 재현을 해보고 테스트를 해봐야 내것이 됨. (캬~ 3)</li></ul><p>나름의 철학으로 글을 작성할 때 일관된 흐름을 유지하려고 노력 중이시고 그게 구글에서 검색하면 아웃사이더님의 글이 처음으로 나오는 이유가 아닐까 싶다. (그만큼 사이트의 신뢰도가 높아져서?)</p><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><p>무슨 말이 필요하겠는가. 필자의 메모장에도 블로깅을 하려고 적어놓은 것들만 있지 실제로 실행에 옮기지 못하고 있는데 꾸준히, 그리고 체계적으로, 읽는 사람의 위치에서 글을 잘 써보겠다고 다짐할 수 있었던 좋은 행사였다. 한 가지, 밋업이 끝나고 네트워킹 행사나 뒷풀이가 있었으면 좋았을 텐데 하는 아쉬움이 있었지만 다른 행사에서 자주 찾아뵈고 하다 보면 인연이 생길 꺼라 감히 소망해본다.</p><p>#wtdseoul #WritetheDocs</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;필자는 평소 개발자에게 가장 중요한 덕목 중 하나가 &lt;code&gt;글쓰기&lt;/code&gt;라고 생각하고 있다. 마침 글쓰기와 기술의 접점을 고민하고 이야기하는 “Write The Docs 서울 밋업”(&lt;a href=&quot;https://festa.io/events/191&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;링크&lt;/a&gt;) 이 있다고 하여 쉬고 싶던 주말이지만 만사를 집어치우고 참석하게 되었다.
    
    </summary>
    
      <category term="review" scheme="https://taetaetae.github.io/categories/review/"/>
    
    
      <category term="write" scheme="https://taetaetae.github.io/tags/write/"/>
    
      <category term="blog" scheme="https://taetaetae.github.io/tags/blog/"/>
    
      <category term="write the docs" scheme="https://taetaetae.github.io/tags/write-the-docs/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins 업그레이드 및 Master-Slave 구성</title>
    <link href="https://taetaetae.github.io/2019/03/17/jenkins-upgrade-master-slave/"/>
    <id>https://taetaetae.github.io/2019/03/17/jenkins-upgrade-master-slave/</id>
    <published>2019-03-17T09:23:03.000Z</published>
    <updated>2019-03-17T15:26:37.502Z</updated>
    
    <content type="html"><![CDATA[<p>어떠한 작업(Job)이 있다고 가정해보자. 이를 “정해진 시간에 주기적” 이나 “필요할때” 작업을 수행하고 싶다면 어떤 툴(Tool)이 떠오르는가? <a id="more"></a>그리고 이 작업(Job)들의 실행이력 등 전체적으로 관리하고 필요에 따라 다양한 플러그인을 활용하여 입맛에 맞는 작업(Job)으로 구성하고 싶을때 가장 첫번째로 떠오르는 툴은 바로 “Jenkins” 다. (극히 필자 개인적인 생각일수도 있지만… ) 물론 리눅스 기반의 crontab 이나 다른 스케쥴러를 활용할수도 있다. 다만 필자 개인적인 느낌으로 나만의 Jarvis(?)처럼 내가 원하는데로 설정만 해두면 정해진 시간에 수행하고 그 결과를 로그로 남겨놓고 문제가 발생했을때 알림도 받을수 있으니 너무 좋은 툴이라 생각이 든다.</p><div class="figure center" style="width:;"><a class="fancybox" href="ColossalSociableBuffalo-size_restricted.gif" title="실제로 Jarvis가 있다면 얼마나 편할까<br>출처 : https://gfycat.com/ko/colossalsociablebuffalo" data-caption="실제로 Jarvis가 있다면 얼마나 편할까<br>출처 : https://gfycat.com/ko/colossalsociablebuffalo" data-fancybox="default"><img class="fig-img" src="ColossalSociableBuffalo-size_restricted.gif" alt="실제로 Jarvis가 있다면 얼마나 편할까<br>출처 : https://gfycat.com/ko/colossalsociablebuffalo"><span class="image-caption">실제로 Jarvis가 있다면 얼마나 편할까<br>출처 : https://gfycat.com/ko/colossalsociablebuffalo</span></a><span class="caption">실제로 Jarvis가 있다면 얼마나 편할까<br>출처 : https://gfycat.com/ko/colossalsociablebuffalo</span></div><p>지난 <a href="https://taetaetae.github.io/2018/12/02/jenkins-install/">포스팅</a>에서는 Jenkins 를 설치하는 방법에 대해 알아보았다. (정확히 말하면 치트키 수준의… ) 이번 포스팅에서는 Jenkins에 노드를 추가하여 master-slave 분산환경으로 구성하는 방법과 Jenkins 버전을 업그레이드 하는 방법에 대해 정리해보고자 한다.</p><blockquote><p>마침 필자의 팀에서 젠킨스를 분산환경으로 운영하고 있었는데 버전은 1.x … 간헐적으로 Jenkins 버전 이슈로 에러가 발생해서 업그레이드를 해야하는 상황이 생긴것이다. 시키지도 않은 일을 하면서 팀에 도움도 될겸, 포스팅도 할겸, 1석 2조 효과. 서버 환경은 CentOS 7.4 64Bit 에서 테스트 하였다.</p></blockquote><h3 id="Jenkins-버전-업그레이드-하기"><a href="#Jenkins-버전-업그레이드-하기" class="headerlink" title="# Jenkins 버전 업그레이드 하기"></a># Jenkins 버전 업그레이드 하기</h3><p>Jenkins를 업그레이드 하게되면 기존에 있었던 Jenkins의 환경설정은 어떻게 마이그레이션 할까? Job 실행기록들은 그냥 날려버려야 하나? 걱정을 하며 구글링을 해본다. 그러면 “안해본것에 대한 두려움” 을 갖는 필자의 마음이 무색할 정도로 너무 간단하게도 그냥 기존에 있던 war 파일을 최신버전으로 교체하고 재시작 하라고 나온다.  읭? 뭐이리 간단해? 대부분의 문제들은 지레 겁부터 먹고 실행에 옮기지 <del>못해서</del> 않아서 해결을 하지 못하는게 절반 이상같다.  자, 바로 실행에 옮겨보자.<br>우선 버전 업그레이드를 테스트 하기 위해 일부러 <a href="http://mirrors.jenkins.io/war-stable/" target="_blank" rel="noopener">낮은버전</a>으로 설치를 해둔다. (필자는 1.609.1로 설치해봤다.) 그리고 버전 업그레이드 후 설정이 그대로 옮겨지는지를 확인하기위해 Security 설정을 해서 Jenkins 접근시 로그인 여부를 물어보록 설정해둔다.</p><div class="figure center" style="width:;"><a class="fancybox" href="old_jenkins.jpg" title="우측 하단에 빨간영역으로 낮은버전이 설치된것을 확인할수 있다." data-caption="우측 하단에 빨간영역으로 낮은버전이 설치된것을 확인할수 있다." data-fancybox="default"><img class="fig-img" src="old_jenkins.jpg" alt="우측 하단에 빨간영역으로 낮은버전이 설치된것을 확인할수 있다."><span class="image-caption">우측 하단에 빨간영역으로 낮은버전이 설치된것을 확인할수 있다.</span></a><span class="caption">우측 하단에 빨간영역으로 낮은버전이 설치된것을 확인할수 있다.</span></div><p>설정이 완료되었으면 최신버전의 war를 다운받아 교체하고 재시작을 해준다. 그러면 너무나도 간단하게 버전이 업그레이드가 된것을 확인할수 있다. 그리고 처음에 설정한 Security 설정까지 그대로 유지되는것 또한 확인이 가능하다. 물론 구 버전에서 설치되었던 플러그인들이 버전업이 되며 그에 따라 지원하지 않는 문제들이 생길 수 있는데 이 부분은 플러그인을 업그레이드를 해준다거나 각 상황에 맞는 대응을 해줘야 한다. 이렇게 해서 생각보다(?) 너무 간단하게 버전업이 완료되었다.</p><div class="figure center" style="width:;"><a class="fancybox" href="upgrade_complete.jpg" title="업그레이드 후 플러그인 업그레이드도 동일하게 맞춰주는게 중요하다." data-caption="업그레이드 후 플러그인 업그레이드도 동일하게 맞춰주는게 중요하다." data-fancybox="default"><img class="fig-img" src="upgrade_complete.jpg" alt="업그레이드 후 플러그인 업그레이드도 동일하게 맞춰주는게 중요하다."><span class="image-caption">업그레이드 후 플러그인 업그레이드도 동일하게 맞춰주는게 중요하다.</span></a><span class="caption">업그레이드 후 플러그인 업그레이드도 동일하게 맞춰주는게 중요하다.</span></div><h3 id="Jenkins-분산환경-구성하기-노드-추가하기"><a href="#Jenkins-분산환경-구성하기-노드-추가하기" class="headerlink" title="# Jenkins 분산환경 구성하기 (노드 추가하기)"></a># Jenkins 분산환경 구성하기 (노드 추가하기)</h3><p>이번엔 Jenkins를 분산환경으로 구성해보고자 한다. 이렇게 노드를 추가하며 분산환경을 구성하는 이유는 마스터-슬레이브(Master-Slave) 패턴의 장점을 얻고자 함이다. 마스터는 작업을 쪼개고 슬레이브로 구성된 노드에게 분배를 하게되면 슬레이브 서버는 마스터의 요청을 처리하고 리턴하게 된다. 마치 스타크래프트에서 일꾼을 늘려서 미네랄과 가스를 더 빨리 얻는것처럼 말이다.</p><p>여기서 필자가 가장 많이 삽질한 부분. 슬레이브 서버를 추가하는데 슬레이브 서버가 되는 서버에 동일하게 젠킨스를 설치하고 그들을 모두 연결하려 했던것… 마치 클러스터링 하는것처럼…  당연히 Jenkins 들의 묶음형태(?) 가 되야 할것같은 생각으로 시도하였지만 엄청난 삽질의 연속이 되어버렸다. 알고보니 마스터 Jenkins에서 슬레이브 서버에 작업을 전달할수 있도록 연동만 시켜주면 자동으로 Agent를 마스터 Jenkins가 슬레이브 서버에 설치/실행을 하고 작업을 분할하는것을 확인할 수 있었다. 자, 그럼 시작해보자.</p><ol><li><p>마스터 서버에서 공개키와 개인키 생성<br>먼저 마스터 서버와 슬레이브 서버를 SSH로 통신할수 있도록 SSH 키 설정을 해준다. 통상 홈 디렉토리 하위 .ssh 폴더에서 생성한다.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">ssh 키 생성</span><br><span class="line"><span class="meta">$</span> ssh-keygen -t rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/~/.ssh/id_rsa):</span><br><span class="line">Enter passphrase (empty for no passphrase):</span><br><span class="line">Enter same passphrase again:</span><br><span class="line">Your identification has been saved in /~/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /~/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ user@hostname</span><br><span class="line">The key's randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|oo. .            |</span><br><span class="line">|o... o  +        |</span><br><span class="line">|. .o  o+.o       |</span><br><span class="line">|.++++. +o+o..    |</span><br><span class="line">|o.+*=.o.SEoo=    |</span><br><span class="line">| .  o+.*...+ +   |</span><br><span class="line">|   .. + +.  +    |</span><br><span class="line">|     + .     .   |</span><br><span class="line">|      ...        |</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line"></span><br><span class="line">공개키 확인</span><br><span class="line"><span class="meta">$</span> cat id_rsa.pub</span><br><span class="line">ssh-rsa AAAAB3Nza~~~~~~~~eQKcx8B6uAflRm1J8In1 user@hostname</span><br></pre></td></tr></table></figure></li><li><p>슬레이브 서버에서 마스터 서버에서 만든 공개키를 등록<br>슬레이브 서버에서는 마스터 서버에서 SSH 접속을 허용해야 하기때문에 마스터 서버에서 생성한 공개키를 등록해준다. 슬레이브 서버의 홈 디렉토리 하위 .ssh 폴더아래 파일을 만들고 위 공개키를 넣어주자.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> vi authorized_keys</span><br><span class="line">ssh-rsa AAAAB3Nza~~~~~~~~eQKcx8B6uAflRm1J8In1 user@hostname</span><br></pre></td></tr></table></figure></li><li><p>Jenkins 에서 Credentials 을 만들때 Private Key 설정을 “From the Jenkins master ~/.ssh”으로 설정한다. 나중에 이 정보로 인증을 처리한다.</p><div class="figure center" style="width:;"><a class="fancybox" href="jenkins_upgrade_3.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="jenkins_upgrade_3.jpg" alt=""></a></div></li></ol><ol start="4"><li>노드를 추가하고 조금 있으면 마스터 노드가 슬레이브 서버에 에이전트를 설치/실행하고 연동이 된것을 확인할수 있다.<div class="figure center" style="width:;"><a class="fancybox" href="jenkins_upgrade_4.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="jenkins_upgrade_4.jpg" alt=""></a></div>실제로 슬레이브 서버에서 프로세스를 확인하면 아래처럼 에이전트( slave.jar )가 설치/실행되고 있는것을 확인할수 있다.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ps -ef | grep java</span><br><span class="line">user   105431 105288  0 01:03 ?        00:00:00 bash -c cd &quot;/home&quot; &amp;&amp; java  -jar slave.jar</span><br><span class="line">user   105463 105431  3 01:03 ?        00:00:08 java -jar slave.jar</span><br></pre></td></tr></table></figure></li></ol><p>위와 같은 방법으로 슬레이브 서버를 총 두개를 구성하고 job을 여러개 실행하게 하면 자동으로(랜덤으로) 분배되어 실행하는것을 확인할 수 있다.<br><div class="figure center" style="width:;"><a class="fancybox" href="jenkins_node_job_execute.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="jenkins_node_job_execute.jpg" alt=""></a></div></p><p>특정 job은 특정 슬레이브 서버에서 실행하고 싶은 경우도 있다. 예로들어 특정 슬레이브 서버가 성능이 더 좋다거나 네트워크 ACL이 특정 슬레이브 서버만 오픈되었다거나… 그럴 경우에는 아래처럼 job 실행설정에서 슬레이브를 강제로 지정할수도 있다. (짱…)<br><div class="figure center" style="width:;"><a class="fancybox" href="execute_target_node.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="execute_target_node.jpg" alt=""></a></div></p><h3 id="Jenkins-분산환경에서-버전-업그레이드-하기"><a href="#Jenkins-분산환경에서-버전-업그레이드-하기" class="headerlink" title="# Jenkins 분산환경에서 버전 업그레이드 하기"></a># Jenkins 분산환경에서 버전 업그레이드 하기</h3><p>이제 위에서 했던것들의 종합 세트인 “Master-Slave로 되어있는 구성에서의 Jenkins 업그레이드” 를 해보자.  우선 위에서 했던것처럼 구버전으로 Master-Slave 를 구성한다.<br>이제부터가 중요한데 필자는 당연히 위에서 했던 업그레이드 방법처럼 (이렇게 노드가 연결되어있는 상황에서) 기존의 war을 교체하면 되겠거니 했다. 하지만 업그레이드는 되었지만 노드가 연결이 안되면서 너무나도 다양한(?)에러를 만나야만 했다. 에러 내용을 찾아보니 필자처럼 버전 업그레이드를 하며 예외상황이 발생해 에러가 나는 경우가 많았고 삽질을 거듭해본 결과 다음과 같은 방법으로 하면 업그레이드도 되고 노드도 연결이 가능한것을 확인할 수 있었다. (다른 더 좋은 방법이 있다면 알고싶다… )</p><ol><li>우선 기존에 추가해둔 노드들을 제거한다.</li><li>그 다음 위에서 했던것처럼 war를 교체하며 업그레이드를 진행한다.</li><li>Credentials 항목에 보면 개인키가 있는것을 볼수 있다. (기존에는 “From the Jenkins master ~/.ssh” 항목이 있었는데 없어졌다. )</li><li>위에서 했던것처럼 노드를 추가해준다. 그럼 다음과 같은 에러를 만날수 있는데 에러 내용을 보면 known_hosts 파일이 없다고 나온다. 뭔가 해결할수 있을것만 같은 느낌이 든다. master 서버에서 <code>ssh 슬레이브서버주소</code> 명령어를 실행해서 known_hosts 파일을 생성하도록 해준다.<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> pwd</span><br><span class="line">/home/.ssh</span><br><span class="line"><span class="meta">$</span> ls</span><br><span class="line">id_rsa  id_rsa.pub</span><br><span class="line"><span class="meta">$</span> ssh slave-host</span><br><span class="line">The authenticity of host 'slave-host (0.0.0.0)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:0zb~~~~~B1A.</span><br><span class="line">ECDSA key fingerprint is MD5:~~~~:87.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added 'slave-host,0.0.0.0' (ECDSA) to the list of known hosts.</span><br><span class="line">Last login: Thu Mar 14 13:30:04 2019 from 10.113.219.197</span><br><span class="line">[user@slave-host ~]$ exit</span><br><span class="line">logout</span><br><span class="line">Connection to slave-host closed.</span><br><span class="line"><span class="meta">$</span> ls</span><br><span class="line">id_rsa  id_rsa.pub  known_hosts</span><br><span class="line"><span class="meta">$</span> cat known_hosts</span><br><span class="line">slave-host,0.0.0.0 ~~~ AAAA~~~~~~~8=</span><br></pre></td></tr></table></figure></li></ol><div class="figure center" style="width:;"><a class="fancybox" href="final_upgrade.jpg" title="업그레이드 후 노드 구성한 화면" data-caption="업그레이드 후 노드 구성한 화면" data-fancybox="default"><img class="fig-img" src="final_upgrade.jpg" alt="업그레이드 후 노드 구성한 화면"><span class="image-caption">업그레이드 후 노드 구성한 화면</span></a><span class="caption">업그레이드 후 노드 구성한 화면</span></div><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><p>“Master-Slave로 되어있는 구성에서의 Jenkins 업그레이드”를 하며 정말 많은 시간을 할애할 수 밖에 없었고 (관련 지식도 없고 경험도 없었으니… ) 너무 안되어 포기할까도 싶었다. 하지만 경험하지 않은 모든 일들은 다 그만큼의 고통이 필요하고, 그 고통이 있어야지만 비로소 내것이 된다는 생각을 하고 있다. 이것도 나만의 무기가 되어 나중에 jenkins 를 업그레이드 한다거나 노드구성을 할때 보다 쉽고 빠르게 할수있지 않을까 기대를 해본다. 더불어 어려운 이야기이지만 삽질도 올바른 삽질을 할수 있도록 소망해본다…<br><div class="figure center" style="width:;"><a class="fancybox" href="spadework.gif" title="이런 삽질은 그만... <br>출처 : https://gfycat.com/ko/illiterateonlyicelandgull" data-caption="이런 삽질은 그만... <br>출처 : https://gfycat.com/ko/illiterateonlyicelandgull" data-fancybox="default"><img class="fig-img" src="spadework.gif" alt="이런 삽질은 그만... <br>출처 : https://gfycat.com/ko/illiterateonlyicelandgull"><span class="image-caption">이런 삽질은 그만... <br>출처 : https://gfycat.com/ko/illiterateonlyicelandgull</span></a><span class="caption">이런 삽질은 그만... <br>출처 : https://gfycat.com/ko/illiterateonlyicelandgull</span></div></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;어떠한 작업(Job)이 있다고 가정해보자. 이를 “정해진 시간에 주기적” 이나 “필요할때” 작업을 수행하고 싶다면 어떤 툴(Tool)이 떠오르는가?
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="jenkins" scheme="https://taetaetae.github.io/tags/jenkins/"/>
    
  </entry>
  
  <entry>
    <title>기술블로그 구독서비스 개발 후기 - 3부</title>
    <link href="https://taetaetae.github.io/2019/02/17/daily-dev-blog-3/"/>
    <id>https://taetaetae.github.io/2019/02/17/daily-dev-blog-3/</id>
    <published>2019-02-16T16:17:27.000Z</published>
    <updated>2019-02-28T05:56:00.588Z</updated>
    
    <content type="html"><![CDATA[<p>작년 7월 12일부터 시작한 필자의 첫 토이프로젝트인 <a href="http://daily-devblog.com" target="_blank" rel="noopener">기술블로그 구독서비스</a>. 오픈할 때까지만 해도 “AWS 프리티어를 사용하고 있는 1년 안에 구독자가 설마 1,000명이 넘겠어?” 라고 생각을 했었는데 <a id="more"></a> 오픈을 하고 220일째 되는 바로 어제 어느덧 벌써 구독자가 1,000명을 달성하게 되었다. 그 기념으로 그동안 미뤄두었던 <code>기술블로그 구독서비스 개발 후기</code> 시리즈의 3부를 쓰고자 한다.<br><div class="figure center" style="width:;"><a class="fancybox" href="nice_minion.gif" title="오예~ 1,000명이다! 땡큐! <br>출처 : https://gfycat.com/ko/leafytorngroundbeetle" data-caption="오예~ 1,000명이다! 땡큐! <br>출처 : https://gfycat.com/ko/leafytorngroundbeetle" data-fancybox="default"><img class="fig-img" src="nice_minion.gif" alt="오예~ 1,000명이다! 땡큐! <br>출처 : https://gfycat.com/ko/leafytorngroundbeetle"><span class="image-caption">오예~ 1,000명이다! 땡큐! <br>출처 : https://gfycat.com/ko/leafytorngroundbeetle</span></a><span class="caption">오예~ 1,000명이다! 땡큐! <br>출처 : https://gfycat.com/ko/leafytorngroundbeetle</span></div></p><p>혹시 전에 내용을 보고자 하면 아래 링크에서 확인할 수 있다.</p><ul><li>1부 : <a href="https://taetaetae.github.io/2018/08/05/daily-dev-blog-1/">왜 만들게 되었는가 그리고 어떤 구조로 만들었는가</a></li><li>2부 : <a href="https://taetaetae.github.io/2018/08/09/daily-dev-blog-2/">문제발생 및 Trouble Shooting</a></li><li>3부 : <a href="https://taetaetae.github.io/2019/02/17/daily-dev-blog-3/">앞으로의 계획과 방향성</a></li></ul><h3 id="그간-어떤-식으로-서비스를-운영했는가"><a href="#그간-어떤-식으로-서비스를-운영했는가" class="headerlink" title="# 그간 어떤 식으로 서비스를 운영했는가?"></a># 그간 어떤 식으로 서비스를 운영했는가?</h3><p>(한마디로 정리할 순 없는 지난 220일이었지만…) 딱 한마디로 정리하자면 <code>엄청나게 많은 것을 배우고 경험할 수 있었으나 그만큼 힘들었던 시간들</code>이라고 말할 수 있을 것 같다.     2부에서 이야기한 <code>문제 발생에 따른 Trouble Shooting</code>들도 있었지만 운영을 해오다 보니 사전에 생각하지도 못한 부분에서 문제가 생기는 정말 다양한 경험을 할 수 있었기 때문이다.</p><ul><li><p>블로그 포스팅을 수집하는 과정에서의 문제<br>일부 블로그 RSS url에 접근을 할 때 요청에 대한 응답이 무한대로 멈춰버리는 현상이 간헐적으로 있었다. 이는 별도의 타임아웃을 설정하지 않았기 때문이다. 그래서 어느 정도의 타임아웃을 두고 시간 내에 응답이 없을 경우 다음 포스팅으로 넘어가도록 하였다. (타임아웃은 아주 기본적인 부분인데…)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get(rss_url, timeout=10.0)</span><br></pre></td></tr></table></figure></li><li><p>메일 발송하는 과정에서의 문제<br>가끔 메일이 오지 않는다고 친절하게 필자 개인 메일로 연락이 오는 경우가 있었다. 그때마다 서버의 상태를 보면 서버에 직접 접속조차 안 될 정도로 메모리 사용량이 너무 많아서 그때마다 AWS 웹 콘솔에서 강제로 서버를 재부팅을 하곤 했었다. 예전에도 이야기한 것처럼 AWS 프리티어를 사용하고 있다 보니 서버의 메모리가 1기가밖에 되지 않아서 … 제한된 시스템에서 서비스 운영을 할 수밖에 없는 상황이었다.<br>그래서 수집/발송 상태를 로깅으로 쉽게 볼 수 있고 스케줄링을 하기 위해 띄워둔 Jenkins(tomcat)를 중단하고 crontab으로 스케줄링을 하도록 하였고, 로깅은 <a href="https://stackoverflow.com/questions/4811738/how-to-log-cron-jobs" target="_blank" rel="noopener">별도의 파일로 로깅</a>하도록 변경하였다. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/python3.6 /home/~~~/email_send.py &gt; /home/~~~/logs/job/email_send_`date +\%Y\%m\%d\%H\%M\%S`.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p>  또한 기존에는 빠르게 발송하기 위해 냅다 스레드로 돌렸는데 구독자 수가 많아지다 보니 <code>RuntimeError: can&#39;t start new thread</code> 라고 스레드를 만들 수 없다는 에러가 발생하기도 했다. 그래서 Pool을 사용하는 방식의 <a href="https://docs.python.org/3.4/library/multiprocessing.html" target="_blank" rel="noopener">multiprocessing</a> 을 도입하여 스레드로 발송할 때보다는 엄청나게 빠른 속도는 아닐지라도 효율적인 메모리 사용으로 2분 안에 1,000명에게 안정된 메일을 보낼 수 있게 되었다. (여담이지만 메일이 안 온다고 알려주셨던 분들께 이 자리를 빌려 감사의 인사를 전하고 싶다.)</p><pre><code class="python"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool...pool = Pool(<span class="number">20</span>)pool.map(sendMail, email_list)</code></pre><blockquote><p><a href="https://www.heroku.com/" target="_blank" rel="noopener">Heroku</a> 나 <a href="https://www.netlify.com/" target="_blank" rel="noopener">Netlify</a> 같이 서버를 직접 들어가지 않고 앱 형태로 배포하는 식으로 할 수도 있다. 하지만 초기에 이 토이프로젝트를 시작할 때 실 서비스와 최대한 동일한 시스템으로 운영해보고 싶었기 때문에 라즈베리파이에 설치하는 것까지 알아보다 결국 AWS를 사용하기로 하게 되었다.<br>그렇다면 AWS 프리티어를 사용하지 않고 별도의 서버를 구매하면 안 될까? 하는 생각도 해봤지만 최소한의 인프라로 최대한의 성능을 내보고 싶은 욕심(?) 때문에 1년간은 프리티어로 운영하고 그다음엔 (혹은 소프트웨어적으로 한계까지 도달한다면) 서버를 구매해서 운영하게 될 것 같다. (적어도 이후에도 이 서비스를 유지한다는 가정하에…)</p></blockquote></li></ul><div class="figure center" style="width:;"><img class="fig-img" src="daily-ddb-check.jpg" alt="농부의 마음으로... <br>출처 : http://www.iwithjesus.com/news/articleView.html?idxno=2511"><span class="image-caption">농부의 마음으로... <br>출처 : http://www.iwithjesus.com/news/articleView.html?idxno=2511</span><span class="caption">농부의 마음으로... <br>출처 : http://www.iwithjesus.com/news/articleView.html?idxno=2511</span></div><p>아침 10시가 되면 자동으로 메일이 잘 발송되었는지, 혹 어제 수집된 것이 아니라 예전에 수집된 내용이 중복 발송된 건 아닌지, 발송은 구독한 사람 전부에게 잘 보내졌는지… 거의 매일같이 Daily-DevBlog 서비스를 살피며 지낸 것 같다. (하루라도 문제가 생기면 밤을 새워서라도 원인을 파악하고 다음 발송에는 정상적으로 발송되도록 수정하기도 했다.)</p><h3 id="앞으로의-계획과-방향성"><a href="#앞으로의-계획과-방향성" class="headerlink" title="# 앞으로의 계획과 방향성"></a># 앞으로의 계획과 방향성</h3><p>여력이 되는 데까지 이 서비스를 운영할 계획이다. AWS 프리티어 기간이 끝나도 라즈베리파이나 안 쓰는 노트북을 활용해서 서버를 구성하던지 (한 달에 얼마를 지불할지는 모르겠지만) AWS에서 서버를 발급받아서라도 운영하고 싶다. 그 이유는 이 토이프로젝트를 진행하면서 얻게 된 인사이트도 상당히 많았고, python과 apache 등 기존에 알고 있던 부분 이외로 알게 되는 것 또한 많았기 때문이다. 그리고 가장 중요한 <code>공유</code>, 사실 이 서비스를 만들면서 필자 또한 많은 좋은 글들을 볼수있었고 그에 큰 도움도 많이 받을 수 있었다.<br>만들고 싶은 기능도 많다. 포스팅의 내용을 분석하여 자동으로 기술과 관련되지 않는 글을 제외하는 기능도 만들고 싶고, 자동으로 주요 키워드 (태그)를 만들어 이후에도 태그 기준으로 검색을 통해 보고싶은 글을 뉴스처럼 볼수 있는 기능도 만들고 싶고… 운영을 하다 보니 만들고 싶은 기능은 많지만 기술적인 접근이 어려운 상황이다.<br>하지만 가장 중요한 건 새로운 기능 추가보다 안정적으로 매일 아침 10시마다 바로 어제의 글들을 수집하여 구독자들에게 발송하는 것이 가장 중요한 게 아닐까 싶다.</p><div class="figure center" style="width:;"><a class="fancybox" href="subscriber.jpg" title="구독자수 증가 그래프" data-caption="구독자수 증가 그래프" data-fancybox="default"><img class="fig-img" src="subscriber.jpg" alt="구독자수 증가 그래프"><span class="image-caption">구독자수 증가 그래프</span></a><span class="caption">구독자수 증가 그래프</span></div><h3 id="구독자-1-000명-기념-추가-기능-공개"><a href="#구독자-1-000명-기념-추가-기능-공개" class="headerlink" title="# 구독자 1,000명 기념 추가 기능 공개!"></a># 구독자 1,000명 기념 추가 기능 공개!</h3><p>예전부터 1,000명이 되는 시점에 뭔가 이벤트 성으로 새로운 기능을 공개하고 싶어서 준비를 해보았다.</p><ol><li><a href="http://daily-devblog.com/log/view" target="_blank" rel="noopener">아카이브</a><br>위에서 이야기했듯이 <code>기술과 관련되지 않는 글들에 대한 필터링</code>을 기술적으로 하고 싶었으나 예로 들어 “00역 맛집리스트 자동으로 가져오기” 나 “코딩하면서 먹기에 좋은 음식” 이라는 제목이 있을 경우 과연 어떤 글이 기술에 관련된 글이고 어떤 글이 기술과는 거리가 있는 글인지 기술적으로 분석할 방법이 아직까지는 떠오르지 않는다. (물론 머신러닝이나 다른 방법이 있겠지만…)<br>그래서 기존에 수집한 글들을 한 곳에서 보여주면서 기술과는 거리가 있어 보이는 글들에 대해서 제외하고 볼 수 있도록 아카이빙 페이지를 만들었다. 그리고 날짜를 넘겨가며 조회할 수 있고 정렬 순서는 랜덤으로 만들었다. </li><li><p><a href="https://chrome.google.com/webstore/detail/daily-dev-blog-extensions/ejaakkdnneplldikcnkbfdjahmlcaeaa?hl=ko" target="_blank" rel="noopener">크롬 익스텐션</a></p><div class="figure center" style="width:;"><a class="fancybox" href="chrome_ddb.jpg" title="기술블로그 라고 검색해도 나온다." data-caption="기술블로그 라고 검색해도 나온다." data-fancybox="default"><img class="fig-img" src="chrome_ddb.jpg" alt="기술블로그 라고 검색해도 나온다."><span class="image-caption">기술블로그 라고 검색해도 나온다.</span></a><span class="caption">기술블로그 라고 검색해도 나온다.</span></div><p>위에서 만들었던 아카이빙 페이지를 단순하게 익스텐션 클릭 한 번으로 접속이 되도록 만들어보았다. 점심시간 또는 여유시간에 공유된 기술 블로그 포스팅을 쉬운 접근성을 통해 읽어보자는 조금이라도 챙겨보자는 느낌으로 만들게 되었고, 크롬 알림 기능을 활용하여 PC 크롬이 켜져 있는 상황에서 아침 10시가 되면 메일이 발송되는 것처럼 아래 화면과 같이 알람을 주도록 하였다.</p><div class="figure center" style="width:;"><a class="fancybox" href="chrome_ddb.gif" title="아침 10시엔 우리 모두 Daily-DevBlog를~" data-caption="아침 10시엔 우리 모두 Daily-DevBlog를~" data-fancybox="default"><img class="fig-img" src="chrome_ddb.gif" alt="아침 10시엔 우리 모두 Daily-DevBlog를~"><span class="image-caption">아침 10시엔 우리 모두 Daily-DevBlog를~</span></a><span class="caption">아침 10시엔 우리 모두 Daily-DevBlog를~</span></div></li><li><p>주간 인기글<br>구독자들이 어떤 글에 더 관심이 갖는지 궁금하였고 많이 본 글에 대해서는 한 번 더 정리하여 메일로 발송해주는 것이 좋을 것 같다는 생각이 들었다. 그래서 메일로 발송된 글에 대해 클릭수를 기준으로 매주 월요일마다 “주간 인기글”을 발행하는 기능을 추가하였다.</p></li><li><p>단체 블로그 추가 수집<br>지금은 <a href="https://awesome-devblog.netlify.com" target="_blank" rel="noopener">어썸 데브블로그</a>에서 제공해주는 개인 블로거들의 피드를 수집하고 있는데 단체 블로그들 또한 추가로 수집하여 메일의 상단에 배치한다. (단체 블로그는 아무래도 검증이 된 글일 거라 생각이 든다.)</p></li></ol><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><p>혹시 이 서비스에 대한 아이디어가 있는 분들은 아래 댓글이나 개인 메일로 알려주시면 최대한 반영해보고자 한다. 또한 나중에는 github에 공개하여 오픈소스화한다면 필자보다 더 뛰어난 python 개발자들이 보다 좋은 코드를 만들어주어 점점 해당 서비스가 좋아지지 않을까 하는 기대를 해보며 <code>기술블로그 구독서비스 개발후기</code>를 마친다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;작년 7월 12일부터 시작한 필자의 첫 토이프로젝트인 &lt;a href=&quot;http://daily-devblog.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;기술블로그 구독서비스&lt;/a&gt;. 오픈할 때까지만 해도 “AWS 프리티어를 사용하고 있는 1년 안에 구독자가 설마 1,000명이 넘겠어?” 라고 생각을 했었는데
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
  </entry>
  
  <entry>
    <title>누구나 할 수 있는 엑세스 로그 분석 따라 해보기 (by Elastic Stack)</title>
    <link href="https://taetaetae.github.io/2019/02/10/access-log-to-elastic-stack/"/>
    <id>https://taetaetae.github.io/2019/02/10/access-log-to-elastic-stack/</id>
    <published>2019-02-10T05:37:31.000Z</published>
    <updated>2019-02-10T15:44:14.470Z</updated>
    
    <content type="html"><![CDATA[<p>필자가 Elastic Stack을 알게된건 2017년 어느 여름 동기형이 공부하고 있는것을 보고 호기심에 따라하며 시작하게 되었다. 그때까지만 해도 버전이 2.x 였는데 지금 글을 쓰고있는 2019년 2월초 최신버전이 6.6이니 정말 빠르게 변화하는것 같다. <a id="more"></a>빠르게 변화하는 버전만큼 사람들의 관심도 (드라마틱하게는 아니지만) 꾸준히 늘어나 개인적으로, 그리고 실무에서도 활용하는 범위가 많아지고 있는것 같다.</p><script type="text/javascript" src="https://ssl.gstatic.com/trends_nrtr/1709_RC01/embed_loader.js"></script> <script type="text/javascript"> trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"elasticsearch","geo":"KR","time":"today 5-y"}],"category":0,"property":""}, {"exploreQuery":"date=today%205-y&geo=KR&q=elasticsearch","guestPath":"https://trends.google.co.kr:443/trends/embed/"}); </script><p>그래서 그런지 최근들어 <code>(아주 코딱지만큼 조금이라도 더 해본)</code> 필자에게 Elastic Stack 사용방법에 대해 물어보는 주변 지인들이 늘어나고 있다. 그리고 예전에 한창 공부했을때의 버전보다 많이 바꼈기에 이 기회에 “그대로 따라만 하면 Elastic Stack을 구성할 수 있을만한 글”을 써보고자 한다. 사실 필자가 예전에 “도큐먼트를 보기엔 너무 어려워 보이는 느낌적인 느낌” 때문에 삽질하며 구성한 힘들었던 기억을 되살려 최대한 심플하고 처음 해보는 사람도 따라하기만 하면 “아~ 이게 Elastic Stack 이구나!”, “이런식으로 돌아가는 거구나!” 하는 도움을 주고 싶다. </p><blockquote><p>+ 그러면서 최신버전도 살펴보고… 1석2조, 이런게 바로 블로그를 하는 이유이지 않을까?<br>다시한번 말하지만 도큐먼트가 최고 지침서이긴 하다…</p></blockquote><p><a href="https://www.elastic.co/kr/products" target="_blank" rel="noopener">Elastic 공식 홈페이지</a>에 가면 각 제품군들에 대해 그림으로 된 자세한 설명과 도큐먼트가 있지만 이들을 어떤식으로 조합하여 사용하는지에 대한 전체적인 흐름을 볼 수 있는 곳은 없어 보인다. (지금 보면 도큐먼트가 그 어디보다 설명이 잘되어 있다고 생각되지만 사전 지식이 전혀없는 상태에서는 봐도봐도 어려워 보였다.)<br>이번 포스팅에서는 <strong>Apache access log를 Elasticsearch에 인덱싱 하는 방법</strong>에 대해 설명해보고자 한다.</p><h4 id="전체적인-흐름"><a href="#전체적인-흐름" class="headerlink" title="# 전체적인 흐름"></a># 전체적인 흐름</h4><p>필자는 글보다는 그림을 좋아하는 편이라 전체적인 흐름을 그림으로 먼저 보자.</p><div class="figure center" style="width:;"><a class="fancybox" href="concept.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="concept.jpg" alt=""></a></div><ol><li>외부에서의 접근이 발생하면 apache 웹서버에서 설정한 경로에 access log가 파일로 생성이 되거나 있는 파일에 추가가 된다. 해당 파일에는 한줄당 하나의 엑세스 정보가 남게 된다.</li><li>fileBeat에서 해당 파일을 트래킹 하고 있다가 라인이 추가되면 이 정보를 logstash 에게 전달해준다.</li><li>logastsh 는 filebeat에서 전달한 정보를 특정 port로 input 받는다.</li><li>받은 정보를 filter 과정을 통해 각 정보를 분할 및 정제한다. (ip, uri, time 등)</li><li>정리된 정보를 elasticsearch 에 ouput 으로 보낸다. (정확히 말하면 인덱싱을 한다.)</li><li>elasticsearch 에 인덱싱 된 정보를 키바나를 통해 손쉽게 분석을 한다.</li></ol><p>한번의 설치고 일련의 과정이 뚝딱 된다면 너무 편하겠지만, 각각의 레이어가 나뉘어져있는 이유는 하는 역활이 전문적으로(?) 나뉘어져 있고 각 레이어에서는 세부 설정을 통해 보다 효율적으로 데이터를 관리할 수 있기 때문이다.</p><blockquote><p>beats라는 레이어가 나오기 전에는 logstash에서 직접 file을 바라보곤 했었는데 beats가 logstash 보다 가벼운 shipper 목적으로 나온 agent 이다보니 통상 logstash 앞단에 filebeat를 위치시키곤 한다고 한다.</p></blockquote><p>전체적인 그림은 위와 같고, 이제 이 글을 보고있는 여러분들이 따라할 차례이다. 각 레이어별로 하나씩 설치를 해보며 구성을 해보자. 설치순서는 데이터 흐름의 순서에 맞춰 다음과 같은 순서로 설치를 해야 효율적으로 볼수가 있다. (아래순서대로 하지 않을경우 설치/시작/종료 를 각각의 타이밍에 맞추어 해줘야 할것 같아 복잡할것같다.)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">elasticsearch → logstash → kibana → filebeat</span><br></pre></td></tr></table></figure><p>이 포스팅은 CentOS 7.4에서 Java 1.8, apache 2.2가 설치되어있다는 가정하에 보면 될듯하다. 또한 각 레이어별 설명은 구글링을 하거나 Elastic 공식 홈페이지에 가보면 자세히 나와있으니 기본 설명은 안하는것으로 하고, 각 레이어의 세부 설정은 하지 않는것으로 한다.</p><h4 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="# Elasticsearch"></a># Elasticsearch</h4><p><a href="https://www.elastic.co/kr/products/elasticsearch" target="_blank" rel="noopener">공식 홈페이지</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">다운받고 압축풀고 심볼릭 경로 만들고 (심볼릭 경로는 선택사항)</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.0.tar.gz</span><br><span class="line">$ tar zxvf elasticsearch-6.6.0.tar.gz</span><br><span class="line">$ ln -s elasticsearch-6.6.0 elasticsearch</span><br><span class="line"></span><br><span class="line">설정 파일을 열고 추가해준다.</span><br><span class="line">$ cd elasticsearch/conf</span><br><span class="line">$ vi elasticsearch.yml</span><br><span class="line">path.data: /~~~/data/elasticsearch (기본경로에서 변경할때추가)</span><br><span class="line">path.logs: /~~~/logs/elasticsearch</span><br><span class="line">network.host: 0.0.0.0 # 외부에서 접근이 가능하도록 (실제 ip를 적어줘도 됨)</span><br><span class="line"></span><br><span class="line">elasticsearch 의 시작과 종료를 조금이나마 편하게 하기위해 스크립트를 작성해줌 (이것또한 선택사항)</span><br><span class="line">$ cd ../bin</span><br><span class="line">$ echo &apos;./elasticsearch -d -p es.pid&apos; &gt; start.sh</span><br><span class="line">$ echo &apos;kill `cat es.pid`&apos; &gt; stop.sh</span><br><span class="line">$ chmod 755 start.sh stop.sh</span><br></pre></td></tr></table></figure></p><p>혹시 아래와 같은 에러가 발생할경우 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#docker-cli-run-prod-mode" target="_blank" rel="noopener">공식문서</a> 대로 진행해준다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ERROR: [1] bootstrap checks failed</span><br><span class="line">[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</span><br><span class="line"></span><br><span class="line">&gt; sudo /sbin/sysctl -w vm.max_map_count=262144</span><br></pre></td></tr></table></figure></p><p>이렇게 하고 시작을 한뒤 브라우저에서 <code>http://{ip}:9200</code> 로 접속하면 다음과 같이 설치된 elasticsearch에 기본 정보가 나오게 되고 이렇게 elasticsearch의 설치 및 실행이 완료되었다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;name&quot;: &quot;@@@&quot;,</span><br><span class="line">&quot;cluster_name&quot;: &quot;elasticsearch&quot;,</span><br><span class="line">&quot;cluster_uuid&quot;: &quot;@@@&quot;,</span><br><span class="line">&quot;version&quot;: &#123;</span><br><span class="line">&quot;number&quot;: &quot;6.6.0&quot;,</span><br><span class="line">&quot;build_flavor&quot;: &quot;default&quot;,</span><br><span class="line">&quot;build_type&quot;: &quot;tar&quot;,</span><br><span class="line">&quot;build_hash&quot;: &quot;@@@&quot;,</span><br><span class="line">&quot;build_date&quot;: &quot;2019-01-24T11:27:09.439740Z&quot;,</span><br><span class="line">&quot;build_snapshot&quot;: false,</span><br><span class="line">&quot;lucene_version&quot;: &quot;7.6.0&quot;,</span><br><span class="line">&quot;minimum_wire_compatibility_version&quot;: &quot;5.6.0&quot;,</span><br><span class="line">&quot;minimum_index_compatibility_version&quot;: &quot;5.0.0&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;tagline&quot;: &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Logstash"><a href="#Logstash" class="headerlink" title="# Logstash"></a># Logstash</h4><p><a href="https://www.elastic.co/kr/products/logstash" target="_blank" rel="noopener">공식 홈페이지</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">다운을 받고 압축풀고 심볼릭 링크 설정</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.6.0.tar.gz</span><br><span class="line">$ tar -zxvf logstash-6.6.0.tar.gz</span><br><span class="line">$ ln -s logstash-6.6.0 logstash</span><br><span class="line"></span><br><span class="line">logstash가 실행될때 설정값 파일을 만들어준다.</span><br><span class="line">$ cd logstash/config</span><br><span class="line">$ vi access_log.conf</span><br><span class="line"># beats 에서 5044 port 로 데이터를 input 받겠다는 의미</span><br><span class="line">input &#123; </span><br><span class="line">        beats &#123; </span><br><span class="line">                port =&gt; &quot;5044&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># grok 필터를 활용하여 엑세스로그 한줄을 아래처럼 파싱하겠다는 의미</span><br><span class="line"># 해당 필터는 apache의 로깅 설정에 의해 만들어지는 파일의 포멧에 맞추어 설정해야한다.</span><br><span class="line">filter &#123;</span><br><span class="line">        grok &#123;</span><br><span class="line">                match =&gt; &#123; &quot;message&quot; =&gt; [&quot;%&#123;IPORHOST:clientip&#125; (?:-|%&#123;USER:ident&#125;) (?:-|%&#123;USER:auth&#125;) \[%&#123;HTTPDATE:timestamp&#125;\] \&quot;(?:%&#123;WORD:httpMethod&#125; %&#123;NOTSPACE:uri&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|-)\&quot; %&#123;NUMBER:responseCode&#125; (?:-|%&#123;NUMBER:bytes&#125;) (?:-|%&#123;NUMBER:bytes2&#125;)( \&quot;%&#123;DATA:referrer&#125;\&quot;)?( \&quot;%&#123;DATA:user-agent&#125;\&quot;)?&quot;] &#125;</span><br><span class="line">                remove_field =&gt; [&quot;timestamp&quot;,&quot;@version&quot;,&quot;path&quot;,&quot;tags&quot;,&quot;httpversion&quot;,&quot;bytes2&quot;]</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 정제된 데이터를 elasticsearch 에 인덱싱 하겟다는 의미</span><br><span class="line"># index 이름에 날짜 형태로 적어주면 인덱싱 하는 시점의 시간에 따라 인덱싱 이름이 자동으로 변경이 된다. (아래는 월별로 인덱스를 만들경우)</span><br><span class="line">output &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">                hosts =&gt; [ &quot;&#123;elasticsearch ip&#125;:9200&quot; ]</span><br><span class="line">                index =&gt; &quot;index-%&#123;+YYYY.MM&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>실행은 다음과 같이 <code>&amp;</code>연산자를 활용하여 background로 실행하게 한다.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/logstash -f config/access_log.conf &amp;</span><br></pre></td></tr></table></figure><p>이렇게 해서 실행을 하고 에러없이 정상적으로 실행이 된뒤 프로세스가 올라와 있으면 (<code>ps -ef | grep logstash</code>) 성공된 상태라 볼수있다.</p><h4 id="Kibana"><a href="#Kibana" class="headerlink" title="# Kibana"></a># Kibana</h4><p><a href="https://www.elastic.co/kr/products/kibana" target="_blank" rel="noopener">공식 홈페이지</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">역시 다운받고 압축풀고 심볼릭 링크 설정</span><br><span class="line">$ https://artifacts.elastic.co/downloads/kibana/kibana-6.6.0-linux-x86_64.tar.gz</span><br><span class="line">$ tar -zxvf kibana-6.6.0-linux-x86_64.tar.gz</span><br><span class="line">$ ln -s kibana-6.6.0-linux-x86_64 kibana</span><br><span class="line"></span><br><span class="line">외부에서 접근을 하기위해 ip를 적어주고, 연결할 elasticsearch 주소또한 적어준다.</span><br><span class="line">$ cd kibana/config</span><br><span class="line">$ vi kibana.yml</span><br><span class="line">server.host: &quot;@.@.@.@&quot;</span><br><span class="line">elasticsearch.hosts: [&quot;http://@.@.@.@:9200&quot;]</span><br></pre></td></tr></table></figure><p>실행은 bin 폴더로 이동후에 다음과 같이 실행시켜준다. 별다른 에러가 없으면 외부에서 접근이 가능한지 확인해보자.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd bin/</span><br><span class="line">$ nohup ./kibana &amp;</span><br><span class="line"></span><br><span class="line">접속 : http://@.@.@.@/5601</span><br></pre></td></tr></table></figure></p><h4 id="Filebeat"><a href="#Filebeat" class="headerlink" title="# Filebeat"></a># Filebeat</h4><p><a href="https://www.elastic.co/kr/products/beats" target="_blank" rel="noopener">공식 홈페이지</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">다운 → 압축해제 → 심볼릭링크</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.6.0-linux-x86_64.tar.gz</span><br><span class="line">$ tar -zxvf filebeat-6.6.0-linux-x86_64.tar.gz</span><br><span class="line">$ ln -s filebeat-6.6.0-linux-x86_64 filebeat</span><br><span class="line"></span><br><span class="line">filebeat가 실행될때의 설정파일을 작성해준다.</span><br><span class="line">$ cd filebeat</span><br><span class="line">$ vi access_log.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">    - /~~~/logs/apache/access.log.* # 실제 엑세스 파일의 경로</span><br><span class="line">  tail_files: true # filebeat 시작시점 기준 파일 끝에서부터 로깅을 읽기 시작</span><br><span class="line">  ignore_older: 1m # filebeat 시작시점 기준 1분전의 내용은 무시</span><br><span class="line">  close_inactive: 2m</span><br><span class="line">  clean_inactive: 15m</span><br><span class="line">logging.level: info</span><br><span class="line">logging.to_files: true</span><br><span class="line">logging.files: # filebeat가 실행되면서 남기는 로깅파일 정보. 도큐먼트를 읽어보는것을 추천한다.</span><br><span class="line">  path: /~~~/logs/filebeat</span><br><span class="line">  name: test-filebeat-log</span><br><span class="line">  keepfiles: 7</span><br><span class="line">  rotateeverybytes: 524288000</span><br><span class="line">output.logstash: # 최종적으로 output 할 logstash의 정보를 입력해준다.</span><br><span class="line">  hosts: [&quot;@.@.@.@:5044&quot;]</span><br></pre></td></tr></table></figure><p>위와 같이 설정파일을 작성한 다음 아래처럼 실행을 하면 엑세스 파일의 내용이 filebeat를 거치고 logstash를 거쳐 최종적으로 elasticsearch 에 도달하게 된다. 기존에 엑세스 로그가 양이 많다면 그 정보를 다 읽는 시간이 걸리므로 주의한다. (filebeat 자체적으로 해당 파일의 offset을 관리하기 때문)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./filebeat -c access_log.yml -d publish &amp;</span><br></pre></td></tr></table></figure><h4 id="최종-확인"><a href="#최종-확인" class="headerlink" title="# 최종 확인"></a># 최종 확인</h4><p>왼쪽에는 해당 서버를 호출하고 오른쪽에는 키바나를 띄워논뒤 테스트를 해보면 아래처럼 access log를 확인이 가능하다. (apache만 띄워놓은 상태라 404상태로 나오긴 한다..) 불필요한 필드가 있다면 logstash 의 filter에서 remove 하면되고 키바나에서 각 정보를 가지고 다양한 유의미한 데이터를 만들어볼 수 있게 되었다.</p><div class="figure center" style="width:;"><a class="fancybox" href="kibana.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="kibana.jpg" alt=""></a></div><h4 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h4><p>막상 해보면 (해보기전에 느끼는 두려움보다는) 엄청나게 미친듯이 어렵지는 않는데… 맨땅에 해딩이든 뭐든 시작해보고 만들어보는게 중요하다고 다시한번 생각해본다. 필자는 elasticsearch 2.4버전에 대해 영어로된 문서를 보며 설치하고 구성하며 (왜 한글로 된 문서가 한명도 없을까…) 하는 아쉬움에 있었는데 이 글이 필자처럼 설치하는데 비슷한(?) 고충을 느낀 사람들에게 도움이 되었으면 한다.<br>마지막으로 세부 설정값들로 인해 성능이나 기능이 다양하게 바뀔수 있으니 <a href="https://www.elastic.co/guide/kr/index.html" target="_blank" rel="noopener">공식 도큐먼트</a>를 보는것을 강력 추천하고 싶다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;필자가 Elastic Stack을 알게된건 2017년 어느 여름 동기형이 공부하고 있는것을 보고 호기심에 따라하며 시작하게 되었다. 그때까지만 해도 버전이 2.x 였는데 지금 글을 쓰고있는 2019년 2월초 최신버전이 6.6이니 정말 빠르게 변화하는것 같다.
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="elasticsearch" scheme="https://taetaetae.github.io/tags/elasticsearch/"/>
    
      <category term="logstash" scheme="https://taetaetae.github.io/tags/logstash/"/>
    
      <category term="kibana" scheme="https://taetaetae.github.io/tags/kibana/"/>
    
      <category term="filebeat" scheme="https://taetaetae.github.io/tags/filebeat/"/>
    
  </entry>
  
  <entry>
    <title>Spring MVC Redirect 처리중에 발생한 Out Of Memory 원인 분석하기</title>
    <link href="https://taetaetae.github.io/2019/01/10/spring-redirect-oom/"/>
    <id>https://taetaetae.github.io/2019/01/10/spring-redirect-oom/</id>
    <published>2019-01-10T14:14:07.296Z</published>
    <updated>2019-01-10T17:22:24.660Z</updated>
    
    <content type="html"><![CDATA[<p>초창기 신입시절에 배우거나 사용했던 기술적인 방법들이 있다. 시간이 지날수록 왠만해선 다른방법은 사용하지 않으려 하고 <code>습관</code>처럼 기존에 사용했던 방법을 고수하는 버릇이 있다. 그 이유는 과거에 사용했을때 아무 탈 없이 잘 되었기 때문에, 그리고 빠른 구현 때문이라는 핑계일 것 같다. <a id="more"></a>이러한 버릇은 비단 이 글을 적고있는 필자 뿐만이 아니라 대부분의 개발자들이 가지고 있을꺼라 조심스레 추측해본다. (아니라면…더욱 분발 해야겠다…ㅠ)<br>최근 운영하고 있는 서비스에서 장애 상황까지 갈수있는 위험한 상황이 있었는데 팀내 코드리뷰를 통해 문제점을 파악할 수 있었다. 그 원인은 Spring MVC Controller 레벨에서 redirect 처리를 할때 return값의 Cardinality가 높을경우 다음과 같이 사용하면 안된다고…</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/test"</span>, method = RequestMethod.GET)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">String url = <span class="string">"어떠한 로직에 의해 생성되는 url"</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="string">"redirect:"</span> + url; <span class="comment">// &lt;- 위험 포인트!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이 코드가 왜? 어디가 어때서?<br>이제까지 Controller 레벨에서 redirect 처리를 할때 아무생각없이 위에 있는 코드 형태로 구현을 했는데 저러한 코드 때문에 OOM이 발생하여 fullGC 가 여러번 발생하고, 일시적으로 서비스가 지연되는 현상이 발생했다고 한다. 자주 사용하던 방법이였는데 장애를 유발할수 있는 위험한 방법이였다니…<br>이번 포스팅에서는 이러한 방법이 왜 잘못되었는지 실제로 테스트를 통해 몸소(?) 체감을 해보고, 그럼 어떤 방법으로 redirect 처리를 해야 하는가와 개선을 함으로써 기존방식에 비해 어떤점이 좋아졌는지에 대해서 정리해보고자 한다. </p><blockquote><p>뭔가 <strong>내것으로 만들기</strong> 시리즈물이 나올것만 같은 느낌이다…</p></blockquote><h4 id="기존방식의-문제점-재현-및-다양한-원인분석"><a href="#기존방식의-문제점-재현-및-다양한-원인분석" class="headerlink" title="# 기존방식의 문제점 재현 및 다양한 원인분석"></a># 기존방식의 문제점 재현 및 다양한 원인분석</h4><p>기존방식으로 했을때 왜 OOM이 발생했을까? 우리는 개발자이기 때문에 이런저런 글들만 보고 추측 할것이 아니라 직접 재현을 해보고 다양한 시각에서 원인분석을 해보자.<br>먼저 기본적인 Spring MVC 뼈대를 만들고 redirect 하는 return 값의 Cardinality가 높도록 random string 을 만들어 주도록 한다. 즉, <code>/random</code>을 호출하면 <code>/result/ETmHfowFkU</code>처럼 random string 이 만들어 지며 redirect 처리가 되는 매우 심플한 구조이다.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Spring 버전은 4.0.6.RELEASE</span></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"random"</span>, method = RequestMethod.GET)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">random</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">"redirect:result/"</span> + UUID.randomUUID();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"result/&#123;message&#125;"</span>, method = RequestMethod.GET)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">result</span><span class="params">(ModelMap model, @PathVariable String message)</span> </span>&#123;</span><br><span class="line">model.addAttribute(<span class="string">"message"</span>, message);</span><br><span class="line"><span class="keyword">return</span> <span class="string">"result"</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>또한 해당 프로젝트에서는 AOP를 사용하고 있었기 때문에 그때와 동일한 상황으로 재현을 하기 위해 AOP관련 설정도 추가해준다.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableWebMvc</span></span><br><span class="line"><span class="meta">@EnableAspectJAutoProxy</span></span><br><span class="line"><span class="meta">@ComponentScan</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloWorldConfiguration</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span>(name=<span class="string">"HelloWorld"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> ViewResolver <span class="title">viewResolver</span><span class="params">()</span> </span>&#123;</span><br><span class="line">InternalResourceViewResolver viewResolver = <span class="keyword">new</span> InternalResourceViewResolver();</span><br><span class="line">viewResolver.setViewClass(JstlView.class);</span><br><span class="line">viewResolver.setPrefix(<span class="string">"/WEB-INF/views/"</span>);</span><br><span class="line">viewResolver.setSuffix(<span class="string">".jsp"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> viewResolver;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>이렇게 한뒤 tomcat으로 최대/최소 메모리를 256m으로 설정후 해당 모듈을 띄워준다. 그다음 메모리 상태를 보기 위해 tomcat에 pinpoint를 연동하고 마지막으로 호출테스트를 위해 nGrinder을 설정해준다. 특별한 설정은 없고 위 컨트롤러의 url (/random) 을 여러번 호출하도록 하였다. nGrinder을 설정하는대에는 <a href="https://black9p.github.io/2019/01/02/nGrinder-%EA%B0%84%ED%8E%B8-%EC%82%AC%EC%9A%A9%EA%B0%80%EC%9D%B4%EB%93%9C/" target="_blank" rel="noopener">이 블로그 포스팅</a>을 참고해서 설정하였다.</p><p>자, 이제 테스트를 시작해보자. (마치 수술 집도하는것 같은 기분으로…간호사~ 칼!)</p><ol><li><p>nGrinder<br>nGrinder의 기본 스크립트에서 url만 해당 서버로 호출되도록 바꿔주고 총 가상 사용자는 2,000으로 시간은 5분으로 설정후에 테스트 시작을 하였더니 다음과 같은 그래프를 볼수 있었다.</p><div class="figure center" style="width:;"><a class="fancybox" href="test1-ngrinder.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test1-ngrinder.jpg" alt=""></a></div><p>TPS가 불안정해지다가 어느시점부터 낮아지는것을 확인할 수 있다. 이게 서비스 였다면 사용자가 접속하는데 불편을 느꼈을꺼라 추측을 해본다. 또한 아주 간단한 random string 을 리턴하는 페이지 임에도 불구하고 에러 응답이 적지 않은것을 확인할 수 있었다.</p></li><li><p>pinpoint<br>메모리 상태는 어떤지 확인하기 위해 pinpoint를 확인해보면 다음과 같은 그래프를 볼수 있었다.</p><div class="figure center" style="width:;"><a class="fancybox" href="test1-pinpoint.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test1-pinpoint.jpg" alt=""></a></div><p>보기만해도 심장이 벌렁벌렁(?) 뛸 정도로 무서운 그림이다. 실제로 서비스에 (이정도까진 아니였지만) 비슷한 상황이 발생했었다. 메모리가 테스트를 점점 하면 할수록 올라가다가 fullGC가 발생하더니 대나무 숲에 있는 대나무마냥 fullGC가 빼곡히 발생하였다. (이러니… 페이지 접근에 지연이 생긴것 같다.)</p></li><li><p>Heap dump<br>그럼 실제로 메모리는 어떤 상태였고 어디서 메모리를 많이 사용하고(점유하고) 있는지를 확인하기 위해 Heap dump를 생성해 보았다. 힙덤프 분석하는데 잘 알려진 <a href="https://www.eclipse.org/mat/" target="_blank" rel="noopener">Memory Analyzer (MAT)</a>를 다운받고 해당 프로세스의 힙덤프를 생성한다음 분석을 해봤더니 아래와 같은 화면을 볼 수 있었다.</p><div class="figure center" style="width:;"><a class="fancybox" href="test1-dump1.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test1-dump1.jpg" alt=""></a></div><p>힙덤프 파일을 열자마자 (저 문제 있어요~ 도와주세요 하듯) 뭔가 많이 점유하고 있는것처럼 보이는 파이그래프가 Overview에 보였다. Reports 영역에 있는 Leak Suspects를 확인해보니 아래 경로에서 많이 사용하는 것을 확인할 수 있었다.</p><blockquote><p>java.util.concurrent.ConcurrentHashMap$Node</p></blockquote><p><br></p><div class="figure center" style="width:;"><a class="fancybox" href="test1-dump2.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test1-dump2.jpg" alt=""></a></div><p>이 툴에서는 OQL이라고 힙덤프에 있는 데이터를 일반 SQL처럼 쿼리처럼 볼수 있었다. 그래서 아래처럼 쿼리를 작성해서 봤더니 결과만 봐도 어디서 메모리를 점유하고 있는지 한눈에 볼수 있었다</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> o.key.toString() </span><br><span class="line"><span class="keyword">FROM</span> java.util.concurrent.ConcurrentHashMap$Node o </span><br><span class="line"><span class="keyword">WHERE</span> ((o.key != <span class="literal">null</span>) <span class="keyword">and</span> (o.key.toString().indexOf(<span class="string">"org.springframework.web.servlet.view.RedirectView_redirect"</span>) = <span class="number">0</span>))</span><br></pre></td></tr></table></figure><div class="figure center" style="width:;"><a class="fancybox" href="test1-dump3.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test1-dump3.jpg" alt=""></a></div><p>무작위로 만들어진 url에 대한 정보를 캐시하고 있는 듯한 결과였다.</p></li></ol><h4 id="방식-개선-및-변화-비교"><a href="#방식-개선-및-변화-비교" class="headerlink" title="# 방식 개선 및 변화 비교"></a># 방식 개선 및 변화 비교</h4><p>결국 <code>return &quot;redirect:&quot; + url;</code> 와 같은 처리가 문제를 야기했던 것이였다. 그럼 redirect 처리를 어떻게 하는게 좋을까?<br>조금 검색을 해보면 <code>RedirectView</code> 나 <code>ModelAndView</code>를 사용하라고 권장하고 있다. 물론 redirect 되는 url의 Cardinality가 높지않고 고정적이라면 지금의 <code>return &quot;redirect:&quot; + url;</code> 이 방식을 사용해도 무방할수 있다. 하지만 컨트롤러 메소드가 String타입을 return 하게 되면 View 클래스로 변환작업을 진행하게 된다고 한다.<br>이 작업중에 <code>org.springframework.beans.factory.config.BeanPostProcessor</code>구현체들도 같이 진행되고, 이중에 하나가 <code>AnnotationAwareAspectJAutoProxyCreator</code> 라고 있는데 해당 클래스 내부적으로 <code>ConcurrentHashMap&lt;Object, Boolean&gt;</code> 타입 객체에 key : viewName, value : 필요 여부(boolean) 형태로 갯수 제한 없이 저장하고 있다. 그러다보니 url의 종류가 많아질수록 메모리가 많이 사용될 수밖에 없었던 것 같다.<br>즉, 동일한 url에 대해 View 객체를 캐싱하고 있으니 위와 같이 url의 종류가 다양할경우 (특히 로그인 같은 처리를 할때 고유값을 파라미터로 넘기는 경우) 캐싱 객체 숫자가 많아지기 마련이다.</p><p>실제로 코드를 보면 캐싱을 하고있는것을 볼수 있다. <a href="https://github.com/spring-projects/spring-framework/blob/master/spring-aop/src/main/java/org/springframework/aop/framework/autoproxy/AbstractAutoProxyCreator.java#L358" target="_blank" rel="noopener">Spring-project github</a><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ... 생략</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> Object <span class="title">wrapIfNecessary</span><span class="params">(Object bean, String beanName, Object cacheKey)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ... 생략</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123;</span><br><span class="line">    <span class="keyword">this</span>.advisedBeans.put(cacheKey, Boolean.FALSE); <span class="comment">// &lt;- 여기 </span></span><br><span class="line">    <span class="keyword">return</span> bean;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ... 생략</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">this</span>.advisedBeans.put(cacheKey, Boolean.FALSE); <span class="comment">// &lt;- 여기 </span></span><br><span class="line">  <span class="keyword">return</span> bean;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ... 생략</span></span><br></pre></td></tr></table></figure></p><p>자, 그럼 개선방법을 알아봤으니 한번 비교를 해보자. 아래처럼 <code>ModelAndView</code>를 사용해서 redirect처리를 할수있도록 코드를 변경하고</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line">  <span class="meta">@RequestMapping</span>(value = <span class="string">"random"</span>, method = RequestMethod.GET)</span><br><span class="line">  <span class="function"><span class="keyword">public</span> ModelAndView <span class="title">random</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ModelAndView modelAndView = <span class="keyword">new</span> ModelAndView();</span><br><span class="line"></span><br><span class="line">    RedirectView redirectView = <span class="keyword">new</span> RedirectView();</span><br><span class="line">    redirectView.setUrl(<span class="string">"result/"</span> + UUID.randomUUID());</span><br><span class="line"></span><br><span class="line">    modelAndView.setView(redirectView);</span><br><span class="line">    <span class="keyword">return</span> modelAndView;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@RequestMapping</span>(value = <span class="string">"/result/&#123;message&#125;"</span>, method = RequestMethod.GET)</span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">result</span><span class="params">(ModelMap model, @PathVariable String message)</span> </span>&#123;</span><br><span class="line">    model.addAttribute(<span class="string">"message"</span>, message);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"result"</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>기존과 동일한 방법과 환경에서 테스트를 해보자.</p><ol><li><p>nGrinder<br>위해서 했던 방법과 동일한 가상 사용자 수와 동일한 시간으로 테스트를 해보니 다음과 같은 그래프를 볼수 있었다.</p><div class="figure center" style="width:;"><a class="fancybox" href="test2-ngrinder.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test2-ngrinder.jpg" alt=""></a></div><p>위에서 봤던 들쭉날쭉 그래프보다 훨씬 더 안정적인것을 볼 수 있었고, 에러도 단 한건도 없이 훨씬 높은 TPS를 끝까지 일정하게 유지하는 모습을 볼수 있었다. (로직상 에러가 나는게 이상한… 아니 안나야 정상이다.) </p></li><li><p>pinpoint<br>TPS가 안정적이였기 때문에 메모리의 상태를 안봐도 되겠지만 비교의 목적이 있기 때문에 pinpoint 의 그래프를 한번 보자.</p><div class="figure center" style="width:;"><a class="fancybox" href="test2-pinpoint.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test2-pinpoint.jpg" alt=""></a></div><p>nGrinder로 테스트하는 시점만 잠깐 메모리가 올라가다가 다시 내려오고 전에 있었던 fullGC도 없고 위에서 테스트 했던 그래프 보다는 안정적인 그래프라고 볼수 있었다.</p></li><li><p>Heap dump<br>메모리가 안정적이였지만 혹시 pinpoint에서 잘못 집계하거나 그래프만 보고 맹신할수 없었기 때문에 이번에도 Heap dump를 생성해 보았다.</p><div class="figure center" style="width:;"><a class="fancybox" href="test1-dump2.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test1-dump2.jpg" alt=""></a></div><p>일단 점유하고 있는 메모리의 크기가 약 10분의 1정도로 줄어든것을 확인할수 있었고, 위에서 했던 OQL을 이용한 메모리 점유를 확인해봐도 기존에 있던 <code>RedirectView_redirect</code>관련 데이터가 아예 없음을 확인할 수 있었다.</p><div class="figure center" style="width:;"><a class="fancybox" href="test2-dump2.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test2-dump2.jpg" alt=""></a></div></li></ol><p>코드 몇줄 변경한것밖에 없는데 같은 테스트 환경에서 확연히 좋아진것을 확인할 수 있다. (뿌듯) 전체적으로 다시 비교를 해보면 아래와 같이 이쁜(?) 변화를 볼수가 있다.<br><div class="figure center" style="width:;"><a class="fancybox" href="test-diff.jpg" title="" data-caption="" data-fancybox="default"><img class="fig-img" src="test-diff.jpg" alt=""></a></div></p><h4 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h4><p>평소에 자주 사용하던 방식인데 성능적으로 자칫 치명적인 결과를 가져올수 있다고 하여 재현을 안해볼수가 없었다. 만약 악의적으로 url뒤에 무작위 문자열을 더해서 ddos공격을 했더라면? 얼마 안가서 서버가 터졌을지도 모른다.<br>지금이라도 알아서 다행이라는 생각과 재현을 안해보고 그냥 그런가보다 하며 넘어갔다면 실제 Spring 내부 코드까지 볼일이 있었을까 하는 생각을 해본다.<br>이번에 재현을 해보면서 nGrinder 로 성능테스트에 pinpoint 모니터링, 마지막으로 힙덤프 분석까지. 꼭 이번 url redirect 문제만이 아니라 다른 성능적인 이슈가 생길때 마치 <code>치트키</code>처럼 활용할수 있을 <code>나만의 무기</code>를 얻은것 같아 다시한번 뿌듯함을 느낀다.</p><p>마지막으로, 이렇게 재현까지 하도록 <code>자극</code>을 주신 팀 동료분께 감사드린다고 전하고 싶다. (보실지 안보실지 모르겠지만 ^^;)</p><hr><ul><li>관련 참고글<br><a href="https://www.baeldung.com/spring-redirect-and-forward" target="_blank" rel="noopener">https://www.baeldung.com/spring-redirect-and-forward</a><br><a href="https://www.slideshare.net/benelog/ss-35627826" target="_blank" rel="noopener">https://www.slideshare.net/benelog/ss-35627826</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;초창기 신입시절에 배우거나 사용했던 기술적인 방법들이 있다. 시간이 지날수록 왠만해선 다른방법은 사용하지 않으려 하고 &lt;code&gt;습관&lt;/code&gt;처럼 기존에 사용했던 방법을 고수하는 버릇이 있다. 그 이유는 과거에 사용했을때 아무 탈 없이 잘 되었기 때문에, 그리고 빠른 구현 때문이라는 핑계일 것 같다.
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="spring" scheme="https://taetaetae.github.io/tags/spring/"/>
    
      <category term="redirect" scheme="https://taetaetae.github.io/tags/redirect/"/>
    
      <category term="out of memory" scheme="https://taetaetae.github.io/tags/out-of-memory/"/>
    
      <category term="heap dump" scheme="https://taetaetae.github.io/tags/heap-dump/"/>
    
  </entry>
  
  <entry>
    <title>천만 명의 사용자에게 1분 내로 알림 보내기 (병렬프로세스의 최적화)</title>
    <link href="https://taetaetae.github.io/2019/01/02/faster-parallel-processes/"/>
    <id>https://taetaetae.github.io/2019/01/02/faster-parallel-processes/</id>
    <published>2019-01-02T03:43:44.000Z</published>
    <updated>2019-01-07T04:23:55.005Z</updated>
    
    <content type="html"><![CDATA[<p>만약 1번부터 10번까지 번호표가 있는 사람들 총 열명에게 혼자서 동일한 내용의 메일을 보낸다고 가정해보자. 그리고 메일 발송시 한번에 한명에게만 보내야 하는 제한사항이 있을때 과연 당신은 어떤식으로 보내겠는가? 이어서 읽지말고 한번 생각해보자.<a id="more"></a><br>아무것도 고려하지 않고 단순하게 생각한다면 1번 보내고 &gt; 2번 보내고 … 9번 보내고 &gt; 10번 보내는 방법이 먼저 떠오르게 된다. (for loop 1 to 10 … ) 하지만 보내야 할 사람들이 많아져서 백명, 천명 많게는 천만명에게 보내야 할 경우 방금과 같은 순차적인 방법을 사용하면 너무 늦게 발송된다는건 코드를 작성하지 않아도 알 수있는 문제… 그렇다면 어떤 방법으로 보내야 보다 빨리 보낼수 있을까?<br>이번 포스팅에서는 필자가 운영하고 있는 서비스에서 기존에 있던 병렬프로세스를 어떤식으로 최적화 했는지, 그래서 결국 얼마나 빨라졌는지에 대한 과정을 정리해 보고자 한다. 비단 메일 발송이나 앱 푸시 등 특정 도메인에 국한되지는 않고 전반적인 프로세스에 대해 이해를 한다면 다른 곳에서도 비슷한 방법으로 활용할 수 있을꺼라 기대 해본다.</p><hr><h3 id="상황파악-및-목표"><a href="#상황파악-및-목표" class="headerlink" title="# 상황파악 및 목표"></a># 상황파악 및 목표</h3><p>(원할한 이해를 돕기 위하여) 먼저 필자가 운영하고있는 서비스를 간략히 소개부터 해야겠다. (그렇다고 필자 혼자 다 하는건 아님^^;…)<br>셀럽의 방송이 시작되면 구독한 사용자에게 각 모바일 기기에 설치되어있는 앱으로 알림을 보내어 예정에 없던 깜짝 라이브 방송이나 VOD 영상 오픈을 보다 빠르게 확인할 수 있도록 제공하고 있다.<br>여기서, 알림이 늦게 발송되면 셀럽은 방송을 시작하고 팬들이 들어오기까지 기다려야 한다거나 반대로 팬들은 방송 시작하고 뒤늦게 방송을 보게되는 불편함이 생기게 된다. 그리고 중복으로 알림이 발송되거나 특정 사용자들에게 발송이 누락되면 안 되는 등 “알림” 이란 기능은 서비스에 있어서 중요한 기능 중에 하나라고 할수 있다.</p><blockquote><p>여기서 “발송 시간”은 처음 발송작업 시작부터 마지막 사용자에 대해 사내 발송 플랫폼으로 발송 요청을 하기까지의 시간을 의미</p></blockquote><p>그리고 “채널” 이라는 샐럽단위의 그룹이 있는데 영상과 채널의 관계는 1:N이다. 즉, 하나의 영상을 여러 채널에 연결시킬수 있어서 하나의 영상에 대해 여러 채널들에게 연결을 시켜놓으면 채널을 구독하고있는 각각의 사용자에게 모두 알림을 발송 할수가 있게 된다.</p><p>우선, 알람이 사용자에게 전달되기까지의 큰 흐름은 다음과 같다.</p><div class="figure center" style="width:;"><img class="fig-img" src="push_process.jpg" alt="알림 프로세스"><span class="image-caption">알림 프로세스</span><span class="caption">알림 프로세스</span></div><ol><li>서비스에서 보낼 대상과 보낼 정보를 조합하여 </li><li>사내 푸시 발송 플랫폼인 사내 발송 플랫폼에게 전달을 하면 플랫폼에 따라 발송이 되고</li><li>최종적으로는 사용자의 모바일 기기에 노출이 됨</li></ol><p>간단하게 “병렬로 발송하면 되지 않을까?”라는 필자의 생각이 부끄러워질 정도로 이미 redis, rabbitMQ 를 활용해서 아래 그림처럼 병렬 프로세스로 구성되어 있었다.</p><div class="figure center" style="width:;"><img class="fig-img" src="legacy_structure.jpg" alt="기존 구조"><span class="image-caption">기존 구조</span><span class="caption">기존 구조</span></div><ol><li>라이브가 시작되거나 VOD가 오픈될 경우 api가 호출이 되고 다시 배치 서버에게 영상의 고유번호를 전달</li><li>전달받은 영상의 고유번호를 rabbitMQ의 수신자 조회 Queue에 produce</li><li>수신자 조회 Queue의 consumer인 수신자 조회 모듈에서 영상의 고유번호를 consume 후 아래 작업을 진행<br>3-1. 영상:채널 은 1:N 구조이기 때문에 여러 채널의 사용자들에게 알림을 발송할 수 있고, 영상에 연결된 채널들의 user를 db에서 가져온다.<br>3-2. 가져온 user를 (중복으로 알림이 발송되지 않기 위해) java set에 담고 모든 채널을 조회했다면 redis에 sorted set으로 담는다.<br>3-3. 적당한 크기로 분할하고 이 분할정보를 발송 Queue에 produce</li><li>발송 모듈에서 분할 정보를 consume 하고 아래 작업을 진행 (병렬처리)<br>4-1. redis 에서 user 모음을 가져오고<br>4-2. 조회한 user에 해당하는 deviceId를 db에서 가져옴</li><li>deviceId와 컨텐츠 정보를 활용하여 적절한 payload를 구성 후 사내 발송 플랫폼 에게 전달</li></ol><p>기존 구조에서 발송 시간은 서비스에서 구독자 수가 가장 많은 채널 기준으로 약 1.1천만 명에게 최종 11분 정도 소요되고 있었다. (맨 처음에 이야기 한 순차적인 방법이였다면… 훨씬더 오래 걸렸을꺼라 예상해본다…)</p><p>기존에 구성하셨던 분들도 수많은 시행착오와 고민을 하시며 구성하셨을 텐데 더 이상 어떻게 더 빠르게 보낼 수 있을까 하는 부담감과 자칫 알림이 잘못 발송되기라도 한다면(장애가 발생한다면) 그 수많은 사용자들의 불만 화살 과녁이 필자가 되어야 한다는 압박감이 개선 시작 전부터 머릿속을 휘감고 있었던 찰나에</p><div class="figure center" style="width:;"><img class="fig-img" src="goal.jpg" alt="답정너"><span class="image-caption">답정너</span><span class="caption">답정너</span></div><p>라는 불가능할 것만 같은 목표가 (<a href="https://ko.dict.naver.com/#/entry/koko/5e83a17fa0064cc0bb6879031f4d32a2" target="_blank" rel="noopener">답정너</a> 마냥) 정해지며 그렇게 푸시 개선 프로젝트가 시작되었다. 결국 <strong>사내 발송 플랫폼에게 얼마나 더 빨리 보낼수 있는가</strong> 가 개선 포인트 라고 할수 있겠다.</p><hr><h3 id="1차-개선-AsyncRestTemplate-적용"><a href="#1차-개선-AsyncRestTemplate-적용" class="headerlink" title="# 1차 개선 : AsyncRestTemplate 적용"></a># 1차 개선 : AsyncRestTemplate 적용</h3><p>사내 발송 플랫폼에 요청을 한 뒤 응답의 종류(성공/실패)에 따라 발송 시간 로깅만 하기 때문에 응답을 기다리지 않고 <a href="https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/web/client/AsyncRestTemplate.html" target="_blank" rel="noopener">AsyncRestTemplate</a>를 사용해서 비동기 호출로 변경하였다. 사내 발송 플랫폼에 요청에 따른 응답은 1~2초 내외였지만 발송 대상이 많을수록 기다리는 시간을 모아보면 무시 못 할 시간이었기 때문이다.</p><p>구조가 크게 변경된 건 없었고 발송하는 부분에서 약간의 로직만 변경하였는데 나름의 큰 효과를 볼 수 있었다.</p><p><strong>▶ 개선 결과</strong></p><table><thead><tr><th>항목</th><th>기존</th><th>1차</th><th>2차</th><th>3차</th></tr></thead><tbody><tr><td>발송 대상수</td><td>약 10,530,000명</td><td><font color="red">약 10,570,000명</font></td><td></td><td></td></tr><tr><td>첫발송</td><td>약 6분</td><td><font color="red">약 6분</font></td><td></td><td></td></tr><tr><td>마지막 발송</td><td>약 11분</td><td><font color="red">약 7분</font></td><td></td></tr></tbody></table><hr><h3 id="2차-개선-발송대상-구하는-즉시-병렬-발송처리-불필요-프로세스-제거"><a href="#2차-개선-발송대상-구하는-즉시-병렬-발송처리-불필요-프로세스-제거" class="headerlink" title="# 2차 개선 : 발송대상 구하는 즉시 병렬 발송처리, 불필요 프로세스 제거"></a># 2차 개선 : 발송대상 구하는 즉시 병렬 발송처리, 불필요 프로세스 제거</h3><ul><li>발송대상 구하는 즉시 병렬 발송처리<br>기존 구조에서는 발송 대상을 전부다 구한 뒤에 발송이 시작되었다. 왜냐하면 영상에 연결된 채널이 여러 개가 될 수 있다 보니 중복 사용자 제거를 해야 하기 때문이었다. 예로 들어 영상 하나에 A, B, C 채널이 연결되어있고 어느 사용자가 A, B 채널을 구독하고 있는 상황에서 중복제거를 하지 않고 보낸다면 해당 사용자는 같은 내용의 알림을 두 번 받는 상황이 된다.<br>영상에 연결된 채널이 한 개라면 문제가 없지만 두 개 이상일 경우부터 중복알림 문제가 발생했기 때문에, 그리고 이 중복제거 프로세스가 다 되어야지만 첫 번째 발송이 되는 구조였기 때문에 어떻게든 다른 방법으로 중복 발송을 해결해야만 했다.<br>그래서 여러 시행착오 끝에 결정된 방법은 “이 사용자는 발송이 되었다”라는 정보를 redis에 담는 식으로 중복체크하는 방법을 바꾸는 것이었다. 또한 첫 번째 채널(구독자 수가 가장 많은 채널)은 중복체크를 할 필요가 없기 때문에 db에서 조회하는 즉시 발송해서 방송 시작 1초 내에 사용자에게 알림을 발송할 수가 있었다.</li><li>불필요 프로세스 제거<br>발송 triggering 을 배치(jenkins)에서 하고 있었다. api에서 jenkins remote api로 호출이 되면 기본적으로 약 20~30초가량의 인스턴스 구동시간이 존재하게 되는데 이 시간 또한 불필요한 프로세스라고 생각되어 api가 바로 수신자 조회 Queue에 produce 하는 식으로 구조를 변경하였다.</li></ul><div class="figure center" style="width:;"><img class="fig-img" src="improvement_2.jpg" alt="2차 개선"><span class="image-caption">2차 개선</span><span class="caption">2차 개선</span></div><ol><li>api에서 바로 수신자 조회 분할 Queue로 produce</li><li>수신자 조회 분할 모듈에서 consume을 하고 적당한 크기로 start index, end index를 구분하여 다시 수신자 조회 Queue로 produce</li><li>수신자 조회 모듈이 병렬로 consume을 하며 아래 작업을 수행합니다.<br>3-1. 발송 대상 user를 db에서 가져옴<br>3-2. 첫 번째 채널일 경우(구독자 수가 가장 많은 채널) 중복제거키에 담고 발송대상 key에 담은 뒤 발송 Queue에 produce<br>3-3. 첫 번째 채널이 아닐 경우 중복제거를 해야 하기 때문에 중복제거키에서 redis의 <a href="https://redis.io/commands/zscore" target="_blank" rel="noopener">zscore 연산</a> (시간 복잡도 O(1) )을 활용하여 발송되지 않은 user만 간추려서 발송 대상 key에 담은 뒤 발송 Queue에 produce</li><li>기존과 동일</li></ol><p>이렇게 개선한 결과 사용자들이 방송이 시작되자마자 알림을 받기 시작할 수 있었고, 발송 대상을 구하자마자 발송하기 때문에 발송 속도도 개선이 됬음을 확인할 수 있었다.</p><p><strong>▶ 개선 결과</strong></p><table><thead><tr><th>항목</th><th>기존</th><th>1차</th><th>2차</th><th>3차</th></tr></thead><tbody><tr><td>발송 대상수</td><td>약 10,530,000명</td><td>약 10,570,000명</td><td><font color="red">약 11,120,000명</font></td><td></td></tr><tr><td>첫발송</td><td>약 6분</td><td>약 6분</td><td><font color="red">약 1초</font></td><td></td></tr><tr><td>마지막 발송</td><td>약 11분</td><td>약 7분</td><td><font color="red">약 5분 30초</font></td></tr></tbody></table><hr><h3 id="3차-개선-발송대상-병렬x병렬조회-redis-파티셔닝-채널간의-발송-타이밍-해소"><a href="#3차-개선-발송대상-병렬x병렬조회-redis-파티셔닝-채널간의-발송-타이밍-해소" class="headerlink" title="# 3차 개선 : 발송대상 병렬x병렬조회, redis 파티셔닝, 채널간의 발송 타이밍 해소"></a># 3차 개선 : 발송대상 병렬x병렬조회, redis 파티셔닝, 채널간의 발송 타이밍 해소</h3><ul><li><p>발송대상 병렬x병렬조회<br>몇 차례 속도 개선을 하는 필자를 보고 팀원 분들이 짠하게(?) 느끼셨는지 아이디어를 하나 건네주셨다. 그건 바로 db에서 user를 조회할 때 병렬 조회하는 것을 다시 병렬 조회하는 것.<br>db에 채널별 구독자 테이블에는 user가 오름차순으로 정렬되어 있다 보니 큰 단위로 나눌수가 있고, 다시 이를 작은 단위로 분할하여 조회가 가능했던 것이었다. 대신, 나누는 단위가 적당해야 하고(테스트를 통해서 찾아내야…) user가 꽉 찬(?) 그룹이 있는가 반면 비어있는 그룹이 있을 수가 있다. 그림으로 그려보면 다음과 같다.</p><div class="figure " style="width:;"><img class="fig-img" src="user.jpg" alt=""></div><ul><li>1단계 : 첫 번째 user가 1, 마지막 user가 300만이라고 가정할 때 큰 단위(10만)로 분할합니다.<br>예 ) 0~100,000 / 100,000~200,000 / … / 2,900,000~3,000,000</li><li>2단계 (병렬) : 1단계에서 나눈 단위를 다시 작은 단위(1,000)로 분할하여 db에서 조회를 하고 그다음 단계를 진행합니다.<br>예) 0~1,000 / 1,000~2,000 / … / 99,000~100,000</li></ul><p>이렇게 하고서 반영을 해보니 속도가 빨라진 대신 redis 가 부하를 많이 받게 되어 다른 모듈에서 redis 를 사용하는 곳에서 지연이 발생하게 되었습니다. 모니터링 툴인 pinpoint에 롯데타워가 뙇..</p><div class="figure " style="width:;"><img class="fig-img" src="pinpoint.jpg" alt=""></div><p>결국 알림 속도를 빠르게 한답시고 서비스 전체가 사용하는 공용 redis에 지연이 발생하게 되어버린 것이었다. 개선을 함에 있어 서비스 영향도를 리스트업 하고, 조금이라도 문제가 생길것 같은 부분을 고려해야 하는 교훈을 얻을수 있었다.</p></li><li>redis 파티셔닝<br>알림 발송만을 위한 별도 redis 클러스터를 구축하기에는 장비 발급부터 간단한 작업이 아니었기에 어떻게든 로직에서 해결점을 찾아야 했다. 고민의 고민을 한 결과 redis 는 Single thread 방식으로 처리하기 때문에 key 하나에 연산이 끝날 때까지 해당 key가 속한 redis는 다른 연산을 처리할 수가 없게 되는 부분을 인지하고 중복 발송을 막기 위한 redis 키를 기존에는 하나를 사용하고 있었는데 이를 user 값 기준으로 여러 개의 키로 파티셔닝 하게 되었다.<br>즉, user가 천만 개라고 가정했을 때 기존에는 한 개의 키에 천만 개가 들어가던 구조에서 user 값을 10,000으로 나누어 결과적으로는 하나의 키에 1,000개씩 총 10,000개의 키에 파티셔닝되어 들어가게 되는 구조로 변경하게 되었다. 그랬더니 발송 속도도 더 빨라지고 pinpoint에 응답 그래프도 전혀 문제가 없는 수치인 것을 확인할 수 있었다.</li><li><p>채널간의 발송 타이밍 해소<br>여러 채널을 동시에 보내다 보니 아주 간헐적으로 중복 알림이 발생하게 되었다. 이유는 지금까지 프로세스를 보면 여러 단계의 병렬 프로세스가 있는데 각 프로세스별 순서 보장이 안되고 각자 진행되기 때문에 중복체크 키에 들어가기 전에 다른 프로세스에서 먼저 중복체크를 하고 발송을 해버리면 중복으로 발송이 되어버리던 것이었다. 간단히 그림으로 설명해보면…</p><div class="figure " style="width:;"><img class="fig-img" src="rabbitmq.jpg" alt=""></div><p>위 그림에서 1,2,3,4,5 가 동시에 발송을 시작한다고 가정했을 때 그 다음은 2번이 먼저 진행될 수도 있고 5번이 먼저 진행될 수도 있게 된니다. 그렇기 때문에 매번 중복 알림이 발생되는 건 아니었지만 아주아주 간헐적으로 발생하게 되었다.<br>이 문제는 간단히 채널별로 병렬 조회 하는 부분에서, 1초마다 발송 대상수(redis 를 활용하여 로깅 목적으로 발송 대상수를 트래킹하고 있다.)가 변하지 않을 경우 한 채널에 대해 발송이 완료되었다고 간주하고 그 다음 채널을 발송하는 방법으로 해결하였다.</p></li></ul><p>이렇게 거듭된 개선을 거쳐 정리된 최종 구조는 다음과 같다.</p><div class="figure center" style="width:;"><img class="fig-img" src="improvement_3.jpg" alt="3차 개선. a.k.a. 최종 구조"><span class="image-caption">3차 개선. a.k.a. 최종 구조</span><span class="caption">3차 개선. a.k.a. 최종 구조</span></div><ol><li>채널별로 큰 단위로 index를 파티셔닝 하여 병렬 조회할 수 있도록 한다.<br>1-1. 첫 consumer는 채널을 채널 간의 알림 발송 진행을 담당해주고,<br>1-2. redis에 발송 대상수가 변함이 없을 경우 다음 채널을 발송하도록 한다.</li><li>1에서보다 더 작은 단위로 파티셔닝하여 아래 작업을 수행한다.<br>2-1. db에서 user를 조회하고<br>2-2. user를 중복제거 key에 10만단위로 파티셔닝 하여 담는다.<br> ex ) user가 105872 인경우 push:overlapCheck:100000 에, user가 3409572 인 경우 push:overlapCheck:3400000<br>2-3. 2-1에서 가져온 user를 임의 redis key에 담는다.</li><li>중복체크 작업을 수행합니다.<br>3-1. 첫 번째 채널일 경우 중복체크를 하지 않고 바로 발송을 한다.<br>3-2. 첫 번째 채널이 아닐 경우 2-3에서 저장한 redis key의 값을 조회하여 2-2에서 저장한 중복제거 key에 있는지 확인 후 발송 여부를 결정한다.</li></ol><p><strong>▶ 개선 결과</strong></p><table><thead><tr><th>항목</th><th>기존</th><th>1차</th><th>2차</th><th>3차</th></tr></thead><tbody><tr><td>발송 대상수</td><td>약 10,530,000명</td><td>약 10,570,000명</td><td>약 11,120,000명</td><td><font color="red">약 11,240,000명</font></td></tr><tr><td>첫발송</td><td>약 6분</td><td>약 6분</td><td>약 1초</td><td><font color="red">약 1초</font></td></tr><tr><td>마지막 발송</td><td>약 11분</td><td>약 7분</td><td>약 5분 30초</td><td><font color="red">51초</font></td></tr></tbody></table><hr><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><p>결국 처음에 개선 프로젝트 시작 시 정해졌던 목표에 도달할 수 있었다.(발송 대상이 약 100만 명이 더 늘었지만 1분내로 발송 성공)<br>또한 무조건 좋다고 사용하다간 오히려 독이 될 수 있고, 반대로 돌아가는 원리를 잘 알아보고 사용한다면 본인이 원하는 가장 이상적인 결과를 만들 수 있다는 좋은 경험을 얻을 수 있었다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;만약 1번부터 10번까지 번호표가 있는 사람들 총 열명에게 혼자서 동일한 내용의 메일을 보낸다고 가정해보자. 그리고 메일 발송시 한번에 한명에게만 보내야 하는 제한사항이 있을때 과연 당신은 어떤식으로 보내겠는가? 이어서 읽지말고 한번 생각해보자.
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="parallel precess" scheme="https://taetaetae.github.io/tags/parallel-precess/"/>
    
      <category term="redis" scheme="https://taetaetae.github.io/tags/redis/"/>
    
      <category term="rabbitMQ" scheme="https://taetaetae.github.io/tags/rabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>2018 회고 - Coder가 아닌 Programmer로</title>
    <link href="https://taetaetae.github.io/2018/12/31/review-2018/"/>
    <id>https://taetaetae.github.io/2018/12/31/review-2018/</id>
    <published>2018-12-31T12:33:29.000Z</published>
    <updated>2018-12-31T17:17:54.820Z</updated>
    
    <content type="html"><![CDATA[<p>매사에 행동하는 모든것들의 끝자락에서는 그동안 잘한것과 못한것을 다시 생각하며 잘한것은 보다 더 잘할수 있도록 하고 못한것은 왜 못했는지 그리고 어떻게 하면 못한 부분을 고칠수 있을지에 대한 시간을 갖으려고 노력해왔다. 그게 개발이 되었든 게임이 되었든 연인과의 데이트가 되었든 뭐든지. <a id="more"></a>이러한 시간들은 필자에게 큰 인사이트를 얻을 수 있게 되었고 지난 한해를 돌이켜 보자면 개인적으로 계획한 전부를 다 이뤄내지는 못했지만 나름의 많은 경험과 성과를 달성했다고 생각해본다.<br>이제 몇시간 뒤면 올해가 끝나고 새로운 한 해가 시작되는 이 시점에 <code>개발자로써의 회고</code>를 해보며 2018년 정리 및 2019년 목표를 다짐해보자.</p><h4 id="글쓰는-개발자가-되자-개인-블로그-운영"><a href="#글쓰는-개발자가-되자-개인-블로그-운영" class="headerlink" title="# 글쓰는 개발자가 되자. 개인 블로그 운영"></a># 글쓰는 개발자가 되자. 개인 블로그 운영</h4><p>아주 오래전, 동기 형을 통해 <code>개발자가 글을 써야하는 중요성</code>에 대해 절실하게 배우게 되었고 그때부터 블로그를 운영하기 시작하였다. 그 동기형의 말에 조금 더 내 생각을 첨가하자면 글을 쓰다보면 누군가 내 글을 본다는 마음에 내가 알고있는 지식을 보다 더 깊게 공부하게 되고 그것들이 모여 내 개발 히스토리가 만들어 지며 포트폴리오 등 다양하게 활용할 수 있기에 블로그를 운영하는건 정말 좋은 선택지 였던것 같다. 실제로 그냥 구글링 해서 알게된 것과는 또 다른 배움이 있었기 때문이다.<br>회사 일 그리고 개인 공부를 하면서 적어도 한달에 한가지 이상은 배우게 되기 때문에 올해 초 한달에 한개 이상의 글을 쓰기로 결심하였다.(그 달의 글이 없다면 뭔가 놀았거나(?) 미친듯이 바빴거나 아니면 게을렀거나…) 블로그에 글을 쓴 내역을 그래프로 시각화 해보면 아래처럼 총 23개의 글을 작성하였고 월 평균 1.9개의 글을 작성하게 된것을 볼수 있다.</p><blockquote><p>9월달엔 팀 옮기자마자 엄청 바빴고, 11월엔 그 바쁜게 결실을 맺는 시간… 이라 핑계를… (나중에 블로깅 예정, 병렬 프로그래밍 관련)</p></blockquote><div class="figure center" style="width:;"><img class="fig-img" src="post_count.jpg" alt="월별 글 작성수"><span class="image-caption">월별 글 작성수</span><span class="caption">월별 글 작성수</span></div><p>위 결과만을 두고 봤을땐 많으면 많고 적으면 적다고 할 수 있는 결과지만 개인적으로는 자투리 시간을 활용해서 그간 배웠던것, 그리고 경험했지만 내것으로 만들지 못하고 보기만 하며 넘어간것들에 대해 귀찮지만 시간을 투자하고 정리했더라면 더 많은 글을 썼을것 같다는 조금 아쉬운 결과라고 생각이 든다.</p><div class="figure center" style="width:;"><img class="fig-img" src="blog_ga.jpg" alt="주 단위 PV, 누군가 내 글을 보고 있다는것에 뿌듯함"><span class="image-caption">주 단위 PV, 누군가 내 글을 보고 있다는것에 뿌듯함</span><span class="caption">주 단위 PV, 누군가 내 글을 보고 있다는것에 뿌듯함</span></div><p>나름 열심히 글을 쓴 결과일까, GA를 통해 본 필자의 블로그에 유입량이 점점 늘어나는것을 보며 하나를 쓰더라도 좀더 자세히 독자의 입장에서 써야겠다고 다시한번 다짐하게 된다. 다만 글을 “많이” 쓰는것보다 하나를 작성하더라도 원인과 근거를 들어가며 문제를 정확히 파악하는데 집중을 해야하고, 단순 사용법 나열이 아닌 실제로 경험을 해가면서 “내것”으로 만드는 과정이 필요하겠다.</p><h4 id="회사-팀-변경-그리고-토이-프로젝트"><a href="#회사-팀-변경-그리고-토이-프로젝트" class="headerlink" title="# 회사 팀 변경 그리고 토이 프로젝트"></a># 회사 팀 변경 그리고 토이 프로젝트</h4><p>기존에 아무것도 없던 환경에서 서버 발급부터 이런 저런 서비스에 도움이 되는 다양한 모니터링 툴을 개발하며 무사히 서비스를 오픈을 하였고, 약간의 매너리즘이 생겨날 즈음 좋은 기회가 생겨 성격이 전혀 다른 서비스를 하는 팀을 옮기게 되었다. 약간 이직과도 비슷한 느낌으로 팀을 옮기게 되었는데 처음엔 새로운 지식을 습득해야 하는 두려움도 있었고 기존 서비스에 애정이 많아서 고민이 많았지만 벌써 옮긴지 5개월이 지나고 돌이켜보면 올해 가장 잘한 일 중 하나가 아닐까하는 생각이 든다. 전 팀에선 서비스를 운영하는데 그쳤지만 지금 내가 있는 곳은 대용량 서비스를 성능측면에서, 그리고 아키텍쳐 측면에서 보다 효율적으로 개발하는데 집중을 하려는 모습들이 보이기 때문이다. 더불어 팀에 투입되자마자 필자 홀로 기존에 있던 병렬 프로세스를 개선하여 서비스적으로 약 90%의 개선효과를 볼수있었는데 이 부분은 추후 포스팅 할 예정이다.<br>그리고 팀을 옮기기 한두달 전 개인적인 여유시간이 많이 있었고, 다른사람들의 블로그를 보며 챙겨보고 싶은 마음에 <a href="http://daily-devblog.com" target="_blank" rel="noopener">토이 프로젝트</a>를 만들게 되었다. 7월 중순부터 시작했으니 이것도 어느덧 반년이 지나고 있는데 운영을 해가면서 기능을 추가하기 위해 종종 밤을 새는 등 올 한해있어 꽤 많은것을 얻을수 있었던 시간이였다. 간혹 버그가 생겨 메일이 발송 안되면 지인 또는 모르는 분들이 메일로 제보도 해주시고 … 색다른 경험이였다. 자세한 내용 및 후기는 <a href="https://taetaetae.github.io/2018/08/05/daily-dev-blog-1/">개발후기-1</a> 과 <a href="https://taetaetae.github.io/2018/08/09/daily-dev-blog-2/">개발후기-2</a>에서 확인 가능하다. (어서 3편을 쓰고 마무리를 지어야 할텐데…) 그리고 최근에는 <a href="http://daily-devblog.com/archive" target="_blank" rel="noopener">아카이빙</a> 기능을 만들어 과거 글을 조회할수 있도록 만들었는데 2% 부족한 느낌이다… (맘같아서는 형태소 분석을 해서 자동 필터링도 해보고 싶은데…)</p><div class="figure center" style="width:;"><img class="fig-img" src="ddb_graph.jpg" alt="점점 늘어가는 구독자수, AWS 프리티어가 끝나기 전에 뭔가 방법을 찾아야 하는데 ..."><span class="image-caption">점점 늘어가는 구독자수, AWS 프리티어가 끝나기 전에 뭔가 방법을 찾아야 하는데 ...</span><span class="caption">점점 늘어가는 구독자수, AWS 프리티어가 끝나기 전에 뭔가 방법을 찾아야 하는데 ...</span></div><h4 id="공유-및-발표"><a href="#공유-및-발표" class="headerlink" title="# 공유 및 발표"></a># 공유 및 발표</h4><p>3월 즈음 <a href="https://www.popit.kr" target="_blank" rel="noopener">POP it</a> 관리자분께서 회사까지 직접 찾아와 주셔서 만남을 갖고 <a href="https://www.popit.kr/author/taetaetae" target="_blank" rel="noopener">POP it 저자활동</a>을 시작하게 된다. 그리고 비슷한 시점 D2 Hello World 담당자의 제안으로 이전 팀에서 활용했었던 기술에 대해 기고를 하는 영광을 얻게되고 (<a href="https://d2.naver.com/helloworld/3585246" target="_blank" rel="noopener">내 서버에는 누가 들어오는 걸까 - Apache 액세스 로그를 Elastic Stack으로 분석하기</a>, 여러차례 각종 개발 관련 행사에 참여하며 “난 언제쯤 저런 발표를 할수 있을까?” 하는 부러움이 무엇때문인지 “나도 할수있다”는 자신감으로 변화되어 2018 Pycon 행사에서 짧은 5분이였지만 급작스럽게 필자가 만들었던 토이 프로젝트에 대해 약 100~200여명 앞에서 간단히 소개하는 발표를 하게된다. (<a href="https://www.pycon.kr/2018/program/81" target="_blank" rel="noopener">Pycon 라이트닝토크</a>)</p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/e10hVYJHvKU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>작년까지만 해도 전혀 생각하지도 못할 외부활동을 정말 다양하게, 그리고 두려움을 떨쳐내고 회사라는 울타리를 벗어나 바깥세상을 바라볼수 있는 눈을 얻는 좋은 기회였다고 생각이 든다.</p><h4 id="결론-그래서-내년엔"><a href="#결론-그래서-내년엔" class="headerlink" title="# 결론, 그래서 내년엔?"></a># 결론, 그래서 내년엔?</h4><p>숨가쁘게 달려온 2018년. 올해는 무엇보다 외부활동을 많이 하면서 기존에 갖고있던 <code>주니어</code>로써의 개발 마인드를 조금이나마 벗어나며 <code>주니어</code>와 <code>시니어</code> 사이의 포지션으로 한발자국 올라선 기분이다. 예전에는 회사내에 팀장님이나 선배 개발자분들이 시킨일을 하며 <code>감</code>을 받아 먹었다면, 지금은 그 <code>감</code>을 어떻게 따먹는지, 어떤 <code>감</code>이 더 맛있고 어떻게 따먹어야 더 효율적인지 스스로 일어서는 방법에 첫 단추를 낀것 같아 한편으로는 마음이 무겁지만 한편으로는 새로움을 경험하고 배운다는 것에 벅차오르기까지 한다. 또한 기존에는 일반적인 Web Framework인 Spring 만을 가지고 CRUD에 고심했다면 ElasticStack, kafka, RabbitMQ, Redis 등 새로운 기술들을 배우기 시작하면서 새로운것에 대한 두려움 보다는 호기심이 더 커서 스펀지마냥 습득할수 있었던것 같다.<br>새해계획이라면 거창하게 들릴지 모르겠지만 다가오는 2019년엔 Coder 가 아닌 Programmer 가 되고 싶다. (<a href="http://openuiz.blogspot.com/2016/09/vs-vs-vs.html" target="_blank" rel="noopener">관련 좋은 글</a>) 막연하게 들릴지 모르겠지만 회사원이 아닌 개발자로써 나를 발전시키고 공유하며 서로 성장해 가는, 골을 직접 넣진 않지만 그 과정을 빌드업 하는 <code>미드필더</code>같은 역활을 할수있는 개발자가 되고 싶다. 이러한 계획을 달성하기 위해서는 내년에도 올 2018년을 계속 회고해가면서 잘못된 점을 고쳐나가고 잘한점을 상기하며 개발에 임해야 하지 않을까 싶다.<br>2018년, 고생했다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;매사에 행동하는 모든것들의 끝자락에서는 그동안 잘한것과 못한것을 다시 생각하며 잘한것은 보다 더 잘할수 있도록 하고 못한것은 왜 못했는지 그리고 어떻게 하면 못한 부분을 고칠수 있을지에 대한 시간을 갖으려고 노력해왔다. 그게 개발이 되었든 게임이 되었든 연인과의 데이트가 되었든 뭐든지.
    
    </summary>
    
      <category term="blog" scheme="https://taetaetae.github.io/categories/blog/"/>
    
    
      <category term="review" scheme="https://taetaetae.github.io/tags/review/"/>
    
  </entry>
  
  <entry>
    <title>엘라스틱서치 12월 서울 밋업 후기</title>
    <link href="https://taetaetae.github.io/2018/12/13/elastic-meetup-201812/"/>
    <id>https://taetaetae.github.io/2018/12/13/elastic-meetup-201812/</id>
    <published>2018-12-13T13:27:02.000Z</published>
    <updated>2018-12-13T16:43:14.303Z</updated>
    
    <content type="html"><![CDATA[<p>엘라스틱을 처음 접하게 된 건 2017년 여름 facebook 피드에 “Elastic Stack을 이용한 서울시 지하철 대시보드” 라는 <a href="https://www.elastic.co/kr/blog/seoul-metro-2014" target="_blank" rel="noopener">링크</a>를 보게 된 것부터인 것 같다. 그 당시 데이터 분석 및 자동화에 관심이 커지고 있던 찰나였는데 <a id="more"></a>키바나로 간단하면서도 아주 멋진 대시보드를 그릴 수 있다는 게 너무 흥미롭게 다가왔고 거기다 실시간으로 볼수 있다는 점에 공부를 시작하지 않을 수 없었다. 그렇게 이것저것 만들어 보기도 하고 한국 엘라스틱서치 커뮤니티 활동을 해오던 찰나 (최근들어 눈팅만 하고 있지만…) 올해 마지막 밋업을 한다고 하여 참여하게 되었다.</p><h3 id="여기어때-본사-방문"><a href="#여기어때-본사-방문" class="headerlink" title="# 여기어때 본사 방문"></a># 여기어때 본사 방문</h3><p>강남에 위치한 여기어때 본사에서 밋업을 하게 되어 덕분에 다른 회사 구경을 할 수 있게 되었다. 예전 다른 IT 스타트업 밋업 행사에서도 느꼈던 부분인데 엄청나게 큰 시설은 아니지만 아기자기하게 회사의 색깔과 특징을 잘 살려놓은 인테리어가 인상적이었다. 그런데 생각보다 사람이 너무~ 많이 와서 약간 집중이 안 될것 같았지만 다행히도 자리를 잘 잡아서 세션을 듣는 데는 무리가 없었다. (정확하진 않지만 참석하신 분들 중의 절반 정도만 강의장에 들어오고 나머지는 밖에서 듣는 걸 보고 이런 IT 행사의 인기를 다시 한번 실감할 수 있었다.)<br><div class="figure center" style="width:;"><img class="fig-img" src="elastic_1.jpg" alt="여기어때 본사건물에서 엘라스틱 밋업을!"><span class="image-caption">여기어때 본사건물에서 엘라스틱 밋업을!</span><span class="caption">여기어때 본사건물에서 엘라스틱 밋업을!</span></div></p><h3 id="엘라스틱서치-6-5-최신버전-소개-및-커뮤니티-회고"><a href="#엘라스틱서치-6-5-최신버전-소개-및-커뮤니티-회고" class="headerlink" title="# 엘라스틱서치 6.5 최신버전 소개 및 커뮤니티 회고"></a># 엘라스틱서치 6.5 최신버전 소개 및 커뮤니티 회고</h3><p>행사 처음 세션으로 김종민 커뮤니티 엔지니어 분께서 엘라스틱의 최근 업데이트 정보와 커뮤니티 활동에 대해서 회고해주셨다. 내가 처음 엘라스틱서치를 접한 버전이 2.4였는데 벌써 6.5라니… 빨라도 너무 빠르다. 이번 버전에서는 한 클러스터에서 다른 클러스터로의 인덱스를 복제하는 방법인 Cross-cluster replication (클러스터 복제) 기능이 추가되었고 ODBC Client 추가, 자바 11지원 등 여러 가지 기능이 추가되었다고 한다.<br>특히 키바나에서는 파일을 업로드하면 자동으로 분석해서 인덱싱을 해주는 기능도 생겼고 (파일 크기가 100메가 제한이라는게 살짝 아쉽긴 했다.) 캔버스, 스페이스 등 역시 키바나 라는 생각이 들 정도로 비주얼라이징을 한번더 업그레이드 한듯 하다. (다 사용할 수 있을까 하는 정도로… 엘라스틱 스택을 들어보기만 하던 함께 참석한 동기 녀석도 당장 해보겠다고 할 정도로…)<br>다른 자세한 내용은 <a href="https://www.elastic.co/kr/blog/elastic-stack-6-5-0-released" target="_blank" rel="noopener">여기</a>서 확인이 가능하다.<br><div class="figure center" style="width:;"><img class="fig-img" src="elastic_2_1.jpg" alt="너무나 빠른 버전업과 너무나 발빠르게 움직이는 사람들"><span class="image-caption">너무나 빠른 버전업과 너무나 발빠르게 움직이는 사람들</span><span class="caption">너무나 빠른 버전업과 너무나 발빠르게 움직이는 사람들</span></div></p><h3 id="엘라스틱서치-활용사례"><a href="#엘라스틱서치-활용사례" class="headerlink" title="# 엘라스틱서치 활용사례"></a># 엘라스틱서치 활용사례</h3><p>스마일게이트 및 여기어때 에서 엘라스틱 서치를 활용한 사례를 발표해 주셨다. 하지만 아쉽게도 필자는 5.6 버전까지밖에 사용한 게 전부여서인지(그것도 일부 기능만) 전체 발표 내용을 다 이해를 하진 못했지만 구축하면서 생긴 문제나 삽질 경험담을 공유해주셔서 간접적으로라도 그때의 현장감(?)을 느낄 수 있어 좋았고, 한편으로 여태까지 나름 엘라스틱서치를 만져봤다고 약간의 자신감 반 자만심 반으로 생각했었는데 역시 세상엔 고수가 많구나 하며 다시 분발해야겠다고 다짐했다.<br><div class="figure center" style="width:;"><img class="fig-img" src="elastic_2_2.jpg" alt="스마일게이트 + 여기어때"><span class="image-caption">스마일게이트 + 여기어때</span><span class="caption">스마일게이트 + 여기어때</span></div></p><h3 id="마치며"><a href="#마치며" class="headerlink" title="# 마치며"></a># 마치며</h3><p>커뮤니티 활동 회고 시간에 누가 페이스북 커뮤니티에서 “공유”라는 단어를 사용해서 게시글을 작성했는지 키바나로 보여주고 밋업에 온 사람이 있다면 5만원 여기어때 쿠폰을 준다고 했었다. 마침 키바나 대시보드 한쪽 구석에 필자의 이름이 보였지만 (예전에 나름 활발하게 질문도 하고 공유도 했던 적이 있어서…) 쿠폰을 받는구나 하며 기대를 하고 있었지만 아쉽게도 최근에 작성한 몇 분에게만 선물이 돌아갔다… 하지만 그 아쉬움도 잠시, 무작위로 추첨하여 또 쿠폰을 준다고 했는데 당첨이 되어서ㅎㅎ 감사하게도 쿠폰을 받는 기쁨을 누릴 수 있었다!!</p><div class="figure center" style="width:;"><img class="fig-img" src="elastic_3.jpg" alt="역시 밋업의 마무리는 굿즈모음이지(?)"><span class="image-caption">역시 밋업의 마무리는 굿즈모음이지(?)</span><span class="caption">역시 밋업의 마무리는 굿즈모음이지(?)</span></div><p>매번 이런 IT밋업에 참가 신청을 하고 참석하기 전에는 “아 귀찮다. 취소할까. 날도 추운데. 피곤한데” 하며 가기 싫었지만 막상 와보면 생각보다 많은 것을 배워가고 얻어 간다. (쿠폰을 받아서가 아니라…) 세션에 발표하시는 분들, 그리고 그 발표를 듣는 참석하신 분들의 눈동자에서 배움에는 끝이 없고 배워야 살아남는다는 걸 (특히 IT직군은 더…) 다시 한번 느끼고 생각할 수 있었던 좋은 시간이었다.</p><p>내년엔 엘라스틱으로 뭘 만들어 볼까! 새로워진 기능들 + 삽질 경험담을 내 것으로 만들어 보자!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;엘라스틱을 처음 접하게 된 건 2017년 여름 facebook 피드에 “Elastic Stack을 이용한 서울시 지하철 대시보드” 라는 &lt;a href=&quot;https://www.elastic.co/kr/blog/seoul-metro-2014&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;링크&lt;/a&gt;를 보게 된 것부터인 것 같다. 그 당시 데이터 분석 및 자동화에 관심이 커지고 있던 찰나였는데
    
    </summary>
    
      <category term="blog" scheme="https://taetaetae.github.io/categories/blog/"/>
    
    
      <category term="elasticsearch" scheme="https://taetaetae.github.io/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins 설치 치트키</title>
    <link href="https://taetaetae.github.io/2018/12/02/jenkins-install/"/>
    <id>https://taetaetae.github.io/2018/12/02/jenkins-install/</id>
    <published>2018-12-01T19:37:59.000Z</published>
    <updated>2019-03-03T10:23:35.601Z</updated>
    
    <content type="html"><![CDATA[<p>“show me the money”, “black sheep wall”.<br>어렸을적 스타크래프트라는 게임이 나오고서 입에 달고 살았던 <code>치트키</code>. 게임이 시작되고 해당 치트키를 입력하면 돈이 들어오거나 맵이 훤하게 보여 컴퓨터를 이기는데 도움을 주곤 했었다. <a id="more"></a><br>개발을 하면서 Jenkins는 나 대신 어떤 업무를 수행하는데 강력한 툴 중에 하나이다. (물론 만능이라는 소리는 아니지만…) 새로운 프로젝트가 시작되거나 개발도중 무언가 자동화를 하고 싶을 경우엔 Jenkins를 찾게 되는데 그럴때마다 설치를 하고 이런저런 설정이 필요하다.<br>눈치를 챘을수도 있지만 이 포스트는 오로지 <code>젠킨스 설치하는 방법</code>을 아주 간단하고 핵심만 정리하고자 한다. 마치 <code>치트키</code>처럼.<br>나중에 다시 보기위해 + 누군가 해당 포스트를 보고 도움이 되었으면 하는 바람으로.</p><p>(물론 이 방법밖에 있는건 아니지만 필자는 아래와 방법을 사용하고 있다.)</p><hr><p>우선 CentOS 환경에 Java가 설치되어 있는 상황이라 가정한다.</p><ul><li><p>적당한 위치에 tomcat 다운 ( <a href="https://tomcat.apache.org/download-80.cgi" target="_blank" rel="noopener">https://tomcat.apache.org/download-80.cgi</a> )</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget &#123;압축파일 다운경로, 필자는 apache-tomcat-8.5.35 &#125;</span><br></pre></td></tr></table></figure></li><li><p>압축 해제후 하위 폴더중 webapps로 이동</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-tomcat-8.5.35.tar.gz</span><br><span class="line">cd apache-tomcat-8.5.35/webapps</span><br></pre></td></tr></table></figure></li><li><p>Jenkins 다운 ( <a href="https://jenkins.io/download/" target="_blank" rel="noopener">https://jenkins.io/download/</a> )</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war</span><br></pre></td></tr></table></figure></li><li><p>tomcat 하위폴더중 conf 폴더로 이동</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ../conf</span><br></pre></td></tr></table></figure></li><li><p>server.xml 수정 및 http port 확인</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi server.xml</span><br><span class="line"></span><br><span class="line">&lt;Host&gt; 하위에 추가</span><br><span class="line">&lt;Context path=&quot;/jenkins&quot; debug=&quot;0&quot; privileged=&quot;true&quot; docBase=&quot;jenkins.war&quot; /&gt;</span><br><span class="line"></span><br><span class="line">port 확인</span><br><span class="line">&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;/&gt;</span><br></pre></td></tr></table></figure></li><li><p>해당 서버의 ip와 위 port에 맞춰 url 입력후 jenkins 설치</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://ip:8080/jenkins</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;“show me the money”, “black sheep wall”.&lt;br&gt;어렸을적 스타크래프트라는 게임이 나오고서 입에 달고 살았던 &lt;code&gt;치트키&lt;/code&gt;. 게임이 시작되고 해당 치트키를 입력하면 돈이 들어오거나 맵이 훤하게 보여 컴퓨터를 이기는데 도움을 주곤 했었다.
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="jenkins" scheme="https://taetaetae.github.io/tags/jenkins/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins에서 파이썬 출력을 실시간으로 보고싶다면?</title>
    <link href="https://taetaetae.github.io/2018/12/02/python-buffer/"/>
    <id>https://taetaetae.github.io/2018/12/02/python-buffer/</id>
    <published>2018-12-01T16:40:11.000Z</published>
    <updated>2018-12-02T21:08:50.974Z</updated>
    
    <content type="html"><![CDATA[<p>필자가 운영하고 있는 <a href="http://daily-devblog.com" target="_blank" rel="noopener">Daily Dev Blog</a> 라는 서비스는 매일 동일한 시간에 주기적으로 데이터를 크롤링 하고 사용자에게 메일을 발송하는 일련의 작업을 수행하고 있다. 헌데 예상하지 못한 부분에서 예외가 발생하게 되면 어떤경우는 메일 발송을 못한다거나 기존에 발송했던 데이터를 다시 보내는 등 정상적이지 못한 상황을 맞이하게 된다.<a id="more"></a><br><div class="figure center" style="width:;"><img class="fig-img" src="ddb_duplication.png" alt="메일이 하루라도 잘못오면 여기저기서 연락이 온다. 감사한 분들..."><span class="image-caption">메일이 하루라도 잘못오면 여기저기서 연락이 온다. 감사한 분들...</span><span class="caption">메일이 하루라도 잘못오면 여기저기서 연락이 온다. 감사한 분들...</span></div><br>이런저런 바쁜일들로 차일피일 미루다 마침 여유가 생겨 기존에는 Crontab 스케쥴로 파이썬 스크립트를 실행하던 것에서 Jenkins로 옮기는 작업을 했다. 젠킨스가 스케쥴링을 해주고 실행이력을 보여주며, 실시간으로 스크립트가 돌아가는걸 볼수 있을것 같다는 기대감에서이다. 위에서 이야기 했던 예외상황을 보다 빠르고 편하게 실시간으로 디버깅을 하기 위해서가 가장 컸다.</p><h3 id="당연히-될거라고-생각했으나…"><a href="#당연히-될거라고-생각했으나…" class="headerlink" title="# 당연히 될거라고 생각했으나…"></a># 당연히 될거라고 생각했으나…</h3><p>작업은 간단할꺼라 생각했다. </p><ol><li>우선 <a href="https://taetaetae.github.io/2018/12/02/jenkins-install/">Jenkins를 설치</a>하고 </li><li>기존에 스크립트 파일을 Jenkins Job으로 옮긴후에 </li><li>적당한 코드 중간중간에 디버깅이 용이하도록 로그를 출력하게 해둔다음</li><li>스케쥴링만 걸어두면 끝이라고 생각했다. </li></ol><p>하지만, 이렇게 간단하게 끝날것만 같았던 작업이 은근 귀찮은 작업이 될줄이야. 디버깅을 위해 로그를 출력하도록 해놨는데 모든 스크립트가 끝이 나서야 해당 로그가 출력되는 것이였다. 로그를 실시간으로 볼수 없다면 Crontab에서 Jenkins로 옮기는 이유가 크게 없게 된다. 실제로 아래처럼 코드를 작성하고 Jenkins Job을 실행시켜보면 다 끝나고서야 출력이 되는걸 볼수 있었다. </p><p>(1초에 한번씩 5초동안 로그를 찍는 간단한 코드다.)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">print(<span class="string">'start'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> second <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>) :</span><br><span class="line">  print(second)</span><br><span class="line">  time.sleep(second)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'end'</span>)</span><br></pre></td></tr></table></figure><div class="figure center" style="width:;"><img class="fig-img" src="before.gif" alt="스크립트가 다 끝나서야 출력을 볼수 있다ㅠ 실시간으로 디버깅이 어렵다."><span class="image-caption">스크립트가 다 끝나서야 출력을 볼수 있다ㅠ 실시간으로 디버깅이 어렵다.</span><span class="caption">스크립트가 다 끝나서야 출력을 볼수 있다ㅠ 실시간으로 디버깅이 어렵다.</span></div><h3 id="그럼-어떻게-해야할까"><a href="#그럼-어떻게-해야할까" class="headerlink" title="# 그럼 어떻게 해야할까?"></a># 그럼 어떻게 해야할까?</h3><p>개발을 하면서 만나는 대부분의 문제들은 누군가 과거에 경험했던 문제였고, 이미 해결된 문제일 확률이 상당히 높은것들이 많다. 이번에도 역시, 갓 스택 오버플로우 : <a href="https://stackoverflow.com/questions/107705/disable-output-buffering" target="_blank" rel="noopener">https://stackoverflow.com/questions/107705/disable-output-buffering</a></p><p>위 링크에서 알려준것처럼 해보면 다음과 같이 로그가 출력되는대로 젠킨스에서 볼수 있게 된다.<br><div class="figure center" style="width:;"><img class="fig-img" src="after.gif" alt="콘솔환경에서의 디버깅은 로깅이 최고!"><span class="image-caption">콘솔환경에서의 디버깅은 로깅이 최고!</span><span class="caption">콘솔환경에서의 디버깅은 로깅이 최고!</span></div></p><p>정리해보면 다음과 같은 방법이 있겠다.</p><ol><li><p><code>Execute Python script</code> 을 활용하여 Jenkins 에 직접 코드를 작성하는 경우 </p><ul><li>print의 flush옵션을 활용 ( <a href="https://docs.python.org/3/library/functions.html?highlight=print#print" target="_blank" rel="noopener">https://docs.python.org/3/library/functions.html?highlight=print#print</a> )</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'hello'</span>, flush=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><ul><li>매번 print 가 될때마다 flush가 되도록 재정의</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Unbuffered</span><span class="params">(object)</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stream)</span>:</span></span><br><span class="line">     self.stream = stream</span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(self, data)</span>:</span></span><br><span class="line">     self.stream.write(data)</span><br><span class="line">     self.stream.flush()</span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">writelines</span><span class="params">(self, datas)</span>:</span></span><br><span class="line">     self.stream.writelines(datas)</span><br><span class="line">     self.stream.flush()</span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span><span class="params">(self, attr)</span>:</span></span><br><span class="line">     <span class="keyword">return</span> getattr(self.stream, attr)</span><br><span class="line"></span><br><span class="line">sys.stdout=Unbuffered(sys.stdout)</span><br></pre></td></tr></table></figure></li><li><p><code>Execute shell</code>을 활용하여 특정경로의 Python 파일을 실행할 경우</p><ul><li><code>-u</code> 옵션을 줘서 실행시킨다. ( python -u python_module.py )</li></ul></li></ol><p>이렇게 두고보면 너무 간단한 작업인데 이런 방법을 모르는 상황에서는 작성된 Python Script를 Shell Script로 다시 감싸보거나 Python 코드를 쓰지 말까 까지 생각했었다… 삽질의 연속들… (Shell Script로 작성하면 바로바로 보였기 때문…)</p><p>다시한번 모르면 몸이 고생한다(?)라는걸 몸소 체험한 좋은…시간이였다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;필자가 운영하고 있는 &lt;a href=&quot;http://daily-devblog.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Daily Dev Blog&lt;/a&gt; 라는 서비스는 매일 동일한 시간에 주기적으로 데이터를 크롤링 하고 사용자에게 메일을 발송하는 일련의 작업을 수행하고 있다. 헌데 예상하지 못한 부분에서 예외가 발생하게 되면 어떤경우는 메일 발송을 못한다거나 기존에 발송했던 데이터를 다시 보내는 등 정상적이지 못한 상황을 맞이하게 된다.
    
    </summary>
    
      <category term="tech" scheme="https://taetaetae.github.io/categories/tech/"/>
    
    
      <category term="jenkins" scheme="https://taetaetae.github.io/tags/jenkins/"/>
    
      <category term="python" scheme="https://taetaetae.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Deview 2018 리뷰 (Day 1, Day2)</title>
    <link href="https://taetaetae.github.io/2018/10/14/deview-2018/"/>
    <id>https://taetaetae.github.io/2018/10/14/deview-2018/</id>
    <published>2018-10-14T09:26:26.000Z</published>
    <updated>2018-10-14T16:21:54.824Z</updated>
    
    <content type="html"><![CDATA[<p>회사 내에서도 대학시절 수강신청마냥 1분도 안되서 마감될 정도로 관심이 많았던 <code>DEVIEW 2018</code>. 다행히 클릭신공으로 운좋게 신청에 성공하였고 팀에서도 바쁜 시기였지만 감사하게도 보내주셔서 올해는 이틀 모두 다녀올수 있게 되었다.<a id="more"></a> 예전에는 <code>연차가 올라가면 DEVIEW행사는 참여 안하겠지~</code>라는 생각이 있었는데 그때는 단순 호기심에 참석을 하고 싶었다면 이번에는 <code>뭐라도 배워오자</code>라는 마음으로 신입 시절보다 조금더 성숙한 마음가짐과 자세를 가지고 참석을 하게 되었다.</p><blockquote><p>다시 생각해보면 호기심만으로 세션들을 듣고 부스에서 나눠주는 굿즈를 조금이라도 더 받아와야지 하고 생각했던 신입시절의 생각이 틀린건 아니였지만, 말 그대로 <code>기술행사</code>이니만큼 가급적이면 세션에서 발표하는 내용을 내것으로 만들고 실무에서 또는 다른곳에서 활용할수는 없을까 하는 생각을 갖는게 보다 성장하려는 개발자로서의 자세가 아닐까 생각이 든다. (라고 멋드러지게 말하지만 세션내용의 절반이라도 이해하면 다행이겠지…)</p></blockquote><h3 id="행사-시작-그리고-키노트"><a href="#행사-시작-그리고-키노트" class="headerlink" title="# 행사 시작 그리고 키노트"></a># 행사 시작 그리고 키노트</h3><p>10초만에 마감되었다는 소리가 있을정도로 올해도 여전히 관심이 많았던 <code>DEVIEW 2018</code>. 코엑스에 도착하고 등록을 한뒤 이곳저곳 부스들을 구경하기 바빴다. 이번에는 지난번과 달리 거의 네이버 서비스가 60~70%를 자리잡고 있었고(파파고, 지도, 클로바, 글로벌 광고 등등) 일반 기업에서는 얼마 오지 않았다.(내 기억으로 5~6개?) 개인적으로 여러 다양한 회사들이 함께하는 기술행사가 되었으면 하는 바램이 있었지만 회사를 선정하는데, 그리고 기타 사정들이 있을꺼라는 아쉬움을 뒤로하고 CTO님이 발표하시는 키노트를 들으러 메인강의장에 들어갔다. (자칫… 이것도 네이버 독과점(?) 이러면 할말이 없는데…ㅠㅠ)<br><div class="figure center" style="width:;"><img class="fig-img" src="keynote.png" alt="송창현 네이버 CTO님의 keynote"><span class="image-caption">송창현 네이버 CTO님의 keynote</span><span class="caption">송창현 네이버 CTO님의 keynote</span></div><br>작년에는 거의 <code>로봇잔치</code>로 느껴졌는데 올해는 그 기술들의 융합(?)잔치 로 받아들여졌다. <code>Ambient Intelligence</code> 를 강조하시며 <code>기술의 진정한 가치는 기술이 생활속으로 사라졌을 때 나온다</code>라는 명언같은 말씀도 해주셨다. </p><ul><li>연결 : 사물, 상황, 위치인식, 이해</li><li>발견 : 적시에 답, 추천, 액션제공</li></ul><p>그리고 그와 관련된 네이버 서비스를 공개 하셨는데, 네이버 지도 Map API를 무제한/무료로 사용할수 있게 된다고 한다. (박수 유도하심 ㅎㅎ) 또한 이번에 가장 크게 바뀌는 네이버 모바일 홈 페이지인 <code>그린닷</code>, 지도 기술들의 종합 플랫폼인 <code>xDM Platform</code>(측위, 지도, 내비), 그리고 자율주행과 로봇에 대해 연구결과 그리고 앞으로의 방향성에 대해 정리해주셨다. 집에 돌아와서 검색좀 하다보니 <code>테크수다</code>에서 벌써(?) 영상을 하나 올린게 있어 공유해본다.</p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/q2TM8KNnF14?rel=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><br>키노트를 다 듣고 작년에는 그런가보다 하고 별생각이 안들었는데 올해는 저런 기술들이 서비스 레벨까지 가는데 이렇다할 허들없이 사용자들에게 보여질수만 있다면 개발자로서 보다 더 큰 자부심을 가지고 기술개발에 정진할텐데… 하는 씁슬한 생각을 해보게 되었다. (물론 이런 부분들도 다 사정이 있을꺼라 생각이 들지만 안타까운건 감출수가 없을것 같다.)</p><p>이틀에 걸쳐 이런저런 다양한 세션들을 들을수 있어 좋았는데 몇몇 세션들은 기본지식이 없어 (AI, 머신러닝 등…ㅠ) 이해하기 힘들었다. 내년엔 이해할수 있도록 준비를 해서 오자며 <code>또</code>다짐을 하고… 그나마 조금이라도 이해할수 있었던 세션들 몇개만 정리해본다.</p><h3 id="React-Native-웹-개발자가-한-달-만에-앱-출시하기"><a href="#React-Native-웹-개발자가-한-달-만에-앱-출시하기" class="headerlink" title="# React Native: 웹 개발자가 한 달 만에 앱 출시하기"></a># React Native: 웹 개발자가 한 달 만에 앱 출시하기</h3><div class="figure center" style="width:;"><img class="fig-img" src="session_1.png" alt="React Native: 웹 개발자가 한 달 만에 앱 출시하기"><span class="image-caption">React Native: 웹 개발자가 한 달 만에 앱 출시하기</span><span class="caption">React Native: 웹 개발자가 한 달 만에 앱 출시하기</span></div><p>지난팀에서 아주 잠깐 React를 경험해보긴 했지만 거의 hello world 수준이였기 때문에 이 세션 역시 이해가 잘 되지 못했다. 하지만 필자처럼 이해를 잘 못하는 사람도 발표자가 전달하려는 목적이 무엇인지 알수 있을 정도로 전체적인 흐름은 조금이나마 이해를 할수 있었고 특히 개발하면서 좋았던 것이나 경험담을 알려주며 <code>삽질공유</code>를 해주는게 듣기 좋았다. React Native 는 빠른개발을 할수있고 코드공유가 쉬우며 개선이 쉽다는 장점이 있다고 한다. 또한 단기간에 크로스 플랫폼을 만들어야 할때 사용한다고 하니 나중에 참고해봐도 좋을듯 싶다.</p><ul><li>발표자료<br><iframe src="//www.slideshare.net/slideshow/embed_code/key/1UGMk1XHgSFIbL" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/deview/121react-native" title="[121]React Native: 웹 개발자가 한 달 만에 앱 출시하기" target="_blank">[121]React Native: 웹 개발자가 한 달 만에 앱 출시하기</a> </strong> from <strong><a href="https://www.slideshare.net/deview" target="_blank">NAVER D2</a></strong> </div></li></ul><h3 id="LINE-x-NAVER-개발-보안-취약점-이야기"><a href="#LINE-x-NAVER-개발-보안-취약점-이야기" class="headerlink" title="# LINE x NAVER 개발 보안 취약점 이야기"></a># LINE x NAVER 개발 보안 취약점 이야기</h3><div class="figure center" style="width:;"><img class="fig-img" src="session_2.png" alt="LINE x NAVER 개발 보안 취약점 이야기"><span class="image-caption">LINE x NAVER 개발 보안 취약점 이야기</span><span class="caption">LINE x NAVER 개발 보안 취약점 이야기</span></div><p><code>버그바운티</code>라는 신기한(?)프로그램에 대한 소개와 운영에 대한 내용을 발표해 주셨다. 가끔 사내에서도 <code>버그를 잡으면 포상을 드려요</code> 라는 글이 올라왔었는데 그때마다 손안데고 코풀려나 하는 비뚤어진(?)생각을 갖곤 했었다. 하지만 듣고보니 해커를 고용하는 가장 좋은 방법이면서도 회사의 보안을 지키는 가장 좋은 방법이라고 한다. 또한 잘 알려진 왠만한 기업들은 버그바운티 프로그램을 운영하고 있다고 한다. 비뚤어진 생각을 다시 고쳐 생각해보면, 해커에게는 취약점을 찾으며 해커 본연의 업무를 더욱더 발전시킬수 있고, 회사로써는 수만가