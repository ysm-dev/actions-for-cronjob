<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>Keunwoo Choi</title>
	<atom:link href="https://keunwoochoi.wordpress.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://keunwoochoi.wordpress.com</link>
	<description></description>
	<lastBuildDate>Wed, 24 Oct 2018 16:41:28 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='keunwoochoi.wordpress.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://s0.wp.com/i/buttonw-com.png</url>
		<title>Keunwoo Choi</title>
		<link>https://keunwoochoi.wordpress.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://keunwoochoi.wordpress.com/osd.xml" title="Keunwoo Choi" />
	<atom:link rel='hub' href='https://keunwoochoi.wordpress.com/?pushpress=hub'/>
	<item>
		<title>Great tutorial on normalizing flows</title>
		<link>https://keunwoochoi.wordpress.com/2019/04/25/great-tutorial-on-normalizing-flows/</link>
				<comments>https://keunwoochoi.wordpress.com/2019/04/25/great-tutorial-on-normalizing-flows/#respond</comments>
				<pubDate>Thu, 25 Apr 2019 23:40:38 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3799</guid>
				<description><![CDATA[http://akosiorek.github.io/ml/2018/04/03/norm_flows.html This tutorial by Adam Kosiorek is so good that I doubted if normalizing flows are inherently easy to explain. Highly recommended! Advertisements]]></description>
								<content:encoded><![CDATA[<p><a href="http://akosiorek.github.io/ml/2018/04/03/norm_flows.html" rel="nofollow">http://akosiorek.github.io/ml/2018/04/03/norm_flows.html</a></p>
<p>This tutorial by Adam Kosiorek is so good that I doubted if normalizing flows are inherently easy to explain. Highly recommended!</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2019/04/25/great-tutorial-on-normalizing-flows/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
		<item>
		<title>SpecAugment</title>
		<link>https://keunwoochoi.wordpress.com/2019/04/23/specaugment/</link>
				<comments>https://keunwoochoi.wordpress.com/2019/04/23/specaugment/#respond</comments>
				<pubDate>Tue, 23 Apr 2019 07:52:22 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3793</guid>
				<description><![CDATA[SpecAugment is well summarized already in Google AI Blog. What&#8217;s interesting for me is seeing people getting surprised by its simplicity &#8211; by saying &#8220;Why has no one thought of this before?&#8221; Seems like many people agree with the augmentation strategies in the paper, namely, i) time warping ii) masking random consecutive mel bins iii) &#8230; <a href="https://keunwoochoi.wordpress.com/2019/04/23/specaugment/" class="more-link">Continue reading <span class="screen-reader-text">SpecAugment</span> <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p>SpecAugment is <a href="https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html">well summarized already in Google AI Blog</a>. What&#8217;s interesting for me is seeing people getting surprised by its simplicity &#8211; by saying &#8220;Why has no one thought of this before?&#8221; Seems like many people agree with the augmentation strategies in the paper, namely, i) time warping ii) masking random consecutive mel bins iii) masking random temporal frames.</p>
<p>Time warpingÂ is probably the least shocking idea. The idea of using phase vocoder to control the speed has been around for a while. I don&#8217;t think I&#8217;ve seen the other two.</p>
<h2>My understanding of SpecAugment</h2>
<p>What does the augmentation do? Well, yes, they change the spectrograms. But in which way? What&#8217;s happening exactly? What does the modification mean? First of all, all the effective data augmentation works because they makeÂ the training set more diverse within a suitable range.</p>
<p>i) Â Time warpingÂ works because it increases the diversity of training data, which then covers a wider range of test cases.</p>
<p>ii) Masking random mel bins and time frames works because &#8212; from here, I assume that &#8211; there are multiple characters or features or shapes or whatever in the spectrogram that are located here and there, and by masking we force the model to (sort of) separate those aspects independently. Say, there&#8217;s a phoneme &#8216;k&#8217;, then what makes the sound of &#8216;k&#8217; would be a combination of different features in, for example, one &lt;400 Hz, one of them maybe 400 Hz &lt; f &lt; 1000 Hz, maybe there are many of them 1k &lt; f &lt; 2k (these are arbitrary numbers). Maybe an easier example would be the formants of vowels. The table below only shows singleÂ frequencies of F1, F2, F3 for different phonetic symbols. But they are not absolute, fixed numbers, they should be rather a probabilistic distribution. (Let me skip the explanation of masking time frames.)</p>
<p><img data-attachment-id="3795" data-permalink="https://keunwoochoi.wordpress.com/2019/04/23/specaugment/formants-3/" data-orig-file="https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png?w=1200" data-orig-size="805,335" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="formants-3" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png?w=1200?w=300" data-large-file="https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png?w=1200?w=805" class="alignnone size-full wp-image-3795" src="https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png?w=1200" alt="formants-3" srcset="https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png 805w, https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png?w=150 150w, https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png?w=300 300w, https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png?w=768 768w" sizes="(max-width: 805px) 100vw, 805px"   /></p>
<p>So what? That means out of <em>N</em> hints each of which indicates a phoneme (e.g., /uh/),Â without masking, we&#8217;re telling the neural network that if there areÂ <strong>all</strong> of them, then it&#8217;s an /uh/ sound. This means we need <strong>all</strong> the combinations of those features to completely cover the instances of /uh/ sound. If there are large numbers of features, (if <em>N</em> is large), chances are we don&#8217;t have them all. Therefore, this {<em>N</em> dimension vector}-to-{number of phonemes} classifier is hard to train. Data sparsity. Maybe the network even has to extrapolate which it sucks at.</p>
<p>By masking, we&#8217;re providing the hints in a more separate way. The network can learn to classify with smaller numbers of features. It also breaks the <em>N</em>-dim feature vectors into something smaller. The <em>N</em> features don&#8217;t need to co-exist.</p>
<p>In other words, I guess <strong>it addresses the curse of dimensionality</strong> to some extent because otherwise, the <em>N</em>-dimensional feature space would be sparse.</p>
<h2>More thoughts</h2>
<p>Some augmentation methods are not as effective as others. How can we <strong>computationally optimize data augment strategies</strong> without an exhaustive search?</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2019/04/23/specaugment/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:thumbnail url="https://keunwoochoi.files.wordpress.com/2019/04/specaugment.png" />
		<media:content url="https://keunwoochoi.files.wordpress.com/2019/04/specaugment.png" medium="image">
			<media:title type="html">specaugment</media:title>
		</media:content>

		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2019/04/formants-3.png" medium="image">
			<media:title type="html">formants-3</media:title>
		</media:content>
	</item>
		<item>
		<title>Inverse-STFT in Pytorch</title>
		<link>https://keunwoochoi.wordpress.com/2019/03/14/inverse-stft-in-pytorch/</link>
				<comments>https://keunwoochoi.wordpress.com/2019/03/14/inverse-stft-in-pytorch/#respond</comments>
				<pubDate>Thu, 14 Mar 2019 05:26:58 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3790</guid>
				<description><![CDATA[&#160; It has been discussed so far, but slowly. I just implemented one for myself. &#160; &#160; &#160;]]></description>
								<content:encoded><![CDATA[<p>&nbsp;</p>
<p><a href="https://github.com/pytorch/pytorch/issues/3775">It has been discussed so far</a>, but slowly. I just implemented one for myself.</p>
<p>&nbsp;</p>
<p><script src="https://gist.github.com/keunwoochoi/2f349e72cc941f6f10d4adf9b0d3f37e.js"></script></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2019/03/14/inverse-stft-in-pytorch/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
		<item>
		<title>Harmonic-percussive source separation in Pytorch</title>
		<link>https://keunwoochoi.wordpress.com/2019/03/13/harmonic-percussive-source-separation-in-pytorch/</link>
				<comments>https://keunwoochoi.wordpress.com/2019/03/13/harmonic-percussive-source-separation-in-pytorch/#comments</comments>
				<pubDate>Thu, 14 Mar 2019 00:16:22 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3788</guid>
				<description><![CDATA[Yes, as the title says.]]></description>
								<content:encoded><![CDATA[<p>Yes, as the title says.</p>
<p><script src="https://gist.github.com/keunwoochoi/dcbaf3eaa72ca22ea4866bd5e458e32c.js"></script></p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2019/03/13/harmonic-percussive-source-separation-in-pytorch/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
		<item>
		<title>Jupyter notebook</title>
		<link>https://keunwoochoi.wordpress.com/2018/12/17/jupyter-notebook/</link>
				<comments>https://keunwoochoi.wordpress.com/2018/12/17/jupyter-notebook/#comments</comments>
				<pubDate>Mon, 17 Dec 2018 14:37:09 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3781</guid>
				<description><![CDATA[This blog post already greatly helped me out. Well, probably I would get it again if I google again. Perhaps Google could get me a better one. Well, but what if not? Well, that&#8217;s what Bookmark is for. But well, come on, Bookmark is broken; OH COME ON, it totally missed getting into my habit &#8230; <a href="https://keunwoochoi.wordpress.com/2018/12/17/jupyter-notebook/" class="more-link">Continue reading <span class="screen-reader-text">Jupyter notebook</span> <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p><a href="https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/">This blog post</a> already greatly helped me out. Well, probably I would get it again if I google again. Perhaps Google could get me a better one. Well, but what if not? Well, that&#8217;s what Bookmark is for. But well, come on, Bookmark is broken; OH COME ON, it totally missed getting into my habit &#8212; my psycho-physiological-neural-somewhat_arbitrary brain doesn&#8217;t work like that. What would be even worse is if I forget I wrote this. Anyway, to play nice and safe with Jupyter notebook/pip/conda, you might wanna read <a href="https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/">it</a>.</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2018/12/17/jupyter-notebook/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
		<item>
		<title>Machine Learning for Creativity and Design Workshop (NeurIPS2018), and +@</title>
		<link>https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/</link>
				<comments>https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/#comments</comments>
				<pubDate>Mon, 10 Dec 2018 21:22:31 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Research]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3738</guid>
				<description><![CDATA[Following their first workshop last year, there was the second ML4 Creativity and Design workshopÂ on 8th Dec 2018 atÂ Neurips2018Â (=one of the biggest machine learning conferences), Montreal (=one of the coldest area I&#8217;ve ever been). It was great! And even greater for those who are interested in music. I missed the last year&#8217;s one but seems &#8230; <a href="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/" class="more-link">Continue reading <span class="screen-reader-text">Machine Learning for Creativity and Design Workshop (NeurIPS2018), and +@</span> <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p>Following their first workshop last year, there was <a href="https://nips2018creativity.github.io">the second ML4 Creativity and Design workshop</a>Â on 8th Dec 2018 atÂ <a href="https://neurips.cc/Conferences/2018">Neurips2018</a>Â (=one of the biggest machine learning conferences), Montreal (=one of the coldest area I&#8217;ve ever been). It was great! And even greater for those who are interested in music. I missed the last year&#8217;s one but seems like there were more musical stuff this year than before. Here&#8217;s my summary for the workshop, aÂ non-exhaustive and mostly musical one, but please treat yourself withÂ <a href="https://nips2018creativity.github.io">other papers</a> too. Ok, here we go.</p>
<h1>1. Music-related works</h1>
<ul>
<li><a href="https://nips2018creativity.github.io/doc/performing_structured_improvisations.pdf">&#8220;Performing structured improvisations with pre-existing generative musical models&#8221;</a>
<ul>
<li>with an intriguing demonstration, which is, hm hm,&#8230; live coding music! Why? Because his work is about using trained models realtime.</li>
<li>By Pablo Samuel Castro at Google Brain</li>
</ul>
</li>
</ul>
<div class="embed-twitter">
<blockquote class="twitter-tweet" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">hereâ€™s the second half. wut, canâ€™t tell which is by machine or human? <a href="https://twitter.com/hashtag/TuringTestBusted?src=hash&amp;ref_src=twsrc%5Etfw">#TuringTestBusted</a> <a href="https://t.co/wWcy1gZnZf">pic.twitter.com/wWcy1gZnZf</a></p>
<p>&mdash; Keunwoo Choi (@keunwoochoi) <a href="https://twitter.com/keunwoochoi/status/1071447166034591745?ref_src=twsrc%5Etfw">December 8, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
<ul>
<li>&#8220;<a href="https://nips2018creativity.github.io/doc/legend_of_wrong_mountain.pdf">Legend of Wrong Mountain: Full generation of traditional Chinese opera using multiple machine learning algorithms</a>&#8221;
<ul>
<li>is such a complete work in a sense that combines LSTM, pix2pix, pix2pixHD, (perhaps other) RNNs, Markov chain, OpoenPose and Detection, etc&#8230; to generate music/script/visual, i.e. full.</li>
<li>By Lingdong Huang et al. from Carnegie Mellon University</li>
<li>Look at this system overview!</li>
</ul>
</li>
</ul>
<p><img data-attachment-id="3741" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/screen-shot-2018-12-10-at-9-12-35-am/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=1200" data-orig-size="2004,810" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2018-12-10 at 9.12.35 AM" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=1200?w=300" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=1200?w=1024" class=" size-full wp-image-3741 aligncenter" src="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=1200" alt="Screen Shot 2018-12-10 at 9.12.35 AM.png" srcset="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=150 150w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=300 300w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=768 768w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png?w=1024 1024w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png 2004w" sizes="(max-width: 1200px) 100vw, 1200px"   /></p>
<ul>
<li><a href="https://nips2018creativity.github.io/doc/neural_wavetable.pdf">&#8220;Neural wavetable: a playable wavetable synthesizer using neural networks&#8221;</a>
<ul>
<li>By Lamtharn Hantrakul and Li-Chia Yang (Google Brain residency and Georgia Tech)</li>
<li>To generate an wavetable, which is a (data)base for a certain type of synthesizer (wavetable synthesizer, obviously), they used WaveNet + AutoEncoder so that by controlling the latent space (hidden representation of AutoEncoder) the waveforms of the table can be manipulated continuously.</li>
</ul>
</li>
</ul>
<p>&nbsp;</p>
<ul>
<li><a href="https://nips2018creativity.github.io/doc/Learning_a_Latent_Space_of_Multitrack_Measures.pdf">&#8220;Learning a latent space of multitrack measures&#8221;</a> (<a href="https://magenta.tensorflow.org/multitrack">Magenta blog post</a>)
<ul>
<li>By Ian Simon et al. (from <a href="https://magenta.tensorflow.org">Magenta, Google Brain</a>)</li>
<li>It&#8217;s an extension of <a href="https://magenta.tensorflow.org/music-vae">MusicVAE</a> to 8-channel multi-tracks. First, MusicVAE is a VAE-based single-track music generator; that outputs a monophonic melody or a drum track as below &#8211; one latent representation (z), applied to the bars of a track globally.</li>
</ul>
</li>
</ul>
<p><img data-attachment-id="3742" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/architecture/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=1200" data-orig-size="2400,1426" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="architecture" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=1200?w=300" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=1200?w=1024" class="alignnone size-full wp-image-3742" src="https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=1200" alt="architecture" srcset="https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/architecture.png 2400w, https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=150 150w, https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=300 300w, https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=768 768w, https://keunwoochoi.files.wordpress.com/2018/12/architecture.png?w=1024 1024w" sizes="(max-width: 1200px) 100vw, 1200px"   /></p>
<p>&nbsp;</p>
<ul>
<li>(continued)
<ul>
<li>Compared to MusicVAE, multitrack VAE is..
<ul>
<li>still with a global z over time, but this time z has multitrack information encoded</li>
<li>and with chord conditioned for each bar.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img data-attachment-id="3743" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/screen-shot-2018-12-10-at-12-56-36-pm/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=1200" data-orig-size="1174,1292" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2018-12-10 at 12.56.36 PM" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=1200?w=273" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=1200?w=930" class="alignnone size-full wp-image-3743" src="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=1200" alt="Screen Shot 2018-12-10 at 12.56.36 PM" srcset="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png 1174w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=136 136w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=273 273w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=768 768w, https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png?w=930 930w" sizes="(max-width: 1174px) 100vw, 1174px"   /></p>
<ul>
<li><a href="https://nips2018creativity.github.io/doc/music_theory_inspired_policy_gradient.pdf">&#8220;Music theory inspired policy gradient method for piano music transcription&#8221;</a>
<ul>
<li>By Jucheng Li et al. (CMU, Stanford, Bosch)</li>
<li>Train a Reinforcement Learning-based transcriber with some constraints based on the properties of music and music signal, which are not really described in detail in the paper, but yes I took some pictures! See below.</li>
</ul>
</li>
</ul>
<p><img data-attachment-id="3767" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-13-28-58/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=1200" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 13.28.58" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=1200?w=225" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=1200?w=768" class="alignnone size-full wp-image-3767" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=1200" alt="2018-12-08 13.28.58" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=113 113w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=225 225w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png?w=768 768w" sizes="(max-width: 1200px) 100vw, 1200px"   /><img data-attachment-id="3758" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-13-28-42/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=1200" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 13.28.42" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=1200?w=225" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=1200?w=768" class="alignnone size-full wp-image-3758" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=1200" alt="2018-12-08 13.28.42" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=113 113w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=225 225w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png?w=768 768w" sizes="(max-width: 1200px) 100vw, 1200px"   /><img data-attachment-id="3749" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-13-28-47/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=1200" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 13.28.47" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=1200?w=300" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=1200?w=1024" class="alignnone size-full wp-image-3749" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=1200" alt="2018-12-08 13.28.47" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=150 150w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=300 300w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=768 768w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png?w=1024 1024w" sizes="(max-width: 1200px) 100vw, 1200px"   /></p>
<p>&nbsp;</p>
<ul>
<li><a href="https://nips2018creativity.github.io/doc/combining_learned_lyrical_structures.pdf">&#8220;Combining learned lyrical structures and vocabulary for Improved lyric generation&#8221;</a>
<ul>
<li>Pablo Samuel Castro and Maria Attarian (Google Brain and Google)</li>
<li>to generate lyrics by modelling the grammar of lyric and getting large vocabulary from somewhere else (book)</li>
<li>I also thought of something similar as a solution for music captioning where you can extract music tags while sentence templets can be provided from some other sources.</li>
</ul>
</li>
</ul>
<p><img data-attachment-id="3747" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-13-42-30/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=1200" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 13.42.30" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=1200?w=225" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=1200?w=768" class="alignnone size-full wp-image-3747" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=1200" alt="2018-12-08 13.42.30" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=113 113w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=225 225w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png?w=768 768w" sizes="(max-width: 1200px) 100vw, 1200px"   /></p>
<ul>
<li><a href="https://nips2018creativity.github.io/doc/Transformer_NADE.pdf">&#8220;Transformer-NADE for piano performances&#8221;</a>
<ul>
<li>by Curtis Hawthorne et al. (Google Magenta)</li>
<li>proposed to use NADE (neural autoregressive distribution estimator) to predict the following note and the dimension is an element of note tuple &#8212; the elements are properties of note (onset timing, duration, ..).</li>
<li>FYI &#8220;Transformer&#8221; is a purely attention-based sequence-to-sequence model, originally proposed for language translation, <a href="https://arxiv.org/abs/1809.04281">recently used for symbolic music generation</a></li>
</ul>
</li>
</ul>
<p><img data-attachment-id="3752" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-14-08-46/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=1200" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 14.08.46" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=1200?w=225" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=1200?w=768" class="alignnone size-full wp-image-3752" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=1200" alt="2018-12-08 14.08.46" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=113 113w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=225 225w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png?w=768 768w" sizes="(max-width: 1200px) 100vw, 1200px"   /><img data-attachment-id="3751" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-14-11-37/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=1200" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 14.11.37" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=1200?w=300" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=1200?w=1024" class="alignnone size-full wp-image-3751" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=1200" alt="2018-12-08 14.11.37" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=150 150w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=300 300w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=768 768w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png?w=1024 1024w" sizes="(max-width: 1200px) 100vw, 1200px"   /><img data-attachment-id="3750" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-14-11-43/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=1200" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 14.11.43" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=1200?w=225" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=1200?w=768" class="alignnone size-full wp-image-3750" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=1200" alt="2018-12-08 14.11.43" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=113 113w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=225 225w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png?w=768 768w" sizes="(max-width: 1200px) 100vw, 1200px"   /></p>
<ul>
<li>&#8220;<a href="https://nips2018creativity.github.io/doc/Generating_Images_from_Audio.pdf">Generating images from audio&#8221;</a>
<ul>
<li>By Chih Wen Lin and Ting-Wei Su</li>
<li>GAN for audio signal-to-image</li>
<li>AudioSet (youtube videos) were used during training</li>
</ul>
</li>
</ul>
<ul>
<li>&#8220;<a href="https://nips2018creativity.github.io/doc/virtuosonet.pdf">VirtuosoNet: A hierarchical attention RNN for generating expressive piano performance from music score</a>&#8221;
<ul>
<li>By Dasaem Jeong, Taegyun Kwon, Juhan Nam (KAIST, S Korea)
<ul>
<li>Btw they&#8217;re doing great in <a href="http://mac.kaist.ac.kr">Maclab at KAIST</a>, please do checkout <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" alt="ðŸ™‚" class="wp-smiley" style="height: 1em; max-height: 1em;" /></li>
</ul>
</li>
<li>Input: MusicXML (symbolic score with all the expressions like allegro, forte, crescendo, etc)</li>
<li>then additional, global conditioning like &#8220;tempo and dynamics&#8221; (according to the paper)</li>
<li>Output: Midi file with &#8216;expressions&#8217; added</li>
<li>Check out the demo below! It&#8217;s pretty cool</li>
</ul>
</li>
</ul>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='1200' height='675' src='https://www.youtube.com/embed/videoseries?list=PLkIVXCxCZ08rD1PXbrb0KNOSYVh5Pvg-c&#038;hl=en_US' allowfullscreen='true' style='border:0;'></iframe></div>
<p>&nbsp;</p>
<ul>
<li>Piano Ginie
<ul>
<li>The coolest ISMIR 2018 demo has come back to NeurIPS!</li>
<li><a href="https://magenta.tensorflow.org/pianogenie">Magenta Demo page</a></li>
</ul>
</li>
</ul>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='1200' height='675' src='https://www.youtube.com/embed/YRb0XAnUpIk?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<p>&nbsp;</p>
<h1>2. Some others</h1>
<ul>
<li>&#8220;<a href="https://openreview.net/forum?id=ryfxVNEajm">Visualizing Music Transformer&#8221;</a>
<ul>
<li>by Anna Huang et al. (Google Magenta)</li>
<li>It&#8217;s from a simultaneous workshop, &#8220;<a href="https://irasl.gitlab.io">Interpretability and robustness in audio speech, and language</a>&#8220;</li>
<li>Probably one another nice thing about purely attention-based system is that they&#8217;re easy to visualise? That&#8217;s what Anna did in this work, which would be a nice supplementary to her and her co-workers&#8217; music transformer.</li>
</ul>
</li>
</ul>
<ul>
<li>&#8220;<a href="http://papers.nips.cc/paper/8023-the-challenge-of-realistic-music-generation-modelling-raw-audio-at-scale">The challenge of realistic music generation: modelling raw audio at scale&#8221;</a>
<ul>
<li>By Sander Dieleman et al. (Deepmind)</li>
<li>a full conference paper!</li>
<li>to add argmax on the top of autoencoder &#8212; for longer signal at bigger scale, a harder problem at a stronger conference</li>
</ul>
</li>
</ul>
<ul>
<li><a href="https://nips2018creativity.github.io/doc/Artist_Influencers.pdf">&#8220;Artistic Influence GAN</a>&#8221;
<ul>
<li>by Eric Chu, MIT Media Lab</li>
<li><em>&#8220;What if Banksy had met Jackson Pollock during his formative years, or if David Hockney had missed out on the Tate Galleryâ€™s famous 1960 Picasso exhibition?&#8221;</em></li>
<li>Similar to one thing that I&#8217;ve always thought about &#8212; to simulate the history of music, maybe with RL though.</li>
</ul>
</li>
</ul>
<p><img data-attachment-id="3754" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-13-34-48/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=1200" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 13.34.48" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=1200?w=300" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=1200?w=1024" class="alignnone size-full wp-image-3754" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=1200" alt="2018-12-08 13.34.48" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=150 150w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=300 300w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=768 768w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png?w=1024 1024w" sizes="(max-width: 1200px) 100vw, 1200px"   /><img data-attachment-id="3746" data-permalink="https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/2018-12-08-13-34-58/" data-orig-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=1200" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2018-12-08 13.34.58" data-image-description="" data-medium-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=1200?w=300" data-large-file="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=1200?w=1024" class="alignnone size-full wp-image-3746" src="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=1200" alt="2018-12-08 13.34.58" srcset="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=1200 1200w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=2400 2400w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=150 150w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=300 300w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=768 768w, https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png?w=1024 1024w" sizes="(max-width: 1200px) 100vw, 1200px"   /></p>
<h1>3. An awesome talk</h1>
<ul>
<li>Michael Levin&#8217;s Keynote titled &#8220;What bodies think about: Bioelectric computation outside the nervous system, primitive cognition, and synthetic morphology&#8221; totally blew many&#8217;s minds, I think it could be one that excited the NeurIPS 2018 participants the most &#8212; and you don&#8217;t need to be a deep learning research to get impressed.</li>
</ul>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='1200' height='675' src='https://www.youtube.com/embed/RjD1aLm4Thg?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<h1>4. Neither musical or talk (i.e. the usual NeurIPS stuff)</h1>
<ul>
<li><a href="http://Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding">Sparse attentive backtracking: Temporal credit assignment through reminding</a></li>
<li><a href="https://arxiv.org/abs/1805.11604">How does batch normalization help optimization?</a> (<a href="http://gradientscience.org/batchnorm/">blog post</a>)
<ul>
<li>because, is there any darker and more popular black box than batch norm?</li>
</ul>
</li>
</ul>
<div class="jetpack-video-wrapper"><iframe class='youtube-player' type='text/html' width='1200' height='675' src='https://www.youtube.com/embed/ZOabsYbmBRM?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe></div>
<div class="embed-twitter">
<blockquote class="twitter-tweet" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">So far (2 days gone), this is my favorite <a href="https://twitter.com/hashtag/NeurIPS18?src=hash&amp;ref_src=twsrc%5Etfw">#NeurIPS18</a> paper. I just love the paper that tells me why it works. It also showed that the popular previous belief &quot;internal covariate shift&quot; has little to do with batch norm&#39;s success. Ah! <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f60d.png" alt="ðŸ˜" class="wp-smiley" style="height: 1em; max-height: 1em;" /><br /> 3-min video: <a href="https://t.co/EbcCRDzyAu">https://t.co/EbcCRDzyAu</a> <a href="https://t.co/8eUUWI9G6u">pic.twitter.com/8eUUWI9G6u</a></p>
<p>&mdash; Aerin Kim <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f64f.png" alt="ðŸ™" class="wp-smiley" style="height: 1em; max-height: 1em;" /> (@aerinykim) <a href="https://twitter.com/aerinykim/status/1070188133810139136?ref_src=twsrc%5Etfw">December 5, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
<ul>
<li>Best GAN ever</li>
</ul>
<div class="embed-twitter">
<blockquote class="twitter-tweet" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">The student-advisor adversarial idea generator architecture (<a href="https://twitter.com/dribnet?ref_src=twsrc%5Etfw">@dribnet</a>) <a href="https://t.co/NQQWB5tBk6">pic.twitter.com/NQQWB5tBk6</a></p>
<p>&mdash; Mark O. Riedl <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/2708.png" alt="âœˆ" class="wp-smiley" style="height: 1em; max-height: 1em;" /> @NeurIPS (@mark_riedl) <a href="https://twitter.com/mark_riedl/status/1071516682831757313?ref_src=twsrc%5Etfw">December 8, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
<ul>
<li><a href="https://static.googleusercontent.com/media/research.google.com/ko//bigpicture/ML_Visualization_NeurIPS_Tutorial.pdf">A tutorial on data visualisation</a></li>
<li>Visualizing the loss landscape of neural nets</li>
</ul>
<div class="embed-twitter">
<blockquote class="twitter-tweet" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">This work is so impressive and so useful. There was a lot of misplaced skepticism about the importance of sharp minima last year, but this work shows that when you properly normalize you can see what&#39;s going on. See the paper for details <a href="https://t.co/VV4x49VBU2">https://t.co/VV4x49VBU2</a> <a href="https://t.co/CabTgaz4P8">https://t.co/CabTgaz4P8</a></p>
<p>&mdash; Jeremy Howard (@jeremyphoward) <a href="https://twitter.com/jeremyphoward/status/1070131365214150657?ref_src=twsrc%5Etfw">December 5, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
<ul>
<li>VAE + GAN</li>
</ul>
<div class="embed-twitter">
<blockquote class="twitter-tweet" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis. They propose a clever way to combine VAE+GAN by reusing the encoder of the VAE as the discriminator, allowing VAE to generate hi-res images. Found this gem at <a href="https://twitter.com/hashtag/NeurIPS2018?src=hash&amp;ref_src=twsrc%5Etfw">#NeurIPS2018</a>. <a href="https://t.co/WQl4DdLyyk">https://t.co/WQl4DdLyyk</a> <a href="https://t.co/hrOpPsJOwT">pic.twitter.com/hrOpPsJOwT</a></p>
<p>&mdash; hardmaru (@hardmaru) <a href="https://twitter.com/hardmaru/status/1070071518447554560?ref_src=twsrc%5Etfw">December 4, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
<p>Ok this is it. Thanks for the great works everyone!</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2018/12/10/machine-learning-for-creativity-and-design-workshop-neurips2018/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						
		<media:thumbnail url="https://keunwoochoi.files.wordpress.com/2018/12/img_1634.jpg" />
		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/img_1634.jpg" medium="image">
			<media:title type="html">IMG_1634</media:title>
		</media:content>

		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-9-12-35-am.png" medium="image">
			<media:title type="html">Screen Shot 2018-12-10 at 9.12.35 AM.png</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/architecture.png" medium="image">
			<media:title type="html">architecture</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/screen-shot-2018-12-10-at-12-56-36-pm.png" medium="image">
			<media:title type="html">Screen Shot 2018-12-10 at 12.56.36 PM</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-58.png" medium="image">
			<media:title type="html">2018-12-08 13.28.58</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-42.png" medium="image">
			<media:title type="html">2018-12-08 13.28.42</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-28-47.png" medium="image">
			<media:title type="html">2018-12-08 13.28.47</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-42-30.png" medium="image">
			<media:title type="html">2018-12-08 13.42.30</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-08-46.png" medium="image">
			<media:title type="html">2018-12-08 14.08.46</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-37.png" medium="image">
			<media:title type="html">2018-12-08 14.11.37</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-14-11-43.png" medium="image">
			<media:title type="html">2018-12-08 14.11.43</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-48.png" medium="image">
			<media:title type="html">2018-12-08 13.34.48</media:title>
		</media:content>

		<media:content url="https://keunwoochoi.files.wordpress.com/2018/12/2018-12-08-13-34-58.png" medium="image">
			<media:title type="html">2018-12-08 13.34.58</media:title>
		</media:content>
	</item>
		<item>
		<title>Pseudo CQT on Pytorch</title>
		<link>https://keunwoochoi.wordpress.com/2018/10/24/pseudo-cqt-on-pytorch/</link>
				<comments>https://keunwoochoi.wordpress.com/2018/10/24/pseudo-cqt-on-pytorch/#comments</comments>
				<pubDate>Wed, 24 Oct 2018 16:41:12 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3735</guid>
				<description><![CDATA[Here&#8217;s a gist for Pseudo CQT on Pytorch &#160; Guess I&#8217;ll be working on something like Kapre-but-Pytorch. TorchaudioÂ was a good start but aren&#8217;t we deserve something better?]]></description>
								<content:encoded><![CDATA[<p>Here&#8217;s a gist for Pseudo CQT on Pytorch</p>
<p><script src="https://gist.github.com/keunwoochoi/be18701219fb671f6c74b3d6e0740513.js"></script></p>
<p>&nbsp;</p>
<p>Guess I&#8217;ll be working on something like Kapre-but-Pytorch. <a href="https://github.com/pytorch/audio">Torchaudio</a>Â was a good start but aren&#8217;t we deserve something better?</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2018/10/24/pseudo-cqt-on-pytorch/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
						
		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
		<item>
		<title>ICLR 2019 submissions</title>
		<link>https://keunwoochoi.wordpress.com/2018/10/06/iclr-2019-submissions/</link>
				<comments>https://keunwoochoi.wordpress.com/2018/10/06/iclr-2019-submissions/#comments</comments>
				<pubDate>Sat, 06 Oct 2018 21:36:35 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3730</guid>
				<description><![CDATA[It&#8217;s nice to see some good music-related submissions in ICLR 2019. Many are about timbre transfer as a part of music style transfer, which is great as now many are clarifying the scope of the problem rather than &#8220;style transfer&#8221; where the &#8220;style&#8221; is retrospectively defined by whatever happened in their neural networks. Some of &#8230; <a href="https://keunwoochoi.wordpress.com/2018/10/06/iclr-2019-submissions/" class="more-link">Continue reading <span class="screen-reader-text">ICLR 2019 submissions</span> <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p>It&#8217;s nice to see some good music-related submissions in ICLR 2019. Many are about timbre transfer as a part of music style transfer, which is great as now many are clarifying the scope of the problem rather than &#8220;style transfer&#8221; where the &#8220;style&#8221; is retrospectively defined by whatever happened in their neural networks.</p>
<p>Some of my comments are as below:</p>
<ol>
<li><a href="https://openreview.net/forum?id=HJGkisCcKm">&#8220;Autoencoder-based music translation&#8221;</a></li>
<li><a href="https://openreview.net/forum?id=S1lvm305YQ">&#8220;TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for musical timbre transfer&#8221;</a></li>
</ol>
<p>Please go check out the submissions! â†’ <a href="https://openreview.net/search?term=music&amp;content=all&amp;group=ICLR.cc/2019/Conference&amp;source=forum">11 results found for &#8220;music&#8221;</a></p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2018/10/06/iclr-2019-submissions/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						
		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
		<item>
		<title>ISMIR 2018 tutorials + etc</title>
		<link>https://keunwoochoi.wordpress.com/2018/09/30/ismir-2018-tutorials-etc/</link>
				<comments>https://keunwoochoi.wordpress.com/2018/09/30/ismir-2018-tutorials-etc/#respond</comments>
				<pubDate>Sun, 30 Sep 2018 01:43:40 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3722</guid>
				<description><![CDATA[Here&#8217;s a bunch of links on ISMIR 2018Â tutorials T1.Â Open Source and Reproducible MIR ResearchÂ &#124;Â github repo T2.Â Computational approaches for analysis of non-western music traditionsÂ &#124;Â materials T3.Â Statistical analysis of results in MIR: Why and howÂ &#124; slides T4.Â Music separation with DNNs: Making it workÂ &#124;Â materials T5.Â Deep learning for MIRÂ &#124;Â github repo T6.Â Fundamental frequency estimation in musicÂ &#124; slidesÂ 1,Â 2,Â 3 T7.Â Optical music recognition for &#8230; <a href="https://keunwoochoi.wordpress.com/2018/09/30/ismir-2018-tutorials-etc/" class="more-link">Continue reading <span class="screen-reader-text">ISMIR 2018 tutorials + etc</span> <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p>Here&#8217;s a bunch of links on <a href="http://ismir2018.ircam.fr">ISMIR 2018</a>Â <a href="http://ismir2018.ircam.fr/pages/events-tutorials.html">tutorials</a></p>
<div>
<p>T1.Â <span style="color:#000033;font-family:inherit;"><a href="http://ismir2018.ircam.fr/pages/events-tutorial-14.html">Open Source and Reproducible MIR Research</a>Â |</span>Â <a href="https://github.com/bmcfee/ismir2018-oss-tutorial">github repo</a></p>
</div>
<div>
<p>T2.Â <a href="http://ismir2018.ircam.fr/pages/events-tutorial-09.html">Computational approaches for analysis of non-western music traditions</a>Â |Â <a href="https://www.upf.edu/web/mtg/non-western-music-tutorial">materials</a></p>
</div>
<div>
<p>T3.<a href="http://ismir2018.ircam.fr/pages/events-tutorial-17.html">Â Statistical analysis of results in MIR: Why and how</a>Â | <a href="https://www.slideshare.net/caerolus/statistical-analysis-of-results-in-music-information-retrieval-why-and-how">slides</a></p>
</div>
<div>
<p>T4.Â <a href="https://www.blogger.com/Statistical%20Analysis%20of%20Results%20in%20Music%20Information%20Retrieval:%20Why%20and%20How">Music separation with DNNs: Making it work</a>Â |Â <a href="https://sigsep.github.io/tutorials/">materials</a></p>
</div>
<div></div>
<div>
<p>T5.Â <a href="http://ismir2018.ircam.fr/pages/events-tutorial-04.html">Deep learning for MIR</a>Â |Â <a href="https://github.com/slychief/ismir2018_tutorial">github repo</a></p>
</div>
<div>
<p>T6.Â <a href="http://ismir2018.ircam.fr/pages/events-tutorial-06.html">Fundamental frequency estimation in music</a>Â | slidesÂ <a href="https://drive.google.com/a/nyu.edu/file/d/1uWCwE03dM0j0Ptp1g5vPsT56nPd0DCW2/view?usp=drive_web">1</a>,Â <a href="https://drive.google.com/a/nyu.edu/file/d/1Jmj6tNBGFMlElEQldgNZ2_YgD17gS6Sv/view?usp=drive_web">2</a>,Â <a href="https://drive.google.com/a/nyu.edu/file/d/11VmV8bBtfMT-tav2JFyliZMBH1nR0l52/view?usp=drive_web">3</a></p>
</div>
<div>
<p>T7.Â <a href="http://ismir2018.ircam.fr/pages/events-tutorial-07.html">Optical music recognition for dummies</a>Â | (todo)</p>
</div>
<div>
<p>T8.Â <a href="http://ismir2018.ircam.fr/pages/events-tutorial-11.html">Overview and new challenges of music recommendation research in 2018</a>Â | <a href="https://www.linkedin.com/pulse/music-recommendation-research-2018-tutorial-ismir-paris-gouyon/">slides</a></p>
</div>
<p>&nbsp;</p>
<p>Also please check out <a href="https://www.youtube.com/channel/UCQ-Y-Wx3UyNI8C2QZxQbmAQ">ISMIR 2018 YouTube channel</a>!</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2018/09/30/ismir-2018-tutorials-etc/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:thumbnail url="https://keunwoochoi.files.wordpress.com/2018/09/screen-shot-2018-09-29-at-9-45-26-pm.png" />
		<media:content url="https://keunwoochoi.files.wordpress.com/2018/09/screen-shot-2018-09-29-at-9-45-26-pm.png" medium="image">
			<media:title type="html">Screen Shot 2018-09-29 at 9.45.26 PM</media:title>
		</media:content>

		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
		<item>
		<title>Slides for paper &#8220;the effects of noisy labels on deep convolutional neural networks for music tagging&#8221;</title>
		<link>https://keunwoochoi.wordpress.com/2017/11/04/slides-for-paper-the-effects-of-noisy-labels-on-deep-convolutional-neural-networks-for-music-tagging/</link>
				<comments>https://keunwoochoi.wordpress.com/2017/11/04/slides-for-paper-the-effects-of-noisy-labels-on-deep-convolutional-neural-networks-for-music-tagging/#respond</comments>
				<pubDate>Sat, 04 Nov 2017 05:17:51 +0000</pubDate>
		<dc:creator><![CDATA[keunwoochoi]]></dc:creator>
				<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://keunwoochoi.wordpress.com/?p=3701</guid>
				<description><![CDATA[Related post:Â Paper revisionâ€™s out: The effects of noisy labels on deep convolutional neural networks for music classification paper: (click)]]></description>
								<content:encoded><![CDATA[<div class="jetpack-video-wrapper"><iframe src='https://www.slideshare.net/slideshow/embed_code/81581143' width='1200' height='983' allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div>
<p>Related post:Â <a href="https://keunwoochoi.wordpress.com/2017/09/12/paper-revisions-out-the-effects-of-noisy-labels-on-deep-convolutional-neural-networks-for-music-classification/">Paper revisionâ€™s out: The effects of noisy labels on deep convolutional neural networks for music classification</a></p>
<p>paper: <a href="https://arxiv.org/abs/1706.02361">(click)</a></p>
]]></content:encoded>
							<wfw:commentRss>https://keunwoochoi.wordpress.com/2017/11/04/slides-for-paper-the-effects-of-noisy-labels-on-deep-convolutional-neural-networks-for-music-tagging/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
						
		<media:thumbnail url="https://keunwoochoi.files.wordpress.com/2017/11/screen-shot-2017-11-04-at-14-19-25.png" />
		<media:content url="https://keunwoochoi.files.wordpress.com/2017/11/screen-shot-2017-11-04-at-14-19-25.png" medium="image">
			<media:title type="html">Screen Shot 2017-11-04 at 14.19.25</media:title>
		</media:content>

		<media:content url="https://2.gravatar.com/avatar/b701e14f222aef3d3c52658b5b95c98e?s=96&#38;d=identicon&#38;r=G" medium="image">
			<media:title type="html">keunwoochoi</media:title>
		</media:content>
	</item>
	</channel>
</rss>
