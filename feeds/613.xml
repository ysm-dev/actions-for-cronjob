<?xml version='1.0' encoding='UTF-8'?><?xml-stylesheet href="http://www.blogger.com/styles/atom.css" type="text/css"?><feed xmlns='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' xmlns:blogger='http://schemas.google.com/blogger/2008' xmlns:georss='http://www.georss.org/georss' xmlns:gd="http://schemas.google.com/g/2005" xmlns:thr='http://purl.org/syndication/thread/1.0'><id>tag:blogger.com,1999:blog-6029100972813152037</id><updated>2019-05-14T16:32:03.082+09:00</updated><category term="kr"/><category term="machine learning"/><category term="GAN"/><category term="PR12"/><category term="bloggertip"/><category term="mathematics"/><category term="DANN"/><category term="setup"/><category term="ICLR2018"/><category term="dsp"/><category term="en"/><category term="skimpaper"/><category term="super-resolution"/><category term="topology"/><category term="개발"/><title type='text'>Jaejun Yoo&#39;s Playground</title><subtitle type='html'>READ A LOT, THINK IN PICTURES, CODE IT, VISUALIZE MORE!</subtitle><link rel='http://schemas.google.com/g/2005#feed' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/posts/default'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/'/><link rel='hub' href='http://pubsubhubbub.appspot.com/'/><link rel='next' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default?start-index=26&amp;max-results=25'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><generator version='7.00' uri='http://www.blogger.com'>Blogger</generator><openSearch:totalResults>70</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-135301957335178820</id><published>2019-05-14T16:32:00.000+09:00</published><updated>2019-05-14T16:32:02.610+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="super-resolution"/><title type='text'>Image Restoration (IR): inverse problem point of view (2)</title><content type='html'>&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/image-restoration-inverse-problem-1.html&quot; target=&quot;_blank&quot;&gt;이전 글&lt;/a&gt;에서 전통적인 model-based optimization 방식에 대해 알아보았다면, 이번 글에서는 deep learning이 이런 관점에서 어떻게 해석될 수 있는지 알아보고자 합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Model-based vs. Deep Learning-based&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;Bayesian 관점에서 보면 Image Restoration (IR)에서 풀고자 하는 문제를 아래와 같이 Maximum A Posteriori (MAP) 형태로 표현할 수 있다고 말씀드렸었습니다: $$\begin{align} \hat{x} &amp;amp;=\arg\min_x\{-\log P(y|x)-\log P(x)\} \notag\\ &amp;amp;= \arg\min_x\{\frac{1}{2\sigma^2}||y-Hx||^2_2+\lambda\rho(x)\}\end{align}$$ 이 문제를 푸는 방식은 model-based optimization과 discriminative learning 이렇게 두 가지로 방식으로 나눌 수 있다고 말씀드렸었죠. 지난 글에서 소개했던 model-based optimization은 image degradation($H$)을 정하고, 특정 image prior(e.g., sparsity, low-rank, etc.)를 고안하여 그렇게 만들어진 모델(objective function)의 최적해를 구하는 것으로 IR 문제를 해결하고자 합니다.&lt;br /&gt;&lt;br /&gt;한편, discriminative learning에 속하는 방식들은 여러 장의 손상된 이미지와 원본 이미지 쌍으로 이루어진 학습 데이터로부터 일종의 mapping function을 학습하고자 합니다. Discriminative learning에서의 IR 모델은 일반적으로 $$\min_\theta l(\hat{x},x),~\text{s.t}~\hat{x}=\mathcal{F}(y,H;\theta)$$와 같으며, 여기서 $\mathcal{F}(\cdot)$은 parameter set $\theta$로 표현되는 mapping function, $l(\hat{x},x)$는 resolve된 이미지와 원본 이미지 간의 유사도를 측정하는 loss function입니다. Deep learning에서는 보통 CNN이 inference (mapping) function 역할을 하게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Deep learning for IR&lt;/h2&gt;&lt;br /&gt;IR 분야에 deep learning을 적용한 가장 초기의 연구는 single-image super-resolution (SISR) 문제를 푼 SRCNN으로 두 개 layer로 이루어져 있는 초보적인 형태를 갖고 있습니다. 그럼에도 불구하고 기존의 방식들 대비 매우 강력한 성능을 보여주었으며 단순히 CNN을 사용하여 성능 개선을 꾀한 것뿐만 아니라 CNN 모델의 sparse coding과의 연관성에 대한 분석으로 서로 다른 두 영역의 가교 역할을 해준 중요한 연구였습니다.&lt;br /&gt;&lt;br /&gt;이후 진정 deep learning이라고 할 수 있는 깊은 구조를 사용한 모델들은 서울대 이경무 교수님 연구실에서 나온 VDSR이 시초이며, 지금은 매우 많은 연구들이 폭발적으로 진행되고 있습니다 (&lt;span style=&quot;color: blue; font-weight: bold;&quot;&gt;**&lt;/span&gt;). 다만 CNN을 사용한 image restoration 연구들은 이 짧은 글 하나로 담기에는 너무 방대하고 이 글의 목적인 개괄적인 소개와는 거리가 있기에 &lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/deep-learning-for-SISR-survey.html&quot; target=&quot;_blank&quot;&gt;다른 글&lt;/a&gt;로 소개하겠습니다 (&lt;span style=&quot;color: blue; font-weight: bold;&quot;&gt;**&lt;/span&gt;).&lt;br /&gt;&lt;b style=&quot;color: blue; font-size: small;&quot;&gt;**&lt;/b&gt;&lt;span style=&quot;color: blue; font-size: x-small;&quot;&gt;&amp;nbsp;그 중에는 제 논문도 있지요!ㅎㅎ CVPRW NTIRE 2017 3rd winning model (&lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Bae_Beyond_Deep_Residual_CVPR_2017_paper.pdf&quot; target=&quot;_blank&quot;&gt;paper&lt;/a&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: blue; font-size: x-small;&quot;&gt;&lt;b&gt;**&lt;/b&gt; IR 중에서 super-resoltion에 국한한 연구들을 모아 따로 &lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/deep-learning-for-SISR-survey.html&quot; target=&quot;_blank&quot;&gt;Survey 글&lt;/a&gt;을 작성 중이며 이로써 갈음하고자 합니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;각 방식의 장단점을 따져보면, model-based optimization은 여러가지 degradation에 대해 사용자가 유연하게 forward 모델을 만들어 사용될 수 있습니다. 즉, image prior가 주어지면 $H$만 바꿔가며 같은 알고리즘으로 여러 IR 문제들을 풀 수 있습니다. 단점은 각 instance마다 새로운 optimization 문제를 풀어줘야하기 때문에 느리겠죠.&lt;br /&gt;&lt;br /&gt;반면에 CNN을 이용한 discriminative learning-based 방식은 그 특성상 parametric mapping function $\mathcal{F}_\theta(\cdot)$이&amp;nbsp;학습 데이터와 매우 강하게 엮여 있습니다. 때문에 Image prior 자체를 데이터로부터 배우면서 좀 더 강력한 representation이 가능하므로 더 좋은 성능을 보이며, optimization에 드는 cost를 training phase로 넘길 수 있고 test phase에서의 inference가 빠릅니다. 그러나 데이터에 의존적인 면이 있으며 하나의 degradation에 대해서만 적용이 가능하고 따라서 모델의 유연성이 떨어진다는 단점이 있습니다.&lt;br /&gt;&lt;br /&gt;이를 정리하면 아래 표와 같습니다:&lt;br /&gt;&lt;br /&gt;&lt;table align=&quot;center&quot; border=&quot;1&quot; cellpadding=&quot;3&quot; cellspacing=&quot;0&quot; style=&quot;text-align: center; width: auto;&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Model-based optimization methods&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Deep CNN-based methods&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;b&gt;Pros&lt;/b&gt;&lt;/td&gt;&lt;td&gt;General to handle different IR problems &lt;br /&gt;Clear physical meanings&lt;/td&gt;&lt;td&gt;Data-driven end-to-end learning&lt;br /&gt;Efficient inference during test-phase&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;b&gt;Cons&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Hand-crafted priors (weak representations) &lt;br /&gt;Optimization task is time-consuming&lt;/td&gt;&lt;td&gt;Generality of model is limited&lt;br /&gt;Interpretability of model is limited&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;&lt;h2&gt;Deep image prior&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;Deep learning도 결국에 일종의 learnable image prior 혹은 image model $P(x)$를 배운다는 점에서 model-based optimization 방식들과 연관이 있다고 생각할 수 있습니다. 그러나 결국에 문제를 푸는 방식에 있어 서로가 매우 다른 전략을 취하기에 그 이상으로 연관짓기란 쉽지 않죠.&lt;br /&gt;&lt;br /&gt;그런 면에서 &lt;a href=&quot;https://arxiv.org/pdf/1711.10925.pdf&quot; target=&quot;_blank&quot;&gt;deep image prior (CVPR 2018)&lt;/a&gt;는 서로 매우 달라보이는 두 방향의 연구(model-based optimization vs. deep learning)들을 이어주는 멋진 연구입니다. 제가 개인적으로 매우 좋아하는 논문이기도 합니다.&lt;br /&gt;&lt;br /&gt;DIP가 멋진 이유는 기존의 inverse problem의 regularization 방식을 다루는 새로운 시각을 보여줬기 때문입니다. 대다수의 deep supervised learning 방식들과 달리&amp;nbsp;&lt;b&gt;&quot;네트워크 구조 그 자체&quot;&lt;/b&gt;를 inverse problem의 regularizer로 사용하는 신선한 방법을 제안하는 데요.&lt;br /&gt;&lt;br /&gt;좀 더 구체적으로 표현하자면, CNN의 구조 자체가 매우 강력한 (내재적인) prior라서 CNN이 표현 가능한 parametric function space가 일반적이지 않다는 가정에서 출발합니다. 이를 바탕으로 DIP는 우리가 모르는 latent image $x$를 CNN output으로 놓되 $z$라는 고정된 random vector에 대해서 아래와 같은 objective function에 대한 optimization 문제를 풉니다: $$\min_\theta ||H\mathcal{F}_\theta(z)-y||_2^2,\qquad \text{where }x=\mathcal{F}_\theta(z)$$ 예를 들면, 어떤 noise가 더해진 이미지를 주고 CNN을 사용하여 이런 이미지를 아무리 fitting (regression or generation)하려 해도 (GAN에서 generator를 생각하시면 편합니다), 해당 CNN으로 대표되는 parametic function space의 함수들로는 성질(property)이 좋지 않은 noise를 표현할 수가 없기에 natural image만을 fitting하여 깨끗한 결과를 내보낸다는 것이죠.&lt;br /&gt;&lt;br /&gt;재미있는 점은 이제 CNN이 이미지 한 장 한 장에 대해 optimization 문제를 풀어 $\theta$를 구한다는 것입니다. 마치 model-based optimization 방식들 같죠? 따라서 다른 model-based optimization이 그러하듯 DIP도 unsupervised 방식으로 IR 문제를 풀 수 있게 됩니다.&amp;nbsp;&lt;br /&gt;&lt;br /&gt;DIP는 이를 super-resolution 뿐만 아니라 denoising, JPEG deblocking, inpainting 등 여러 IR 문제에 적용(model-based optimization의 유연성) 가능한 framework을 제안하면서도 기존의 optimization 방식들보다 월등한 성능(deep learning의 성능)을 보여주었습니다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-vsky1XbpFWQ/XNpoTsH8QqI/AAAAAAAADZI/xNqdy-VP9iAljiEd3hbpomawJwVXaFYYwCK4BGAYYCw/s1600/dip.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-vsky1XbpFWQ/XNpoTsH8QqI/AAAAAAAADZI/xNqdy-VP9iAljiEd3hbpomawJwVXaFYYwCK4BGAYYCw/s1600/dip.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Inpainting과 denoising task&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-wY-HYbGE8O4/XNpuX3w7YVI/AAAAAAAADZU/3METN8Sw9h4yA0vjyCOpITUrE80S2KfEACK4BGAYYCw/s1600/dip2.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-wY-HYbGE8O4/XNpuX3w7YVI/AAAAAAAADZU/3METN8Sw9h4yA0vjyCOpITUrE80S2KfEACK4BGAYYCw/s1600/dip2.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Blind restoration of a JPEG-compressed image&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-ASg4b59V7zU/XNpumFgXwII/AAAAAAAADZc/ShQQHiS1e4QtehJDouf1mW47NNoeiPYgwCK4BGAYYCw/s1600/dip3.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-ASg4b59V7zU/XNpumFgXwII/AAAAAAAADZc/ShQQHiS1e4QtehJDouf1mW47NNoeiPYgwCK4BGAYYCw/s1600/dip3.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;4x image super-resolution&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;h2&gt;Deep Plug-and-Play Priors&amp;nbsp;&lt;/h2&gt;&lt;br /&gt;앞서 소개한 DIP는 학습되지 않은 네트워크를 사용해서 멋진 결과들을 보여주었는데, 혹시 그러면 기존에 이미 IR에 대해 학습이 잘 된 deep model들을 가져와서 plug-and-play 방식으로 사용하여 좀 더 강력한 IR 모델을 만들 수는 없을까요?&lt;br /&gt;&lt;br /&gt;이런 방향의 연구 역시 매우 흥미로운 주제이고, 다양한 방향으로 개발이 되고 있습니다. 이 부분은 제가 알고 있는 최신 연구들만 해도 네다섯 개가 넘는 논문들이 있기 때문에, 이에 대한 리뷰는 아무래도 기회가 된다면 다른 글에서 소개하겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;h2&gt;다음 읽을 거리&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Image Restoration (IR): inverse problem point of view (3) (TBC? maybe or maybe not)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/deep-learning-for-SISR-survey.html&quot; target=&quot;_blank&quot;&gt;Deep Learning for Image Super-Resolution: A Survey (TBC)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;디지털 신호 처리가 궁금하다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Signal Processing For Communications&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에 속하는 전반적인 연구 내용들이 궁금하다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/machine%20learning&quot; target=&quot;_blank&quot;&gt;Machine learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GAN에 관심이 많다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/GAN&quot; target=&quot;_blank&quot;&gt;GAN&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에서 잘 사용되는 수학에 관심이 있다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/mathematics&quot; target=&quot;_blank&quot;&gt;Mathematics&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/135301957335178820/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/image-restoration-inverse-problem-2.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/135301957335178820'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/135301957335178820'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/image-restoration-inverse-problem-2.html' title='Image Restoration (IR): inverse problem point of view (2)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-vsky1XbpFWQ/XNpoTsH8QqI/AAAAAAAADZI/xNqdy-VP9iAljiEd3hbpomawJwVXaFYYwCK4BGAYYCw/s72-c/dip.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-6596702812498144602</id><published>2019-05-13T17:31:00.002+09:00</published><updated>2019-05-14T15:05:43.633+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="dsp"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>Signal Processing For Communications (9-1)</title><content type='html'>모든 textbook들은 보통 재미있는 부분이 가장 뒷 chapter에 몰려있고 여기서 할 얘기를 위해 필요한 도구들을 소개하느라 공부하는 사람의 진을 다 빼곤한다. 학문적 측면에서 그리고 완결된 설명을 위해서는 이런 방식의 presentation이 맞는 것이겠으나 개인적으로는 앞 부분에서 지루한 내용들만 쭉 이어지는 형태가 불만이었다.&lt;br /&gt;&lt;br /&gt;도대체 무엇을 위해 이런 지루한 내용들을 배워야하는지도 알려주지 않은 채로 학습 과정을 따라가야 하는 경우, 지친 나머지 정작 중요한 내용에 갈 때쯤엔 (심지어는 학기 중 진도가 느려져서 가지도 못하고!) 힘이 다 빠져서 아무래도 좋을 상태가 되곤 했다.&lt;br /&gt;&lt;br /&gt;그래서 이번에는 내 마음대로 가장 뒤에 챕터에서 어떤 것을 배우려는 것인지를 먼저 확인한 후, 그 내용을 더 제대로 이해하기 위해 필요한 도구들을 살피는 순서를 밟을 생각이다.&lt;br /&gt;&lt;br /&gt;이 방식이 싫다면, 목차 자체는 일반적인 학습 순서대로 되어있으니 이 글타래가 완성된 이후, 순서대로 읽으면 되겠다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Interpolation and Sampling&lt;/h2&gt;&lt;br /&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;이전 글&lt;/a&gt;에서 continuous-time과 discrete-time 신호 간의 간극에 대한 논의를 짧게 한 바 있다. 간단히 말해 interpolation과 sampling은 정보 손실 없이 continuous-time과 discrete-time, 이 두 세계 사이를 오가는 방법에 대한 이야기이다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Interpolation은&lt;/b&gt; discrete-time 신호를 continuous-time 신호로 바꿀 때 사용한다. Interpolation이 중요한 이유는 아날로그 시스템인 우리 인간이 인지할 수 있는 신호의 형태가 결국 아날로그이기 때문이다. 또한 전자기기에 사용되는 아날로그 회로를 가장 잘 모델링 하는 방법이 real variable에 대한 함수, 즉 continuous-time 함수로 표현하는 것이기 때문이기도 하다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Sampling은&lt;/b&gt; 반대로 continuous-time 신호를 discrete-time 신호로 바꿀 때 사용하는 방법이다. 가장 간단한 sampling 방식은 일정 주기로 반복하여 기록을 하는 것이겠다. Sampling 방법은 random부터 radial 등 여러가지가 있지만, 가장 간단한 방식이 uniform한 주기 $T_s$로 샘플을 얻는 uniform sampling이며 여기서는 이를 기준으로 설명을 한다. 중요한 것은 어떤 sampling 방식이든 관계없이 continuous-time의 임의의 값과 해당하는 discrete-time 수열의 점(points) 사이에는 언제나 어떤 대응(correspondence) 혹은 관계가 만들어진다는 것이다.&lt;br /&gt;&lt;br /&gt;그러므로 interpolation과 sampling 둘은 결국 동전의 양면과 같이 떼어낼 수 없는 사이라는 점을 알아야겠다. 앞으로 다룰 내용을 간략히 소개하자면,&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation:&lt;/b&gt; &quot;이 행위(interpolation)로 인하여 기존 함수와 interpolated 함수 사이의 spectral 성질이 어떻게 달라지는가?&quot;에 대한 것이며,&amp;nbsp;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling:&lt;/b&gt; &quot;이 행위(sampling)로 인해 정보 손실이 생기는가?&quot; 그리고 &quot;손실이 있다면 얼마나 생기며 이를 피할 수 있는가?&quot;가 되겠다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;여기서 만약 sampling의 첫번째 질문에 대한 답이 (최소한 특정 신호에 대해) &quot;없다&quot;라면, 이는 우리가 discrete-time domain에서 개발한 모든 신호 처리 도구들을 고스란히 continuous-time 신호에도 적용할 수 있다는 것을 뜻한다. 이는 직관적으로는 잘 와닿지 않는 매우 흥미로운 점이다.&lt;br /&gt;&lt;br /&gt;당연하지만 interpolation 함수의 가장 필수충족 요소는 샘플 주기 $T_s$에 대해 아래가 성립해야한다는 것이다:&lt;br /&gt;$$x(t)\bigg\rvert_{t=nT_s}=x[n]$$ 이렇게 각 instants에서의 값이 같다는 것을 제외하고 나면 interpolation에서 남은 문제는 이 &quot;값들 사이사이를 어떻게 채울 것인가?&quot;가 되겠다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Local Interpolation&lt;/h2&gt;&lt;br /&gt;임의의 discrete-time sequence $x[n]$에 대한 continuous-time 함수 $x(t)$를 만드는 가장 간단한 방법은 $t=nT_s$에 대해 $x(t)$의 값이 $x[n]$과 같도록 한 후 그 사이를 이웃하는 sequence 값들에 대한&amp;nbsp; 임의의 선형 조합으로 나타내는 것이다.&lt;br /&gt;&lt;br /&gt;일반적으로 local interpolation 방식은 다음과 같이 표현할 수 있다: $$\begin{align}x(t)=\sum^\infty_{n=-\infty} x[n]I\left (\frac{t-nT_s}{T_s}\right) \end{align}$$ 여기서 $I(t)$는 interpolation 함수를 뜻한다. $I_N(t)$와 같이 표현된 경우 $N$은 $x(t)$을 보간할 때, 현재 instanst에 대응하는 샘플 외에 N개의 discrete-time 샘플을 사용하였다는 것을 말한다.&lt;br /&gt;&lt;b style=&quot;color: blue; font-size: small;&quot;&gt;**&lt;/b&gt;&lt;span style=&quot;color: blue; font-size: x-small;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: blue; font-size: x-small;&quot;&gt;여기서 식 (1)을 잘 살펴보면 신호 $x(t)$가 하나의 interpolation 함수 $I(t)$의 shifted version들의 선형 조합으로 나타내진다고 이해할 수 있다. 이런 해석은 차후 유용하게 사용될 수 있는 관점이므로&amp;nbsp;염두에 두고 넘어갈 필요가 있다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: blue; font-size: x-small;&quot;&gt;&lt;b&gt;**&lt;/b&gt;&amp;nbsp;또 한 편으로 이 식이 재미있는 이유는 두 신호를 convolution 하는 것으로 생각하되, 하나는 discrete-time signal $x[n]$이고 다른 하나는 continuous-time &quot;impulse response&quot; $I(t)$인 &quot;mixed-domain&quot; convolution으로 생각할 수 있다는 점이다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;$I(t)$에 어떤 함수를 사용하느냐에 따라 신호 $x(t)$에 대한 interpolation 성격이 정해지는데 어떤 $I(t)$이든 interpolation 함수라면 다음과 같은 성질을 만족해야한다:&lt;br /&gt;$$\begin{align}\begin{cases} I(0)=1 \\&amp;nbsp; I(k)=0 \quad \text{for} \quad k\in\mathbb{Z}\setminus\{0\} \\ \end{cases} \end{align}$$ 두 번째 조건이 뜻하는 것은 $I(t)$가 몇 개의 support를 갖는지와는 상관없이 절대로 다른 interpolation instants에 영향을 주어서는 안 된다는 것이다.&lt;br /&gt;&lt;br /&gt;아래 그림은 기본적으로 사용되는 $I(t)$로 하나씩 살펴볼 예정이다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-ZFIQ4ckvHuY/XNkuK31o4aI/AAAAAAAADY0/LiAyqRKeM-4sJhO1cpW9P12qQHf9gjj2ACK4BGAYYCw/s1600/fig9-0.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-ZFIQ4ckvHuY/XNkuK31o4aI/AAAAAAAADY0/LiAyqRKeM-4sJhO1cpW9P12qQHf9gjj2ACK4BGAYYCw/s1600/fig9-0.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;Zero-order $I(t)$ and First-order $I(t)$&lt;/div&gt;&lt;br /&gt;&lt;h3&gt;Zero-Order Hold&lt;/h3&gt;&lt;br /&gt;가장 쉽게 생각할 수 있는 interpolation 방식은 piecewise-constant interpolation이다. 즉, 샘플값 사이를 상수로 interpolation 하는 것이다: $$x(t) = x[n], \quad \text{for} \quad\left(n-\frac{1}{2}\right)T_s\leq t \leq \left(n+\frac{1}{2}\right)T_s$$&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-bPgNpf2MMsU/XNfBSpG4fJI/AAAAAAAADXQ/CpJQf5XDEEI8hSg5ZAzmHgRpHVBDgJu7wCK4BGAYYCw/s1600/fig9-1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-bPgNpf2MMsU/XNfBSpG4fJI/AAAAAAAADXQ/CpJQf5XDEEI8hSg5ZAzmHgRpHVBDgJu7wCK4BGAYYCw/s1600/fig9-1.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Zero-order hold&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;Interpolation 함수가 불연속 함수기 때문에, 당연하지만 결과가 절대 부드럽지는 않다: $$I_0(t)=\text{rect}(t)$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;아래 첨자 0에서 알 수 있듯, $x(t)$ 값이 현재 discrete-time 샘플 값에만 영향을 받는다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style=&quot;text-align: justify;&quot;&gt;First-Order Hold&lt;/h3&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;그 다음으로 생각해볼 수 있는 interpolation은 선형 interpolator가 되겠다. 두 샘플들 간에 일직선을 그어 보간을 하는 것으로 아래 그림과 같이 조금은 더 부드러운 모습을 볼 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$ I_1(t)=\begin{cases} 1-|t| \quad \text{if}~|t|&amp;lt;1 \\&amp;nbsp; 0 \quad\qquad \text{otherwise} \\ \end{cases} $$&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-TP8ta55s6Os/XNfBTTPQ5wI/AAAAAAAADXY/FX_H1wwaKDoijI_ct4AOW1fHeaA1Z1qVACK4BGAYYCw/s1600/fig9-2.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-TP8ta55s6Os/XNfBTTPQ5wI/AAAAAAAADXY/FX_H1wwaKDoijI_ct4AOW1fHeaA1Z1qVACK4BGAYYCw/s1600/fig9-2.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;First-order hold&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;h3&gt;Higher-Order Interpolators&lt;/h3&gt;&lt;br /&gt;$I_0(t)$와 $I_1(t)$는 각각 zero-order와 first-order B-spline 함수라고 불리운다. 이를 $N$-th-order로 확장한 것이 $t$에 대한 $N$-th-order polynomial $I_N(t)$이며 앞선 예시에서 유추할 수 있듯이 order가 커질수록 더 부드러운 보간이 가능해진다.&lt;br /&gt;&lt;br /&gt;이러한 local interpolation의 장점은 실제 적용이 간단하다는 점이지만, N번째 미분부터는 불연속 함수가 되기 때문에 그 이상의 부드러운 보간이 불가능하다는 단점이 존재한다. 이를 spectral 관점에서 얘기하자면, 불연속성이 곧 high frequency에 대응하고 이는 보통 원치않는 결과를 부르기 때문에 좋지 않다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Polynomial Interpolation&lt;/h2&gt;&lt;br /&gt;Local interpolation에서 문제가 되는 lack of smoothness는 우리가 유한한 길이의 discrete-time 샘플들을 보간해야한다면 쉽게 우회할 수 있다. 이렇게 신호의 범주를 유한한 길이로 제한을 두는 순간, 이 문제는 전통적인 polynomial을 이용한 보간 문제로 치환이 가능해지고 우리는 이에 대한 optimal solution을 알고 있다: &lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrange_polynomial&quot; target=&quot;_blank&quot;&gt;Lagrange interpolation&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Polynomial interpolation이 좋은 점은 유한한 갯수의 점에 대한 polynomial interpolation은 모든 미분에 대해 언제나 연속을 보장한다는 것이다. 즉, interpolated 함수가 &lt;a href=&quot;https://en.wikipedia.org/wiki/Smoothness#Differentiability_classes&quot; target=&quot;_blank&quot;&gt;maximally smooth한 함수&lt;/a&gt;가 된다는 강력한 장점을 갖고 있다는 것! (&lt;a href=&quot;https://math.stackexchange.com/questions/1343904/are-polynomials-infinitely-many-times-differentiable&quot; target=&quot;_blank&quot;&gt;polynomials are infinitely many times differentiable.&lt;/a&gt;)&lt;br /&gt;&lt;br /&gt;$2N+1$ 길이의 discrete-time signal $x[n],~(n=-N\cdots,N)$을 생각해보자. 모든 $2N+1$ 점 $(t_n,x[n])$을 지나는 $2N$-차 polynomial $P(t)$는 유일(unique)하고, 이는 Lagrange interpolator라는 것은 잘 알려져있다&lt;br /&gt;&lt;span style=&quot;color: blue; font-size: x-small;&quot;&gt;&lt;b&gt;**&lt;/b&gt; $P(t)$의 existence는 construction 자체로 자명하고 uniqueness 증명은 contradiction으로 쉽게 알 수 있다.&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;이런 polynomial의 coefficients는 다음과 같은 $2N+1$개의 방정식을 풀면 구할 수 있으며: $$\{P(t_n)=x[n]\}_{n=-N,\cdots,N}$$ 이보다 더 쉬운 방법은 $P(t)$를 $2N+1$ 개의 Lagrange polynomials (of degree $2N$)로 나타내는 것이다: $$\begin{align*}L^{(N)}_n(t) &amp;amp;=\prod_{\substack{k=-N\\k\neq n}}^N \frac{t-t_k}{(t_n-t_k)} \\&lt;br /&gt;&amp;amp;=\prod_{\substack{k=-N\\k\neq n}}^N \frac{t/T_s-k}{(n-k)}, \quad n=-N, \cdots, N\end{align*}$$ 이런 polynomial이 글 서두에 소개한 식 (2)의 interpolation의 성질을 만족하는 것은 자명하다. 예를 들어 점 4개를 보간할 때 $L^{(N)}_n(t)$를 보면 아래 그림과 같다 (wikipedia의 그림이 좋아 빌려왔기에 notation이 안 맞을 수 있다.) :&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-7pfbncyAxqY/XNkUvmaDbhI/AAAAAAAADYc/g_dgL7QfGiM3Vxr0-iq7-WqWB8DOpfHMgCK4BGAYYCw/s1600/lagrange_poly.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;270&quot; src=&quot;https://1.bp.blogspot.com/-7pfbncyAxqY/XNkUvmaDbhI/AAAAAAAADYc/g_dgL7QfGiM3Vxr0-iq7-WqWB8DOpfHMgCK4BGAYYCw/s400/lagrange_poly.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: right;&quot;&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$P(x)$ (dashed, black), which is the sum of the scaled basis polynomials $y_0ℓ_0(x), x_1 ℓ_1(x), y_2ℓ_2(x),~and~~y_3 ℓ_3(x)$. The interpolation polynomial passes through all four control points, and each scaled basis polynomial passes through its respective control point and is 0 where x corresponds to the other three control points.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: right;&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrange_polynomial&quot; style=&quot;text-align: center;&quot; target=&quot;_blank&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrange_polynomial&quot; target=&quot;_blank&quot;&gt;Wikipedia &quot;Lagrange polynomial&lt;/a&gt;&quot;&lt;/div&gt;&lt;/blockquote&gt;&lt;br /&gt;따라서 &lt;b&gt;&quot;global&quot;&lt;/b&gt; Lagrange interpolator는 Lagrange polynomial들의 선형 조합으로 표현되며: $$P(t)=\sum_{n=-N}^Nx[n]L^{(N)}_n(t)$$ 여기서 global은 $x(t)=P(t)$는 interpolation을 할 때 언제나 모든 샘플들을 고려한다는 뜻이다. 즉, 유한한 길이를 가진 discrete-time 신호 $x[n]$에 대해 Lagrange polynomials는 global interpolating 함수이며 이렇게 보간된 함수 $x(t)$는 maximally smooth하다 ($x(t)\in C^\infty$).&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Sinc Interpolation&lt;/h2&gt;&lt;br /&gt;본격적으로 Sinc interpolation에 대해 알아보기에 앞서, 지금까지 살펴본 local &amp;amp; global interpolation에 대해 장단점을 비교해보자.&lt;br /&gt;&lt;br /&gt;Local interpolation 방식의 멋진 점은 interpolated 함수가 interpolation 함수 $I(t)$의 shifted version들 간의 선형 조합으로 표현할 수 있다는 것이다: &quot;An interpolated function is simply a linear combination of shifted versions of the same prototype $I(t)$.&quot; (식 (1)을 보라) 다만 smoothness에 한계가 있다는 단점이 있다.&lt;br /&gt;&lt;br /&gt;반면에 polynomial interpolation은 완벽하게 부드러운 보간이 가능하지만 finite-length 신호에 대해서만 적용이 가능하며 다른 길이를 갖는 신호에 대해 서로 다른 interpolation 함수가 필요하다는 단점이 있다.&lt;br /&gt;&lt;br /&gt;이 두 가지 방식의 장점만 쏙쏙 빼면 참 좋을텐데...에 대한 답이 바로 Sinc Interpolation이다! 이제 지금까지 설명한 내용들을 바탕으로 infinite discrete-time 신호에 대해 maximally smooth한 interpolation 방법을 소개할 때가 되었다.&lt;br /&gt;&lt;br /&gt;앞서 살펴본 Lagrange polynomial of degree N에 대해 N을 무한대로 보내면: $$\begin{align*} \lim_{N\rightarrow\infty}L_n^{(N)}(t) &amp;amp;= \prod_{\substack{k=-\infty\\k\neq n}}^\infty \frac{t/T_s-k}{n-k} = \prod_{\substack{m=-\infty\\m\neq0}}^\infty \frac{t/T_s-n+m}{m}\\&lt;br /&gt;&amp;amp;=\prod_{\substack{m=-\infty\\m\neq0}}^\infty \left(1+\frac{t/T_s-n}{m}\right)\\&lt;br /&gt;&amp;amp;=\prod_{m=1}^\infty \left(1-\left(\frac{t/T_s-n}{m}\right)^2\right)\\&lt;br /&gt;\end{align*}&lt;br /&gt;$$&lt;br /&gt;두번째 등호는 $m=n-k$를 사용하여 변수를 치환한 것이고, 이후 전개는 sine 함수에 대한 오일러의 infinite product expansion을 사용한 것이다: $$sin(\pi\tau) = (\pi\tau) \prod_{k=1}^\infty\left(1-\frac{\tau^2}{k^2}\right)$$ 이를 정리하면 최종적으로 아래 식을 얻을 수 있는데: $$\lim_{N\rightarrow\infty}L_n^{(N)}(t) = \text{sinc}\left(\frac{t-nT_s}{T_s}\right) $$&lt;br /&gt;포인트는 차수가 증가할 수록 Lagrange polynomial $L_0^{(N)}(t)$는 점차 sinc 함수로 수렴한다는 것이다. 즉, 점의 갯수가 무한이 되면서 모든 Lagrange polynomial은 각각 sinc 함수에 대한 shifted version으로 수렴하게 된다는 점이다. 따라서 식 (1)과 같이 $I(t)=sinc(t)$를 사용하여 무한수열 x[n]에 대해 $$x(t)=\sum_{n=-\infty}^\infty x[n] sinc\left(\frac{t-nT_s}{T_s}\right)$$로 표현하는 것이 가능해진다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Spectral Properties of the Sinc Interpolation&lt;/h2&gt;&lt;br /&gt;Interpolation을 할 때 주안점을 둘 부분이 바로 spectral 영역에서 interpolated 신호가 어떤 식으로 달라지는지 확인하는 것이라고 말한 바 있다. 이제 이게 어떤 의미인지 얘기할 준비물이 대략 갖춰졌다.&lt;br /&gt;&lt;br /&gt;지금까지 interpolation 방법들 여러 개를 살펴보았으나 일반화하면서 결국 마지막에 다다른 것은 Sinc interpolation이다. 이렇게 얻은 Sinc interpolation은 spectral 영역에서 보면 재미있는 분석이 가능해지는데, 간단히 말하면 시간 영역의 Sinc 함수에 대응하는 주파수 영역의 형태는 ideal low-pass filter로써 0을 기준으로 한 사각형 박스처럼 생겼다.&lt;br /&gt;&lt;br /&gt;즉, discrete-time sequence에 대한 Sinc interpolation은 continuous-time 신호가 band-limited low-pass filtering이 된 것과 정확히 일치한다 (수식적으로도 그러하다). $$\begin{align*}X(j\Omega) &amp;amp;= \left(\frac{\pi}{\Omega_N}\right)\text{rect}\left(\frac{\Omega}{2\Omega_N}\right)\sum_{n=-\infty}^\infty x[n]e^{-j\pi(\Omega/\Omega_N)} \\ &amp;amp;= \begin{cases} \frac{\pi}{\Omega_N}X(e^{-j\pi\Omega/\Omega_N}) \quad \text{for}~|\Omega|\leq\Omega_N \\ 0 \qquad \qquad\qquad\quad \text{otherwise}\end{cases}\end{align*}$$이를 다르게 말하면, 임의의 continuous-time 신호가 애초부터 bandlimited 신호인 경우 이 신호에 대한 적절한 sampling을 하므로써 어떠한 정보 손실도 전혀 없이&amp;nbsp;discrete-time 신호를 얻는 것이 가능하다는 뜻이다.&lt;br /&gt;&lt;br /&gt;이런 사실은 이후에 Fourier transform을 살펴본 다음에 자명하게 수식적으로 보일 수 있겠지만, 이렇게 미리 살짝 엿보는 것까지는 굳이 복잡한 Fourier transform 내용을 배우지 않고도 가능하다.&amp;nbsp;왜 복잡한 내용을 공부하는지 그리고 Sinc 함수와 같이 이상하게 생긴 것을 굳이 왜 배워야하는지 이제 조금은 감이 생겼으리라 생각한다.&lt;br /&gt;&lt;br /&gt;여기에 대한 더 자세한 설명 및 Sampling Theorem 그리고 Aliasing 현상에 관한 내용은 이제 다시 순서대로 Fourier transform 등의 수학적 도구를 더 든든히 갖춘 다음 살펴보겠다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b&gt;To be continued ... (planned)&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Preface&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;What is Digital Signal Processing? (1)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Signals and Hilbert Spaces&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Fourier Analysis&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Interpolation and Sampling (&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-9-1.html&quot; target=&quot;_blank&quot;&gt;9-1&lt;/a&gt;&amp;nbsp;$\leftarrow$)&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation&amp;nbsp;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling theorem&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Aliasing&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Multirate Signal Processing&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Downsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Upsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b style=&quot;text-align: center;&quot;&gt;Oversampling&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;h2 style=&quot;text-align: justify;&quot;&gt;참고 문헌&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;ul&gt;&lt;li&gt;https://math.stackexchange.com/questions/1343904/are-polynomials-infinitely-many-times-differentiable&lt;/li&gt;&lt;li&gt;https://www.youtube.com/watch?v=ygcQJqcHdOM&lt;/li&gt;&lt;li&gt;http://home.iitk.ac.in/~pranab/ESO208/rajesh/03-04/interpolation.pdf&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/6596702812498144602/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-9-1.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6596702812498144602'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6596702812498144602'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-9-1.html' title='Signal Processing For Communications (9-1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-ZFIQ4ckvHuY/XNkuK31o4aI/AAAAAAAADY0/LiAyqRKeM-4sJhO1cpW9P12qQHf9gjj2ACK4BGAYYCw/s72-c/fig9-0.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-8605236143566792770</id><published>2019-05-13T14:35:00.001+09:00</published><updated>2019-05-13T14:56:03.355+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><title type='text'>카카오 리포트 (Part II)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;지난 글에서 GAN의 기본 원리와 배경 이론에 대해 살펴보았다면, 이번 글에서는 GAN에 대한 기본적인 이해를 바탕으로 GAN의 특징과 장단점에 대해 조금 더 심화된 내용을 다루고자 한다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;h2&gt;DCGAN&lt;/h2&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;초창기 GAN에 대해 얘기하려고 하면 빼놓을 수 없는 연구가 바로 DCGAN이다. GAN이 지금은 매우 뛰어난 결과들을 보여주고 있지만, 초기 결과는 아이디어의 참신성에 비해 그리 인상적이지 않았다. GAN 구조가 학습시키기 매우 어려웠다는 것도 여러 이유 중 하나였는데 Deep Convolutional GAN (DCGAN)이 나온 이후, GAN으로 만드는 결과들이 매우 급격하게 발전하기 시작했다. 크게 이 논문이 기여한 바를 정리해보면,&lt;/div&gt;&lt;br /&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;대부분의 상황에서 언제나 안정적으로 학습이 되는 구조를 제안하였다는 점&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;마치 word2vec과 같이 DCGAN으로 학습된 생성기가 벡터 산술 연산이 가능한 성질을 갖고 이것으로 의미론적(semantic)으로 신규 샘플을 생성할 수 있다는 것을 보여주었다는 점&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;등이 있겠다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;DCGAN 논문은 GAN이 잘 학습되는 구조를 매우 세세한 가이드라인으로 제시한 연구이다. 이 논문 이후에 나온 대부분의 GAN 연구들은 어떤 형태로든 DCGAN 구조를 바탕으로 하고 있다고 할 정도로 매우 잘 확립된 구조이다. 일단 DCGAN에서 제시한 가이드 라인대로 GAN 구조를 짜면 상당히 안정적으로 학습이 된다. 이런 구조를 발견하기 위해서 얼마나 대학원생들이 힘들었을지 논문의 한 구절에서 언뜻 느껴볼 수 있다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;“However, &lt;b&gt;after extensive model exploration&lt;/b&gt;, we identified a family of architectures that resulted in stable training across a range of datasets and allowed for higher resolution and deeper generative models.”&lt;/blockquote&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;DCGAN은 이름에서 알 수 있듯이 convolution 구조를 GAN에 잘 결합한 것이다. Convolutional neural network (CNN)이 지도학습(supervised learning)에서 매우 큰 성공을 거둔 것에 비해 비지도 학습(unsupervised learning)에서는 상대적으로 잘 사용되지 못하였다. 그런 면에서 DCGAN 논문은 지도학습에서 CNN의 성공적인 모습과 비지도 학습에서의 격차를 줄이는 데에 큰 역할을 하였다고도 평가된다. 그러나 이렇게 추상적인 영향력을 굳이 말할 필요가 없을 정도로 생성한 이미지의 질부터 매우 인상적인 것을 볼 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;DCGAN 결과에서 가장 재미있는 부분은 아래와 같이 생성기의 입력으로 들어가는 $z$ 은닉 공간(latent space)에서 벡터 산술 연산이 가능하다는 점이다. 가장 흔한 예시로 word2vec 연구가 있다. 다음 수식을 계산하고 답을 추정해보자: $$KING~(왕) - MAN~(남자) + WOMAN~(여자)$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;사람은 생각보다&amp;nbsp;쉽게&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$QUEEN~(여왕)$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이라는 단어를 연상할 수 있지만 컴퓨터에게 이런 연산은 사실&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;ol&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;단어의 의미를 이해하고,&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;그에 맞는 새로운 단어를 찾는 등의&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;매우 고차원의 처리가 필요한 어려운 문제이다. 기존의 word2vec 연구에서는 뉴럴넷을 사용하여 말뭉치에서 실제로 단어 간의 관계를 학습하는 것을 보여주었고, DCGAN은 이런 문제를 말뭉치가 아닌 이미지에서 하는 것이 가능하다는 것을 보여주었다. 아래 그림이 바로 그 결과이다.&lt;/div&gt;&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-kpejybfFbMw/WfAyUMTYbKI/AAAAAAAACNw/bCRgP4mgA5QzVqoStESNmgwoUCE8Nj_XwCK4BGAYYCw/s1600/dcgan-vector-arithmatic.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-kpejybfFbMw/WfAyUMTYbKI/AAAAAAAACNw/bCRgP4mgA5QzVqoStESNmgwoUCE8Nj_XwCK4BGAYYCw/s1600/dcgan-vector-arithmatic.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;실제로 모두 DCGAN으로 생성된 결과들이다. 상당히 진짜 같은 결과만으로도 놀라운데, 이미지가 갖는 의미를 바탕으로 직관적인 벡터 산술이 된다는 것을 알 수 있다. 안경을 쓴 남자와 그냥 남자 그리고 일반 여자를 생성하게 하는 입력값들이 은닉 공간에 각각 벡터로 존재하고 있을텐데, 각각의 벡터를 서로 빼고 더해주면 최종적으로는 안경을 쓴 여자를 생성하는 입력 벡터를 찾을 수 있다는 것이다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;물론 생성기의 입력인 $z$ 벡터 하나만으로는 깔끔한 결과가 나오지 않기에 세 개 정도를 평균한 $\bar{z}$ 벡터를 사용해서 결과를 만든 것이기는 하지만 신기한 것은 매한가지다.&amp;nbsp;어떻게 보면 네트워크가 영상의 의미를 이해했다고 생각할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이 외에도 아래와 같이 침실을 생성한 결과 그림들을 보면 작은 그림이긴 하지만 꽤나 그럴듯한 결과를 만들어 냈다는 것을 확인할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-y07sQbX0qGk/WfBGYYc-afI/AAAAAAAACOA/tUH_W4kgZXw1QZle8bN9KgFabJowyORsACK4BGAYYCw/s1600/dcgan-fig3.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-y07sQbX0qGk/WfBGYYc-afI/AAAAAAAACOA/tUH_W4kgZXw1QZle8bN9KgFabJowyORsACK4BGAYYCw/s1600/dcgan-fig3.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;다섯 번 epoch을 돌려 학습한 후 생성된 침실 사진&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;뿐만 아니라 논문에서 &quot;공간을 걷는다&quot;라고 표현하였듯이 은닉 공간에서 천천히 벡터의 값을 바꿔가면, 생성기가 내보내는 이미지가 하나의 침실에서 다른 침실로 위화감 없이 부드럽게 변화하는 것을 볼 수 있다. 특히 벽이었던 부분이 자연스럽게 하나의 창으로 변화해가는 것을 보면 매우 놀랍다.&amp;nbsp;&lt;/div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-RYq_4D4R8Pw/WfBGoAN5wSI/AAAAAAAACOI/Gl7567khmVg7txmJEDuABzNFyg1uCmqlgCK4BGAYYCw/s1600/dcgan-fig4.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-RYq_4D4R8Pw/WfBGoAN5wSI/AAAAAAAACOI/Gl7567khmVg7txmJEDuABzNFyg1uCmqlgCK4BGAYYCw/s1600/dcgan-fig4.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&quot;은닉 공간에서 돌아다니기&quot;&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;만약 생성기가 단순하게 영상을 외워서 보여줄 뿐이라면 주어진 특정 입력에 대해 특정 이미지를 내보내는 일대일 대응 함수를 학습한 것으로 생각할 수 있다. 이럴 경우 은닉 공간에서 굳이 부드러운 변화가 있을 이유가 없다. 바로 옆의 $z$ 벡터가 전혀 다른 샘플과 일대일로 연동될 수 있기 때문이다.&amp;nbsp;이렇듯 은닉 공간에서 벡터 연산이 가능하다는 것과 입력에 변화를 줬을 때 생성되는 결과가 부드럽게 변하는 것을 보는 등의 분석이 중요한 이유는 우리가 학습시킨 GAN의 생성기가 일대일 대응 함수와 같이 매우 단순한 의미없는 함수(mapping)를 학습한 것이 아니란 것을 시사하기 때문이다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이렇게 수많은 이미지를 표현할 수 있는 정보들을 포괄할 수 있으면서도 부드러운 변화에 대응할 수 있는 함수를 학습할 수 있게 하기 위해서 은닉 공간을 잘 정하는 것도 매우 중요한 일이다. GAN에서는 보통 $z$ 은닉 공간은 고차원의 가우시안 분포를 많이 사용한다. 적절한 가정 하에서 충분히 복잡한 함수를 사용하여 대응시킬 수만 있다면 임의의 $d$ 차원 분포는 정규 분포를 따르는 $d$개의 변수로 나타낼 수 있다는 것이 알려져 있기 때문이다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;h2&gt;기존 생성 모델과 GAN의 차이점&lt;/h2&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;그러면 GAN은 기존의 생성 모델들과 어떤 면이 다르기에 이렇게 비교적 또렷한 이미지를 만들 수 있는 것일까? GAN의 특징이자 가장 큰 차이점은 바로 GAN이 사실 샘플러(sampler)라는 것이다.&amp;nbsp; 즉, 직접적으로 데이터의 분포를 학습하는 형태가 아니라 하나의 입력이 들어갔을 때 하나의 출력을 주는 형태의 독특한 특징을 지닌다.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;조금 더 자세히 이해하기 위해 &quot;확률 모델을 학습한다&quot;는 것에 대해 생각해보면,&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-odgQfqzmS9Y/WfE3XK65SII/AAAAAAAACOs/Oz1Ed_HR2uo3OoYo9AmB_0N6QKETxdJAgCK4BGAYYCw/s1600/fgan_1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;138&quot; src=&quot;https://1.bp.blogspot.com/-odgQfqzmS9Y/WfE3XK65SII/AAAAAAAACOs/Oz1Ed_HR2uo3OoYo9AmB_0N6QKETxdJAgCK4BGAYYCw/s400/fgan_1.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;모델을 추정한다는 것은 일반적으로 우리가 알고 싶은 $\cal{P}$라는 진짜 데이터의 분포가 어딘가에 있을 때, 이로부터 얻은 샘플들이 i.i.d.하게 관측되었다고 가정한 후 $\cal{Q}$라는 모수 모델 클래스(parametric model class)를 만들어 그 안에서 $\cal{P}$와 가장 &quot;가까운&quot; 모델의 모수를 찾아내는 것을 말한다. 가장 간단한 예시로 데이터의 분포가 정규 분포를 따를 것이라 가정하여 가우시안 모델을 세우고 현재 내가 갖고 있는 데이터를 가장 잘 설명할 수 있는 평균과 분산 값을 찾는 과정을 생각해볼 수 있다. &lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이를 위해서는 $\cal{P}$와 $\cal{Q}$의 &quot;차이&quot; 혹은 &quot;거리&quot;를 계산할 수 있어야 한다. 그러면 구한 두 분포 사이의 거리를 줄여나가는 방향으로 모델의 모수들을 조정할 수 있고, 이 과정을 적합(fitting)이라고 한다. GAN도 Jensen-Shannon divergence라는 측도를 사용하여 분포 간의 거리를 계산하고 이를 최소화하는 방향으로 생성기를 학습한다고 분석할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;보통 기존의 방식에서는 아래와 같은 $\cal{Q}$에 대한 가정들을 사용하는데:&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;tractable sampling&lt;/li&gt;&lt;li&gt;tractable parameter gradient with respect to sample&lt;/li&gt;&lt;li&gt;tractable likelihood function&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이 중 가장 강력한 가정이 바로 우도 함수(likelihood function)가 계산 가능하다(tractable)는 것이다. 많은 경우 현실의 모델은 계산이 불가능한 형태의 수식으로 나타나는 것을 상기한다면 기존의 모델들이 얼마나 강력한 가정을 사용하고 있는지 알 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;한편 GAN 형태의 모델들은 임의의 확률 변수 입력 값을 사용하여 비선형 변환 함수를 통과시키면 출력으로 샘플이 하나 튀어나오는 구조이다. 마치 버튼을 누르면 샘플이 튀어나오는 자판기처럼 생각할 수 있다. GAN 모델들의 독특한 점은 바로 이 부분에서 나온다. GAN 모델들은 다른 확률 모델들과는 달리 우도 함수를 근사하려하지 않고 샘플을 뽑아주는 함수를 학습했을뿐이기 때문에 우도 함수 모델링이 필요없는(likelihood-free) 모델이라고 할 수 있기 때문이다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;물론 이 부분은 GAN의 특징일뿐 장점일 수도 있고 단점이라 할 수도 있다. 데이터 분포에 대한 모델을 특정하지 않고 하나의 샘플을 뽑아서 보여주기 때문에 고정된 모델에 한계에 제약을 받지 않고 또렷한 이미지를 보여줄 수 있기도 하지만, 다른 한편으로는 정작 이미지를 잘 뽑더라도 데이터의 분포에 대한 정보를 직접적으로 얻기는 어렵기 때문에 분포를 알았을 때 시도해볼 수 있는 많은 분석들을 시도할 수가 없다는 아쉬움이 있다. 이 부분에 대해서는 Ian Goodfellow의 NIPS 2016 tutorial 논문[ref]이나 같은 워크샵에서 발표된&amp;nbsp;Sebastian Nowozin의 f-GAN [ref] 논문을 참고한다면 조금 더 심화된 내용을 확인할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이외에도 이후 연구된 WGAN에서는 기존의 GAN이 divergence를 측도로 사용하기 때문에 생기는 여러가지 문제를 지적하며 다른 방식의 측도를 제안하는 등, 점차 수식적인 분석과 함께 GAN의 가치 함수 자체를 근본적으로 수정하는 방향으로 연구가 발전되었다. 이를 바탕으로 보다 안정적인 학습과 결과를 보여주었는데 EBGAN LSGAN BEGAN 등 이후 나온 많은 GAN들이 WGAN의 카테고리로 분류할 수 있다.&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이렇게 보면 모든 연구가 끝나서 더이상 할 것이 없는 것처럼 보이고 점차 이론적인 문제로 깊게 들어가면서 수학이 많이 들어가고 공학자들이 개입할 수 있는 여지가 없는 것 같지만 아직은 직관이 필요한 부분들이 많이 남아있으며 풀어야할 문제들도 많이 남아있다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;학습이 예전에 비해 수월해졌다는 것이지 정말 쉬워졌다는 것을 의미하진 않고 네트워크의 안정적으로 학습이 이미지의 질을 보장하지 않는 경우가 많으며 수렴은 여전히 어렵고 이어 소개할 mode collapse나 모델 평가 등 역시 아직도 풀어야 할 문제가 산적해 있다. 그런 의미에서 GAN 학습이 어려운 이유를 하나씩 소개하겠다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;h2&gt;GAN 학습이 어려운 이유 I: Convergence&lt;/h2&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;지난 글에서 소개하였듯이 원 논문에서 GAN에 대한 이론적 근거를 증명해주었지만 아쉽게도 실제 구현은 이론적 배경이 되는 가정과 거리가 있다. 때문에 GAN 가치 함수를 뉴럴넷을 이용하여 풀었을 때 이상적인 전역해로 수렴한다는 보장이 되지 않는다. 게다가 풀어야하는 문제의 형태부터 이미 쉽게 문제를 풀 수 있는 볼록 함수 형태가 아닌 변수 두 개가 서로 엮여있는 안장점 문제(saddle point problem)를 고려해야하기 때문에 GAN은 학습이 매우 어렵기로 유명하다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이 때문에 많은 사람들이 생각보다 간단한 예제에서도 문제를 풀기가 어려울 수 있는데 더 복잡한 문제에서 GAN 형태가 잘 풀릴 것인지에 대해 의문을 제기한 바 있다. 이 문제를 약간 더 직접적으로 느끼기 위해서 실제로 간단한 예제인 $V(x,y) = xy$가 어떻게 생겼는지 그려보면 다음과 같다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-X8BmCjW2U5o/We_3dGyk5xI/AAAAAAAACNM/xUZPrrahemM438nyIbnsUaoThsJj5LFmQCK4BGAYYCw/s1600/kakao_report2-1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-X8BmCjW2U5o/We_3dGyk5xI/AAAAAAAACNM/xUZPrrahemM438nyIbnsUaoThsJj5LFmQCK4BGAYYCw/s1600/kakao_report2-1.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;f(x,y) = xy&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이 문제는 $x=0, y=0$에서 안장점을 갖는 매우 대표적인 예시다. 그리고 $x$와 $y$에 대해 최소최대 문제를 풀면 이 안장점이 평형점이라는 것도 쉽게 알 수 있다. 사실 안장점이 모두 평형점이 되는 것은 아니지만 이 경우 하나의 변수에 대한 작은 변화가 다른 변수에 대해 가치 값을 줄일 수 없기 때문에 평형점이 되는 것이다. 만약 이 문제를 구배 감소법(gradient descent)으로 풀면 결과가 평형점 주변에서 수렴하지 못하고 최초 시작점에 따라서 반지름이 정해지는 궤도(orbit)를 영원히 움직이는 것을 확인할 수 있다. 심지어 학습율(learning rate)이 크면, 바깥 방향으로 발산하는 경우도 생길 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이를 수식과 함께 확인해보면 좀 더 명확해진다. 학습율 $\gamma$를 고정하고 $n\in\mathbb{N}$일 때, 각 변수에 대해 구배 감소를 번갈아 계산하는 것은&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$\begin{align*} &amp;amp;x_{n+1} = x_n-\gamma y_n \\&amp;amp;y_{n+1}= y_n+\gamma x_n\end{align*}$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;와 같이 나타낼 수 있다. 이 때,&lt;br /&gt;$$\left[ {\begin{array}{c}&lt;br /&gt;x_{n+1} \\&lt;br /&gt;y_{n+1} \\&lt;br /&gt;\end{array} }\right] = \left[ {\begin{array}{cc}&lt;br /&gt;&lt;br /&gt;1 &amp;amp; -\gamma \\&lt;br /&gt;&lt;br /&gt;\gamma &amp;amp; 1 \\&lt;br /&gt;&lt;br /&gt;\end{array} }\right] \left[{\begin{array}{c}&lt;br /&gt;&lt;br /&gt;x_n \\&lt;br /&gt;&lt;br /&gt;y_n \\&lt;br /&gt;&lt;br /&gt;\end{array} }\right]$$&lt;br /&gt;이므로 여기서 $$\left[{\begin{array}{cc}&lt;br /&gt;1 &amp;amp; -\gamma \\&lt;br /&gt;\gamma &amp;amp; 1 \\&lt;br /&gt;\end{array} }\right] = \frac{1}{\alpha}\left[ {\begin{array}{cc}&lt;br /&gt;\alpha &amp;amp; -\alpha\gamma \\&lt;br /&gt;\alpha\gamma &amp;amp; \alpha \\&lt;br /&gt;\end{array} }\right] = \frac{1}{\alpha}\left[{\begin{array}{cc}&lt;br /&gt;\cos\theta &amp;amp; -\sin\theta \\&lt;br /&gt;\sin\theta &amp;amp; \cos\theta \\&lt;br /&gt;\end{array} }\right] $$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;로 바꾸고 $\alpha = \sqrt{\frac{1}{1+\gamma^2}}\in(0,1), \theta = \cos^{-1}\alpha\in\left(0,\frac{\pi}{2}\right)$이라 해보겠다. 고등학교에서 회전 행렬에 대해 배운 사람이라면 위의 행렬식이 매우 익숙할 것이다.&amp;nbsp; $\gamma\approx0$일 때, 즉 학습율이 충분히 작아서 $\alpha\approx 1$이면 구배 감소의 결과가 언제나 안정한 궤도(stable orbit)으로 빠지고, $\alpha&amp;lt;1$인 경우 $(x_n,y_n)$이 나선형으로 발산하게 된다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;GAN 학습이 어려운 이유 II: Mode Collapse&lt;/h2&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;앞서 소개한 문제도 그렇지만 GAN 학습이 어려운 이유는 대부분 그 가치 함수의 형태에서 기인한다. 두 번째로 소개할 mode collapse 문제 역시도 GAN의 독특한 가치 함수와 그 문제 풀이 방식 때문에 생기는 것으로 해석할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-gdCvaHIuLks/WfAninwZwBI/AAAAAAAACNg/k2rz7qeibu8rBKsYQaP0C-TWWmQMlI7OgCK4BGAYYCw/s1600/unrolled-GAN-mode-collapse-1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-gdCvaHIuLks/WfAninwZwBI/AAAAAAAACNg/k2rz7qeibu8rBKsYQaP0C-TWWmQMlI7OgCK4BGAYYCw/s1600/unrolled-GAN-mode-collapse-1.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Mode Collpase 예시 [ref]&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;위 그림이 전형적인 mode collapse 문제의 예시다. 맨 오른쪽의 목표 분포를 보시면 가우시안 혼합 모델로 총 여덟 개의 최빈값(mode)이 있는 것을 볼 수 있다. 아래 줄의 그림이 이 목표 분포를 근사하기 위해 GAN으로 여러번 반복하여 학습을 한 결과들을 보여준다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;GAN이 뽑은 샘플들을 보면 각각의 최빈값들을 각 단계마다 돌아가며 방문하는 것을 볼 수 있다. 즉, 원래라면 윗 줄과 같이 전체 최빈값들을 보고 목표 분포가 여덟 개의 최빈값을 갖는 분포라는 것을 찾아내야하지만, GAN은 그렇게 하지 못하는 모습을 보여준다. 좀 더 직접적인 예를 들자면 숫자가 1부터 8까지 섞여 있는 이미지들로 데이터 분포가 있을 때, 우리는 GAN이 1부터 8까지 모든 숫자들을 만들어낼 수 있기를 바라는데 실제로는 1과 같이 가장 쉬운 한 가지 숫자만 만드는 모델을 학습한다는 것이다. 이런 현상을 하나의 최빈값에만 함몰되는 모델이나 함수를 학습한다고 하여 mode collapse 문제라고 부른다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;사실 우리가 매 단계마다 최적의 구별자 $D^*$를 계산할 수 있다면야 이런 문제가 생기지 않겠지만 뉴럴넷으로 모델을 만들 경우 수렴이 될 때까지 계산을 매우 여러 번 해야하고 여러 가정이 깨지면서 수렴이 보장되지도 않는다. 따라서 현실적으로는 가치 함수를 각각의 변수에 대해 일정 횟수만큼 번갈아 푸는 방식을 택하는데 이런 방식 때문에 문제가 생기게 된다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;원래 풀고자하는 GAN의 가치 문제는 다음과 같은 최소최대 문제이다:&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$G^* = \min_G \max_D V(G,D).$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;그렇지만 실제 학습을 할 때는 $G$와 $D$에 대해 번갈아가며 풀어주기 때문에 뉴럴넷의 입장에서는 이러한 최소최대 문제와 아래 같은 최대최소 문제가 구별되지 않는다:&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$G^* = \max_D \min_G V(G,D).$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;문제는 최대최소 문제에서 생긴다. 수식의 안 쪽부터 살펴보면 $G$에 대한 최소 문제가 먼저 있기 때문에 생성자의 입장에서는 현재 고정되어있는 (비최적, non-optimal) 구별자가 가장 헷갈려 할 수 있는 샘플 하나만 학습하면 된다. 즉, 가치 함수를 가장 최소화할 수 있는 최빈값 하나만 내보내면 된다. 이렇듯 GAN의 가치 함수 자체와 엮여 있는 문제이기 때문에 mode collapse 문제는 아직도 GAN에서 완전히 해결되지 않고 있다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;h2&gt;GAN 학습이 어려운 이유 III: Evaluation&lt;/h2&gt;&lt;br /&gt;이에 더해 모든 생성 모델이 갖는 고질적인 문제가 파로 평가의 객관성이다. 생성을 한 이미지의 질을 평가할 수 있는 객관적인 기준을 정하는 것이 매우 어렵기 때문에 새로운 모델이 예전의 모델에 비해 발전한 것인지 평가하는 것이 쉽지 않고 연구의 방향을 잡기도 어렵다.&lt;br /&gt;&lt;br /&gt;현재 사용되는 방식을 몇 가지 살펴보자면 대표적인 것이 아마존 매카니컬 터크(Amazon Mechanical Turk)를 사용하여 사람이 직접 평가하도록 하는 방식이다. 그러나 이런 방법은 매우 주관적이고, 일관된 평가가 어려우며, 위에서 설명한 mode collapse가 일어난 경우 전혀 모델의 문제점을 파악할 수 없다는 단점이 있다. Mode collapse가 일어난 모델의 경우 생성하는 이미지의 다양성이 부족할 뿐이지 단일 이미지의 자체는 상당히 질이 좋을 수 있기 때문이다.&lt;br /&gt;&lt;br /&gt;두번째로는 Inception score라고 하여 구글의 인셉션 이미지 분류 모델에 생성된 이미지를 넣어 나오는 값을 바탕으로 평가를 하는 방식이 있다. 이 방법은 값이 일관되고 어느 정도 객관성을 보장할 수 있다는 장점이 있어 꽤 자주 사용되고 있다. 하지만 굳이 인셉션 모델을 사용해야하는 이유도 없고 어떤 모델의 경우 인셉션 모델에 특화(overfitting)되어 실제 이미지의 질과는 무관하게 점수가 좋게 나올 수도 있다는 문제를 안고 있다.&lt;br /&gt;&lt;br /&gt;이렇게 앞서 소개한 문제들 외에도 다양한 연구거리가 남아있겠지만 세 가지로 크게 정리해보았다. GAN 연구가 활발하고 매일 하루가 멀다하고 쏟아지는만큼 더이상 연구할 것이 없고 너무 늦었다고 생각할 수 있으나 알고보면 아직 가야할 길이 멀다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;창GAN기-믿거나 말거나&lt;/h2&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;마지막으로 GAN에 대한 탄생비화 [ref]를 소개해드리면서 글을 마무리하겠다. Ian Goodfellow가 최초로 만든 GAN은 multi-layer perceptron (MLP)을 이용한 매우 단순한 형태의 GAN이었다고 한다. 거짓말 같지만 단 한 번의 시도만에 바로 성공했다는데... 물론 매우 간단한 문제에 대해 적용해봤을 것으로 추측되지만 GAN이 수렴시키기 어렵기로 악명 높다는 것을 생각해보면 솔직히 믿기지 않는 일화이다 (마치 박혁거세 설화를 보는 느낌이랄까...).&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;Ian Goodfellow가 GAN에 대한 아이디어를 처음 떠올린 순간은 몬트리올의 ``The 3 Brewers&#39;&#39;라는 펍에서 친구들과 얘기를 하던 중이었다고 한다. 박사를 마치고 연구실을 떠나는 친구를 송별하는 자리였는데, 그렇게 모인 친구들 중 한 명이 모든 사진의 통계적 정보를 넣어서 스스로 사진을 만들어 낼 수 있는 기계에 대해 얘기를 꺼냈고, 어떻게 하면 그런 기계를 현실적으로 만들 수 있을 지에 대해 논쟁이 벌어졌다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;존재하는 모든 사진에 대한 통계적인 정보를 얻는 것부터 일단 말이 되지 않으니 불가능한 프로젝트라고 생각하다가 순간 뉴럴넷을 사용해서 기계를 가르치면 더 진짜 같은 사진을 만들 수 있지 않을까 하는 생각이 들었다고 한다. 하지만 친구들은 그 아이디어에 대해 부정적이였고, 살짝 열이 받은 Ian은 새벽에 술자리에서 돌아오자마자 앉은 자리에서 노트북으로 GAN을 코딩했다고 한다. 그리고 거짓말 같이 단 번에 성공했다는데, 이후 인터뷰에서도 ``매우 매우 운이 좋았다. 만약 GAN이 한 번에 성공하지 않았다면, 그냥 포기했을 것이다&#39;&#39; 라며 스스로도 운이 좋았다고 하였다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이 인터뷰 내용이 사실이라면 여기서 우리는 여러가지 교훈을 얻을 수 있다 (옛날 이야기에는 언제나 교훈이 있는 법). 문제를 설정하고 풀 때 직관력이 매우 중요하다는 것과 그 직관으로 얻은 아이디어를 바로 실험해보는 실행력이 중요하다는 것, 술자리에서 연구 얘기만 주구장창 하여도 진지하고 재미있게 들어줄 사람들이 있는 집단에 들어가야 한다는 것 그리고 마지막으로 되는 놈은 뭘 해도 된다고 운도 조금은 좋아야 한다는 것이다. 희망적인 것은 어떤 문제에 대한 직관력은 그 분야와 연관된 깊은 수학적 지식에서 나올 수도 있지만 수많은 시행착오(a.k.a. 삽질)을 바탕으로 한 경험으로 길러질 수도 있다는 점이다. 그리고 매우 다양하게 많은 시도를 하다보면 통계적으로 되는 방법을 찾을 확률이 높으니 운이라는 것도 어느 정도&amp;nbsp;통계에 기대볼 수 있을 것 같다. 이렇게 열정적으로 문제를 풀다보면 비슷한 사람들이 모여있는 집단(카카오..?)에 갈 수 있는 기회가 생기고, 더 재미있게 잘 연구를 할 수 있는 선순환이 이루어지지 않을까?&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;엄밀한 수학 지식을 바탕으로 차근차근 쌓아 올렸을 것 같은 매우 복잡한 이론들도 순간적인 직관에서 시작하는 경우가 매우 많은 것 같다. 그러니 수학이 어려운 공학자들이여 우리 모두 힘을 내자! 수학을 잘하는 수학자들과 실험을 바탕으로 감이 살아있는 공학자들이 각자가 잘하는 영역에서 연구를 하며 협업을 통해 문제를 발전시켜 나간다면 언젠가는 정말로 이미지뿐만 아니라 사람의 생각을 모사하는 궁극의 생성 모델을 만들 수 있지 않을까 기대해본다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;다음 읽을 거리&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;디지털 신호 처리가 궁금하다면: &lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Signal Processing For Communications&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에 속하는 전반적인 연구 내용들이 궁금하다면: &lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/machine%20learning&quot; target=&quot;_blank&quot;&gt;Machine learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GAN에 관심이 많다면: &lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/GAN&quot; target=&quot;_blank&quot;&gt;GAN&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에서 잘 사용되는 수학에 관심이 있다면: &lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/mathematics&quot; target=&quot;_blank&quot;&gt;Mathematics&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/8605236143566792770/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/partii.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/8605236143566792770'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/8605236143566792770'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/partii.html' title='카카오 리포트 (Part II)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-kpejybfFbMw/WfAyUMTYbKI/AAAAAAAACNw/bCRgP4mgA5QzVqoStESNmgwoUCE8Nj_XwCK4BGAYYCw/s72-c/dcgan-vector-arithmatic.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-3903038159189647518</id><published>2019-05-13T14:35:00.000+09:00</published><updated>2019-05-13T14:50:34.013+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><title type='text'>카카오 리포트 (Part I)</title><content type='html'>이전에 카카오 리포트에 기고한 글을 개인 블로그에도 올린다. 두 파트로 나뉘어 글을 기고하였는데, 둘이 합쳐 GAN에 대한 전체적인 조망이 되기 때문에, 개별 GAN 논문을 리뷰하는 것에 비해 개괄적인 정보를 알 수 있을 것이다.&lt;br /&gt;&lt;br /&gt;파트 I은 GAN에 대한 소개로 이전 &lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 시리즈&lt;/a&gt;에서 대부분 다룬 내용이지만 첫 글 이후로 GAN에 대해 이해가 더 깊어진 후 정리한 글이기에 내용적 측면에서 낫다는 장점도 있겠다. 파트 II는 GAN 연구에 대해 좀 더 개괄적으로 다루고 있으므로 연구 방향이나 흐름을 빠르게 알고 싶은 사람들에게 도움이 되리라 생각한다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;** 이 글을 기고할 당시만 해도 대학원생으로 박사 졸업을 언제 할 수 있을지 불분명 하였을뿐 아니라, GAN이 참 재미있으면서도 내 연구 주제에 머신러닝을 적용하는 것이 가능할지도 잘 모르던 때였는데, 지금은 네이버에서 본격적으로 generative model들을 연구하고 있으니 시간이 참 빠르다. 열심히 살아야지.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;div style=&quot;text-align: right;&quot;&gt;2019.05.13&lt;/div&gt;&lt;div style=&quot;text-align: right;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: right;&quot;&gt;&lt;/div&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;오늘 소개드릴 주제는 Generatvie Adversarial Network (GAN)입니다. GAN은 이름 그대로 뉴럴넷을 이용한 생성 모델입니다. 흔하게는 이미지를 생성하는 것에부터 음성, 문자에 이르기까지 다양한 분야에 적용되고 있습니다. 2014년에 Ian Goodfellow가 GAN [1]을 처음 선보였을 때부터 이미 대박의 낌새가 보였지만, NIPS 2016 이후부터는 GAN에 대한 관심이 더욱 폭발적으로 늘어나고 있습니다. 원래도 핫한 기계학습 분야에서도 GAN에 대한 연구는 유독 빠르게 발전하고 있는데요 일주일이 멀다하고 새로운 아이디어를 사용한 논문이 나오는 한 편, 재미있는 뱡향의 어플리케이션들이 속속들이 나오면서 기세를 더해가고 있습니다. 페이스북의 Yann Lecun 교수님도 최근 10-20년 간에 기계학습 나온 아이디어 중 최고라고 찬사할만큼 그 열기가 쉽게 식지는 않을 것 같습니다.&lt;br /&gt;&lt;br /&gt;이 글에서는 이렇게 사람들이 열광하는 GAN이 무엇인지, 어떤 원리로 그림을 생성하는지에 대해 먼저 소개하겠습니다. 그리고 글을 읽으신 분들이 GAN의 개념과 그 밑에 깔려 있는 기본적인 수학적 배경을 이해하고, 이후 새로운 GAN 연구를 봤을 때 흐름을 따라갈 수 있는 기초적인 배경을 제공하는 것을 목표로 합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Generative Adversarial Networks&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;GAN 이전에도 생성 모델(Generative Model)은 매우 다양하게 있었는데 왜 하필 GAN만 유독 이렇게 난리일까요?&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;span style=&quot;font-size: large;&quot;&gt;&quot;잘 되니까.&quot;&lt;/span&gt;&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;아래 [그림 1]은 구글에서 올해 3월에 발표한 BEGAN 모델로 생성한 이미지들입니다.&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-wyCBGMKhdpI/Wcewg8VVmjI/AAAAAAAACH8/Q4D0BODwlEMag1d3rFTcZSjfpR8GzMOOgCK4BGAYYCw/s1600/began_1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-wyCBGMKhdpI/Wcewg8VVmjI/AAAAAAAACH8/Q4D0BODwlEMag1d3rFTcZSjfpR8GzMOOgCK4BGAYYCw/s1600/began_1.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;[그림 1] BEGAN 결과 [2]&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;즉, 이 사진들은 모두 실존하는 인물의 것이 아니란 것이죠. 상당히 그럴듯 하지 않나요? 꽤나 자세히 뜯어봐도 실제 사람의 사진인 것으로 보일 정도입니다. 워낙 잘 되다보니 우리나라로 치면 디시인사이드와 같은 Reddit의 Machine Learning 게시판에서는 한 때 다음과 같은 게시물이 눈길을 끌기도 했습니다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-7NdWbeJajC0/Wceyzm-qWoI/AAAAAAAACIc/q0887NH3ynY2pA5ELmRt5AuFL06SGbKlgCK4BGAYYCw/s1600/kakao_report1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-7NdWbeJajC0/Wceyzm-qWoI/AAAAAAAACIc/q0887NH3ynY2pA5ELmRt5AuFL06SGbKlgCK4BGAYYCw/s1600/kakao_report1.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;[그림 2] Reddit 게시글 [3]&lt;/b&gt;&lt;/div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;b&gt;&quot;BEGAN으로 학습시키던 중 16만8천 번째쯤 귀여운 그녀를 보았습니다. 그리고...다시는 보지 못했어요 :(&quot;&amp;nbsp;&lt;/b&gt;(여러분의 이상형이 데이터 분포 저기 어디엔가 분명히 존재합니다! 그러니 모든 솔로들은 GAN 연구를! 글쓴이에게는 심심한 위로를... weight 저장을 꼭 생활화 합시다!)&lt;br /&gt;&lt;br /&gt;사실 GAN이란 모델을 이렇게 잘 학습시키는 것은 매우 쉬운 일이 아닙니다만, 그 이유에 대해서는 나중에 차차 설명하도록 하고 GAN의 원리에 대해 먼저 소개해드리도록 하겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;GAN에 대한 개념적 소개&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;GAN은 이름만 뜯어봐도 큰 줄기를 알 수 있습니다:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&quot;Generative&quot;&lt;/b&gt; 모델입니다. CNN을 이용한 이미지 분류기(Classifier)와 같이 이미지의 종류를 구분하는 것이 아닌 이미지를 만들어내는 방법을 배우는 모델이라는 것을 알 수 있습니다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;&lt;b&gt;&quot;Adversarial&quot;&lt;/b&gt;이란 단어의 사전적 의미는 &quot;대립하는, 적대하는&quot; 입니다. 대립하려면 상대가 있어야하니 GAN은 크게 두 부분으로 나뉘어 있다는 것을 직관적으로 알 수 있죠.&lt;/li&gt;&lt;li&gt;&lt;b&gt;&quot;Network&quot;&lt;/b&gt;, 즉 뉴럴넷을 사용해서 모델이 구성되어있습니다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;정리하자면, GAN은 이미지를 만들어내는 네트워크(&lt;b&gt;Generator&lt;/b&gt;)와 이렇게 만들어진 이미지를 평가하는 네트워크(&lt;b&gt;Discriminator&lt;/b&gt;)가 있어서 서로 대립(&lt;b&gt;Adversarial&lt;/b&gt;)하며 서로의 성능을 점차 개선할 수 있는 구조로 만들어져있습니다.&lt;br /&gt;&lt;br /&gt;&lt;div&gt;좀 더 직관적으로 이해하고 싶다면, Generator를 지폐위조범, Discriminator를 경찰로 생각해보시면 됩니다.&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;지폐위조범(Generator)은 위조 지폐를 최대한 진짜와 같이 만들어 경찰을 속이기 위해 노력하고, 경찰(Discriminator)은 이렇게 위조된 지폐를 진짜와 감별하려고(Classify) 노력한다. 이런 과정을 반복하면서 두 그룹이 각각 서로를 속이고 구별하는 능력이 발전하게 되고, 궁극적으로는 지폐위조범의 솜씨가 매우 좋아져서 경찰이 더이상 진짜 지폐와 위조 지폐를 구별할 수 없을 정도(구별할 확률 $p=0.5$)가 된다는 것.&lt;/div&gt;&lt;br /&gt;이런 예시를 좀 더 수학적 용어를 섞어 표현하면 다음과 같습니다. Generative 모델 $G$는 우리가 갖고 있는 실제 이미지 $x$의 분포(data&amp;nbsp;distribution)를 알아내려고 노력합니다. 만약 $G$가 정확히 데이터 분포를 모사할 수 있다면 이 분포로부터 뽑은 (혹은 생성한) 샘플 이미지는 진짜 이미지와 전혀 구별할 수 없겠죠. 즉, $G$는 $z\sim p_z$일 때 가짜 이미지 샘플 $G(z)$의 분포 $p_g$를 정의하는 모델로 생각하실 수 있습니다. 여기서 $z$는 $G$라는 샘플링 모델에 들어갈 input 값이라고 생각하시면 됩니다.&amp;nbsp;보통 $z$의 분포 $p_z$는 Gaussian 분포를 사용하는데 이 부분은 차차 설명드리겠습니다.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;한편, discriminator 모델 $D$는 현재 자기가 보고 있는 샘플이 진짜 이미지 $x$인 지 혹은 $G$로부터 만들어진 가짜 이미지 $G(z)$인 지 구별하여 샘플이 진짜일 확률을 계산합니다. 앞서 예를 든 것처럼 $p_g=p_{data}$가 된다면 각각의 분포로부터 뽑힌 샘플만을 가지고 어느 쪽에서 왔는지 구별할 방법이 없기 때문에 $D$가 할 수 있는 최선은 동전 던지기입니다. 즉, 임의의 샘플 $x$에 대해 $D(x)=\frac{1}{2}$이 되는 것이죠.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-BgYz6OQc4WU/WchaisOCgOI/AAAAAAAACI0/ONloRtdmVisug_HbkotMbP9tr2hkyfg-ACK4BGAYYCw/s1600/kakao_report2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-BgYz6OQc4WU/WchaisOCgOI/AAAAAAAACI0/ONloRtdmVisug_HbkotMbP9tr2hkyfg-ACK4BGAYYCw/s1600/kakao_report2.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;[그림3] 지폐위조범 VS 경찰&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;h2&gt;최소최대 문제 (minimax problem)&lt;/h2&gt;&lt;br /&gt;우리의 목적은 Generator는 점점 더 실제 이미지와 닮은 샘플을 생성하게 하고 Discriminator는 샘플을 점점 더 잘 구별하는 모델을 만드는 것입니다. 따라서 [그림 3]을 보면 알 수 있듯이 $D$의 입장에서는 data로부터 뽑은 샘플 $x$는 $D(x)=1$이 되고, $G$에 임의의 input $z$ 넣고 만들어진 샘플에 대해서는 $D(G(z))=0$가 되도록 노력합니다. 즉, $D$는 실수할 확률을 낮추기(&lt;b&gt;mini&lt;/b&gt;) 위해 노력하고 반대로 $G$는 $D$가 실수할 확률을 높이기(&lt;b&gt;max&lt;/b&gt;) 위해 노력하는데, 따라서 둘을 같이 놓고보면 &lt;b&gt;&quot;minimax two-player game or minimax problem&quot;&lt;/b&gt;이라 할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;이를 수식으로 정리하면 우리가 하고자 하는 것은 다음과 같은 가치 함수(value function) $V(G,D)$에 대한 minimax problem을 푸는 것과 같아집니다:&lt;br /&gt;$$\min_G \max_D V(D,G) = \mathbb{E}_{x\sim p_{data}~(x)}[log D(x)] + \mathbb{E}_{z\sim p_z(z)}[log(1-D(G(z)))]$$&lt;br /&gt;뭐든지 간에 이런 수식이 있으면 극단적인 예시를 넣어 이해하는 것이 빠릅니다. 먼저 $G$ 입장에서 가장 이상적인 상황을 생각해보겠습니다. $G$가 진짜 이미지와 완벽히 닮은 샘플을 만들어서 $D$가 $G(z)$가 만들어낸 이미지가 진짜일 확률이 1이라고 잘못 결론을 내린다면, $D(G(z))=1$이므로 두 번째 항의 값이 $-\infty$가 되는 것을 보실 수 있습니다. 이 때가 $G$의 입장에서 $V$의 &quot;최소값&quot;이라는 것은 자명합니다.&lt;br /&gt;&lt;br /&gt;반면에 $D$가 진짜 이미지와 가짜 이미지를 완벽하게 잘 구별을 하는 경우, 현재 보고있는 샘플 $x$가 실제로 data distribution으로부터 온 녀석일 경우 $D(x) =1$, 샘플이 $G(z)$가 만들어낸 녀석이라면 $D(G(z))=0$가 되므로 위에 식 첫 번째 항과 두 번째 항이 모두 0으로 사라지죠. 이 때 $D$의 입장에서 $V$의 &quot;최대값&quot;을 얻을 수 있다는 것 역시 자명합니다.&lt;br /&gt;&lt;br /&gt;이제 드디어 우리가 풀 문제를 수식으로 명확히 정의하였습니다. 그런데 보시다시피 이 문제는 변수 $G$와 $D$ 두 개가 서로 엮여 있습니다. 이런 관계 덕분에 서로에게 피드백을 줘서 성능이 각각 좋아지기도 하지만 한편으로는 한 쪽 모델에 대해 문제를 풀면 다른 한 쪽은 손해를 보기 때문에 둘 모두를 만족시키는 평형점을 찾기가 쉽지 않습니다.&lt;br /&gt;&lt;br /&gt;따라서 실제로 문제를 풀기 위해서는 한 쪽을 상수로 고정하고 다른 변수에 대해 문제를 푸는 방식의 접근을 할 수밖에 없습니다. 예를 들자면, 먼저 현재 생성 모델을 $G&#39;$으로 고정하고, $D$에 대해 $\max_D V(D,G&#39;)$ 문제를 먼저 풀어서 $D&#39;$을 구합니다. 이렇게 얻은 $D&#39;$를 넣고 $G$에 대해 $\min_G V(D&#39;,G)$ 문제를 번갈아 푸는 전략을 쉽게 생각해볼 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;이론적 근거 (Theoretical Results)&lt;/h2&gt;&lt;br /&gt;이제 방법도 알았고 문제를 열심히 잘 풀기만 하면 될 것 같지만! 그러기 전에 아직 해결해야할 것들이 몇 가지 남아있습니다. 먼저 우리가 정의한 이 문제가 실제로 정답이 있는지(existence), 만약 해가 존재한다면 유일한지(uniqueness) 확인할 필요가 있습니다. 그리고 제안한 방법이 실제로 원하는 해를 찾을 수 있는지(convergence) 확인해야합니다. 애초에 답이 없는 문제를 풀거나, 답이 있더라도 여러 개이거나, 풀 방법을 제안했는데 그 방법이 해로 수렴한다는 보장이 없으면 여러 모로 곤란하겠죠.&lt;br /&gt;&lt;br /&gt;따라서 이제부터는 이 부분들을 하나씩 체크해보겠습니다. 이 장에서 중요한 내용은 크게 두 가지로 나눌 수 있을 것 같습니다.&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;li&gt;앞서 소개한 minimax problem이 $p_g = p_{data}$에서 global optimum으로 unique solution을 갖는다는 것을 보인다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;알고리즘이 global optimum로 수렴한다.&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;일단, 첫 번째 주제인 global optimality에 관한 얘기를 하기 위해서는 먼저 가져가야 할 도구가 하나 있습니다.&lt;br /&gt;&lt;div class=&quot;proposition&quot;&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;임의의 $G$에 대하여, 최적의 discriminator $D$는 다음과 같다: $$D^*_G(x) = \frac{p_{data}~(x)}{p_{data}~(x)+p_{g}(x)}.$$&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;proof&quot;&gt;위 수식을 증명하는 것은 크게 어렵지 않습니다. 먼저 $V(G,D)$를 다음과 같이 풀어쓸 수 있습니다: $$\begin{align*}V(G,D) &amp;amp;=\mathbb{E}_{x\sim p_{data}~(x)}[log D(x)] + \mathbb{E}_{z\sim p_z(z)}[log(1-D(G(z)))] \\&amp;amp;= \int_x p_{data}~(x)log(D(x))dx + \int_z p_z(z)log(1-D(G(z)))dz \\ &amp;amp;= \int_x p_{data}~(x)log(D(x)) + p_g(x)log(1-D(x))dx \end{align*}$$&lt;br /&gt;마지막 식의 형태를 참고하면, $D^*$을 구하는 문제는 임의의 $(a,b) \in \mathbb{R}^2 \setminus \{0,0\}$에 대하여, $y \rightarrow {\rm a} log(y) + {\rm b} log(1-y)$라는 함수에서 최대값을 구하는 문제로 단순화할 수 있습니다. 이 함수는 $y^*=\frac{a}{a+b}$에서 최대값을 갖기 때문에 이 것으로 증명이 완료됩니다.&lt;/div&gt;&lt;br /&gt;결국, 위 결과를 바탕으로 minimax problem을 다시 써보면 이제 변수가 $G$ 하나인 $C(G)$라는 문제로 나타낼 수 있습니다:&lt;br /&gt;$$\begin{align*} C(G) &amp;amp; = \max_D V(G,D) \\&lt;br /&gt;&amp;amp;= \mathbb{E}_{x \sim p_{data}} \left[ log D^*_G(x) \right] + \mathbb{E}_{z\sim p_z}\left[ log(1-D^*_G(G(z))) \right] \\&lt;br /&gt;&amp;amp;= \mathbb{E}_{x \sim p_{data}} \left[ log D^*_G(x) \right] + \mathbb{E}_{x\sim p_g}\left[ log(1-D^*_G(x)) \right] \\&lt;br /&gt;&amp;amp;= \mathbb{E}_{x \sim p_{data}} \left[ log \frac{p_{data}~(x)}{p_{data}~(x)+p_{g}(x)} \right] + \mathbb{E}_{x\sim p_g} \left[ log \frac{p_{g}(x)}{p_{data}~(x)+p_{g}(x)} \right] \end{align*}$$&lt;br /&gt;&lt;h2&gt;전역해(Global optimum) 증명&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;이제 이 도구를 사용해서 main theorem을 증명해봅시다!&lt;br /&gt;&lt;div class=&quot;theorem&quot;&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;$C(G)$의 global minimum은 오직 $p_g=p_{data}$으로 유일하게 존재하며, &amp;nbsp;이 때 $C(G)$의 값은 $-log(4)$이다.&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;proof&quot;&gt;증명은 양방향으로 진행됩니다. 먼저 가장 이상적으로 $p_g = p_{data}$일 때 $C(G)$가 어떤 값을 갖는지 확인해보겠습니다. 앞서 구한 식에 의해 $D^*_G(x)=\frac{1}{2}$이고, 이를 대입하면 다음과 같이 나타낼 수 있습니다: $$C(G) = \mathbb{E}_{x \sim p_{data}} \left[ -log(2)\right] +&amp;nbsp;\mathbb{E}_{x \sim p_{g}} \left[ -log(2)\right]=-log(4).$$&lt;br /&gt;한편, $C(G)$ 수식을 바꿔 표현해서 $-log(4)$가 $C(G)$가 갖을 수 있는 유일한 최적값임을 알기 위해서는 다음과 같이 $C(G)$를 표현하는 것이 증명의 키 입니다:&lt;br /&gt;&lt;span style=&quot;text-align: justify;&quot;&gt;&amp;nbsp;$$\begin{align*}C(G) &amp;amp;= C(G) +&amp;nbsp;log(4) -log(4) \\ &amp;amp;= -log(4) + KL \left( p_{data} || \frac{p_{data}~+ p_g}{2}\right) + KL \left( p_g|| \frac{p_{data}~+ p_g}{2}\right) \\ &amp;amp;= -log(4) + 2\cdot JSD(p_{data}||p_g) \end{align*}$$&amp;nbsp;&lt;/span&gt;&lt;br /&gt;첫 번째 등호에서 두 번째 등호로 넘어가는 것은 Kullbeck-Leibler divergence에 대한 정의를 알아야합니다. Kullbeck-Leibler divergence는 $P$라는 확률 분포와 $Q$라는 확률 분포가 있을 때 두 분포가 얼마나 다른 지를 측정하는 값입니다: $$D_{KL}(P||Q) = \sum_i P(i) log\frac{P(i)}{Q(i)}.$$&lt;br /&gt;$P$와 $Q$의 분포가 일치하면 $log$ 안의 값이 1이되어 divergence가 0이 되는 것을 알 수 있습니다. 따라서 첫 번째 수식의 $C(G)+log(4)$를 풀어서,&lt;br /&gt;$$\mathbb{E}_{x \sim p_{data}} \left[ log \frac{p_{data}~(x)}{p_{data}~(x)+p_{g}(x)} \right] + \mathbb{E}_{z\sim p_x(z)} \left[ log \frac{p_{g}(x)}{p_{data}~(x)+p_{g}(x)} \right] + log(2) + log(2)$$&lt;br /&gt;이와 같이 나타낸 후 각 expectation 안으로 $log(2)$를 넣어주면 두 번째 등호의 수식의 형태로 나오게 됩니다. 두 번째에서 세 번째 등호도 $JSD$의 정의를 알면 자연스럽게 따라옵니다:&lt;br /&gt;$${\rm JSD}(P \parallel Q)= \frac{1}{2}D_{KL}(P \parallel M)+\frac{1}{2}D_{KL}(Q \parallel M).$$&lt;br /&gt;여기서 $M=\frac{1}{2}(P+Q)$이므로 그대로 원 수식에 비교 대조해보면, 쉽게 유도할 수 있습니다. 결국 $JSD$는 분포 간의 차이를 나타내는 값으로 항상 양수이며, 비교하는 두 분포가 일치할 때만 값이 $0$이기 때문에 $C^*=-log(4)$가 $C(G)$의 global minimum이며 그 유일한 해가 $p_g = p_{data}$임을 알 수 있습니다.&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;따라서 앞서 정의한&amp;nbsp;minimax problem을 잘 풀기만 하면 (즉, global optimal을 찾으면), generator가 만드는 probability distribution $p_g$가 data distribution $p_{data}$와 정확히 일치하도록 할 수 있다는 것을 알았습니다. 결국, generator가 뽑은 샘플을 discriminator가 실제와 구별할 수 없게 된다는 것이죠.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;수렴성(convergence) 증명&lt;/h2&gt;&lt;br /&gt;남은 것은 앞서 제시한 것과 같이 $G$와 $D$에 대해 번갈아가며 문제를 풀었을 때, $p_g = p_{data}$를 얻을 수 있는지 확인하는 것입니다. 여기서 증명을 용이하게 하기 위해 몇 가지 제약이 들어가는데요 먼저 $G$와 $D$라는 모델이 각각 우리가 원하는 데이터의 확률 분포를 표현하거나 구별할 수 있는 모델을 학습할 수 있을만큼 용량(capacity)이 충분하고, discriminator $D$가 주어진 $G$에 대해 최적값인 $D^*$으로 수렴한다고 가정합니다.&lt;br /&gt;&lt;div class=&quot;proposition&quot;&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;위 가정이 충족되었을 때, $$\mathbb{E}_{x \sim p_{data}} \left[ log D^*_G(x) \right] + \mathbb{E}_{x\sim p_g}\left[ log(1-D^*_G(x)) \right]$$에 대하여 $G$의 최적값을 구하면 $p_g$가 $p_{data}$로 수렴한다.&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;proof&quot;&gt;먼저 $D$가 고정일 때, $V(G,D)=U(p_g,D)$라 표현하겠습니다. 증명의 방향은 먼저 $U(p_g,D)$가 $p_g$에 대해서 볼록(convex) 함수임을 확인하는 것입니다. $U(p_g,D)$의 유일한 해가 $p_g = p_{data}$라는 것은 앞선 정리에서 확인하였기 때문에 이로써 증명이 끝나게 됩니다. 정의에 의해 $$U(p_g,D)=\int_x p_{data}~(x)log(D(x)) + p_g(x)log(1-D(x))dx $$이므로 $p_g$에 대해 미분을 하면 $log(1-D(x))$만 남게 되고 이는 $p_g$에 대해서 상수이기 때문에 $U(p_g,D)$가 선형 함수임을 알 수 있습니다. 그러므로 $\sup_D U(p_g,D)$가 $p_g$에 대해 볼록 함수*로 유일한 전역해(global optimum)를 갖고, 따라서 $p_g$에 대한 적은 업데이트만으로도 $p_g\rightarrow p_{data}$라 얘기할 수 있겠습니다.&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;이제 앞서 제안한 전략이 global optimal으로 해가 수렴한다는 것까지도 증명했습니다. 단! 지금까지 전개한 논리들에는 몇 가지 꼭 알고 넘어가야할 내용들이 있습니다.&lt;br /&gt;&lt;br /&gt;첫째, 잘 보시면 아시겠지만&amp;nbsp;지금까지 논리를 전개하며 $G$와 $D$를 만들 모델에 대해 어떤 제약을 두지 않았습니다. 즉, 여기서 $G$와 $D$는 무한대의 표현 용량을 가진 (임의의 어떤 함수라도 표현할 수 있는) 모델로써 앞서 진행한 증명들은 모두 probability density function 공간에서 전개된 것입니다. 그러나 실제로 모델을 만들 때 위와 같은 non-parametric 모델을 만드는 것은 현실적으로 어려움이 많습니다.&lt;br /&gt;&lt;br /&gt;그런데 뉴럴넷은 충분한 용량만 주어진다면 universal function approximator로써 역할을 잘 해준다는 것이 잘 알려져 있고 미분이 가능한 함수들로 표현되므로 backpropagation이라는 매우 직관적이고 효율적인 방식으로 학습을 할 수 있다는 장점이 있습니다. 또한 probability distribution을 학습하기 위해 Markov Chain Monte Carlo (MCMC)와 같은 무식한 방법을 사용하지 않아도 되기 때문에 여러 모로 빠르기도 하죠. 이런 여러 장점들 때문에 실용적인 측면에서 GAN에서는 뉴럴넷을 사용하여 모델을 완성합니다.&lt;br /&gt;&lt;br /&gt;따라서 각각의 $G$와 $D$를 단순한 뉴럴넷인 multilayer perceptron(MLP)으로 모델을 만들면, $G$는 input $z$에 대해 output으로는 이미지 샘플을 뽑아주는 $G(z;\theta_g)$로 표현할 수 있습니다. 한편, $D$ 역시 $D(x;\theta_d)$로 나타내며 output으로 샘플 $x$가 $p_{data}$로부터 뽑혔을 확률값을 내보냅니다. 여기서 $\theta_g$와 $\theta_d$는 각 MLP의 parameter가 되겠습니다.&lt;br /&gt;&lt;br /&gt;그러나 이렇게 함수 공간을 일반적인 공간에서 뉴럴넷이 표현할 수 있는 공간으로 바꾸게 되면, GAN이 표현할 수 있는 $p_g$가 $G(z;\theta_g)$ 함수로 나타낼 수 있는 종류로 제한이 됩니다. 뿐만 아니라 더이상 $p_g$에 대해 직접 최적화 문제를 푸는 것이 아닌 $\theta_g$에 대해 최적화 문제를 푸는 것으로 모든 구조가 바뀌기 때문에 앞서 증명들에서 사용한 가정들이 모두 깨지게 됩니다. 즉, MLP를 모델로 사용하면 $G$가 parameter space에서 multiple critical points를 가지기 때문에 완전히 증명한 바와 합치하지는 않다는 것이죠. 다만 실제로 학습을 해보면 성능이 잘 나오는 것으로 미루어봤을 때, MLP가 이론적 보장이 좀 부족할지라도 실용적으로 쓰기에는 합리적인 모델이라고 할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;둘째, 수렴성 증명에 들어간 가정들을 보시면 생각보다 매우 강력한 제약임을 알 수 있습니다. 실제로는 계산량이나 학습 시간에 한계가 있기 때문에 $D^*$를 얻기 위해 $D$가 수렴할 때까지 학습시키는 것은 현실적으로 어렵습니다. 게다가 모델의 용량이 $p_{data}$를 학습하기에 충분한지에 대한 문제 역시 쉽게 다루기 어렵죠. 최대한 이론적 상황과 비슷하게 맞춰주기 위하여 $D$에 대한 학습을 $G$에 비해 보다 많이 수행해주는 등 기술적인 노하우를 사용하기는 하지만 근본적인 해결책이라 할 수는 없습니다. 따라서 어떤 면에서는 유명무실한 증명이라 할 수도 있겠습니다.&lt;br /&gt;&lt;br /&gt;셋째, 심지어 구현시 사용하는 가치 함수 (value function)의 형태가 이론과 다릅니다. 실제로는 $\min_G log(1-D(G(z)))$ 대신 $\max_G log(D(G(z)))$로 모델을 바꾸어 학습시킵니다. 학습 초기에는 $G$가 매우 이상한 이미지를 생성하기 때문에 $D$가 너무도 쉽게 이를 진짜와 구별하고 $log(1-D(G(z)))$의 기울기가 아주 작아서 학습이 엄청 느립니다. 문제를 $G = \max_G log(D(G(z)))$로 바꾸면, 위와 같은 문제가 생기지 않기 때문에 쉬운 해결 방법입니다만, 더이상 다루는 형태가 이론적인 수식과 같지 않기 때문에 이 역시도 아쉬운 점이라 할 수 있습니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: start;&quot;&gt;이로써 GAN에 대해 원 논문에서 나온 이론적 증명까지 모두 살펴보았습니다. 다음 호에서는 기존 생성 모델과 GAN의 차이점에 대해 살펴보고 GAN의 특징과 장단점에 대해 좀 더 소개하겠습니다.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: start;&quot;&gt;&lt;h2&gt;다음 읽을 거리&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/partii.html&quot; target=&quot;_blank&quot;&gt;카카오 리포트 (Part II)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GAN에 관심이 많다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/GAN&quot; target=&quot;_blank&quot;&gt;GAN&lt;/a&gt;&lt;/li&gt;&lt;li&gt;디지털 신호 처리가 궁금하다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Signal Processing For Communications&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에 속하는 전반적인 연구 내용들이 궁금하다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/machine%20learning&quot; target=&quot;_blank&quot;&gt;Machine learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에서 잘 사용되는 수학에 관심이 있다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/mathematics&quot; target=&quot;_blank&quot;&gt;Mathematics&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: start;&quot;&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;-webkit-text-stroke-width: 0px; color: black; font-family: &amp;quot;Malgun Gothic&amp;quot;; font-size: medium; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/3903038159189647518/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/part-i.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/3903038159189647518'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/3903038159189647518'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/part-i.html' title='카카오 리포트 (Part I)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-wyCBGMKhdpI/Wcewg8VVmjI/AAAAAAAACH8/Q4D0BODwlEMag1d3rFTcZSjfpR8GzMOOgCK4BGAYYCw/s72-c/began_1.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-2351542051333992824</id><published>2019-05-12T23:44:00.000+09:00</published><updated>2019-05-14T16:32:03.072+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="super-resolution"/><title type='text'>Image Restoration (IR): inverse problem point of view (1)</title><content type='html'>제 박사 학위 논문 제목은 &quot;Learning-based approaches for Inverse Scattering Problems&quot;입니다. 이 제목은 제 지도 교수님께서 지어주셨는데, 박사 학위 디펜스를 하면서 committee 교수님들께 학위 논문이 아니라 textbook에나 어울리는 제목이라고 좀 더 범위를 좁혀 수정을 하라는 지적을 다수 받았던 기억이 납니다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;** 그럼에도 불구하고 지도 교수님께서는 차라리 다른 imaging modality에 대한 연구를 추가로 할지언정 이 제목은 꿋꿋히 유지하라고 말씀하셨고, 결국에는 추가 연구를 더 해서 넣고 (하하하...orz...) 결국 제 학위 논문의 제목은 그대로 유지했습니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;오늘 소개할 내용은 제 학위 논문 제목에도 나와있는 inverse problem에 대한 얘기입니다. 그 중에서도 영상(image)에 대한 inverse problem에 대한 것으로 좀 더 좁게는 image restoration 문제에 대한 정리를 하고자 합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Inverse Problems&lt;/h2&gt;&lt;div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;An inverse problem in science is the process of calculating from a set of observations the causal factors that produced them: for example, calculating an image in X-ray computed tomography, source reconstruction in acoustics, or calculating the density of the Earth from measurements of its gravity field. It is called an inverse problem because it starts with the effects and then calculates the causes. It is the inverse of a forward problem, which starts with the causes and then calculates the effects.&lt;br /&gt;&lt;div style=&quot;text-align: right;&quot;&gt;&lt;b&gt;- &lt;a href=&quot;https://en.wikipedia.org/wiki/Inverse_problem&quot; target=&quot;_blank&quot;&gt;Wikipedia: Inverse problem&lt;/a&gt;&lt;/b&gt;&lt;/div&gt;&lt;/blockquote&gt;어느 정도 감을 잡으셨을지 모르겠습니다만, 사실 committee 교수님들께서 제게 주셨던 의견들은 매우 온당한 것으로 inverse problem이라는 분야는 매우 광범위합니다. 위의 정의에서도 볼 수 있듯이 어떤 물리적 시스템을 묘사하는 문제를 forward modeling이라 한다면 그의 반대 방향을 모델링하고 연구하는 것을 inverse problem이라 할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;하나의 예시로 아래와 같이 어떤 시스템 (e.g., 카메라)을 통과한 자연 이미지(latent original image)가 natural noise (e.g., additive white Gaussian noise, AWGN)뿐만 아니라 blurring 혹은 down-sampling과 같은 시스템의 특성으로 인한 degradation이 추가되어 관측된 이미지를 얻은 상황을 고려해보겠습니다:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-60ZHIeoaPE8/XNfxFUCZ3qI/AAAAAAAADXo/EXZR1yMpcsImXvtlfGEU7ghPH9jA5g-PQCK4BGAYYCw/s1600/inv_prob.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-60ZHIeoaPE8/XNfxFUCZ3qI/AAAAAAAADXo/EXZR1yMpcsImXvtlfGEU7ghPH9jA5g-PQCK4BGAYYCw/s1600/inv_prob.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;이 때, 시스템 함수 혹은 operator $G$에 대한 물리적인 이해를 바탕으로 이를 찾거나 모델링하는 것을 forward problem이라 하고, 반대로 관측한 이미지를 바탕으로 깨끗한 원래 이미지를 찾는 문제를 inverse problem이라 합니다. 시스템에서 일어난 degradation에 따라서 각각 deblurring, denoising, super-resolution 등의 여러 영상 복원 (image restoration) 문제들로 세분화 될 수 있습니다.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;Problem statement&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;h3&gt;General formulation&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Image restoration을 수식적으로 모델링하는 방법은 매우 다양하겠으나, 측정 벡터 $y$가 임의의 선형 시스템 행렬 $H$와 가우시안 노이즈 (additive white Gaussian noise, AWGN)에 대해 $$y=Hx+v$$로 표현하는 것이 가장 일반적이며, 시스템 행렬 혹은 operator $H$가 어떤 것이냐에 따라 여러가지 영상 복원 문제가 모델링됩니다.&lt;br /&gt;&lt;br /&gt;예를 들어 denoising은&lt;b&gt;&amp;nbsp;&lt;/b&gt;$H=I$, deblurring (deconvolution)은 $H$가 convolution filter로 $Hx = k\circledast x$인 경우가 되며, inpainting은&amp;nbsp;$H$가 identity matrix이되 missing samples에 해당하는 부분이 듬성듬성 비어있는 degradation matrix로 모델링이 가능합니다. 또한 super-resolution은&amp;nbsp;$H$가 blur kernel과 sub-sampling (혹은 down-sampling)이 결합된 형태이며, 의료 영상 분야에서 사용되는 tomographic reconstruction은&amp;nbsp;$H$가 특정한 physical projections (e.g., Radon projections)이라 할 수 있겠습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;영상에 가해진 degradation으로 인해 이를 되돌리는 것은 매우 &quot;어려운데&quot;, 여기서 어렵다는 것은 image restoration (IR)은 &quot;ill-posed&quot; inverse problem (&lt;b&gt;&lt;span style=&quot;color: blue;&quot;&gt;**&lt;/span&gt;&lt;/b&gt;)이라는 뜻입니다. 예를 들어 Single Image Super-Resolution (SISR)은 대표적인&amp;nbsp; ill-posed problem으로 방정식의 변수가 독립적으로 구성할 수 있는 식의 갯수보다 많은 경우입니다. 좀 더 구체적으로는 $H$의 row 수에 비해 column의 수가 훨씬 많기에 $x$의 해가 무한히 많을 수 있어서 진짜 $x^*$를 특정하기 어렵다는 것으로, 한 장의 저해상도 이미지에 대응할 수 있는 고해상도 이미지는 다양한 경우의 수가 있다는 예시로 이해하시면 쉽습니다.&lt;br /&gt;&lt;span style=&quot;color: blue; font-size: x-small;&quot;&gt;&lt;b&gt;** &lt;/b&gt;ill-posedness를 알고 싶다면 well-posed problem이 무엇인지를 알면 됩니다. 이는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Well-posed_problem&quot; target=&quot;_blank&quot;&gt;wikipedia&lt;/a&gt;를 참고하시면 되겠습니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;특히나 natural image와 같이 전체 공간(search space)이 매우 큰 경우 해를 찾는 일이 더 지난하기 때문에, 가능한 해가 살고 있는 공간(solution space)을 좁히기 위해서 문제에 따라 시스템에 따라 적절한 constraint를 바탕으로 제약(regularize)을 걸어주는 방식을 취하게 됩니다. 따라서 관측된 데이터 $y$로부터 $x$를 구하기 위해서는 $$\min_x\frac{1}{2}||Hx-y||^2_2+\lambda\rho (x)$$를 푸는 것이 일반적이며 $\rho(x)$는 우리가 고른 regularization 항이 되겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Bayesian perspective&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;이를 Bayesian 관점으로 표현하면, likelihood function $P(y|x)=exp(-\frac{1}{2\sigma^2}||y-Hx||^2_2)$에 적절한 image prior $P(x)$를 사용하여 $P(x|y)$를 구하는&amp;nbsp;&lt;i&gt;maximum a posteriori&lt;/i&gt; (MAP&lt;i&gt;) estimation&lt;/i&gt;으로 생각할 수 있습니다:$$\begin{align*} \hat{x} &amp;amp;=\arg\min_x\{-\log P(y|x)-\log P(x)\} \\ &amp;amp;= \arg\min_x\{\frac{1}{2\sigma^2}||y-Hx||^2_2+\lambda\rho(x)\}\end{align*}$$ 여기서 $\sigma^2$는 $\lambda$에 흡수될 수 있으므로 결과적으로 같은 형태가 된다는 것을 알 수 있죠.&lt;br /&gt;&lt;br /&gt;이런 MAP framework로 IR 분야에 연구들을 살펴보면, image에 대한 prior를 어떤 것으로 정하느냐가 모델링의 주안점이 되어왔다는 것을 알 수 있습니다. 대표적인 image prior 모델로는 sparsity-inducing prior나 low-rank prior가 있겠으며, 이를 이용하여 optimization 문제를 푸는 전통적인 방식을 model-based optimization이라는 하나의 큰 카테고리로 묶을 수 있습니다.&lt;br /&gt;&lt;br /&gt;한편 model-based optimization과는 조금 다른 갈래가 최근 트랜드인 deep learning입니다. 이를 MAP framework 관점에서 생각하면 deep learning 역시도 일종의 discriminative learning prior로써 image prior 모델링의 한 종류라고 생각할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;지금부터는 이런 분류를 바탕으로 각 카테고리의 방식들을 하나씩 소개하겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;h2&gt;Sparse representation&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;많은 IR 알고리즘들이 sparsity prior를 사용하고 있습니다. 대표적인 예로는 total variation (TV)이 있으며, wavelet transform 이후 soft-thresholding을 하는 간단하지만 강력한 denoising 기법들이 있습니다. (이 방식은 natural image에 대한 wavelet domain representation이 일반적으로 sparse하다는 것을 근거로 합니다.)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;또한 이미지 patch들이 sparse dictionary representation이 가능하다는 것 역시도 잘 알려진 사실이며 이를 이용하는 대표적인 알고리즘이 sparse coding입니다. IR에 대한 일반적인 sparse representation 모델은 overcomplete dictionary $D$와 이에 대응하는 coding (coefficients) vector $\alpha$에 $l_1$-norm을 취한 sparsity regularization이 더해진 형태입니다 (i.e., $\min_\alpha ||\alpha||_1$ s.t. $x=D\alpha$): $$\hat{\alpha}=\arg\min_\alpha||y-HD\alpha||+\lambda||\alpha||_1$$ 즉, sparse coding에서는 $x$에 대한 문제를 $\alpha$에 대한 estimation으로 문제를 바꾸어 풉니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Sparse representation이&amp;nbsp;IR에서 성공적이었던 이유는&amp;nbsp;여러 가지로 방향으로 설명이 가능한데,&lt;/div&gt;&lt;div&gt;&lt;ol&gt;&lt;li&gt;Bayesian 관점에서 보면 sparsity prior를 이용하여 MAP 문제를 매우 잘 풀었다고 할 수 있고,&lt;/li&gt;&lt;li&gt;neuroscience 측면에서 보면 실제로 인간의 primary visual cortex의 simple cells들이 들어오는 시각 신호에 대해 spatially localized, oriented 혹은 band-passed 형태로 각각 특화되어 있는데, wavelet filter를 사용한 sparsity-inducing representation이 이를 잘 모사하기 때문일 수도 있으며,&lt;/li&gt;&lt;li&gt;compressed sensing 관점에서는 image patch들이 $k$-sparse한 신호들이라서 애초에 sparse optimization 형태로 가장 잘 풀 수 있는 문제이므로 여러 모로 성격이 잘 맞았다고 설명할 수도 있습니다.&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3&gt;Sparse Dictionary Learning&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Sparse representation 방식이 잘 통하려면 이를 표현할 atom들이 모인 dictionary를 잘 만드는 것이 가장 기본이 되겠습니다. 초기에는 DCT나 wavelets, curvelets 등을 사용한 analytical dictionary 구성이 주를 이루었으나 natural image의 복잡성을 충분히 표현하기에는 이런 hand-crafted analytical dictionary로는 한계가 있었습니다. 즉, 복잡한 이미지에 대해서는 더 많은 atom들이 필요했고 자연스럽게 sparseness가 떨어지는 문제가 있었죠.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이를 해결하기 위해 다음으로 연구된 것이 dictionary에 들어갈 atom들을 이미지들로부터 학습하는 것이었습니다. 즉, $Y=[y_1,\cdots,y_n]$과 같은 학습 샘플들이 있을 때, $m&amp;lt;n$인 atom을 갖는 dictionary $D=[d_1,\cdots, d_m]$을 $Y$로부터 배우되 $Y=D\Lambda,~\Lambda=[\alpha_1,\cdots, \alpha_n]$을 만족하는 code $\alpha$에 $l_0$-norm sparsity constraint를 주어 학습시킵니다. 여기서 $y_i$는 vectorized된 이미지 patch로 생각하시면 됩니다. 이 카테고리의 가장 대표적인 알고리즘으로는 K-SVD가 있습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Dictionary learning 방식은 analytically designed dictionary에 비해 특정 task나 data에 좀 더 adaptive한 표현이 가능했기에 일반적으로 더 좋은 성능을 보여주었고, multi-scale dictionary learning, double sparsity, adaptive PCA dictionaries, semi-coupled dictionary learning 등 다양한 알고리즘들이 개발되었으며 많은 연구 분야에서 애용되어 왔습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;Low-rank minimization&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Natural image에서 patch를 뽑으면 생각보다 패턴이 반복되는 경우가 많습니다. 이런 경험적인 지식을 바탕으로 non-local self-similarity (NSS) prior를 사용하는 연구들이 있는데요. 이런 방법들은 보통 이미지 내에 correlated patch들을 여러 장 모아 사용합니다. 각각의 이미지 patch를 따로따로 처리하는 sparse representation과는 확실히 다르다는 것을 알 수있습니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-kxS9wyvHbfs/XNgp0xBHAaI/AAAAAAAADX4/W7Qx_MFV4IkpYaU3pvyozuykvwRhkTlWgCK4BGAYYCw/s1600/nonlocal.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;210&quot; src=&quot;https://1.bp.blogspot.com/-kxS9wyvHbfs/XNgp0xBHAaI/AAAAAAAADX4/W7Qx_MFV4IkpYaU3pvyozuykvwRhkTlWgCK4BGAYYCw/s400/nonlocal.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Non-local self-similarity in natural image&lt;/b&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;그림과 같이 이미지로부터 patch들을 뽑은 다음 column의 형태로 옆으로 쌓아 matrix 형태로 만들면, 이렇게 만든 matrix는 correlated patch들로 인해 low-rank한 특징을 갖게 됩니다.&lt;br /&gt;&lt;br /&gt;이런 특징을 이용하는 IR 방법을 low-rank minimization이라 합니다. 예를 들어 이미지에 Gaussian noise가 더해지는 denoising 문제를 생각해보겠습니다. Noise는 패치들을 여럿 모은다고 해서 서로 correlate 할 이유가 없으므로 일반적으로 full-rank한 특성을 갖겠지만, 우리가 원하는 실제 이미지는 low-rank한 특성이 있을테니 데이터 행렬을 low-rank한 행렬로 approximation하므로써 denoising이 가능합니다. 즉, corrupted patch를 다른 patch로부터 수집한 redundant information을 바탕으로 수정하는 것이죠.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;문제는 행렬의 rank를 minimize하는 것이 매우 잘 알려진 NP-hard 문제라는 것입니다. 따라서 rank minimization 문제는 rank penalty의 convex relaxation인 nuclear norm을 사용해서 문제를 풀게 됩니다: $$\hat{X}=\arg\min_X ||Y-X||^2_F+\lambda||X||_*$$ 이 때, $X$의 nuclear norm은 $||X||_*=\sum_i||\sigma_i(X)||_1$로써 singular value의 합입니다. 이런 formulation의 장점은 문제의 closed-form solution이 존재한다는 것입니다. $Y=U\Sigma V^T$일 때, $$\hat{X}=US_{\frac{\lambda}{2}}(\Sigma)V^T$$이며, $S_{\frac{\lambda}{2}}(\Sigma)_{ii}=\max(\Sigma_{ii}-\frac{\lambda}{2},0)$으로 일종의 thresholding operator입니다. 이렇게 보면 행렬 $X$에 low-rankness도 다르게 말하면 행렬의 singular value들이 sparsely distribute할 것이라는 가정에서 시작하는 것이므로 sparsity prior라고 할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;지금까지 매우 간결하게 Image restoration에서 사용되어 온 큰 줄기를 훑어보았는데요. 다음 글에서는 이런 model-based optimization 방식과는 좀 다른 결을 보여주는 learning-based approach를 소개하겠습니다.&lt;br /&gt;&lt;br /&gt;간단히만 소개하자면, MAP estimation이라는 관점에서 discriminative learning 방식은 MAP inference를 predefined nonlinear function으로 대체하여 문제를 푸는 것으로 생각할 수 있습니다: $$\min_\theta l(\hat{x},x),~\text{s.t}~\hat{x}=\mathcal{F}(y,H;\theta)$$ 여기서 $\mathcal{F(\cdot)}$는 CNN이라고 생각하시면 됩니다.&lt;br /&gt;&lt;br /&gt;이런 discriminative learning 방식은 model-based optimization 방식에 비해 유연성이 떨어지지만, 대신 test time에서 inference 속도가 빠르다는 장점이 있습니다. 이 외에도 여러 장단점과 특징이 있는데 왜 그러한 특징이 생기는지 등 자세한 것은 다음 글에서 다루겠습니다.&lt;br /&gt;&lt;br /&gt;결국 하고 싶은 말은 deep learning을 사용하는 방식이 절대로 기존에 연구되어 온 많은 연구들과 완전 다른 길을 걷고 있는 것이 아니고, 이 역시도 크게는 image prior $P(x)$를 모델링하는 방식 중 하나라는 관점에서 설명할 수 있다는 것입니다.&lt;br /&gt;&lt;br /&gt;그럼 곧 다음 글에서 뵙겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;다음 읽을 거리&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/image-restoration-inverse-problem-2.html&quot; target=&quot;_blank&quot;&gt;Image Restoration (IR): inverse problem point of view (2)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;디지털 신호 처리가 궁금하다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Signal Processing For Communications&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에 속하는 전반적인 연구 내용들이 궁금하다면: &lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/machine%20learning&quot; target=&quot;_blank&quot;&gt;Machine learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GAN에 관심이 많다면: &lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/GAN&quot; target=&quot;_blank&quot;&gt;GAN&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에서 잘 사용되는 수학에 관심이 있다면: &lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/mathematics&quot; target=&quot;_blank&quot;&gt;Mathematics&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/2351542051333992824/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/image-restoration-inverse-problem-1.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/2351542051333992824'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/2351542051333992824'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/image-restoration-inverse-problem-1.html' title='Image Restoration (IR): inverse problem point of view (1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-60ZHIeoaPE8/XNfxFUCZ3qI/AAAAAAAADXo/EXZR1yMpcsImXvtlfGEU7ghPH9jA5g-PQCK4BGAYYCw/s72-c/inv_prob.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1797523556505861360</id><published>2019-05-11T20:30:00.000+09:00</published><updated>2019-05-13T17:34:10.967+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="dsp"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>Signal Processing For Communications (0)</title><content type='html'>이 시리즈는 signal processing을 학부 때 배웠으나 여러 이유로 이해를 잘 하지 못하다가 뒤늦게서야 유용성을 깨닫고 개인적으로 공부하며 정리한 흔적이다.&lt;br /&gt;&lt;br /&gt;결국 machine learning을 하든 deep learning을 하든 모두 신호를 다루기 위한 도구일 따름이고, 내가 주로 다루는 신호가 이미지라는 형태를 띄고 있을뿐 근본적으로 디지털 신호 처리에서 다루는 내용에서 벗어나지 않는다는 생각이 들었다.&lt;br /&gt;&lt;br /&gt;이런 맥락에서 신호 처리에 대해 좀 더 잘 알고 싶다는 생각에 정리를 시작하였는데, 대부분의 글은 주로 EPFL의 Martin Vetterli 교수님이 저술하신 textbook을 기반으로 요약하였다.&lt;br /&gt;&lt;br /&gt;앞으로 쓸 글들은 (얼마나 걸릴지는 모르겠지만) 모두 신호처리의 기본에 대해 대학교 학부생을 위한 기초 수준으로 작성될 것이다. 스스로가 그 이상을 설명할만큼 잘 알고 있다고 생각하지도 않는만큼 차후 시간이 흘러 내가 다시 이 글을 보더라도 이해가 쉽게 하겠다는 목적을 갖고 글을 정리한다.&lt;br /&gt;&lt;br /&gt;약간의 선형대수학, 신호처리에 대한 기초 지식 그리고 더 나가서 해석학을 들어본 적이 있다면 보다 깊은 이해에 도움이 될 것이지만, 그런 선행 지식이 없이도 어렵지 않게 이해할 수 있는 수준으로 작성하고자 노력하였다.&lt;br /&gt;&lt;br /&gt;간단한 예시 그리고 덜 형식적인 설명을 바탕으로 신호처리라는 딱딱한 주제에 대해 쉽게 접근할 수 있도록 작성하였으며 이해하기 쉬운 설명을 위해 수학적 엄밀성 강조하지는 않겠지만 언제나 정확한 설명을 하는 것에 주안점을 두었다. 계획된 목차는 아래와 같다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;목차 (planned)&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Preface&lt;/a&gt; ($\leftarrow$)&amp;nbsp;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;What is Digital Signal Processing? (1)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Signals and Hilbert Spaces&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Fourier Analysis&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Interpolation and Sampling (&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-9-1.html&quot; target=&quot;_blank&quot;&gt;9-1&lt;/a&gt;)&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling theorem&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Aliasing&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Multirate Signal Processing&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Downsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Upsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Oversampling&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;다만, 꼭 순서대로 글이 작성되리라는 보장은 없으며, 각 글의 제목 뒤에 붙은 숫자는 책에서 해당 내용이 다뤄진 chapter를 따랐다. 따라서 모든 chapter를 정리하지는 않을 예정이므로 숫자가 다 채워질 이유도 순서대로 나열될 이유도 없다. (e.g., 현재 이 글은 서문과 같은 역할이므로 chapter 0라 임의로 칭했고, 따라서 제목이 다음과 같다; Signal Processing For Communications (0))&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1797523556505861360/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1797523556505861360'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1797523556505861360'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html' title='Signal Processing For Communications (0)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-9158657182315759528</id><published>2019-05-11T20:03:00.001+09:00</published><updated>2019-05-13T17:36:44.695+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="dsp"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>Signal Processing For Communications (1)</title><content type='html'>&lt;div&gt;&lt;h2&gt;What Is Digital Signal Processing?&lt;/h2&gt;&lt;/div&gt;&lt;br /&gt;신호(signal)와 신호 처리(signal processing) 대해서 정의를 내리자면 각각 다음과 같다:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;&lt;b&gt;신호:&lt;/b&gt; 시간 혹은 공간에 대해 변화하는 현상에 대한 formal description&lt;br /&gt;&lt;b&gt;신호 처리:&lt;/b&gt; 신호에 들어있는 정보를 바꾸거나 분석하는 any operation.&lt;/div&gt;&lt;/blockquote&gt;예를 들어 주변 온도를 우리가 Celsius degree라는 물리적 변수를 기준으로 시간에 따른 온도의 변화를 기록하는 경우, 이렇게 만들어진 data set은 온도 &quot;신호&quot;가 될 것이다. 이 신호에 대한 가장 단순한 &quot;처리&quot;로는 월간 온도 평균과 같은 어떤 파라미터를 계산하는 것이 있겠다.&lt;br /&gt;&lt;br /&gt;또한 신호 처리는 어떤 물리적인 값 자체에 직접 가해지는 것이 아니라 물리적인 값의 &quot;abstract representation&quot;을 기반으로 수행된다는 점이 중요하다. 이런 abstract representation의 방식에 따라서 신호 처리의 기본 단위(unit)가 정해진다.&lt;br /&gt;&lt;br /&gt;한편 &quot;디지털 (digital)&quot;이라는 수식어구는 라틴어 digitus에서 유래한 것으로 손가락을 의미하는데, counting은 가장 기초적이고 오래된 abstraction이다. 즉, 디지털 신호 처리는 시간을 포함한 모든 것들에 정수(integer number)와 같이 countable한 abstraction representation을 사용한다는 것을 의미한다.&lt;br /&gt;&lt;br /&gt;좀 더 구체적 예시로는, 주변 온도를 측정한 각각의 관측(instants)이 셀 수 있는 집합(the days in a month)을 이루고 각 관측값(measure)들 역시도 온도계의 눈금 단위와 같이 유한한 수의 집합으로 표현되는 것을 생각해보면 된다.&lt;br /&gt;&lt;br /&gt;재미있는 점은 디지털 신호 처리에서는 신호가 &quot;어디서 유래한 것인가에 관계없이&quot;&amp;nbsp;이를 &quot;정수로 표현 가능한&quot;&amp;nbsp;abstract representation을 사용한다는 것이다. 지금은 이 사실이 별 달리 중요해보이지 않을 수 있으나, 이 특징이 디지털 신호처리가 지금과 같이 크게 발전할 수 있었던 큰 동력이라는 점은 앞으로 차차 분명해지리라 생각한다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Analog vs. Digital worlds&lt;/h2&gt;&lt;br /&gt;세계에 대한 &quot;digital&quot; 혹은 정수를 이용한 표현 방식은 우리가 다루는 문제가 가축이나 날짜를 세는 것과 같이 간단할 때까지는 아무 문제가 없이 잘 동작했으나, 점차 세상이 복잡해지고 이를 설명하는 모델 역시도 복잡해질 필요가 생기면서 한계에 부닥쳤다.&lt;br /&gt;&lt;br /&gt;신호 처리 쪽 용어로 얘기하자면 정수로 표현되는 세계가 &quot;analog&quot;와 같이 연속적인 세계를 설명하는 잣대로 사용하기에는 너무 초보적이고 거칠어서 마치 시계공이 망치를 들고 있는 것과 같다는 것이다.&lt;br /&gt;&lt;br /&gt;문제는 무한대와 무한소로 나눠질 수 있는 연속적인 analog 세계의 analytical 모델을 사용하면 이론적으로 분석하기는 편할지언정 실제로 이를 사용하기 위해서는 언제나 유한하고 이산적인 digital 세계로 내려와야한다는 점이다.&lt;br /&gt;&lt;br /&gt;예를 들어 온도를 측정하는 것만해도 우리가 얻을 수 있는 것은 언제나 일정 간격(time)을 두고 측정한 관측값들뿐 임의의 시간에 대해 해당하는 온도에 대한 관계를 보여주는 analytical 모델이 아니다.&lt;br /&gt;&lt;br /&gt;따라서 analog와 digital representation이 서로 만족할만한 합의에 이르기 위한 부단한 노력들이 이루어져 왔고, series expansion이나 numerical integration과 같은 알고리즘들이 analytic 결과를 practically computable한 형태로&amp;nbsp;만들기 위한 노력의 예시들이다.&lt;br /&gt;&lt;br /&gt;디지털 신호 처리가 멋진 것은 이렇게 양분된 두 세계가 서로 가장 만족스러운 형태로 합의에 이를 수 있도록 한다는 점이다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Discrete Time&lt;/h2&gt;&lt;br /&gt;아날로그 기록 방식의 가장 큰 문제점은 신호를 추상화 하여 기록하는 것이 아닌 하나의 물리적인 현상을 또 다른 물리적 현상으로 옮기는 것에 불과하다는 점이다. 이 때문에 근본적으로 아날로그 신호는 기록(recording)의 형태에 따라 각각 다른 신호 처리 시스템이 필요하다. 예를 들어 우리가 온도 변화 함수 $f(t)$를 알고 있고,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s1600/fig1-5.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;275&quot; src=&quot;https://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s400/fig1-5.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Analytical and empirical averages&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;일정 간격 $[T_0, T_1]$ 사이에 일어난 온도 변화의 평균값을 알고싶다면 이에 대한 analytical solution은 다음과 같은 적분 방적식을 푸는 것이다: $$\bar{C} = \frac{1}{T_1-T_0}\int_{T_0}^{T_1} f(t) dt.$$ 그러나 analytic model이 없는 현실에서는 어떤 기기를 사용하여 온도를 측정, 기록하였을 것이고 그 데이터를 가지고 평균 온도를 계산할 것이다. 만약 온도가 thermograph를 이용하여 그래프의 형태로 기록되었다면 plainmeter라는 면적을 구하는 기계적 도구를 사용하여 면적을 알 수 있을 것이다. 그러나 온도 변화가 thermocouple과 같이 전압을 이용하여 기록을 하는 경우 학부 전자기초 시간에 배우는 RC 네트워크로 voltage integration 회로를 만들어 평균값을 계산해야 할 것이다. 이렇듯 아날로그 신호에서는 평균을 구하는 매우 단순한 예에서도 각 경우마다 특정한 디자인이 필요하기에 범용적으로 사용할 수 있는 방식을 고안하기 어렵다는 것을 알 수 있다.&lt;br /&gt;&lt;br /&gt;한편, 디지털 방식과 같이 하루에 한 번씩 측정한 온도에 대해 평균을 구하는 것은 매우 쉽다: $$\hat{C}=\frac{1}{D}\sum^D_{n=1}c_n.$$ 단순히 초보적인 덧셈과 나눗셈만 수행하면 원하는 값을 얻을 수 있다! 그렇다면,&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;$\bar{C}$와 $\hat{C}$의 차이가 (만약 있다면) 얼마나 되는가?&quot;&lt;/blockquote&gt;만약 저 자연계 어딘가에 $f(t)$라는 온도 함수가 있다는 것을 받아들인다면 하루 주기($T_s$)마다 측정한 $c_n$ 온도 측정값들은 이 함수의 $samples$라고 할 수 있다: $$c_n=f(nT_s).$$ 이런 맥락에서 보면 $\hat{C}$는 $\bar{C}$의 Riemann approximation이라고 할 수 있으며 앞선 질문은 이 approximation의 질 즉, continuous-time 함수에서 일부 샘플들만 취함으로써 우리가 얼마나 정보를 버렸는지에 대해 묻는 것과 같다.&lt;br /&gt;&lt;br /&gt;이에 대한 정답은 놀랍게도 해당 물리적 현상이 &quot;그렇게 빨리 변하지 않는다&quot;는 가정 하에,&amp;nbsp; 두 representation이 &quot;완벽히 일치한다&quot;는 것이다. 즉, continuous-time function과 우리가 얻은 측정 샘플들 간의 정보 손실이 전혀 없다.&lt;br /&gt;&lt;br /&gt;잠시 가정에 대한 걱정을 내려놓고 이 사실이 얘기해주는 것에만 집중해보면 매우 놀랍게도&lt;br /&gt;&lt;ol&gt;&lt;li&gt;아날로그와 디지털 세계가 완전히 공존하는 것이 가능하다는 뜻이며&amp;nbsp;&lt;/li&gt;&lt;li&gt;우리가 두 세계 사이를 오갈 수 있는 매우 강력한 도구를 갖고 있다는 것이다 (sampling theorem).&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;20세기 초에 발견된 이 놀라운 정리는 우리가 가진 샘플들을 바탕으로 임의의 continous-time function를 알아내는 것이 가능하다는 것을 말해준다:&lt;br /&gt;$$f(t)=\sum_{n=-\infty}^\infty c_n \frac{\sin(\pi(t-nT_s)/T_s)}{\pi(t-nT_s)/T_s}.$$ 따라서 이론적으로는 우리가 측정값들을 가지고만 있다면 이를 바탕으로 continous-time 형태로 표현하는 것이 가능하며, 이것은 이어서 우리가 갖고 있는 매우 강력한 수학적 도구인 미분을 사용하여 함수를 분석하는 것이 가능해진다는 것을 뜻한다. 더 좋은 점은 continous-time에서 이루어진 미분과 같은 분석이 항상 discrete-time에 대응하는 방식이 존재하여 굳이 우리가 얻은 측정값들을 가지고 continous domain으로 옮겨서 분석한 후 다시 discrete domain으로 내려오는 복잡한 방식을 취할 것 없이 discrete domain에서 바로 분석을 하면 된다는 것이다.&lt;br /&gt;&lt;br /&gt;Discrete과 continuous representations 사이의 equivalence는 우리가 샘플을 얻는 속도에 비해&amp;nbsp;다루는 신호가 얼마나 충분히 &quot;느린가&quot;에 달려 있다. 즉, 연속된 샘플을 측정하는 사이에 신호가 갑자기 이상하게 움직이지 않고 충분히 부드럽게 (smooth and well behaved) 움직인다면 문제가 없다는 뜻이다.&lt;br /&gt;&lt;br /&gt;그래서 sampling theorem이 해주는 역할은 (좀 더 쉽게 설명하자면) 신호가 갖는 최대 주파수와 우리가 얼마나 자주 혹은 빨리 샘플을 얻어야 하는지에 대한 정량적인 기준을 알려주는 것이다. 대다수의 학부 수준 디지털 신호 처리 과목의 반절 혹은 그 이상은 이 sampling theorem을 배우기 위한 준비와 theorem의 의미에 대해 공부하는 것이다. 특히 주파수 영역은 Fourier transform을 사용하여 알아낼 수 있기에 이를 신호 처리 과목에서 중요하게 다루며 배우는 것이라 할 수 있는데, 재미있는 점은 Fourier transform이라는 것 자체가 주기성을 띄는 함수들을 &lt;i&gt;&quot;셀 수 있는&quot;&lt;/i&gt; 값들로 표현하기 위한 도구로서 사용된다는 것이다.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;Everything comes together.&quot;&lt;/blockquote&gt;&lt;h2&gt;Discrete Amplitude&lt;/h2&gt;&lt;br /&gt;시간 연속성에 대한 문제는 sampling theorem으로 어느 정도 해결이 되었지만, 여전히 남아있는 문제가 하나 있다. 현실 세계의 한계로 인해 실제 측정을 할 때 생기는 오차는 우리가 어찌 할 수 없는 문제다.&lt;br /&gt;&lt;br /&gt;만약 우리가 analytical model을 다룬다면 시간축뿐만 아니라 함수 값 역시도 연속적인 성격을 갖고 있다. 그러나 현실에서는 절대로 이와 같은 무한대의 정밀성을 얻을 수 없다는 것은 자명하다. (아무리 온도계의 눈금을 잘게 쪼개어 기록을 하더라도 한계가 있는 것처럼)&lt;br /&gt;&lt;br /&gt;따라서 실제로는 우리가 얻는 측정값들도 결국 유한한 숫자들의 집합이고 그렇다면 이들은 셀 수 있기에 정수로 mapping하는 것이 가능하다. 이러한 과정을 quantization이라고 부르고 이는 sampling과 함께 digital signal을 얻는데 필수적인 요소가 된다.&lt;br /&gt;&lt;br /&gt;Quantization은 정보 손실을 어쩔 수 없는 것으로 받아들인다는 점에서 연속체 문제를 시간에 비해 매우 거칠게 해결하는 것이라 할 수 있다. 여기에는 그럴 수 밖에 없는 이유가 있는데 그게 바로 신호 처리를 하다보면 언제나 만나게 되는 &quot;noise&quot;이다.&lt;br /&gt;&lt;br /&gt;우리가 어떠한 기계적 기록 장치를 쓴다고 해도 아날로그 기록을 하는 기기라면 언제나 noise가 함께하게 된다. Noise는 자연에서 오는 것이고 이를 완전히 제거하는 것은 불가능하기 때문에 신호 처리를 할 때 일정 수준의 정밀성으로 만족하는 정도로 합의를 하는 것이다.&lt;br /&gt;&lt;br /&gt;문제는 noise가 단순히 측정에서만의 문제가 아니라 처리를 할 때도 함께한다는 점이다.&lt;br /&gt;여기서 디지털 신호 처리의 또 다른 장점이 나오는데, 디지털 신호 처리는 언제나 셀 수 있는 정수의 수열을 다루기 때문에 디지털 영역에서는 processing으로 인한 noise가 생기지 않는다.&lt;br /&gt;&lt;br /&gt;매우 자명한 예로 신호를 복제하는 것을 생각해보면, 테이프를 복사하는 것은 원본 테이프를 복사본과 그 복사본을 이용한 다음 복사본으로 넘어갈 때마다 추가적인 nosie가 더해져서 점점 음질이 열화하는 것을 알 수 있지만 mp3의 경우 원본과 복사본이 근본적으로 차이가 없다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Terminology&lt;/h2&gt;&lt;br /&gt;마지막으로 용어에 대해 한가지 짚고 넘어가겠다. Amplitude에 대한 정확성은 사실 하드웨어에 달린 문제로 예를 들자면 CD와 DVD는 서로 precision 즉 샘플 당 담는 정보량에 차이가 있다. 이렇게 amplitude에 대한 정밀성은 하드웨어에 의존적이므로 사실상 신호 처리 이론에 대해 배우거나 개발할 때는 quantization을 고려하지 않고 마치 연속된 실수 값인 것 마냥 취급한다. 따라서 사실상 우리가 앞으로 배우는 것은 엄밀히 말하자면 모두 discrete-time signal processing이라 불러야 맞고 digital signal processing은 실제 기기의 영역에서 이뤄지는 일임을 알아야한다. 그러나 quantization을 고려하지 않는 것이 좀 더 이론적으로 다루기도 쉽고 일반적인 분석이 가능하기 때문에 이를 잘 구별하지 않고 digital signal processing이라 얘기한다는 점을 분명히 알아야한다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b&gt;To be continued ... (planned)&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Preface&amp;nbsp;&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;What is Digital Signal Processing? (1)&lt;/a&gt;&amp;nbsp;($\leftarrow$)&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Signals and Hilbert Spaces&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Fourier Analysis&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Interpolation and Sampling (&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-9-1.html&quot; target=&quot;_blank&quot;&gt;9-1&lt;/a&gt;&amp;nbsp;&lt;/b&gt;&lt;b&gt;$\leftarrow$&amp;nbsp;&lt;b&gt;next to read&lt;/b&gt;)&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling theorem&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Aliasing&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Multirate Signal Processing&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Downsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Upsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Oversampling&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/9158657182315759528/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/9158657182315759528'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/9158657182315759528'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html' title='Signal Processing For Communications (1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s72-c/fig1-5.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-243971491237100208</id><published>2019-05-07T17:31:00.001+09:00</published><updated>2019-05-13T10:14:17.635+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><category scheme="http://www.blogger.com/atom/ns#" term="topology"/><title type='text'>공이 점점 비눗방울처럼 변할 때 (When ball becomes a soap bubble)</title><content type='html'>&lt;h2&gt;공이 점점 비눗방울처럼 변할 때&lt;/h2&gt;&lt;br /&gt;이전에 소개했던&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; target=&quot;_blank&quot;&gt;박스 안에 넣은 공의 지름이 박스보다 클 때&lt;/a&gt;처럼&amp;nbsp;고차원으로 갈 때 우리의 직관이 얼마나 달라질 수 있는지를 알려주는 또 다른 좋은 예시를 소개해보자.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;구의 부피&lt;/h3&gt;&lt;br /&gt;또다시 &lt;a href=&quot;https://en.wikipedia.org/wiki/Ball_(mathematics)&quot; target=&quot;_blank&quot;&gt;공(ball)&lt;/a&gt;이다! 수학적인 용어에서의 공은 간단히 말해 겉껍질이 자기보다 한차원 낮은 &lt;a href=&quot;https://en.wikipedia.org/wiki/N-sphere&quot;&gt;구(sphere)&lt;/a&gt;로 쌓여있는 닫힌 공간 전체, 즉, 안이 꽉 찬 공간을 뜻한다. 1차원 공(ball)은 선(line segment)이고 2차원 공은 원반(disk), 3차원 공은 음...공(ordinary ball)이다. 대응되는 구(sphere)를 생각해보면 0차원 구는 시작과 끝 점(point), 1차원 구는 원(circle), 2차원 구는 구(ordinary sphere)다.&lt;br /&gt;&lt;br /&gt;이런 공의 부피를 바탕으로 초등학교 시절 배운 내용 수준만으로 아주 쉽고 간단하게 고차원에서는 직관이 우리를 배반한다는 것을 보일 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; target=&quot;_blank&quot;&gt;이전 글&lt;/a&gt;과 같이 먼저 쉽고 우리 직관이 잘 통하는 2차원에서부터 시작해보자:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s1600/high_dim_1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;170&quot; src=&quot;https://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s200/high_dim_1.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;우리 모두 초등학교 때, 원의 부피, 즉 2차원에서의 넓이를 구하는 것은 배웠을 것이다: $$V_2(r)=\pi r^2.$$ 한 차원 더 나가서,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-54kOhWunGxQ/XNE781irJXI/AAAAAAAADUs/AZpUOb7nWXA3gAwrEL5pJuY91MDRMD4ZACK4BGAYYCw/s1600/high_dim_2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;170&quot; src=&quot;https://2.bp.blogspot.com/-54kOhWunGxQ/XNE781irJXI/AAAAAAAADUs/AZpUOb7nWXA3gAwrEL5pJuY91MDRMD4ZACK4BGAYYCw/s200/high_dim_2.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;3차원 공의 부피는 $$V_3=\frac{4\pi}{3}r^3$$이라는 것도 열심히 외웠을 것이다.&lt;br /&gt;&lt;br /&gt;그리고 아마도 이걸 $d$차원에 대해 일반화하는 공식은 테이블 형태로 &quot;심화 학습&quot; 뭐 이런 형태로 가볍게 보여주고 지나갔을 것이다: $$V_d(r)=k_d r^d.$$ 여기서 $k_d$는 상수다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;구각 (Spherical shell)&lt;/h3&gt;&lt;br /&gt;이제부터 좀 재미있는 실험을 할텐데, 원점을 중심으로 반지름이 1인 구와 반지름이 $1-\epsilon$으로 그보다 아주 약간 ($\epsilon\ll 1$만큼) 공 두 개를 준비하고 이 두 공 부피의 차를 구해보자: $$V_d(1) - V_d(1-\epsilon).$$&lt;br /&gt;이걸 겉 껍데기를 구하는 것이라 해서 구각(spherical shell)이라 하는데 두 공의 반지름의 차이가 $\epsilon$만큼 나기 때문에 우리가 생각하는 겉껍질(구각)이 차지하는 부피는 매우 작다.&lt;br /&gt;&lt;br /&gt;만약 정확히 그 비율이 얼마나 되는지 알고 싶다면 반지름이 1인 구와 위에서 구한 구각의 비율을 구하면 될텐데 이 비율은 간단히: $$\frac{V_d(1) - V_d(1-\epsilon)}{V_d(1)}=1-(1-\epsilon)^d$$가 될 것이다.&lt;br /&gt;&lt;br /&gt;이제 준비물은 모두 모았으니 사고 실험을 해보면 재미있는 일이 벌어지는 것을 알 수 있다.&amp;nbsp; 점점 고차원으로 갈수록 ($d\rightarrow \infty$) 두번째 항의 값이 0에 가까워지고 공과 구각의 비율이 1로 수렴한다! 즉, &lt;i&gt;&quot;공이 점점 비눗방울처럼 바뀌는 것&quot;&amp;nbsp;&lt;/i&gt;이다.&lt;br /&gt;&lt;br /&gt;모든 부피가 껍데기에만 몰려있고 안이 텅텅 비어있는 매우 요상한 &quot;속이 꽉찬&quot; 공이 될 것이다. 이 역시도&amp;nbsp;고차원으로 넘어갈 때, 우리의 직관이 얼마나 틀릴 수 있는지 보여주는 좋은 예시로 이 글을 읽는 다른 분들에게도 brain candy가 되었길 기대한다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;딴 이야기&amp;nbsp;&lt;/h2&gt;&lt;h3&gt;(for those who are interested in GANs)&lt;/h3&gt;&lt;br /&gt;재미있는 GAN blog 글로 유명한&amp;nbsp;inFERENCe가 &quot;&lt;a href=&quot;https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/&quot; target=&quot;_blank&quot;&gt;Gaussian Distributions are Soap Bubbles&lt;/a&gt;&quot;라는 제목으로 글을 써서 화제가 된 적이 한 번 있는데, 생각보다 복잡하게 설명을 해서 이해하기 어려울 수 있지만 사실 지금 한 얘기를 다른 방식으로 열심히 적은 것이다.&lt;br /&gt;&lt;br /&gt;GAN 모델을 학습시킨 다음 High dimensional Gaussian latent space에서 walking을 하기 위해 두 latent vector간의 interpolation을 할 때, 왜 linear interpolation을 하면 문제가 될 수 있는지 이 글을 읽으신 분들이 이해가 쉽게 될 것이라 생각한다.&lt;br /&gt;&lt;br /&gt;어떤 의미에서는 중간이 텅 비어있는데 겉껍질을 타고(polar) 움직여야지(interpolate) 중간을 쑥 뚫고(linear) 움직이면 본적이 없는 latent vector가 model로 들어갈 수 있기 때문이다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; style=&quot;text-align: start;&quot; target=&quot;_blank&quot;&gt;박스 안에 넣은 공의 지름이 박스보다 클 때&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/&quot; style=&quot;text-align: start;&quot; target=&quot;_blank&quot;&gt;Gaussian Distributions are Soap Bubbles&lt;/a&gt;,&amp;nbsp;&lt;span style=&quot;text-align: start;&quot;&gt;inFERENCe&lt;/span&gt;&amp;nbsp;2017. 11. 09.&lt;/li&gt;&lt;li&gt;디지털 신호 처리가 궁금하다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html&quot; target=&quot;_blank&quot;&gt;Signal Processing For Communications&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에 속하는 전반적인 연구 내용들이 궁금하다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/machine%20learning&quot; target=&quot;_blank&quot;&gt;Machine learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;GAN에 관심이 많다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/GAN&quot; target=&quot;_blank&quot;&gt;GAN&lt;/a&gt;&lt;/li&gt;&lt;li&gt;머신러닝에서 잘 사용되는 수학에 관심이 있다면:&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/search/label/mathematics&quot; target=&quot;_blank&quot;&gt;Mathematics&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/243971491237100208/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/when-ball-becomes-soap-bubble.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/243971491237100208'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/243971491237100208'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/when-ball-becomes-soap-bubble.html' title='공이 점점 비눗방울처럼 변할 때 (When ball becomes a soap bubble)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s72-c/high_dim_1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-6213532524610182574</id><published>2018-09-02T22:18:00.002+09:00</published><updated>2018-09-02T22:18:57.919+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="개발"/><title type='text'>[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  2. 이름에 정보 담기</title><content type='html'>&lt;h2 style=&quot;height: 0px;&quot;&gt;표면적인 수준에서의 개선&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;표면적 수준이란 좋은 이름을 짓고, 좋은 설명을 달고, 코드를 보기 좋게 정렬하는 따위를 의미한다.&quot;&lt;/blockquote&gt;&lt;br /&gt;책의 첫 단락은 표면적인 수준에서의 개선부터 시작합니다. 이런 수정은 코드를 통째로 바꾸거나 동작하는 방식을 변화시키지 않고 &#39;그 자리에서&#39; 곧바로 만들 수 있기에 첫 시작으로 매우 적절하다 생각합니다.&lt;br /&gt;&lt;br /&gt;물론 가독성에 관련된 논의는 이 수준보다 더 나아가 많은 내용을 담고 있겠으나 이는 차차 살펴갈 것이며 먼저 1부에서는 폭넓게 적용할 수 있고, 그다지 많은 노력을 요구하지 않는 내용을 우선적으로 다룹니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;이름에 정보 담기&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;변수, 함수, 혹은 클래스 등의 이름을 결정할 때는 항상 같은 원리가 적용합니다.&amp;nbsp;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;이름을 일종의 설명문으로 간주해야 한다.&quot;&lt;/blockquote&gt;충분한 공간은 아니지만, 좋은 이름을 선택하면 생각보다 많은 정보를 전달할 수 있다는 것이죠. 구체적으로는 아래의 여섯 가지 방법을 제안합니다.&lt;br /&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;특정한 단어 고르기&lt;/li&gt;&lt;li&gt;보편적인 이름 피하기 (혹은 언제 그런 이름을 사용해야 하는지 깨닫기)&lt;/li&gt;&lt;li&gt;추상적인 이름 대식 구체적인 이름 사용하기&lt;/li&gt;&lt;li&gt;접두사 혹은 접미사로 이름에 추가적인 정보 덧붙이기&lt;/li&gt;&lt;li&gt;이름이 얼마나 길어져도 좋은지 결정하기&lt;/li&gt;&lt;li&gt;추가적인 정보를 담을 수 있게 이름 구성하기&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;앞으로는 책에 나온 내용을 모두 다 소개하기 보다는 개중 제가 재미있었던 내용들을 좀 골라서 예시와 함께 알아보겠습니다.&amp;nbsp;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;특정한 단어 고르기&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;매우 구체적인 단어를 선택하여 &quot;무의미한&quot; 단어를 피하자.&amp;nbsp;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;예를 들어 &quot;get&quot;은 지나치게 보편적입니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;def GetPage(url):&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; ...&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;여기서 &quot;get&quot;보다는 메소드가 어디에서 페이지를 가져오는 지 알려줄 수 있게 FetchPage() 혹은 DownloadPage()와 같이 구체적으로 명명하는 것이 더 좋습니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;사실 위 예시보다 다음 예시가 더 좋았는데요. 다음과 같이 BinaryTree 클래스에서&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;class BinaryTree {&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; int Size();&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; ...&lt;/div&gt;&lt;div&gt;} &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;우리는 Size() 메소드가 반환하는 것이 무엇일 지 이름만 봐서는 알 수 없습니다. 트리의 높이, 노드의 개수, 혹은 트리의 메모리 사용량이 될 수도 있겠죠.&amp;nbsp; 따라서 Height(), NumNodes(), 혹은 MemoryBytes() 등이 더 의미 있는 이름이라는 것에는 모두 동의하리라 생각합니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;같은 맥락에서 저자들은 thesaurus를 뒤져보고 더 나은 이름을 생각하기를 권합니다. 다만 너무 &quot;재치&quot; 있는 이름보다는 명확하고 간결한 이름이 더 좋습니다. 다음에 이어지는 내용들도 사실 같은 내용인데 예제들과 소소한 팁 위주로 살펴보곘습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;tmp나 retval 같은 표편적인 이름 피하기&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;변수값을 설명하는 이름을 사용하라&quot;&lt;/blockquote&gt;&lt;br /&gt;예를 들어, 다음과 같이 Euclidean norm을 계산하는 자바스크립트 코드에서&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;var euclidean_norm = function (v) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; var &lt;b&gt;retval&lt;/b&gt; = 0.0;&lt;br /&gt;&amp;nbsp; &amp;nbsp; for (var = i = 0; i&amp;lt;v.length; i+=1)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;b&gt;retval&lt;/b&gt; += v[i];&lt;br /&gt;&amp;nbsp; &amp;nbsp; return Math.sqrt(&lt;b&gt;retval&lt;/b&gt;);&lt;br /&gt;};&lt;/div&gt;&lt;div&gt;&lt;br /&gt;retval보다는 sum_squares라고 이름을 붙여준다면 변수의 목적을 바로 이해할 수 있으며 나중에 버그를 잡을 때도 용의합니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;retval&lt;/b&gt;&amp;nbsp;+= v[i]; 부분이&amp;nbsp;&lt;b&gt;sum_squares&lt;/b&gt; += v[i]; 였다면 훨씬 눈에 잘 띄었겠죠.&lt;br /&gt;&lt;br /&gt;물론 아래와 같이 정말로 대상이 짧게 임시적으로만 존재하고, 임시적 존재 자체가 변수의 가장 중요한 용도일 때는 tmp와 같은 변수를 사용할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;두 변수를 서로 교환하는 알고리즘 예:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;if (right&amp;lt;left) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;b&gt;tmp&lt;/b&gt; = right;&lt;br /&gt;&amp;nbsp; &amp;nbsp; right = left;&lt;br /&gt;&amp;nbsp; &amp;nbsp; left = &lt;b&gt;tmp&lt;/b&gt;;&lt;br /&gt;}&lt;/div&gt;&lt;br /&gt;같은 맥락으로 i, j, iter, it 같은 이름이 인덱스나 루프 반복자로 사용되는 것은 충분히 괜찮습니다. 다만 이 역시도 디버깅의 용이성을 위해서 아래와 같이 소속을 표현해준다면 더 좋겠죠.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;(i, j, k) -&amp;gt; (club_i, members_j, users_i) or (ci, mj, ui)&lt;br /&gt;&lt;br /&gt;활용 예:&lt;br /&gt;if (clubs[ci].members[ui] == users[mi]) # 버그! 처음 문자가 일치 하지 않는다.&lt;/div&gt;&lt;br /&gt;따라서 표편적인 이름이 항상 나쁜 것은 아니지만, 이를 사용하려면 &lt;b&gt;꼭 그렇게 해야하는 이유가 있어야 합니다.&amp;nbsp;&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;br /&gt;&lt;h3&gt;추가적인 정보를 이름에 추가하기&lt;span style=&quot;font-weight: normal;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;단위(sec, millisecond, kg 등)를 포함하거나 다른 중요한 속성(unsafe, utf_8 등)이 있을 때는 변수에 그런 내용을 추가해주면 좋습니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;start -&amp;gt; start_ms, elapsed -&amp;gt; elapsed_ms&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;html -&amp;gt; html_utf-8 # html의 바이트가 UTF-8으로 변환되었다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;이름은 얼마나 길어야 하는가?&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;만일 변수가 좁은 scope (예: 끽해야 몇 줄 안의 함수 scope)에서 사용된다면 멤버 변수가 &quot;m&quot;과 같이 매우 짧은 이름을 사용해도 별 문제가 없으나 이 변수의 scope이 클래스나 전역으로 넓어지면 가독성이 매우 떨어지게 되므로 상황에 따라 잘 사용하라고 하는군요.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;게다가 요즘은 긴 이름을 입력하는 것이 자동완성 기능으로 매우 편해져서 그리 주저할 일이 아닙니다. 그렇기 때문에 약어와 축약형은 매우 보편적인 경우(string-&amp;gt; str과 같이)를 제외하고는 지양하는 편이 좋겠습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이에 좀 더 더한다면 ConvertToString()에서 ToString()과 같이 불필요한 단어를 제거해서 간결하게 만드는 등의 팁이 있으나 앞의 내용들이 더 핵심에 가까운 것으로 보입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이로써 이름에 정보를 넣는 방법에 대해 요약해보았습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;책에서 다음 장은 의미를 오해하기 쉬운 이름들에 대한 팁입니다만 사실 오늘 소개한 내용에 어느 정도 포함되는 것 같습니다. 다음 글에서는 미학(Aesthetics) 즉 &quot;눈을 편하게&quot; 하는 코드에 대해 정리하겠습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/6213532524610182574/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-2.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6213532524610182574'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6213532524610182574'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-2.html' title='[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  2. 이름에 정보 담기'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-643283542644223785</id><published>2018-09-02T12:32:00.000+09:00</published><updated>2018-09-02T12:34:46.558+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 71. Categorical Reparameterization with Gumbel Softmax</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#71. Categorical Reparameterization with Gumbel Softmax&lt;/h2&gt;&lt;br /&gt;이 리뷰에서는 NIPS 2016 workshop에 같이 발표되었고 최근 ICLR 2017에 발표된 두 편의 논문을 리뷰하겠습니다. 재미있는 점은 이 두 편의 논문들이 똑같은 아이디어를 바탕으로 정확히 같은 수식을 사용하여 arXiv에도 고작 하루 차이로 올라왔다는 것입니다. 아이디어가 공중에 떠다닌다는 말이 정말 맞는가 싶습니다. 즐겁게 들어주시면 감사하겠습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ty3SciyoIyk&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;(추신) 24분 부분에 질문 주신 부분에 대해 답이 미진한것 같아 끝나고 곰곰히 생각해본 답글을 여기에 추가합니다.&amp;nbsp; 둘 다 categorical dist를 만드는데 다른 방법을 사용할 뿐이라는것이 맞는 답인것 같습니다. 우리가 nn으로부터 샘플링을 하고 싶으면 logit을 받아서 softmax를 통과시켜서 확률값을 얻어서 이를 바탕으로 분포에 값을 넣어주고 그 분포로부터 샘플을 뽑는 방법이 있겠구요 (이 방법이 준범님이 말씀하신 보통의 방식인 것 같습니다. 결국 마지막 단에서 softmax하여 확률 값을 주니까요) 다만 샘플링을 하지 않고 확률값 자체를 라벨과 빼서 에러를 계산하는데 사용되는 것이라 백프롭에서는 문제가 없는것 같습니다. 자기자신으로 1이니까 그렇다고 생각하는데 혹 이상하면 말씀주세요. 그리고 두번째 방법이 logit에 검벨에서 뽑은 노이즈를 더하여 argmax를 통과시켜서 값을 얻으면 그 자체가 discrete categorical dist에서 나온 샘플입니다. 여기서 argmax를 softmax로 relaxation한 것이 gumbel softmax trick이구요 그래서 이렇게 복잡하게 과정을 거친 이유는 말씀드린 바와 같이 미분이 가능하게 해서 중간에 node가 껴있을때 gradient를 계산하기 위해서인 것으로 이해하면 되지 않을까 싶습니다.﻿&lt;br /&gt;&lt;br /&gt;&lt;b&gt;(paper1)&lt;/b&gt; Categorical Reparameterization with Gumbel Softmax and&lt;br /&gt;&lt;b&gt;(paper2)&lt;/b&gt; The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables&lt;br /&gt;&lt;br /&gt;Paper1: &lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;https://arxiv.org/abs/1611.01144&lt;/a&gt;&lt;br /&gt;Paper2: &lt;a href=&quot;https://arxiv.org/abs/1611.00712&quot;&gt;https://arxiv.org/abs/1611.00712&lt;/a&gt;&lt;br /&gt;슬라이드: &lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-categorical-reparameterization-with-gumbel-softmax&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-categorical-reparameterization-with-gumbel-softmax&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/643283542644223785/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/pr12-video-71-gumbel-softmax.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/643283542644223785'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/643283542644223785'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/pr12-video-71-gumbel-softmax.html' title='[PR12-Video] 71. Categorical Reparameterization with Gumbel Softmax'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/ty3SciyoIyk/default.jpg" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-868743091536295491</id><published>2018-09-01T18:40:00.001+09:00</published><updated>2018-09-02T14:56:38.765+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="개발"/><title type='text'>[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  Intro. 코드는 이해하기가 쉬워야 한다. </title><content type='html'>많은 분들이 그러실텐데 저 역시도 항상 좋은 코드란 어떤 것인지 알고 싶었습니다. 이런 고민을 듣고 최근 회사 동료인 전상혁님이 &quot;The Art of Readable Code&quot;라는 책을 추천해주시기에 책을 도서관에서 빌려 읽고 있는데 정말 많이 배우고 있습니다. 책의 내용이 좋아서 한 권 사서 두고두고 읽으려 합니다.&lt;br /&gt;&lt;br /&gt;이런 내용들을 코드에 직접 적용하면서 체득하는 것이 가장 좋겠지만 당장 단기간에 이뤄질 수 있는 일은 아니기에, 일단은 좋은 내용들이 머리에 좀 더 오래 남기를 바라며 책 내용을 정리해서 올리고자 합니다.&lt;br /&gt;&lt;br /&gt;나중에 이 글을 찾은 분 혹은 미래의 나 스스로에게 초심자의 입장에서 어떤 점들이 도움이 되었는지를 보여줄 수 있을거라 기대합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;이 책은 무엇에 대한 것인가?&lt;/h2&gt;&lt;br /&gt;이 책은 매우 읽기 편한 코드를 작성하는 방법을 설명하는데요. C++, 파이썬, 자바스크립트, 자바 등을 포함한 다양한 언어로 작성된 코드를 예로 들며 설명해줍니다. 중간중간 껴있는 삽화들도 매우 재치있고 각 장의 주제와 연관되어 있어 이해를 도와줍니다.&lt;br /&gt;&lt;br /&gt;재밌는 점은 언어들을 다 알지 못하더라도 책을 읽는 데는 별 어려움이 없다는 것입니다.&lt;br /&gt;저자들이 얘기하기론 &quot;코드의 가독성&quot;이라는 개념 자체가 언어로부터 독립적이기 때문이라고 하지만 제가 보기엔 여기서 저자들의 내공이 드러나는 것이 아닌가 싶습니다.&lt;br /&gt;&lt;br /&gt;크게 아래와 같이 4부로 나누어&lt;br /&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;표면적인 수준에서의 개선&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;루프와 로직를 단순화하기&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;코드를 재작성하기&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;선택된 주제들&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;div&gt;여러 측면에서 코드를 이해하기 쉽게 만드는 방법을 설명해줍니다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;가독성의 기본 정리&lt;/h2&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;b&gt;&quot;코드는 다른 사람이 그것을 이해하는 데 들이는 시간을 최소화하는 방식으로 작성되어야 한다.&quot;&lt;/b&gt;&lt;/blockquote&gt;&lt;br /&gt;분량이 적다고 항상 좋은 것이 아닙니다. 좋은 예로 주석도 사실은 &quot;코드를 더하는 행위&quot;지만 코드를 더 빨리 이해하게 도와줍니다. 적은 분량으로 코드를 작성하는 것이 좋은 목표긴 하지만, 이해를 위한 시간을 최소화하는 것이 더 좋은 목표입니다.&lt;br /&gt;&lt;br /&gt;또 다른 예로,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;return exponent &amp;gt;=0 ? mantissa * (1 &amp;lt;&amp;lt;exponent) : mantissa / (1 &amp;lt;&amp;lt; -exponent);&lt;/div&gt;&lt;br /&gt;라는 코드보다는&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;if (exponent &amp;gt;=0) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; return mantissa * (1 &amp;lt;&amp;lt; exponent);&lt;br /&gt;} else {&lt;br /&gt;&amp;nbsp; &amp;nbsp; return mantissa / (1 &amp;lt;&amp;lt; -exponent);&lt;br /&gt;}&lt;/div&gt;&lt;br /&gt;이렇게 바꾼 코드가 앞서보다 간결하진 않지만 더 이해하기 쉽습니다.&lt;br /&gt;&lt;br /&gt;이해를 위한 시간은 코드의 효율성, 아키텍처, 테스트의 용이성과 같은 다른 목표와 충돌할까봐 걱정할 수도 있으나, 저자들의 경험에 따르면 대다수의 경우 이러한 조건은 거의 아무런 방해가 되지 않다고 합니다.&lt;br /&gt;&lt;br /&gt;가장 기본적인 대원칙은 코드를 &quot;읽기 쉽게&quot; 만드는 원리가 적용될 때마다 의심의 여지가 생기면 언제나 가독성의 기본 정리가 다른 어떤 규칙보다 앞선다는 점입니다.&lt;br /&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;h3&gt;&lt;b&gt;&quot;이 코드는 이해하기 쉬운가?&quot;&lt;/b&gt;&lt;/h3&gt;&lt;/blockquote&gt;&lt;br /&gt;만일 정리가 되지 않을 코드를 고치고 싶을 때는 먼저 뒤로 한 걸음 물러나서 스스로에게 물어보는 것이 중요합니다: &quot;이 코드는 이해하기 쉬운가?&quot;. 만약 그렇다면 다른 코드로 건너뛰어도 별 상관이 없습니다.</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/868743091536295491/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-intro.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/868743091536295491'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/868743091536295491'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-intro.html' title='[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  Intro. 코드는 이해하기가 쉬워야 한다. '/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-649523289300133464</id><published>2018-08-04T18:02:00.000+09:00</published><updated>2018-09-02T15:04:31.122+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>What is the relationship between orthogonal, correlation and independence?</title><content type='html'>제게는 마주칠 때마다 헷갈려서 다시 고민하게 되는 개념들이 있는데, 그 중 대표적인 것이 바로 이 세 가지 녀석들입니다:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;h3&gt;&lt;b&gt;Orthogonality, Correlation, Independence.&lt;/b&gt;&lt;/h3&gt;&lt;/blockquote&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;오늘도 다시 한 번 마주칠 일이 있어서 또 하루종일 공부하는 우매한 짓을 저지른 후, 다시는 이러지 않도록(....이러고선 또 언젠가 다시 이 포스트를 보고 공부하겠지...뻔해...) 정리를 해보고자 합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Independence&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&quot;Independence&quot;&lt;/b&gt;는 통계적인 개념입니다. 두 random variables X와 Y의 joint distribution이 marginal distribution의 곱으로 표현이 될 때 statistically independent하다고 말한다. 각 variable의 density를 $f$라고 하면:&lt;/div&gt;&lt;div&gt;$$f(x,y) = f(x)f(y),$$&lt;/div&gt;&lt;div&gt;좀 더 일반적으로는 cumulative distribution function을 $F$라고 할 때,&amp;nbsp;&lt;/div&gt;&lt;div&gt;$$F(x,y) = F(x)F(y)$$&lt;/div&gt;&lt;div&gt;라고 표현할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Correlation&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&quot;Correlation&quot;&lt;/b&gt;은 independence와 관련이 있으나 좀 더 약한 통계적 개념으로 두 random variables 간 (Pearson) correlation은 정규화된(standardized) variables의 곱의 기대값을 말합니다:&lt;/div&gt;&lt;div&gt;$$\begin{align*}\rho_{XY} &amp;amp;= \mathbf{E}\left[\frac{X-\mathbf{E}[X]}{\sqrt{\mathbf{E}[(X-\mathbf{E}[X])^2]}}\frac{Y-\mathbf{E}[Y]}{\sqrt{\mathbf{E}[(Y-\mathbf{E}[Y])^2]}}\right]\\&lt;br /&gt;&amp;amp;= \frac{cov(X,Y)}{\sigma_X\sigma_Y}.\end{align*}$$&lt;br /&gt;이 때, $\rho_{XY}=0$는 variables X와 Y가 서로&lt;i&gt; uncorrelated&lt;/i&gt; 되어있다는 말입니다. 한 가지 유의할 점은 두 random variables가 independent하면 항상 uncorrelated이지만 그 역은 성립하지 않는다는 점입니다. (순방향은 정의에 맞게 식을 전개해보면 되고, 역은 counter example을 들어 쉽게 증명할 수 있습니다.)&lt;br /&gt;&lt;br /&gt;순방향에 대한 식 전개:&lt;br /&gt;&lt;div class=&quot;proof&quot;&gt;$$\begin{align*}\mathbf{E}[XY]&amp;amp;=\int\int xyP_{X,Y}(x,y)dxdy \\&lt;br /&gt;&amp;amp; = \int\int xyP_X(x)P_Y(y)dxdy\\&lt;br /&gt;&amp;amp;=\mathbf{E}[X]\mathbf{E}[Y] \end{align*}$$&lt;br /&gt;역방향에 대한 counter examples:&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/303798&quot;&gt;https://stats.stackexchange.com/a/303798&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;여기서 한 가지 헷갈리는 부분이 나오는데요. 지금까지 얘기한 independence는 statistical independence인데 이게 linear independence랑 서로 관련이 있으면서도 다르다는 것입니다. Linear dependent한 경우 statistically dependent 입니다. 이는 $\alpha X = Y$를 만족하는 non-zero scalar $\alpha$가 있을 때,&lt;br /&gt;$$cov(X,Y)=cov(\frac{1}{\alpha}Y,Y) = \frac{1}{\alpha}Var(Y) \neq 0 $$&lt;br /&gt;인 것으로 확인할 수 있습니다. 그러나&amp;nbsp; X와 Y가 linear independent할지라도 $\rho_{XY}\neq 0$일 수 있기 떄문에 linear independence가 statistical independence를 보장해주지는 않죠.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Orthogonality&lt;/h2&gt;&lt;br /&gt;&lt;b&gt;&quot;Orthogonality&quot;&lt;/b&gt;는 기하에서 온 개념으로 선형 대수학에서 일반적인 정의를 배울 수 있습니다.&amp;nbsp; 선형대수학에서 정의하는 것을 보면, 두 벡터 $u$ 와 $v$가 서로 orthogonal하다는 것은 두 벡터 간의 내적 $&amp;lt;u,v&amp;gt;$이 정의된 내적 공간(inner product spaces)에서 다음 조건을 만족한다는 것입니다:&lt;br /&gt;$$&amp;lt;u,v&amp;gt;=0.$$&lt;br /&gt;즉, 어떤 벡터 간의 orthogonality는 정의한 내적에 따라 달라지기 때문에 주의해야 합니다.&lt;br /&gt;&lt;br /&gt;내적은 여러 방식으로 정의될 수 있는데, 한 예로 벡터들이 다음과 같이 수열로 나타내질 때는 우리가 흔히 아는 dot product를 골라서 사용할 수 있겠습니다:&lt;br /&gt;$$u=(u_1,u_2,\cdots,u_n), &amp;lt;u,v&amp;gt;=\sum_{i=1}^{n}u_i v_j.$$&lt;br /&gt;앞서 설명을 유심히 봤으면 알겠지만 orthogonality는 본질적으로 통계적인 개념이 아닙니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Orthogonality&lt;/b&gt;는 본질적으로 &lt;b&gt;통계적인 개념이 아니다!&lt;/b&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br /&gt;그래서 우리가 헷갈리는 이유가 보통 선형대수학에서의 개념을 통계로 가져오면서 생기는 것에서 기인하는 경우가 많습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;A)&lt;/h3&gt;&lt;br /&gt;형식상 random variables의 공간은 vector space로 생각할 수 있습니다. 그러면 당연히 그 공간에서 내적을 다양한 방식으로 정의할 수도 있을텐데, 그 중 &lt;a href=&quot;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&quot; target=&quot;_blank&quot;&gt;한 가지 방식&lt;/a&gt;이 바로 covariance를 내적으로 사용하는 것입니다:&lt;br /&gt;$$&amp;lt;X,Y&amp;gt; = cov(X,Y) = \mathbf{E}(X-\mathbf{E}[X])\mathbf{E}(Y-\mathbf{E}[Y]).$$&lt;br /&gt;두 random variables간 correlation이 0이면 covariance도 0이기 때문에, &lt;i&gt;이 정의에 의해서&lt;/i&gt;&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Uncorrelated_random_variables&quot; target=&quot;_blank&quot;&gt;($\mathbf{E}[X]$나 $\mathbf{E}[Y]$ 중 하나가 0인 경우) uncorrelatedness가 orthogonality와 정확히 같아집니다.&lt;/a&gt; 따라서 두 random variables가&amp;nbsp;&lt;b&gt;independent하면&amp;nbsp;&lt;/b&gt;&lt;b&gt;(그리고 둘 중 하나는 zero-centered일 때)&amp;nbsp;&lt;/b&gt;&lt;b&gt;서로 uncorrelated이며&lt;/b&gt; &lt;b&gt;orthogonal 하다&lt;/b&gt;고 얘기할 수 있습니다.&amp;nbsp;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&quot; target=&quot;_blank&quot;&gt;다른 방식&lt;/a&gt;으로는 $\mathbf{E}[XY]$으로도 내적을 정의할 수도 있습니다 (결국 같은 얘기).&lt;br /&gt;&lt;br /&gt;다만, 앞서 얘기한 바와 같이 그 역은 항상 성립하지는 않는데요. 즉, 두 random variable이 orthogonal하다고 해서 independent하지는 않습니다. 이 부분에서 헷갈리는 것이 &quot;음? 직교하는데 independent하지 않는 경우가 어떤게 있지?&quot; 하는 생각이 바로 들게 되죠.&lt;br /&gt;&lt;br /&gt;이 부분이 매우 어색하고 이상하다고 여겨지는 이유는 random variable을 어느 순간 fixed variable과 dot product를 가지고 노는 선형 벡터 쪽 영역으로 은근슬쩍 넘어가서 생각하기 때문입니다. 여기서의 직교는 내적을 covariance로 정의하였을 때를 기준으로 얘기하기 때문에 우리가 흔히 생각하던 fixed variable vectors 둘을 골라서 dot product한 기준으로 얘기하면 안 됩니다. 즉, 정의대로 orthogonal = uncorrelated인 경우만을 생각하면 uncorrelated이나 dependent인 경우는 쉽게 받아들일 수 있습니다.&lt;br /&gt;&lt;br /&gt;예를 들어 $X$가 $\{-1,0,1\}$ 중 하나의 값을 동일한 확률로 뽑는 random variable일 때 $Y=X^2$에 대해 $\rho_{XY}=0$이지만 dependent임을 쉽게 알 수 있습니다. 사실 $X$가 0을 기준으로 symmetric pdf를 가지면 그 모든 예시에 대해 $X$와 $Y$는 서로 (covariance-wise) orthogonal하지만 dependent합니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;B)&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;그러나 &lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/156554#156554&quot; target=&quot;_blank&quot;&gt;통계에서 다루는 모든 variables가 random variables는 아니라는 점&lt;/a&gt;에 주의해야 합니다. 특히, 선형 회귀 문제를 생각해보면 거기서 사용하는 입력값과 같은 독립 변수(independent variables)들은 random이 아니라 이미 &quot;정해진&quot; 값들입니다. Independent variables는 보통 수열로 주어지고 위에서 얘기한 바와 같이 자연스럽게 dot product를 내적으로 사용할 수 있겠습니다. 이 때, independent variables가 regression line에 대해 orthogonal인지 아닌지 등을 얘기하는데 이런 맥락에서 보면 애시당초 orthogonality는 statistical definition도 갖지 않고 random variable에 적용되는 얘기도 아니죠. (ANOVA에서의 &lt;a href=&quot;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&quot; target=&quot;_blank&quot;&gt;orthogonal contrasts&lt;/a&gt; 등)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;정리해보자면 A)에서는 uncorrelatedness와 orthogonality는 사실 같은 것에 대한 다른 이름일뿐입니다. 따라서 가장 좋은 것은 random variable에 대해 uncorrelatedness를 말할 때는 orthogonality라는 용어를 사용하지 않는 것입니다. 그리고 같은 논지로 B)의 맥락에서는 non-random variable에 대해 correlation이라는 용어를 사용하는 것을 지양하는 것이 좋겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;더 읽어볼 것...&lt;/h2&gt;&lt;br /&gt;아래 reference로 달아둔 링크 중 &lt;a href=&quot;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&quot; target=&quot;_blank&quot;&gt;&quot;Linearly Independent, Orthogonal, and Uncorrelated Variables&quot;&lt;/a&gt;라는 제목의 레포트가 있습니다. Non-random variable에 대해 내적으로 dot product를 사용하여&amp;nbsp;지금까지 본문에서 바라본 statistical 관점이 아니라 대수적 혹은 기하적 관점에서 바라본 논문 형태의 레포트인데요. 내용을 매우 잘 설명한 좋은(짧은) 논문이지만, 이 경우 내적이 dot product로 달라졌으므로, &lt;b&gt;orthogonality와 uncorrelatedness가 같지 않으며&lt;/b&gt; 자칫하면 지금까지 간신히 잡아둔 개념들이 더 헷갈릴 수 있습니다. 따라서 분명한 차이가 있다는 것을 염두에 두고 봐야 합니다.&lt;br /&gt;&lt;br /&gt;* 그리고 위 레포트에서는 non-random variable에 대해서도 correlation의 개념을 사용합니다. 엄밀히 말하자면 이는 지금까지가 우리가 얘기했던 population에 대한 correlation coefficient가 아닌 &lt;a href=&quot;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#For_a_sample&quot; target=&quot;_blank&quot;&gt;sample correlation coefficient일 때 성립합니다.&lt;/a&gt;&amp;nbsp;앞서는 random variable이 표본 공간(sample space)에 대해 정의된 함수이며, 이 때 함수(random variables)들에 대한 내적을 얘기한 것이었다면, 위 레포트에서는 fixed or predefined variable 즉, sample에 대한 얘기이므로 분명히 다릅니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;References&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/171347&quot;&gt;https://stats.stackexchange.com/a/171347&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://math.stackexchange.com/questions/917313/the-difference-between-statistically-independent-and-linearly-independent&quot;&gt;https://math.stackexchange.com/questions/917313/the-difference-between-statistically-independent-and-linearly-independent&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/129600/linear-independence-vs-statistical-independence-pca-and-ica&quot;&gt;https://stats.stackexchange.com/questions/129600/linear-independence-vs-statistical-independence-pca-and-ica&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&quot;&gt;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products&quot;&gt;https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/29172#29172&quot;&gt;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/29172#29172&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&quot;&gt;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/303798&quot;&gt;https://stats.stackexchange.com/a/303798&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&quot;&gt;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&quot;&gt;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/649523289300133464/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/08/what-is-relationship-between-orthogonal.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/649523289300133464'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/649523289300133464'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/08/what-is-relationship-between-orthogonal.html' title='What is the relationship between orthogonal, correlation and independence?'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-7046349279022556648</id><published>2018-05-09T15:08:00.001+09:00</published><updated>2018-06-04T10:27:02.126+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] Spectral Normalization for Generative Adversarial Networks</title><content type='html'>&lt;h2&gt;Spectral Normalization for Generative Adversarial Networks&lt;/h2&gt;&lt;h2&gt;&lt;div&gt;&lt;span style=&quot;font-size: small;&quot;&gt;TL;DR: A novel weight normalization technique called spectral normalization to stabilize the training of the discriminator of GANs.&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Keywords: Generative Adversarial Networks, Deep Generative Models, Unsupervised Learning&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Accept: (Oral)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Rating: 8-8-8&lt;/span&gt;&lt;br /&gt;&lt;b style=&quot;font-size: medium;&quot;&gt;Review:&lt;/b&gt;&lt;span style=&quot;font-size: small; font-weight: 400;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://openreview.net/forum?id=B1QRgziT-&quot; style=&quot;font-size: medium; font-weight: 400;&quot;&gt;https://openreview.net/forum?id=B1QRgziT-&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;1. Introduction&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium;&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Preferred network 그룹에서 나온 논문. (최근 핫한 일본 그룹) 그리고 Ian Goodfellow의 홍보 (보증?...) 개인적으로 매우 취향인 논문. &lt;/span&gt;(이후 더 자세히 리뷰 예정)&lt;span style=&quot;font-weight: 400;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;div style=&quot;font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-weight: 400;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s1600/SNGAN2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s1600/SNGAN2.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;GANs를 안정적으로 학습시키는 것을 새로운 weight normalization으로 해결해보고자 함. Spectral normalization이라 불리는 이 방법은,&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;/div&gt;&lt;ul style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;li&gt;Intensive hyper parameter이 필요없음. Lipshitz&amp;nbsp;constant가 유일한&amp;nbsp;hyperparameter&amp;nbsp;to be tuned. (심지어는 tuning 안 해도 잘 됨)&lt;/li&gt;&lt;li&gt;Implementation이 단순하고 computational cost가 적음.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;Batch normalization이나 weight decay, feature matching on the discriminator와 같은 regularization tech.가 없이도 working 잘 함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;2. Spectral Normalization&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;각 레이어의 spectral norm을 제약함으로써 Discriminator function $f$의 Lipschitz constant를 컨트롤 함.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;ReLU와 같은 activation function의 Lipschitz norm은 1이기 때문에 네트워크 전체를 볼 때 고려하지 않아도 되고, 결국 Weight의 Lipschitz norm을 나눠줌으로써 각 weight matrix $W$의 Lipschitz constant $\sigma(W)=1$:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;$$\bar{W}_{SN}(W):=W/\sigma(W).$$&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;이를 바탕으로 $||f||_{Lip}$가 1로 상계를 갖도록(upper bounded) 함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h3&gt;Gradient Analysis of the Spectrally&amp;nbsp;Normalized Weights&lt;/h3&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;The gradient of $\bar{W}_{SN}(W)$ w.r.t. $W_{ij}$:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;\begin{align} \frac{\partial\bar{W}_{SN}(W)}{\partial W_{ij}}&amp;nbsp; &amp;amp;= \frac{1}{\sigma(W)}E_{ij} - \frac{1}{\sigma(W)^2}\frac{\partial \sigma(W)}{\partial W_{ij}}W \\&amp;amp;= \frac{1}{\sigma(W)}E_{ij} - \frac{[u_1v_1^T]_{ij}}{\sigma(W)^2}W \\&amp;amp;= \frac{1}{\sigma(W)} (E_{ij} - [u_1v_1^T]_{ij}\bar{W}_{SN}) \end{align}&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;여기서 $E_{ij}$는 $(i,j)$-th entry는 1 나머지는 0인 행렬이고 $u_1$과 $v_1$이 first left and right singular vecotrs of $W$. $h$를 hidden layer라고 하면 아래가 성립함:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;\begin{align}\frac{\partial V(G,D)}{\partial W}&amp;amp;=\frac{1}{\sigma(W)}(\hat{E}[\delta h^T]-(\hat{E}[\delta^T\bar{W}_{SN}h])u_1v_1^T)\\&lt;br /&gt;&amp;amp;= \frac{1}{\sigma(W)}(\hat{E}[\delta h^T]-\lambda u_1v_1^T) \end{align}&lt;br /&gt;여기서 $\delta:=(\partial V(G,D)/ \partial(\bar{W}_{SN}h))^T, \lambda:=\hat{E}[\delta^T(\bar{W}_{SN}h)]$이고 $\hat{E}[\cdot]$은 각 미니 배치의 empirical expectiation을 나타냄.&lt;br /&gt;For some $k\in \mathbb{R}$, $\hat{E}[\delta h^T]=ku_1v_1^T$일 때 $\frac{\partial V}{\partial W}=0$이 성립함.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;여기서 식 (5)의 해석이 매우 재미있는데, 식의 첫번째 항은 normalize되지 않은 weights에 대한 미분이므로 별다를 것이 없고 두번째 항이 추가된 것으로 생각해보면, 이를&amp;nbsp;adaptive regularization coefficient $\lambda$만큼 첫번째 singular component를 penalize하는 regularization 항으로 본다면 다음과 같은 해석이 가능함:&lt;br /&gt;&lt;br /&gt;$\lambda$가 양수라는 얘기는 $\delta$와 $\bar{W}_{SN}h$가 비슷한 방향을 가르키고 있다는 것을 의미함. 즉, $W$의 column space가 한 쪽 방향으로만 집중해서 update되는 것을 막아준다고 해석할 수 있음. 논문에서는 이를 통해 spectral normalization이 네트워크의 각 layer가 한 방향으로만 sensitive하지 않도록 막는다고 얘기함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;3. Spectral Normalization vs Other Regularization Techniques&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;Weight normalization은 결과적으로 너무 강한 constraint를 걸어버리는 경향이 있음. Weight normalization은 weight matrix의 rank를 1이 되도록 강제함 (matrix norm과 weight normalization definition에 의해 수식을 보면 확인할 수 있음).&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;그런데 이렇게 하면 discriminator가 하나의 feature만을 보고 probability distribution을 구별해야하기 때문에 discriminator가 매우 sensitive하고 unstable하게 만드는 경향이 있음.&lt;br /&gt;&lt;br /&gt;Orthonormal regularization on each weight는 spectral normalization과 유사하면서도 학습을 안정화해주기는 하지만,&lt;br /&gt;$$||W^TW-I||_F^2$$&lt;br /&gt;weights를 orthonormal하게 하므로써 (모든 singular value를 1로 강제하기 때문에) spectrum의 envelop을 망치고 중요한 정보를 잃어버리는 경향이 있음. Spectral normalization은 spectrum의 scale만을 조절하기 때문에 (최대 값을 1) 이와는 다름.&lt;br /&gt;&lt;br /&gt;GP와 같은 경우는 위에서 설명한 다른 normalization tech.들과 같은 문제는 없지만 현재 generative distribution의 support에 매우 강하게 엮여있다는 약점이 있음. 이 때문에 학습이 진행됨에 따라 generative distribution의 support도 바뀌기 때문에 학습 과정이 불안정적이 된다는 단점이 생김. Spectral normalization은 학습하는 함수를 operator space에서 regularize하기 때문에 들어오는 데이터 batch에 보다 덜 민감한 것을 볼 수 있음.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;4. Experiments&lt;/h2&gt;&lt;br /&gt;최초로 단일 네트워크로 이미지넷 1000개 범주의 이미지를 생성한 방법인 것만으로도 큰 의미를 지님.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-1y_O1cz9f3I/WvKP5QfVk6I/AAAAAAAACuE/1xkIn4De4uEwXE3sO87cle_Fy7iMNX_XACK4BGAYYCw/s1600/SNGAN1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-1y_O1cz9f3I/WvKP5QfVk6I/AAAAAAAACuE/1xkIn4De4uEwXE3sO87cle_Fy7iMNX_XACK4BGAYYCw/s1600/SNGAN1.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;/div&gt;&lt;/h2&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/7046349279022556648/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-spectral-normalization-for-gan.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7046349279022556648'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7046349279022556648'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-spectral-normalization-for-gan.html' title='[Paper Skim] Spectral Normalization for Generative Adversarial Networks'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s72-c/SNGAN2.png" height="72" width="72"/><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1857320262473439791</id><published>2018-05-01T08:09:00.001+09:00</published><updated>2018-05-01T10:07:50.973+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] AmbientGAN: Generative Models From Lossy Measurements</title><content type='html'>&lt;h2 style=&quot;height: 0px;&quot;&gt;AmbientGAN: Generative Models From Lossy Measurements&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;b&gt;TL;DR:&lt;/b&gt;&amp;nbsp;How to learn GANs from noisy, distorted, partial observations&lt;/div&gt;&lt;div&gt;&lt;b&gt;Keywords:&lt;/b&gt; Generative models, Adversarial networks, Lossy measurements&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;b&gt;Accept: (Oral)&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Rating: 8-7-7&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Review:&amp;nbsp;&lt;/b&gt;&lt;a href=&quot;https://openreview.net/forum?id=Hy7fDog0b&quot;&gt;https://openreview.net/forum?id=Hy7fDog0b&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;GAN을 학습시키기 위해서 고퀄리티 샘플들이 필요한데 (예시: 노이즈가 없는 사진들) 보통 그런 경우가 많지 않다는 것을 지적하고 이를 해결하고자 한 논문.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;즉, 샘플에 occlusion이나 noise, blur 등의 문제가 있는 데이터셋만으로도 원래와 같이 고퀄리티 샘플(occulusion noise blur 혹은 unknown any noise가 없는)을 생성할 수 있는 Generative model을 학습하고자 함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;직관적인 이해를 위해 결과부터 좀 소개하자면:&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s1600/ambiGAN1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s1600/ambiGAN1.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이렇게 맨 왼쪽과 같이 patch가 잘려서 zero가 되는 noise function으로 더럽혀진 데이터셋만 있는 경우에도 generator가 맨 오른쪽과 같이 어느정도 얼굴 형태를 생성해내는 모델을 학습함. (중간은 baseline)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;개인적으로 재미있었던 실험은 MNIST 데이터를 패딩을 바탕으로 크기를 키운 다음 임의의 각도로 회전하고 한쪽 방향으로 sum 된 1D 데이터로 squash한 데이터들을 바탕으로 학습을 해도 generator가 아래와 같이 어느정도 숫자를 generate하는 모델을 학습해내는 것.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-p3IGxbiiXws/WuefgK2M7_I/AAAAAAAACso/H5gKiiocpNgDKv34Wx1asYin0VBRYprmgCK4BGAYYCw/s1600/ambiGAN2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-p3IGxbiiXws/WuefgK2M7_I/AAAAAAAACso/H5gKiiocpNgDKv34Wx1asYin0VBRYprmgCK4BGAYYCw/s1600/ambiGAN2.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;추가 정보로 회전각을 넣어주었을 때 더 잘 복원됨. (오른쪽, 사실 이건 의료 영상에서 CT와 같은 projection으로 생각해보면 자명함)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 논문이 재미있는건 이렇게 이미지가 복원이 되는 조건을 명확하게 하고 수학적으로 증명을 하였다는 점.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-JBN_Xjc92P4/WuefJ6O2JFI/AAAAAAAACsY/GBcsxRb6tb0KveFJ_mBT9cqh6lWhnwFvACK4BGAYYCw/s1600/ambiGAN3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-JBN_Xjc92P4/WuefJ6O2JFI/AAAAAAAACsY/GBcsxRb6tb0KveFJ_mBT9cqh6lWhnwFvACK4BGAYYCw/s1600/ambiGAN3.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;네트워크 구조도&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;Generator가 먼저 깨끗한 이미지 $X_g$를 만들면 $f_{\theta}$가 이를 corrupt하는 noise function을 학습해서 $Y_g$를 만들어내고 Discriminator가 corrupt된 real data $Y_r$와 이를 비교하게 하는 구조.&lt;br /&gt;&lt;br /&gt;풀고자 하는 문제를 참 잘 특정해서 잡았다고 생각하는 것이, 우리가 얻을 수 있는 데이터는 실제로는 이미 어떤 unknown noise function에 의해 corrupt 되어 나온 것인 경우가 많다는 것이 기본 바탕.&lt;br /&gt;&lt;br /&gt;AmbientGANs에서는 데이터가 충분히 많기만 하다면, 이런 noise function을 학습하고 기존의 data distribution을 복원하는 것이 가능하다는 것을 analytically &amp;amp; empirically 보임.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이거 보고 나서 결과를 improve해볼 수 있는 idea들이 몇 개 생각나긴 했는데 해보고 싶은것들이 막 생깁니다ㅋㅋ 당장 recon loss와 cyclic loss를 붙여볼 수 있겠네요.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;참고자료&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;(slideshare) &lt;a href=&quot;https://www.slideshare.net/thinkingfactory/introduction-to-ambient-gan&quot;&gt;https://www.slideshare.net/thinkingfactory/introduction-to-ambient-gan&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1857320262473439791/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-ambientgan-generative-models.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1857320262473439791'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1857320262473439791'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-ambientgan-generative-models.html' title='[Paper Skim] AmbientGAN: Generative Models From Lossy Measurements'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s72-c/ambiGAN1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-673973366306707726</id><published>2018-05-01T07:28:00.000+09:00</published><updated>2018-05-01T10:23:16.712+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] Progressive Growing of GANs for Improved Quality, Stability, and Variation</title><content type='html'>&lt;h2&gt;&lt;b&gt;Progressive Growing of GANs for Improved Quality, Stability, and Variation&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;b&gt;TL;DR:&lt;/b&gt;&amp;nbsp;Train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.&lt;/div&gt;&lt;div&gt;&lt;b&gt;Keywords:&lt;/b&gt;&amp;nbsp;generative adversarial networks, unsupervised learning, hierarchical methods&lt;/div&gt;&lt;b&gt;Accept: (Oral)&lt;/b&gt;&lt;br /&gt;&lt;b&gt;Rating: 8-8-8&lt;/b&gt;&lt;br /&gt;&lt;b&gt;Review:&lt;/b&gt;&amp;nbsp;&lt;a href=&quot;https://openreview.net/forum?id=Hk99zCeAb&quot;&gt;https://openreview.net/forum?id=Hk99zCeAb&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;GANs를 학습하는 새로운 방법을 제안.&lt;br /&gt;핵심 아이디어는 generator와 discriminator를 점진적으로 키운다는 것: 저해상도에서 시작해서 세밀한 점들을 배울 수 있도록 새로운 레이어들을 추가하는 방식.&lt;br /&gt;이런 방식을 취함으로 인해 GANs을 보다 안정적이면서 빠르게 학습하는 것이 가능해졌다고 얘기함; CelebA 1024^2 해상도 이미지를 만들어 내는 네트워크 학습.&lt;br /&gt;또한 CIFAR10에서 비지도학습 방식으로 생성된 이미지들의 종류가 다양하도록 할 수 있는 간단한 방법을 제안함. Inception score가 8.80에 달한다고 함.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;1. Introduction&lt;/h2&gt;&lt;br /&gt;고해상도 이미지를 만드는 것은 매우 어려운데 그 이유는 해상도가 높을 수록 생성한 이미지인지를 구분하는 것이 쉬워지기 때문.&lt;br /&gt;게다가 큰 해상도 이미지로 인해 메모리 문제로 더 작은 minibatches를 사용하게되고 학습 안정성에 문제가 됨.&lt;br /&gt;여기서 저자들의 주요 insight는 generator와 discriminator를 점진적(progressively)으로 키우는 것.&lt;br /&gt;&lt;br /&gt;기존의 GAN 수식은 학습된 생성 모델이 굳이 학습 데이터 분포 전체를 모두 표현할 필요가 없었음. (?)&lt;br /&gt;기존의 공통된 의견은 이미지의 질과 다양성이 서로 tradeoff 관계라는 것이었으나 최근 Odena et al. 2017에 의해 다른 의견이 제기됨. (확인 필요)&lt;br /&gt;다양성에 대한 측정 방법에 대해 매우 많은 방식들이 제안되고 있는데:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;including inception score (Salimans et al., 2016), multi-scale structural similarity (MS-SSIM) (Odena et al., 2017; Wang et al., 2003), birthday paradox (Arora &amp;amp; Zhang, 2017), and explicit tests for the number of discrete modes discovered (Metz et al., 2016).&amp;nbsp;&lt;/blockquote&gt;PGGAN에서는 이 외에 다양성을 보다 북돋기 위해 사용한 방법을 설명하고 이미지의 질과 다양성을 측정하기 위한 새로운 metric을 제안하였음.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;2. Progressive Growing of GANs&lt;/h2&gt;&lt;br /&gt;&lt;b&gt;키 아이디어 정리: 단계별 학습 (구몬??!)&lt;/b&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;The complex mapping from latents to high-resolution images is easier to learn in steps&quot;&amp;nbsp;&lt;/blockquote&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s1600/pggan1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s1600/pggan1.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;아래 그림에서 볼 수 있듯이 점진적으로 네트워크 레이어를 추가할 때 sudden shock이 일어나지 않도록 새로 추가하는 레이어를 부드럽게 (fade in) 넣어줌.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-SkNSj3dGOyE/WuSEeMByscI/AAAAAAAACrI/N1MweSP6q-AAtmfTBW6KhKXJ2hQNaIOFgCK4BGAYYCw/s1600/pggan2.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-SkNSj3dGOyE/WuSEeMByscI/AAAAAAAACrI/N1MweSP6q-AAtmfTBW6KhKXJ2hQNaIOFgCK4BGAYYCw/s1600/pggan2.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;3. Increasing Variation using Minibatch Standard Deviation&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이미지가 다양하게 생성되도록 하기 위해 GANs이 학습 데이터의 일부분만 집중하는 성질이 있는 것을 고려하여 Salimans et al. (2016)에서는 Minibatch discrimination 방식을 제안했었음. Feature statistics를 계산할 때 각각의 이미지만 보는 것이 아니라 minibatch 전체에 대해 계산하므로써 생성된 이미지와 학습 이미지들이 비슷한 statistics를 갖도록 하자는게 아이디어였음. (구체적 방식은 다시 &lt;b&gt;체크&lt;/b&gt;) PGGAN에서는 이 접근 방식을 보다 단순하게 만들면서도 다양성은 증대하는 방법을 제안함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 방식은 parameter 학습이 필요하거나 새로운 hyperparameter가 필요하지 않음. 먼저 minibatch에 있는 각 spatial location에서의 feature 각각의 stardard deviation을 계산함. 이 estimates를 모든 features와 spatical locations에 대해 평균을 내고 하나의 값을 계산함. 이 값을 복사해서 모든 spatial locations와 minibatch에 대해 concat하는 방식으로 (constant) feature map을 하나 추가함. 이 레이어는 discriminator의 어느 위치에도 들어갈 수 있으나 inset it towards the end가 가장 좋은 성능을 보였음.&amp;nbsp;&lt;/div&gt;&lt;div&gt;Parallel work으로 Lin et al. (2017)이 이와 유사한 방식(multiple images를 discriminator에 보여주는 것이 좋은 이유)을 이론적으로 설명한 바 있음. (&lt;b&gt;체크&lt;/b&gt;)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;4. Normalization in Generation and Discriminator&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;GANs에서의 normalization은 signal magnitude와 competition을 제한하는 쪽에 주안점을 두어야한다고 생각함.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;4.1 Equalized Learning Rate&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;기존의 방식들이 weight initialization에 심혈을 기울이는 것과는 달리 여기서는 초기값은 대충 표준정규분포로 주되 runtime 중 weights의 scale을 조절하는 방향을 취함.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;4.2 Pixelwise Feature Vector Normalization in Generator&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Generator와 Discriminator가 서로 경쟁한 끝에 발산하는 경우를 막기 위해서 generator에서 하나의 conv layer를 지날때마다 각 pixel의 feature vector를 정규화.&amp;nbsp;&lt;/div&gt;&lt;div&gt;이 방식이 실험 결과는 크게 바꾸지 않았지만 signal magnitude가 급격히 커지는 현상을 매우 효과적으로 없애주었다고 함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;5. Multi-Scale Statistical Similarity for Assesing GAN results&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;서로 다른 GAN을 비교하는 것은 여러모로 쉽지 않음. MS-SSIM(Odena et al., 2017)과 같은 방식은 large-scale mode collapse를 잘 발견하지만 color나 texture의 작은 loss들을 발견하지 못하는 단점들이 알려져있음. 그리고 학습 데이터와의 유사한 정도를 직접적으로 고려하지 않기 때문에 문제가 있음.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;PGGAN에서는 각 scale 별로 학습데이터와 생성 데이터의 local structure가 서로 유사해야한다는 intuition을 바탕으로 local image patches의 분포 간의 multi-scale statistical similarity를 확인하는 방식을 취함(Laplacian pyramid, Burt &amp;amp; Adelson, 1987 다시 &lt;b&gt;체크&lt;/b&gt;).&amp;nbsp;&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;6. Experiments&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&amp;nbsp;판타스틱함!&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-O3xwR2CISPc/WuSKmX4LqHI/AAAAAAAACrY/QAI81FW6WRE9bw0wmyPF5SlvUaHvWd-2QCK4BGAYYCw/s1600/pggan3.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-O3xwR2CISPc/WuSKmX4LqHI/AAAAAAAACrY/QAI81FW6WRE9bw0wmyPF5SlvUaHvWd-2QCK4BGAYYCw/s1600/pggan3.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-Dpvmlxcfe40/WuSLAM1ZuoI/AAAAAAAACrk/zrUNwJnpSmgidOv6z8Ju1BwSxJYzlnXegCK4BGAYYCw/s1600/pggan4.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Dpvmlxcfe40/WuSLAM1ZuoI/AAAAAAAACrk/zrUNwJnpSmgidOv6z8Ju1BwSxJYzlnXegCK4BGAYYCw/s1600/pggan4.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-GZhLarAlXdw/WuSLGDX1gHI/AAAAAAAACrs/hu7ZoogQR7U8jCFwGkuhZMSlY0Tm1cQbwCK4BGAYYCw/s1600/pggan5.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-GZhLarAlXdw/WuSLGDX1gHI/AAAAAAAACrs/hu7ZoogQR7U8jCFwGkuhZMSlY0Tm1cQbwCK4BGAYYCw/s1600/pggan5.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;h2&gt;Stillcut from ICLR oral presentation&amp;nbsp;&lt;/h2&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-uCBmO7Bw9ao/WufAWjb8hCI/AAAAAAAACs4/wMgShNPn238JdxM__H8yhWEqgareoY-mQCK4BGAYYCw/s1600/PGGAN0.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-uCBmO7Bw9ao/WufAWjb8hCI/AAAAAAAACs4/wMgShNPn238JdxM__H8yhWEqgareoY-mQCK4BGAYYCw/s1600/PGGAN0.jpg&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/h2&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;Video presentation&lt;/h2&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;&lt;iframe allowfullscreen=&#39;allowfullscreen&#39; webkitallowfullscreen=&#39;webkitallowfullscreen&#39; mozallowfullscreen=&#39;mozallowfullscreen&#39; width=&#39;530&#39; height=&#39;266&#39; src=&#39;https://www.blogger.com/video.g?token=AD6v5dyK2_LdulAvNVkEBjXmNhC195CMM2mxX2Sv9x1eBeXo4i1yoEvn11y1NSF5Rsn_jLW4aWKauuUM6QBnGtkzIg&#39; class=&#39;b-hbp-video b-uploaded&#39; frameborder=&#39;0&#39; /&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/673973366306707726/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-progressive-growing-of-gans.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/673973366306707726'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/673973366306707726'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-progressive-growing-of-gans.html' title='[Paper Skim] Progressive Growing of GANs for Improved Quality, Stability, and Variation'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s72-c/pggan1.PNG" height="72" width="72"/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-3983669769096239575</id><published>2018-02-24T15:00:00.001+09:00</published><updated>2018-08-04T22:24:05.873+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>Minimizing the Negative Log-Likelihood, in Korean (3)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;color: blue; font-size: small;&quot;&gt;* This is the Korean translation of the original post by &lt;a href=&quot;http://willwolf.io/&quot;&gt;will wolf&lt;/a&gt; under his permission. You can find the English version at his blog: &lt;a href=&quot;http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;span style=&quot;font-size: xx-small;&quot;&gt;저자의 허락을 득하고 번역하여 옮깁니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html&quot;&gt;저번 글&lt;/a&gt;까지 하여 우리는 이제 드디어 parameter의 좋고 나쁨을 정량화할 방법에 대해 얘기해볼 때가 되었습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;h2&gt;Loss function&lt;/h2&gt;&lt;br /&gt;지금까지는 response variable이 어떻게 생성되고 각각의 관찰값에 따라 각 분포에 대한 parameters를 어떻게 계산하는지에 대해 알아보았습니다. 자, 그럼 어떤 parameters가 좋은 것인지 어떻게 정량화할 수 있을까요?&lt;br /&gt;&lt;br /&gt;시작하기에 앞서, 잠시&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;를 예측하는 것을 상기해보겠습니다. 만약 우리가 고양이 그림을 모델에게 넣어준다면 다음의 binomial distribution가 주어졌을 때, $\phi\approx0$이도록 